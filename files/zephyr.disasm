
files/zephyr.elf:     file format elf32-littlearm


Disassembly of section rom_start:

70000000 <_vector_table>:
#include "macro_priv.inc"

_ASM_FILE_PROLOGUE

SECTION_SUBSEC_FUNC(exc_vector_table,_vector_table_section,_vector_table)
	ldr pc, =z_arm_reset             /*                   offset 0 */
70000000:	18 f0 9f e5 18 f0 9f e5 18 f0 9f e5 18 f0 9f e5     ................
	ldr pc, =z_arm_undef_instruction /* undef instruction offset 4 */
	ldr pc, =z_arm_svc               /* svc               offset 8 */
	ldr pc, =z_arm_prefetch_abort    /* prefetch abort offset  0xc */
	ldr pc, =z_arm_data_abort        /* data abort     offset 0x10 */
70000010:	18 f0 9f e5 00 f0 20 e3 14 f0 9f e5 14 f0 9f e5     ...... .........
	ldr pc, =z_arm_reset             /*                   offset 0 */
70000020:	b8 07 00 70 e8 06 00 70 70 09 00 70 2c 07 00 70     ...p...pp..p,..p
	ldr pc, =z_arm_data_abort        /* data abort     offset 0x10 */
70000030:	5c 07 00 70 84 08 00 70 8d 06 00 70                 \..p...p...p

Disassembly of section text:

70000040 <__aeabi_uldivmod>:
70000040:	b953      	cbnz	r3, 70000058 <__aeabi_uldivmod+0x18>
70000042:	b94a      	cbnz	r2, 70000058 <__aeabi_uldivmod+0x18>
70000044:	2900      	cmp	r1, #0
70000046:	bf08      	it	eq
70000048:	2800      	cmpeq	r0, #0
7000004a:	bf1c      	itt	ne
7000004c:	f04f 31ff 	movne.w	r1, #4294967295	; 0xffffffff
70000050:	f04f 30ff 	movne.w	r0, #4294967295	; 0xffffffff
70000054:	f000 b80c 	b.w	70000070 <__aeabi_idiv0>
70000058:	f1ad 0c08 	sub.w	ip, sp, #8
7000005c:	e96d ce04 	strd	ip, lr, [sp, #-16]!
70000060:	f000 f812 	bl	70000088 <__udivmoddi4>
70000064:	f8dd e004 	ldr.w	lr, [sp, #4]
70000068:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
7000006c:	b004      	add	sp, #16
7000006e:	4770      	bx	lr

70000070 <__aeabi_idiv0>:
70000070:	4770      	bx	lr
70000072:	bf00      	nop

70000074 <strcmp>:
70000074:	f810 2b01 	ldrb.w	r2, [r0], #1
70000078:	f811 3b01 	ldrb.w	r3, [r1], #1
7000007c:	2a01      	cmp	r2, #1
7000007e:	bf28      	it	cs
70000080:	429a      	cmpcs	r2, r3
70000082:	d0f7      	beq.n	70000074 <strcmp>
70000084:	1ad0      	subs	r0, r2, r3
70000086:	4770      	bx	lr

70000088 <__udivmoddi4>:
70000088:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
7000008c:	4290      	cmp	r0, r2
7000008e:	460d      	mov	r5, r1
70000090:	9f07      	ldr	r7, [sp, #28]
70000092:	4604      	mov	r4, r0
70000094:	eb75 0103 	sbcs.w	r1, r5, r3
70000098:	d36f      	bcc.n	7000017a <__udivmoddi4+0xf2>
7000009a:	2b00      	cmp	r3, #0
7000009c:	d05f      	beq.n	7000015e <__udivmoddi4+0xd6>
7000009e:	fab3 f683 	clz	r6, r3
700000a2:	2d00      	cmp	r5, #0
700000a4:	d05f      	beq.n	70000166 <__udivmoddi4+0xde>
700000a6:	fab5 f185 	clz	r1, r5
700000aa:	1a76      	subs	r6, r6, r1
700000ac:	f1a6 0020 	sub.w	r0, r6, #32
700000b0:	f1c6 0120 	rsb	r1, r6, #32
700000b4:	40b3      	lsls	r3, r6
700000b6:	f1a6 0c20 	sub.w	ip, r6, #32
700000ba:	fa02 f000 	lsl.w	r0, r2, r0
700000be:	f1c6 0e20 	rsb	lr, r6, #32
700000c2:	fa22 f101 	lsr.w	r1, r2, r1
700000c6:	4303      	orrs	r3, r0
700000c8:	40b2      	lsls	r2, r6
700000ca:	430b      	orrs	r3, r1
700000cc:	4294      	cmp	r4, r2
700000ce:	eb75 0103 	sbcs.w	r1, r5, r3
700000d2:	d34c      	bcc.n	7000016e <__udivmoddi4+0xe6>
700000d4:	2001      	movs	r0, #1
700000d6:	1aa4      	subs	r4, r4, r2
700000d8:	fa00 f10c 	lsl.w	r1, r0, ip
700000dc:	eb65 0503 	sbc.w	r5, r5, r3
700000e0:	fa20 f80e 	lsr.w	r8, r0, lr
700000e4:	ea41 0108 	orr.w	r1, r1, r8
700000e8:	40b0      	lsls	r0, r6
700000ea:	b39e      	cbz	r6, 70000154 <__udivmoddi4+0xcc>
700000ec:	0852      	lsrs	r2, r2, #1
700000ee:	46b0      	mov	r8, r6
700000f0:	ea42 72c3 	orr.w	r2, r2, r3, lsl #31
700000f4:	085b      	lsrs	r3, r3, #1
700000f6:	4294      	cmp	r4, r2
700000f8:	eb75 0903 	sbcs.w	r9, r5, r3
700000fc:	d33a      	bcc.n	70000174 <__udivmoddi4+0xec>
700000fe:	1aa4      	subs	r4, r4, r2
70000100:	eb65 0503 	sbc.w	r5, r5, r3
70000104:	1924      	adds	r4, r4, r4
70000106:	416d      	adcs	r5, r5
70000108:	3401      	adds	r4, #1
7000010a:	f145 0500 	adc.w	r5, r5, #0
7000010e:	f1b8 0801 	subs.w	r8, r8, #1
70000112:	d1f0      	bne.n	700000f6 <__udivmoddi4+0x6e>
70000114:	1900      	adds	r0, r0, r4
70000116:	fa05 fe0e 	lsl.w	lr, r5, lr
7000011a:	fa24 f406 	lsr.w	r4, r4, r6
7000011e:	eb41 0105 	adc.w	r1, r1, r5
70000122:	fa25 fc0c 	lsr.w	ip, r5, ip
70000126:	ea44 040e 	orr.w	r4, r4, lr
7000012a:	ea44 040c 	orr.w	r4, r4, ip
7000012e:	40f5      	lsrs	r5, r6
70000130:	f1a6 0c20 	sub.w	ip, r6, #32
70000134:	f1c6 0220 	rsb	r2, r6, #32
70000138:	fa05 f306 	lsl.w	r3, r5, r6
7000013c:	fa04 fc0c 	lsl.w	ip, r4, ip
70000140:	ea43 030c 	orr.w	r3, r3, ip
70000144:	fa24 f202 	lsr.w	r2, r4, r2
70000148:	fa04 f606 	lsl.w	r6, r4, r6
7000014c:	4313      	orrs	r3, r2
7000014e:	1b80      	subs	r0, r0, r6
70000150:	eb61 0103 	sbc.w	r1, r1, r3
70000154:	b10f      	cbz	r7, 7000015a <__udivmoddi4+0xd2>
70000156:	e9c7 4500 	strd	r4, r5, [r7]
7000015a:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
7000015e:	fab2 f682 	clz	r6, r2
70000162:	3620      	adds	r6, #32
70000164:	e79d      	b.n	700000a2 <__udivmoddi4+0x1a>
70000166:	fab4 f184 	clz	r1, r4
7000016a:	3120      	adds	r1, #32
7000016c:	e79d      	b.n	700000aa <__udivmoddi4+0x22>
7000016e:	2000      	movs	r0, #0
70000170:	4601      	mov	r1, r0
70000172:	e7ba      	b.n	700000ea <__udivmoddi4+0x62>
70000174:	1924      	adds	r4, r4, r4
70000176:	416d      	adcs	r5, r5
70000178:	e7c9      	b.n	7000010e <__udivmoddi4+0x86>
7000017a:	2000      	movs	r0, #0
7000017c:	4601      	mov	r1, r0
7000017e:	e7e9      	b.n	70000154 <__udivmoddi4+0xcc>

70000180 <tm_thread_locking_test_initialize>:
void tm_thread_locking_reporting_thread(void* p1, void* p2, void* p3);
void tm_thread_locking_test_initialize(void);

/* Initialization function */
void tm_thread_locking_test_initialize(void)
{
70000180:	b570      	push	{r4, r5, r6, lr}
   int i;
   tm_setup_pmu();
70000182:	f000 f945 	bl	70000410 <tm_setup_pmu>

   /* Precompute PMU names for each iteration to avoid runtime formatting overhead */
   for (i = 0; i < ITERATION_COUNT; i++)
70000186:	4d10      	ldr	r5, [pc, #64]	; (700001c8 <tm_thread_locking_test_initialize+0x48>)
70000188:	2400      	movs	r4, #0
   {
      snprintf(pmu_lock_numbers[i], sizeof(pmu_lock_numbers[i]), "L%02d", i);
7000018a:	4e10      	ldr	r6, [pc, #64]	; (700001cc <tm_thread_locking_test_initialize+0x4c>)
7000018c:	4623      	mov	r3, r4
7000018e:	4628      	mov	r0, r5
70000190:	4632      	mov	r2, r6
70000192:	2110      	movs	r1, #16
   for (i = 0; i < ITERATION_COUNT; i++)
70000194:	3401      	adds	r4, #1
      snprintf(pmu_lock_numbers[i], sizeof(pmu_lock_numbers[i]), "L%02d", i);
70000196:	f001 fe67 	bl	70001e68 <snprintf>
   for (i = 0; i < ITERATION_COUNT; i++)
7000019a:	2c20      	cmp	r4, #32
7000019c:	f105 0510 	add.w	r5, r5, #16
700001a0:	d1f4      	bne.n	7000018c <tm_thread_locking_test_initialize+0xc>
   }

   /* Create the benchmark thread that drives the locking test */
   tm_thread_create(0, 5, tm_thread_locking_benchmark_thread);
700001a2:	4a0b      	ldr	r2, [pc, #44]	; (700001d0 <tm_thread_locking_test_initialize+0x50>)
700001a4:	2105      	movs	r1, #5
700001a6:	2000      	movs	r0, #0
700001a8:	f000 f8d8 	bl	7000035c <tm_thread_create>
   tm_thread_resume(0);
700001ac:	2000      	movs	r0, #0
700001ae:	f000 f901 	bl	700003b4 <tm_thread_resume>

   /* Create a reporting thread to output benchmark results */
   tm_thread_create(1, 1, tm_thread_locking_reporting_thread);
700001b2:	4a08      	ldr	r2, [pc, #32]	; (700001d4 <tm_thread_locking_test_initialize+0x54>)
700001b4:	2101      	movs	r1, #1
700001b6:	4608      	mov	r0, r1
700001b8:	f000 f8d0 	bl	7000035c <tm_thread_create>
   tm_thread_resume(1);
}
700001bc:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
   tm_thread_resume(1);
700001c0:	2001      	movs	r0, #1
700001c2:	f000 b8f7 	b.w	700003b4 <tm_thread_resume>
700001c6:	bf00      	nop
700001c8:	70005f4c 	.word	0x70005f4c
700001cc:	700041b0 	.word	0x700041b0
700001d0:	700001d9 	.word	0x700001d9
700001d4:	70000225 	.word	0x70000225

700001d8 <tm_thread_locking_benchmark_thread>:

/* Benchmark thread that tests thread locking */
void tm_thread_locking_benchmark_thread(void* p1, void* p2, void* p3)
{
700001d8:	b538      	push	{r3, r4, r5, lr}
   (void) p2;
   (void) p3;

   while (1)
   {
      if (thread_locking_counter < ITERATION_COUNT)
700001da:	4c10      	ldr	r4, [pc, #64]	; (7000021c <tm_thread_locking_benchmark_thread+0x44>)
      {
         tm_pmu_profile_start(pmu_lock_numbers[thread_locking_counter]);
700001dc:	4d10      	ldr	r5, [pc, #64]	; (70000220 <tm_thread_locking_benchmark_thread+0x48>)
      if (thread_locking_counter < ITERATION_COUNT)
700001de:	6823      	ldr	r3, [r4, #0]
700001e0:	2b1f      	cmp	r3, #31
700001e2:	d804      	bhi.n	700001ee <tm_thread_locking_benchmark_thread+0x16>
         tm_pmu_profile_start(pmu_lock_numbers[thread_locking_counter]);
700001e4:	6820      	ldr	r0, [r4, #0]
700001e6:	eb05 1000 	add.w	r0, r5, r0, lsl #4
700001ea:	f000 f95b 	bl	700004a4 <tm_pmu_profile_start>
      }

      /* Lock the thread by stopping the scheduler */
      tm_suspend_scheduler();
700001ee:	f002 f8ee 	bl	700023ce <tm_suspend_scheduler>
      thread_locking_counter++;
700001f2:	6823      	ldr	r3, [r4, #0]
700001f4:	3301      	adds	r3, #1
700001f6:	6023      	str	r3, [r4, #0]
700001f8:	f44f 737a 	mov.w	r3, #1000	; 0x3e8
      /* busy work loop to have some blocked time*/
      for (int i = 0; i < 1000; i++)
      {
         __asm__ volatile("nop");
700001fc:	bf00      	nop
      for (int i = 0; i < 1000; i++)
700001fe:	3b01      	subs	r3, #1
70000200:	d1fc      	bne.n	700001fc <tm_thread_locking_benchmark_thread+0x24>
      }
      /* Unlock the thread by restarting the scheduler */
      tm_resume_scheduler();
70000202:	f002 f8e6 	bl	700023d2 <tm_resume_scheduler>

      if (thread_locking_counter < ITERATION_COUNT + 1)
70000206:	6823      	ldr	r3, [r4, #0]
70000208:	2b20      	cmp	r3, #32
7000020a:	d8e8      	bhi.n	700001de <tm_thread_locking_benchmark_thread+0x6>
      {
         tm_pmu_profile_end(pmu_lock_numbers[thread_locking_counter - 1]);
7000020c:	6820      	ldr	r0, [r4, #0]
7000020e:	3801      	subs	r0, #1
70000210:	eb05 1000 	add.w	r0, r5, r0, lsl #4
70000214:	f000 f97a 	bl	7000050c <tm_pmu_profile_end>
70000218:	e7e1      	b.n	700001de <tm_thread_locking_benchmark_thread+0x6>
7000021a:	bf00      	nop
7000021c:	70004b18 	.word	0x70004b18
70000220:	70005f4c 	.word	0x70005f4c

70000224 <tm_thread_locking_reporting_thread>:
   }
}

/* Reporting thread to display PMU measurements and counter progress */
void tm_thread_locking_reporting_thread(void* p1, void* p2, void* p3)
{
70000224:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}

   while (1)
   {
      tm_thread_sleep(TM_TEST_DURATION);
      relative_time += TM_TEST_DURATION;
      printf("**** Thread Locking Benchmark **** Relative Time: %lu\r\n", relative_time);
70000228:	f8df 8048 	ldr.w	r8, [pc, #72]	; 70000274 <tm_thread_locking_reporting_thread+0x50>
   unsigned long relative_time = 0;
7000022c:	2500      	movs	r5, #0

      if (thread_locking_counter == last_counter)
7000022e:	4e12      	ldr	r6, [pc, #72]	; (70000278 <tm_thread_locking_reporting_thread+0x54>)
   unsigned long last_counter = 0;
70000230:	462c      	mov	r4, r5
      tm_thread_sleep(TM_TEST_DURATION);
70000232:	201e      	movs	r0, #30
      relative_time += TM_TEST_DURATION;
70000234:	351e      	adds	r5, #30
      tm_thread_sleep(TM_TEST_DURATION);
70000236:	f002 f8c2 	bl	700023be <tm_thread_sleep>
      printf("**** Thread Locking Benchmark **** Relative Time: %lu\r\n", relative_time);
7000023a:	4629      	mov	r1, r5
7000023c:	4640      	mov	r0, r8
7000023e:	f002 f935 	bl	700024ac <printk>
      if (thread_locking_counter == last_counter)
70000242:	6833      	ldr	r3, [r6, #0]
70000244:	42a3      	cmp	r3, r4
70000246:	d10e      	bne.n	70000266 <tm_thread_locking_reporting_thread+0x42>
      {
         printf("ERROR: No progress in thread locking counter!\r\n");
70000248:	480c      	ldr	r0, [pc, #48]	; (7000027c <tm_thread_locking_reporting_thread+0x58>)
7000024a:	f002 f92f 	bl	700024ac <printk>
      {
         printf("Locking Operations in Period: %lu\r\n", thread_locking_counter - last_counter);
      }

      /* Print PMU profile results on the first reporting interval */
      if (last_counter == 0)
7000024e:	b944      	cbnz	r4, 70000262 <tm_thread_locking_reporting_thread+0x3e>
70000250:	4f0b      	ldr	r7, [pc, #44]	; (70000280 <tm_thread_locking_reporting_thread+0x5c>)
      {
         for (int i = 0; i < ITERATION_COUNT; i++)
         {
            tm_pmu_profile_print(pmu_lock_numbers[i]);
70000252:	4638      	mov	r0, r7
         for (int i = 0; i < ITERATION_COUNT; i++)
70000254:	3401      	adds	r4, #1
            tm_pmu_profile_print(pmu_lock_numbers[i]);
70000256:	f000 f991 	bl	7000057c <tm_pmu_profile_print>
         for (int i = 0; i < ITERATION_COUNT; i++)
7000025a:	2c20      	cmp	r4, #32
7000025c:	f107 0710 	add.w	r7, r7, #16
70000260:	d1f7      	bne.n	70000252 <tm_thread_locking_reporting_thread+0x2e>
         }
      }
      last_counter = thread_locking_counter;
70000262:	6834      	ldr	r4, [r6, #0]
      tm_thread_sleep(TM_TEST_DURATION);
70000264:	e7e5      	b.n	70000232 <tm_thread_locking_reporting_thread+0xe>
         printf("Locking Operations in Period: %lu\r\n", thread_locking_counter - last_counter);
70000266:	6831      	ldr	r1, [r6, #0]
70000268:	4806      	ldr	r0, [pc, #24]	; (70000284 <tm_thread_locking_reporting_thread+0x60>)
7000026a:	1b09      	subs	r1, r1, r4
7000026c:	f002 f91e 	bl	700024ac <printk>
70000270:	e7ed      	b.n	7000024e <tm_thread_locking_reporting_thread+0x2a>
70000272:	bf00      	nop
70000274:	700041b6 	.word	0x700041b6
70000278:	70004b18 	.word	0x70004b18
7000027c:	700041ee 	.word	0x700041ee
70000280:	70005f4c 	.word	0x70005f4c
70000284:	7000421e 	.word	0x7000421e

70000288 <main_thread_locking_test>:
}

/* Main entry point for the thread locking test */
int main_thread_locking_test(void)
{
   tm_initialize(tm_thread_locking_test_initialize);
70000288:	4802      	ldr	r0, [pc, #8]	; (70000294 <main_thread_locking_test+0xc>)
{
7000028a:	b508      	push	{r3, lr}
   tm_initialize(tm_thread_locking_test_initialize);
7000028c:	f002 f896 	bl	700023bc <tm_initialize>
   return 0;
}
70000290:	2000      	movs	r0, #0
70000292:	bd08      	pop	{r3, pc}
70000294:	70000181 	.word	0x70000181

70000298 <tm_interrupt_handler>:
void* test_interrupt_handler = NULL;

/* Define the interrupt handler */
void tm_interrupt_handler(void* args)
{
   if (test_interrupt_handler != NULL)
70000298:	4b02      	ldr	r3, [pc, #8]	; (700002a4 <tm_interrupt_handler+0xc>)
7000029a:	681b      	ldr	r3, [r3, #0]
7000029c:	b103      	cbz	r3, 700002a0 <tm_interrupt_handler+0x8>
   {
      /* Call the assigned handler function */
      ((void (*)(void)) test_interrupt_handler)();
7000029e:	4718      	bx	r3
   }
}
700002a0:	4770      	bx	lr
700002a2:	bf00      	nop
700002a4:	70004b1c 	.word	0x70004b1c

700002a8 <main_task>:
   /* Interrupt aktivieren */
   z_vim_irq_enable(irq);
}

void main_task(void* pvParameters)
{
700002a8:	b508      	push	{r3, lr}
   /* Start Thread-Metric tests */
   printk("Starting Thread-Metric tests...\r\n");
700002aa:	4809      	ldr	r0, [pc, #36]	; (700002d0 <main_task+0x28>)
700002ac:	f002 f8fe 	bl	700024ac <printk>

   /* Initialize custom interrupts*/
   test_interrupt_handler = tm_isr_message_handler;
700002b0:	4b08      	ldr	r3, [pc, #32]	; (700002d4 <main_task+0x2c>)
700002b2:	4a09      	ldr	r2, [pc, #36]	; (700002d8 <main_task+0x30>)
700002b4:	601a      	str	r2, [r3, #0]
   setup_interrupt();
700002b6:	f002 f862 	bl	7000237e <setup_interrupt>

   /* Call the main Thread-Metric function */
   main_thread_locking_test();
700002ba:	f7ff ffe5 	bl	70000288 <main_thread_locking_test>
#ifdef CONFIG_CURRENT_THREAD_USE_TLS

	/* Thread-local cache of current thread ID, set in z_thread_entry() */
	extern Z_THREAD_LOCAL k_tid_t z_tls_current;

	return z_tls_current;
700002be:	4b07      	ldr	r3, [pc, #28]	; (700002dc <main_task+0x34>)
700002c0:	f000 eb20 	blx	70000904 <__aeabi_read_tp>
700002c4:	5818      	ldr	r0, [r3, r0]

   /* Delete thread after completion */
   k_thread_abort(k_current_get());
}
700002c6:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_ABORT);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_abort(thread);
700002ca:	f002 bd89 	b.w	70002de0 <z_impl_k_thread_abort>
700002ce:	bf00      	nop
700002d0:	70004242 	.word	0x70004242
700002d4:	70004b1c 	.word	0x70004b1c
700002d8:	70000305 	.word	0x70000305
700002dc:	00000008 	.word	0x00000008

700002e0 <rtos_main_zephyr>:

/* Thread definition */
K_THREAD_DEFINE(main_thread, 512 /* STACKSIZE */, main_task, NULL, NULL, NULL, MAIN_TASK_PRI, K_USER, -1);

int rtos_main_zephyr(void)
{
700002e0:	b508      	push	{r3, lr}
   printk("Initializing Zephyr system...\r\n");
700002e2:	4805      	ldr	r0, [pc, #20]	; (700002f8 <rtos_main_zephyr+0x18>)
700002e4:	f002 f8e2 	bl	700024ac <printk>
	z_impl_k_wakeup(thread);
700002e8:	4804      	ldr	r0, [pc, #16]	; (700002fc <rtos_main_zephyr+0x1c>)
700002ea:	f001 fa73 	bl	700017d4 <z_impl_k_wakeup>

   /* Create main task */
   k_thread_start(main_thread);

   printk("Main task created and running...\r\n");
700002ee:	4804      	ldr	r0, [pc, #16]	; (70000300 <rtos_main_zephyr+0x20>)
700002f0:	f002 f8dc 	bl	700024ac <printk>

   return 0;
}
700002f4:	2000      	movs	r0, #0
700002f6:	bd08      	pop	{r3, pc}
700002f8:	70004264 	.word	0x70004264
700002fc:	700043d0 	.word	0x700043d0
70000300:	70004284 	.word	0x70004284

70000304 <tm_isr_message_handler>:

/* Minimal ISR: No prints, no dynamic formatting */
void tm_isr_message_handler(void)
{
   int i;
   tm_isr_counter++;
70000304:	4a11      	ldr	r2, [pc, #68]	; (7000034c <tm_isr_message_handler+0x48>)
   message[1] = isr_message_counter;
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
   {
      message[i] = 1000 + (isr_message_counter * 10) + i;
   }
   message[MESSAGE_SIZE - 1] = compute_checksum(message, MESSAGE_SIZE - 1);
70000306:	2103      	movs	r1, #3
{
70000308:	b538      	push	{r3, r4, r5, lr}
   tm_isr_counter++;
7000030a:	6813      	ldr	r3, [r2, #0]
   message[1] = isr_message_counter;
7000030c:	4d10      	ldr	r5, [pc, #64]	; (70000350 <tm_isr_message_handler+0x4c>)
   message[0] = 1;
7000030e:	4c11      	ldr	r4, [pc, #68]	; (70000354 <tm_isr_message_handler+0x50>)
   tm_isr_counter++;
70000310:	3301      	adds	r3, #1
   message[MESSAGE_SIZE - 1] = compute_checksum(message, MESSAGE_SIZE - 1);
70000312:	4620      	mov	r0, r4
   tm_isr_counter++;
70000314:	6013      	str	r3, [r2, #0]
   message[0] = 1;
70000316:	2301      	movs	r3, #1
      message[i] = 1000 + (isr_message_counter * 10) + i;
70000318:	220a      	movs	r2, #10
   message[0] = 1;
7000031a:	6023      	str	r3, [r4, #0]
   message[1] = isr_message_counter;
7000031c:	682b      	ldr	r3, [r5, #0]
7000031e:	6063      	str	r3, [r4, #4]
      message[i] = 1000 + (isr_message_counter * 10) + i;
70000320:	682b      	ldr	r3, [r5, #0]
70000322:	4353      	muls	r3, r2
70000324:	f203 33ea 	addw	r3, r3, #1002	; 0x3ea
70000328:	60a3      	str	r3, [r4, #8]
   message[MESSAGE_SIZE - 1] = compute_checksum(message, MESSAGE_SIZE - 1);
7000032a:	f002 f83b 	bl	700023a4 <compute_checksum>

   /* Measure send latency using a precomputed PMU name */
   tm_pmu_profile_start(pmu_send_names[isr_message_counter]);
7000032e:	4b0a      	ldr	r3, [pc, #40]	; (70000358 <tm_isr_message_handler+0x54>)
   message[MESSAGE_SIZE - 1] = compute_checksum(message, MESSAGE_SIZE - 1);
70000330:	60e0      	str	r0, [r4, #12]
   tm_pmu_profile_start(pmu_send_names[isr_message_counter]);
70000332:	6828      	ldr	r0, [r5, #0]
70000334:	eb03 1000 	add.w	r0, r3, r0, lsl #4
70000338:	f000 f8b4 	bl	700004a4 <tm_pmu_profile_start>
   tm_queue_send_from_isr(0, message);
7000033c:	4621      	mov	r1, r4
7000033e:	2000      	movs	r0, #0
70000340:	f000 f844 	bl	700003cc <tm_queue_send_from_isr>
   // tm_pmu_profile_end(pmu_send_names[isr_message_counter]);

   isr_message_counter++; /* Prepare for next iteration */
70000344:	682b      	ldr	r3, [r5, #0]
70000346:	3301      	adds	r3, #1
70000348:	602b      	str	r3, [r5, #0]
}
7000034a:	bd38      	pop	{r3, r4, r5, pc}
7000034c:	70004b34 	.word	0x70004b34
70000350:	70004b30 	.word	0x70004b30
70000354:	70004b20 	.word	0x70004b20
70000358:	7000614c 	.word	0x7000614c

7000035c <tm_thread_create>:
 * file in the underlying RTOS. Valid priorities range from 1 through 31,
 * where 1 is the highest priority and 31 is the lowest. If successful,
 * the function should return TM_SUCCESS. Otherwise, TM_ERROR should be returned.
 */
int tm_thread_create(int thread_id, int priority, void (*entry_function)(void*, void*, void*))
{
7000035c:	b5f0      	push	{r4, r5, r6, r7, lr}
   k_tid_t tid;

   tid = k_thread_create(&test_thread[thread_id], test_stack[thread_id], TM_TEST_STACK_SIZE, entry_function, NULL, NULL,
7000035e:	4c13      	ldr	r4, [pc, #76]	; (700003ac <tm_thread_create+0x50>)
{
70000360:	4613      	mov	r3, r2
   tid = k_thread_create(&test_thread[thread_id], test_stack[thread_id], TM_TEST_STACK_SIZE, entry_function, NULL, NULL,
70000362:	2278      	movs	r2, #120	; 0x78
{
70000364:	b089      	sub	sp, #36	; 0x24
   tid = k_thread_create(&test_thread[thread_id], test_stack[thread_id], TM_TEST_STACK_SIZE, entry_function, NULL, NULL,
70000366:	fb02 4400 	mla	r4, r2, r0, r4
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
7000036a:	2500      	movs	r5, #0
7000036c:	f04f 36ff 	mov.w	r6, #4294967295	; 0xffffffff
70000370:	f04f 37ff 	mov.w	r7, #4294967295	; 0xffffffff
70000374:	f44f 6280 	mov.w	r2, #1024	; 0x400
70000378:	e9cd 1503 	strd	r1, r5, [sp, #12]
7000037c:	490c      	ldr	r1, [pc, #48]	; (700003b0 <tm_thread_create+0x54>)
7000037e:	e9cd 5501 	strd	r5, r5, [sp, #4]
70000382:	9500      	str	r5, [sp, #0]
70000384:	eb01 2180 	add.w	r1, r1, r0, lsl #10
70000388:	e9cd 6706 	strd	r6, r7, [sp, #24]
7000038c:	4620      	mov	r0, r4
7000038e:	f000 ff45 	bl	7000121c <z_impl_k_thread_create>
70000392:	4605      	mov	r5, r0
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_SUSPEND);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_suspend(thread);
70000394:	4620      	mov	r0, r4
70000396:	f001 f8bb 	bl	70001510 <z_impl_k_thread_suspend>
	z_impl_k_wakeup(thread);
7000039a:	4620      	mov	r0, r4
7000039c:	f001 fa1a 	bl	700017d4 <z_impl_k_wakeup>

   k_thread_suspend(&test_thread[thread_id]);
   k_wakeup(&test_thread[thread_id]);

   return (tid == &test_thread[thread_id]) ? TM_SUCCESS : TM_ERROR;
}
700003a0:	1b60      	subs	r0, r4, r5
700003a2:	bf18      	it	ne
700003a4:	2001      	movne	r0, #1
700003a6:	b009      	add	sp, #36	; 0x24
700003a8:	bdf0      	pop	{r4, r5, r6, r7, pc}
700003aa:	bf00      	nop
700003ac:	70004448 	.word	0x70004448
700003b0:	70006550 	.word	0x70006550

700003b4 <tm_thread_resume>:
/*
 * This function resumes the specified thread.  If successful, the function should
 * return TM_SUCCESS. Otherwise, TM_ERROR should be returned.
 */
int tm_thread_resume(int thread_id)
{
700003b4:	b508      	push	{r3, lr}
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_RESUME);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_resume(thread);
700003b6:	4b04      	ldr	r3, [pc, #16]	; (700003c8 <tm_thread_resume+0x14>)
700003b8:	2278      	movs	r2, #120	; 0x78
700003ba:	fb02 3000 	mla	r0, r2, r0, r3
700003be:	f001 f91f 	bl	70001600 <z_impl_k_thread_resume>
   k_thread_resume(&test_thread[thread_id]);

   return TM_SUCCESS;
}
700003c2:	2000      	movs	r0, #0
700003c4:	bd08      	pop	{r3, pc}
700003c6:	bf00      	nop
700003c8:	70004448 	.word	0x70004448

700003cc <tm_queue_send_from_isr>:

/* This function sends a message to the specified queue from an ISR.  If successful,
   the function should return TM_SUCCESS. Otherwise, TM_ERROR should be returned.  */
__attribute__((noinline))
int tm_queue_send_from_isr(int queue_id, unsigned long* message_ptr)
{
700003cc:	b430      	push	{r4, r5}
		union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm2 = { .val = timeout };
		return (int) arch_syscall_invoke4(parm0.x, parm1.x, parm2.split.lo, parm2.split.hi, K_SYSCALL_K_MSGQ_PUT);
	}
#endif
	compiler_barrier();
	return z_impl_k_msgq_put(msgq, data, timeout);
700003ce:	4c05      	ldr	r4, [pc, #20]	; (700003e4 <tm_queue_send_from_isr+0x18>)
700003d0:	2530      	movs	r5, #48	; 0x30
700003d2:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
700003d6:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
700003da:	fb05 4000 	mla	r0, r5, r0, r4
   return k_msgq_put(&test_msgq[queue_id], message_ptr, K_FOREVER);
}
700003de:	bc30      	pop	{r4, r5}
700003e0:	f000 be5c 	b.w	7000109c <z_impl_k_msgq_put>
700003e4:	70005e44 	.word	0x70005e44

700003e8 <pmu_init_profile>:

/* --------------------------------------------------------------------------
 * Init for the Chache Hits/Misses profile structure
 * -------------------------------------------------------------------------- */
void pmu_init_profile(void)
{
700003e8:	b508      	push	{r3, lr}
   memset(&gProfileObject, 0, sizeof(gProfileObject));
700003ea:	4b08      	ldr	r3, [pc, #32]	; (7000040c <pmu_init_profile+0x24>)
700003ec:	f241 320c 	movw	r2, #4876	; 0x130c
700003f0:	4618      	mov	r0, r3
700003f2:	2100      	movs	r1, #0
700003f4:	f002 fdbb 	bl	70002f6e <memset>
   gProfileObject.logIndex = 0;
   gProfileObject.numEvents = PMU_MAX_EVENT_COUNTERS;
700003f8:	2203      	movs	r2, #3
700003fa:	f500 5380 	add.w	r3, r0, #4096	; 0x1000
700003fe:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
   gProfileObject.bCycleCounter = 1; /* We use cycle counter */
70000402:	2201      	movs	r2, #1
70000404:	f883 2308 	strb.w	r2, [r3, #776]	; 0x308
}
70000408:	bd08      	pop	{r3, pc}
7000040a:	bf00      	nop
7000040c:	70004b38 	.word	0x70004b38

70000410 <tm_setup_pmu>:
{
70000410:	b510      	push	{r4, lr}
   printk("Initializing PMU...\r\n");
70000412:	4820      	ldr	r0, [pc, #128]	; (70000494 <tm_setup_pmu+0x84>)
70000414:	f002 f84a 	bl	700024ac <printk>

/* Performance Monitor Control Register (PMCR) */
__STATIC_FORCEINLINE uint32_t pmu_read_pmcr(void)
{
    uint32_t val;
    __asm__ volatile ("mrc p15, 0, %0, c9, c12, 0" : "=r" (val));
70000418:	ee19 3f1c 	mrc	15, 0, r3, cr9, cr12, {0}
   pmcr &= ~0x1;
7000041c:	f023 0301 	bic.w	r3, r3, #1
    return val;
}

__STATIC_FORCEINLINE void pmu_write_pmcr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
70000420:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}
}

/* Performance Monitor Count Enable Clear Register (PMCNTENCLR) */
__STATIC_FORCEINLINE void pmu_write_cntenclr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 2" : : "r" (val));
70000424:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
70000428:	ee09 3f5c 	mcr	15, 0, r3, cr9, cr12, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
7000042c:	2306      	movs	r3, #6
7000042e:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}
    return val;
}

__STATIC_FORCEINLINE void pmu_write_pmccntr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 0" : : "r" (val));
70000432:	2400      	movs	r4, #0
70000434:	ee09 4f1d 	mcr	15, 0, r4, cr9, cr13, {0}
}

/* Event Counter Selection Register (PMSELR) */
__STATIC_FORCEINLINE void pmu_select_event_counter(uint32_t counter_idx)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
70000438:	ee09 4fbc 	mcr	15, 0, r4, cr9, cr12, {5}
      pmu_write_evtyper(gPmuConfig.eventCounters[i].type);
7000043c:	4b16      	ldr	r3, [pc, #88]	; (70000498 <tm_setup_pmu+0x88>)
}

/* Event Type Register (PMXEVTYPER) */
__STATIC_FORCEINLINE void pmu_write_evtyper(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
7000043e:	685a      	ldr	r2, [r3, #4]
70000440:	ee09 2f3d 	mcr	15, 0, r2, cr9, cr13, {1}
    return val;
}

__STATIC_FORCEINLINE void pmu_write_evcounter(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
70000444:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
70000448:	2201      	movs	r2, #1
7000044a:	ee09 2fbc 	mcr	15, 0, r2, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
7000044e:	68da      	ldr	r2, [r3, #12]
70000450:	ee09 2f3d 	mcr	15, 0, r2, cr9, cr13, {1}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
70000454:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
70000458:	2202      	movs	r2, #2
7000045a:	ee09 2fbc 	mcr	15, 0, r2, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
7000045e:	695b      	ldr	r3, [r3, #20]
70000460:	ee09 3f3d 	mcr	15, 0, r3, cr9, cr13, {1}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
70000464:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 1" : : "r" (val));
70000468:	4b0c      	ldr	r3, [pc, #48]	; (7000049c <tm_setup_pmu+0x8c>)
7000046a:	ee09 3f3c 	mcr	15, 0, r3, cr9, cr12, {1}
    __asm__ volatile ("mrc p15, 0, %0, c9, c12, 0" : "=r" (val));
7000046e:	ee19 3f1c 	mrc	15, 0, r3, cr9, cr12, {0}
   pmcr |= 0x1;
70000472:	f043 0301 	orr.w	r3, r3, #1
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
70000476:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}

/* PMU User Access Enable Register (PMUSERENR) */
__STATIC_FORCEINLINE void pmu_enable_user_access(void)
{
    uint32_t val;
    __asm__ volatile ("mrc p15, 0, %0, c9, c14, 0" : "=r" (val));
7000047a:	ee19 3f1e 	mrc	15, 0, r3, cr9, cr14, {0}
    val |= 1;  // Enable user mode access
7000047e:	f043 0301 	orr.w	r3, r3, #1
    __asm__ volatile ("mcr p15, 0, %0, c9, c14, 0" : : "r" (val));
70000482:	ee09 3f1e 	mcr	15, 0, r3, cr9, cr14, {0}
   pmu_init_profile();
70000486:	f7ff ffaf 	bl	700003e8 <pmu_init_profile>
   printk("PMU Initialized.\r\n");
7000048a:	4805      	ldr	r0, [pc, #20]	; (700004a0 <tm_setup_pmu+0x90>)
7000048c:	f002 f80e 	bl	700024ac <printk>
}
70000490:	4620      	mov	r0, r4
70000492:	bd10      	pop	{r4, pc}
70000494:	700042b3 	.word	0x700042b3
70000498:	7000a750 	.word	0x7000a750
7000049c:	80000007 	.word	0x80000007
700004a0:	700042c9 	.word	0x700042c9

700004a4 <tm_pmu_profile_start>:
 * - Read "start" values
 * - Store them in the next free slot
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_start(const char* name)
{
   uint32_t idx = gProfileObject.logIndex;
700004a4:	4a17      	ldr	r2, [pc, #92]	; (70000504 <tm_pmu_profile_start+0x60>)
{
700004a6:	b5f0      	push	{r4, r5, r6, r7, lr}
   uint32_t idx = gProfileObject.logIndex;
700004a8:	6815      	ldr	r5, [r2, #0]
   if (idx >= PMU_MAX_LOG_ENTRIES)
700004aa:	2d3f      	cmp	r5, #63	; 0x3f
700004ac:	d818      	bhi.n	700004e0 <tm_pmu_profile_start+0x3c>
      /* no more space */
      return;
   }

   TM_PMUProfilePoint* p = &gProfileObject.point[idx];
   p->name = name;
700004ae:	4c16      	ldr	r4, [pc, #88]	; (70000508 <tm_pmu_profile_start+0x64>)
700004b0:	234c      	movs	r3, #76	; 0x4c
700004b2:	436b      	muls	r3, r5
700004b4:	18d1      	adds	r1, r2, r3
700004b6:	3334      	adds	r3, #52	; 0x34
700004b8:	6048      	str	r0, [r1, #4]

   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700004ba:	f502 5080 	add.w	r0, r2, #4096	; 0x1000
700004be:	4413      	add	r3, r2
700004c0:	f8d0 6304 	ldr.w	r6, [r0, #772]	; 0x304
700004c4:	2000      	movs	r0, #0
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
700004c6:	4684      	mov	ip, r0
700004c8:	4286      	cmp	r6, r0
700004ca:	f104 0408 	add.w	r4, r4, #8
700004ce:	f101 010c 	add.w	r1, r1, #12
700004d2:	d106      	bne.n	700004e2 <tm_pmu_profile_start+0x3e>
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 0" : "=r" (val));
700004d4:	ee19 3f1d 	mrc	15, 0, r3, cr9, cr13, {0}
      /* Also store name & type */
      p->events[i].name = gPmuEventCfg[i].name;
      p->events[i].type = gPmuEventCfg[i].type;
   }
   /* Immediately read them as "start" values */
   p->cycleCountStart = pmu_read_pmccntr();
700004d8:	214c      	movs	r1, #76	; 0x4c
700004da:	fb01 2205 	mla	r2, r1, r5, r2
700004de:	6093      	str	r3, [r2, #8]
}
700004e0:	bdf0      	pop	{r4, r5, r6, r7, pc}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
700004e2:	ee09 0fbc 	mcr	15, 0, r0, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
700004e6:	ee09 cf5d 	mcr	15, 0, ip, cr9, cr13, {2}
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 2" : "=r" (val));
700004ea:	ee19 7f5d 	mrc	15, 0, r7, cr9, cr13, {2}
      p->eventStart[i] = pmu_read_evcounter();
700004ee:	f843 7f04 	str.w	r7, [r3, #4]!
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700004f2:	3001      	adds	r0, #1
      p->events[i].name = gPmuEventCfg[i].name;
700004f4:	f854 7c08 	ldr.w	r7, [r4, #-8]
700004f8:	608f      	str	r7, [r1, #8]
      p->events[i].type = gPmuEventCfg[i].type;
700004fa:	f854 7c04 	ldr.w	r7, [r4, #-4]
700004fe:	60cf      	str	r7, [r1, #12]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000500:	e7e2      	b.n	700004c8 <tm_pmu_profile_start+0x24>
70000502:	bf00      	nop
70000504:	70004b38 	.word	0x70004b38
70000508:	7000a750 	.word	0x7000a750

7000050c <tm_pmu_profile_end>:
 * - Compute delta
 * - Increase log index
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_end(const char* name)
{
   uint32_t idx = gProfileObject.logIndex;
7000050c:	4a1a      	ldr	r2, [pc, #104]	; (70000578 <tm_pmu_profile_end+0x6c>)
{
7000050e:	b5f0      	push	{r4, r5, r6, r7, lr}
   uint32_t idx = gProfileObject.logIndex;
70000510:	6811      	ldr	r1, [r2, #0]
   if (idx >= PMU_MAX_LOG_ENTRIES)
70000512:	293f      	cmp	r1, #63	; 0x3f
70000514:	d820      	bhi.n	70000558 <tm_pmu_profile_end+0x4c>
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 0" : "=r" (val));
70000516:	ee19 5f1d 	mrc	15, 0, r5, cr9, cr13, {0}
   //    /* mismatch => error or skip */
   //    return;
   // }

   /* Read end counters */
   p->cycleCountEnd = pmu_read_pmccntr();
7000051a:	234c      	movs	r3, #76	; 0x4c
7000051c:	434b      	muls	r3, r1
7000051e:	18d0      	adds	r0, r2, r3
70000520:	f103 0440 	add.w	r4, r3, #64	; 0x40
70000524:	60c5      	str	r5, [r0, #12]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000526:	f502 5080 	add.w	r0, r2, #4096	; 0x1000
7000052a:	4414      	add	r4, r2
7000052c:	f8d0 6304 	ldr.w	r6, [r0, #772]	; 0x304
70000530:	2000      	movs	r0, #0
70000532:	4286      	cmp	r6, r0
70000534:	d111      	bne.n	7000055a <tm_pmu_profile_end+0x4e>
      pmu_select_event_counter(i);
      p->eventEnd[i] = pmu_read_evcounter();
   }

   /* Compute deltas */
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
70000536:	244c      	movs	r4, #76	; 0x4c
70000538:	fb04 2401 	mla	r4, r4, r1, r2
7000053c:	68a6      	ldr	r6, [r4, #8]
7000053e:	1bad      	subs	r5, r5, r6
70000540:	6125      	str	r5, [r4, #16]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000542:	f103 0434 	add.w	r4, r3, #52	; 0x34
70000546:	2500      	movs	r5, #0
70000548:	4414      	add	r4, r2
7000054a:	4413      	add	r3, r2
7000054c:	42a8      	cmp	r0, r5
7000054e:	f103 030c 	add.w	r3, r3, #12
70000552:	d10a      	bne.n	7000056a <tm_pmu_profile_end+0x5e>
      uint32_t diff = p->eventEnd[i] - p->eventStart[i];
      p->events[i].value = diff;
   }

   /* Move to next log slot for future profileStart() */
   gProfileObject.logIndex++;
70000554:	3101      	adds	r1, #1
70000556:	6011      	str	r1, [r2, #0]
}
70000558:	bdf0      	pop	{r4, r5, r6, r7, pc}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
7000055a:	ee09 0fbc 	mcr	15, 0, r0, cr9, cr12, {5}
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 2" : "=r" (val));
7000055e:	ee19 7f5d 	mrc	15, 0, r7, cr9, cr13, {2}
      p->eventEnd[i] = pmu_read_evcounter();
70000562:	f844 7f04 	str.w	r7, [r4, #4]!
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000566:	3001      	adds	r0, #1
70000568:	e7e3      	b.n	70000532 <tm_pmu_profile_end+0x26>
      uint32_t diff = p->eventEnd[i] - p->eventStart[i];
7000056a:	6926      	ldr	r6, [r4, #16]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
7000056c:	3501      	adds	r5, #1
      uint32_t diff = p->eventEnd[i] - p->eventStart[i];
7000056e:	f854 7f04 	ldr.w	r7, [r4, #4]!
70000572:	1bf6      	subs	r6, r6, r7
      p->events[i].value = diff;
70000574:	611e      	str	r6, [r3, #16]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000576:	e7e9      	b.n	7000054c <tm_pmu_profile_end+0x40>
70000578:	70004b38 	.word	0x70004b38

7000057c <tm_pmu_profile_print>:
 * tm_pmu_profile_print_entry(name)
 * - Search for an entry with the given name
 * - Print results
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_print(const char* name)
{
7000057c:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
70000580:	4e1c      	ldr	r6, [pc, #112]	; (700005f4 <tm_pmu_profile_print+0x78>)
{
70000582:	4607      	mov	r7, r0
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
70000584:	2400      	movs	r4, #0
70000586:	46b2      	mov	sl, r6
70000588:	f8d6 9000 	ldr.w	r9, [r6]
7000058c:	45a1      	cmp	r9, r4
7000058e:	d105      	bne.n	7000059c <tm_pmu_profile_print+0x20>
         }
         printk("\r\n");
         return;
      }
   }
   printk("No profile entry found for name: %s\r\n", name);
70000590:	4819      	ldr	r0, [pc, #100]	; (700005f8 <tm_pmu_profile_print+0x7c>)
70000592:	4639      	mov	r1, r7
}
70000594:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   printk("No profile entry found for name: %s\r\n", name);
70000598:	f001 bf88 	b.w	700024ac <printk>
      if (p->name != NULL && strcmp(p->name, name) == 0)
7000059c:	f8d6 8004 	ldr.w	r8, [r6, #4]
700005a0:	f1b8 0f00 	cmp.w	r8, #0
700005a4:	d023      	beq.n	700005ee <tm_pmu_profile_print+0x72>
700005a6:	4639      	mov	r1, r7
700005a8:	4640      	mov	r0, r8
700005aa:	f7ff fd63 	bl	70000074 <strcmp>
700005ae:	4605      	mov	r5, r0
700005b0:	b9e8      	cbnz	r0, 700005ee <tm_pmu_profile_print+0x72>
         printk("Profile Entry: %s\r\n", p->name);
700005b2:	4812      	ldr	r0, [pc, #72]	; (700005fc <tm_pmu_profile_print+0x80>)
700005b4:	4641      	mov	r1, r8
700005b6:	f001 ff79 	bl	700024ac <printk>
         printk("Cycle Count: %u\r\n", p->cycleCountValue);
700005ba:	4811      	ldr	r0, [pc, #68]	; (70000600 <tm_pmu_profile_print+0x84>)
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
700005bc:	4e11      	ldr	r6, [pc, #68]	; (70000604 <tm_pmu_profile_print+0x88>)
         printk("Cycle Count: %u\r\n", p->cycleCountValue);
700005be:	234c      	movs	r3, #76	; 0x4c
            printk("%s Count: %u\r\n", p->events[j].name, p->events[j].value);
700005c0:	4f11      	ldr	r7, [pc, #68]	; (70000608 <tm_pmu_profile_print+0x8c>)
         printk("Cycle Count: %u\r\n", p->cycleCountValue);
700005c2:	fb03 a404 	mla	r4, r3, r4, sl
700005c6:	6921      	ldr	r1, [r4, #16]
700005c8:	f001 ff70 	bl	700024ac <printk>
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
700005cc:	f8d6 3304 	ldr.w	r3, [r6, #772]	; 0x304
700005d0:	340c      	adds	r4, #12
700005d2:	42ab      	cmp	r3, r5
700005d4:	d804      	bhi.n	700005e0 <tm_pmu_profile_print+0x64>
}
700005d6:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
         printk("\r\n");
700005da:	480c      	ldr	r0, [pc, #48]	; (7000060c <tm_pmu_profile_print+0x90>)
700005dc:	f001 bf66 	b.w	700024ac <printk>
            printk("%s Count: %u\r\n", p->events[j].name, p->events[j].value);
700005e0:	6922      	ldr	r2, [r4, #16]
700005e2:	4638      	mov	r0, r7
700005e4:	68a1      	ldr	r1, [r4, #8]
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
700005e6:	3501      	adds	r5, #1
            printk("%s Count: %u\r\n", p->events[j].name, p->events[j].value);
700005e8:	f001 ff60 	bl	700024ac <printk>
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
700005ec:	e7ee      	b.n	700005cc <tm_pmu_profile_print+0x50>
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
700005ee:	3401      	adds	r4, #1
700005f0:	364c      	adds	r6, #76	; 0x4c
700005f2:	e7cb      	b.n	7000058c <tm_pmu_profile_print+0x10>
700005f4:	70004b38 	.word	0x70004b38
700005f8:	70004311 	.word	0x70004311
700005fc:	700042dc 	.word	0x700042dc
70000600:	700042f0 	.word	0x700042f0
70000604:	70005b38 	.word	0x70005b38
70000608:	70004302 	.word	0x70004302
7000060c:	7000421b 	.word	0x7000421b

70000610 <char_out>:
}

static int char_out(int c, void *ctx_p)
{
	ARG_UNUSED(ctx_p);
	return _char_out(c);
70000610:	4b01      	ldr	r3, [pc, #4]	; (70000618 <char_out+0x8>)
70000612:	681b      	ldr	r3, [r3, #0]
70000614:	4718      	bx	r3
70000616:	bf00      	nop
70000618:	7000a768 	.word	0x7000a768

7000061c <__printk_hook_install>:
	_char_out = fn;
7000061c:	4b01      	ldr	r3, [pc, #4]	; (70000624 <__printk_hook_install+0x8>)
7000061e:	6018      	str	r0, [r3, #0]
}
70000620:	4770      	bx	lr
70000622:	bf00      	nop
70000624:	7000a768 	.word	0x7000a768

70000628 <vprintk>:
}

void vprintk(const char *fmt, va_list ap)
{
70000628:	b530      	push	{r4, r5, lr}
#ifdef CONFIG_PRINTK_SYNC
		k_spinlock_key_t key = k_spin_lock(&lock);
#endif

#ifdef CONFIG_PICOLIBC
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
7000062a:	2210      	movs	r2, #16
{
7000062c:	b085      	sub	sp, #20
7000062e:	4604      	mov	r4, r0
70000630:	460d      	mov	r5, r1
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000632:	4668      	mov	r0, sp
70000634:	2100      	movs	r1, #0
70000636:	f002 fc9a 	bl	70002f6e <memset>
7000063a:	2302      	movs	r3, #2
						 NULL, NULL, _FDEV_SETUP_WRITE);
		(void) vfprintf(&console, fmt, ap);
7000063c:	462a      	mov	r2, r5
7000063e:	4621      	mov	r1, r4
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000640:	f88d 3002 	strb.w	r3, [sp, #2]
		(void) vfprintf(&console, fmt, ap);
70000644:	4668      	mov	r0, sp
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000646:	4b03      	ldr	r3, [pc, #12]	; (70000654 <vprintk+0x2c>)
70000648:	9301      	str	r3, [sp, #4]
		(void) vfprintf(&console, fmt, ap);
7000064a:	f001 fc39 	bl	70001ec0 <__l_vfprintf>

#ifdef CONFIG_PRINTK_SYNC
		k_spin_unlock(&lock, key);
#endif
	}
}
7000064e:	b005      	add	sp, #20
70000650:	bd30      	pop	{r4, r5, pc}
70000652:	bf00      	nop
70000654:	70000611 	.word	0x70000611

70000658 <z_thread_entry>:
 * This routine does not return, and is marked as such so the compiler won't
 * generate preamble code that is only used by functions that actually return.
 */
FUNC_NORETURN void z_thread_entry(k_thread_entry_t entry,
				 void *p1, void *p2, void *p3)
{
70000658:	b580      	push	{r7, lr}
7000065a:	4605      	mov	r5, r0
7000065c:	460e      	mov	r6, r1
7000065e:	4617      	mov	r7, r2
70000660:	4698      	mov	r8, r3
	return z_impl_k_sched_current_thread_query();
70000662:	f001 f8dd 	bl	70001820 <z_impl_k_sched_current_thread_query>
#ifdef CONFIG_CURRENT_THREAD_USE_TLS
	z_tls_current = k_sched_current_thread_query();
70000666:	f8df 9020 	ldr.w	r9, [pc, #32]	; 70000688 <z_thread_entry+0x30>

	sys_rand_get((uint8_t *)&stack_guard, sizeof(stack_guard));
	__stack_chk_guard = stack_guard;
	__stack_chk_guard <<= 8;
#endif	/* CONFIG_STACK_CANARIES */
	entry(p1, p2, p3);
7000066a:	4642      	mov	r2, r8
7000066c:	4639      	mov	r1, r7
7000066e:	4603      	mov	r3, r0
	z_tls_current = k_sched_current_thread_query();
70000670:	f000 e948 	blx	70000904 <__aeabi_read_tp>
70000674:	4604      	mov	r4, r0
70000676:	f849 3000 	str.w	r3, [r9, r0]
	entry(p1, p2, p3);
7000067a:	4630      	mov	r0, r6
7000067c:	47a8      	blx	r5
7000067e:	f854 0009 	ldr.w	r0, [r4, r9]
	z_impl_k_thread_abort(thread);
70000682:	f002 fbad 	bl	70002de0 <z_impl_k_thread_abort>
	/*
	 * Compiler can't tell that k_thread_abort() won't return and issues a
	 * warning unless we tell it that control never gets this far.
	 */

	CODE_UNREACHABLE; /* LCOV_EXCL_LINE */
70000686:	bf00      	nop
70000688:	00000008 	.word	0x00000008

7000068c <z_arm_nmi>:
 * Simply call what is installed in 'static void(*handler)(void)'.
 *
 */

void z_arm_nmi(void)
{
7000068c:	b508      	push	{r3, lr}
	handler();
7000068e:	4b03      	ldr	r3, [pc, #12]	; (7000069c <z_arm_nmi+0x10>)
70000690:	681b      	ldr	r3, [r3, #0]
70000692:	4798      	blx	r3
	z_arm_int_exit();
}
70000694:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_arm_int_exit();
70000698:	f002 bcde 	b.w	70003058 <__z_arm_int_exit_from_thumb>
7000069c:	7000a7c8 	.word	0x7000a7c8

700006a0 <z_SysNmiOnReset>:
_ASM_FILE_PROLOGUE

GTEXT(z_SysNmiOnReset)

SECTION_FUNC(TEXT, z_SysNmiOnReset)
    wfi
700006a0:	e320f003 	wfi
    b z_SysNmiOnReset
700006a4:	eafffffd 	b	700006a0 <z_SysNmiOnReset>

700006a8 <arch_tls_stack_setup>:
 */
K_APP_DMEM(z_libc_partition) uintptr_t z_arm_tls_ptr;
#endif

size_t arch_tls_stack_setup(struct k_thread *new_thread, char *stack_ptr)
{
700006a8:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
 *
 * @return Total size of TLS data/bss areas
 */
static inline size_t z_tls_data_size(void)
{
	return (size_t)(uintptr_t)__tdata_size +
700006ac:	4e0b      	ldr	r6, [pc, #44]	; (700006dc <arch_tls_stack_setup+0x34>)
700006ae:	4605      	mov	r5, r0
	       (size_t)(uintptr_t)__tbss_size;
700006b0:	f8df 802c 	ldr.w	r8, [pc, #44]	; 700006e0 <arch_tls_stack_setup+0x38>
 * @param dest Pointer to destination
 */
static inline void z_tls_copy(char *dest)
{
	/* Copy initialized data (tdata) */
	memcpy(dest, __tdata_start, (size_t)(uintptr_t)__tdata_size);
700006b4:	4632      	mov	r2, r6
	return (size_t)(uintptr_t)__tdata_size +
700006b6:	eb06 0708 	add.w	r7, r6, r8

	/*
	 * Since we are populating things backwards,
	 * setup the TLS data/bss area first.
	 */
	stack_ptr -= z_tls_data_size();
700006ba:	1bcc      	subs	r4, r1, r7
	memcpy(dest, __tdata_start, (size_t)(uintptr_t)__tdata_size);
700006bc:	4909      	ldr	r1, [pc, #36]	; (700006e4 <arch_tls_stack_setup+0x3c>)
700006be:	4620      	mov	r0, r4
700006c0:	f002 fc48 	bl	70002f54 <memcpy>

	/* Clear BSS data (tbss) */
	dest += (size_t)(uintptr_t)__tdata_size;
	memset(dest, 0, (size_t)(uintptr_t)__tbss_size);
700006c4:	4642      	mov	r2, r8
700006c6:	2100      	movs	r1, #0
700006c8:	19a0      	adds	r0, r4, r6
	z_tls_copy(stack_ptr);

	/* Skip two pointers due to toolchain */
	stack_ptr -= sizeof(uintptr_t) * 2;
700006ca:	3c08      	subs	r4, #8
700006cc:	f002 fc4f 	bl	70002f6e <memset>
	 * context switch to point to TLS area.
	 */
	new_thread->tls = POINTER_TO_UINT(stack_ptr);

	return (z_tls_data_size() + (sizeof(uintptr_t) * 2));
}
700006d0:	f107 0008 	add.w	r0, r7, #8
	new_thread->tls = POINTER_TO_UINT(stack_ptr);
700006d4:	66ac      	str	r4, [r5, #104]	; 0x68
}
700006d6:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
700006da:	bf00      	nop
700006dc:	00000000 	.word	0x00000000
700006e0:	00000004 	.word	0x00000004
700006e4:	70004154 	.word	0x70004154

700006e8 <z_arm_undef_instruction>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_undef_instruction)
	/*
	 * The undefined instruction address is offset by 2 if the previous
	 * mode is Thumb; otherwise, it is offset by 4.
	 */
	push {r0}
700006e8:	e52d0004 	push	{r0}		; (str r0, [sp, #-4]!)
	mrs r0, spsr
700006ec:	e14f0000 	mrs	r0, SPSR
	tst r0, #T_BIT
700006f0:	e3100020 	tst	r0, #32
	subeq lr, #4	/* ARM   (!T_BIT) */
700006f4:	024ee004 	subeq	lr, lr, #4
	subne lr, #2	/* Thumb (T_BIT) */
700006f8:	124ee002 	subne	lr, lr, #2
	pop {r0}
700006fc:	e49d0004 	pop	{r0}		; (ldr r0, [sp], #4)

	/*
	 * Store r0-r3, r12, lr, lr_und and spsr_und into the stack to
	 * construct an exception stack frame.
	 */
	srsdb sp!, #MODE_UND
70000700:	f96d051b 	srsdb	sp!, #27
	stmfd sp, {r0-r3, r12, lr}^
70000704:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
	sub sp, #24
70000708:	e24dd018 	sub	sp, sp, #24

	/* Increment exception nesting count */
	get_cpu r2
7000070c:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000710:	e3c22003 	bic	r2, r2, #3
	ldr r1, [r2, #___cpu_t_nested_OFFSET]
70000714:	e5921000 	ldr	r1, [r2]
	add r1, r1, #1
70000718:	e2811001 	add	r1, r1, #1
	str r1, [r2, #___cpu_t_nested_OFFSET]
7000071c:	e5821000 	str	r1, [r2]
	cps #MODE_UND

	mov r0, sp
	mov sp, r1
#else
	mov r0, sp
70000720:	e1a0000d 	mov	r0, sp
#endif

	bl z_arm_fault_undef_instruction
70000724:	fb000786 	blx	70002546 <z_arm_fault_undef_instruction>
	exception_exit

	b z_arm_exc_exit
70000728:	ea0000ca 	b	70000a58 <z_arm_exc_exit>

7000072c <z_arm_prefetch_abort>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_prefetch_abort)
	/*
	 * The faulting instruction address is always offset by 4 for the
	 * prefetch abort exceptions.
	 */
	sub lr, #4
7000072c:	e24ee004 	sub	lr, lr, #4

	exception_entry MODE_ABT
70000730:	f96d0517 	srsdb	sp!, #23
70000734:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
70000738:	e24dd018 	sub	sp, sp, #24
7000073c:	e1a0000d 	mov	r0, sp
70000740:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000744:	e3c22003 	bic	r2, r2, #3
70000748:	e5921000 	ldr	r1, [r2]
7000074c:	e2811001 	add	r1, r1, #1
70000750:	e5821000 	str	r1, [r2]
	bl z_arm_fault_prefetch
70000754:	fa00077e 	blx	70002554 <z_arm_fault_prefetch>
	exception_exit

	b z_arm_exc_exit
70000758:	ea0000be 	b	70000a58 <z_arm_exc_exit>

7000075c <z_arm_data_abort>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_data_abort)
	/*
	 * The faulting instruction address is always offset by 8 for the data
	 * abort exceptions.
	 */
	sub lr, #8
7000075c:	e24ee008 	sub	lr, lr, #8

	exception_entry MODE_ABT
70000760:	f96d0517 	srsdb	sp!, #23
70000764:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
70000768:	e24dd018 	sub	sp, sp, #24
7000076c:	e1a0000d 	mov	r0, sp
70000770:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000774:	e3c22003 	bic	r2, r2, #3
70000778:	e5921000 	ldr	r1, [r2]
7000077c:	e2811001 	add	r1, r1, #1
70000780:	e5821000 	str	r1, [r2]
	bl z_arm_fault_data
70000784:	fa00077b 	blx	70002578 <z_arm_fault_data>
	/*
	 * If z_arm_fault_data returns false, then we recovered from
	 * the error.  It may have updated $pc, so copy $pc back to
	 * the true esf from the one passed to z_arm_fault_data.
	 */
	cmp r0, #0
70000788:	e3500000 	cmp	r0, #0
	ldreq r1, [sp, #24 + FPU_SF_SIZE]
7000078c:	059d1018 	ldreq	r1, [sp, #24]

	exception_exit

	streq r1, [sp, #24 + FPU_SF_SIZE]
70000790:	058d1018 	streq	r1, [sp, #24]

	b z_arm_exc_exit
70000794:	ea0000af 	b	70000a58 <z_arm_exc_exit>

70000798 <relocate_vector_table>:
		write_sysreg64(val, op1, CRm);				\
	}

MAKE_REG_HELPER(mpuir,	     0, 0, 0, 4);
MAKE_REG_HELPER(mpidr,	     0, 0, 0, 5);
MAKE_REG_HELPER(sctlr,	     0, 1, 0, 0);
70000798:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}

void __weak relocate_vector_table(void)
{
#if defined(CONFIG_XIP) && (CONFIG_FLASH_BASE_ADDRESS != 0) ||                                     \
	!defined(CONFIG_XIP) && (CONFIG_SRAM_BASE_ADDRESS != 0)
	write_sctlr(read_sctlr() & ~HIVECS);
7000079c:	f423 5300 	bic.w	r3, r3, #8192	; 0x2000
700007a0:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
	size_t vector_size = (size_t)_vector_end - (size_t)_vector_start;
700007a4:	4902      	ldr	r1, [pc, #8]	; (700007b0 <relocate_vector_table+0x18>)
	(void)memcpy(VECTOR_ADDRESS, _vector_start, vector_size);
700007a6:	2000      	movs	r0, #0
700007a8:	4a02      	ldr	r2, [pc, #8]	; (700007b4 <relocate_vector_table+0x1c>)
700007aa:	1a52      	subs	r2, r2, r1
700007ac:	f002 bbd2 	b.w	70002f54 <memcpy>
700007b0:	70000000 	.word	0x70000000
700007b4:	7000003c 	.word	0x7000003c

700007b8 <__start>:
    ldr r0, =IMP_CSCTLR(CONFIG_CPU_CORTEX_R52_ICACHE_FLASH_WAY,
                        CONFIG_CPU_CORTEX_R52_DCACHE_FLASH_WAY)
    mcr p15, 1, r0, c9, c1, 0
#endif

    ldr r0, =arm_cpu_boot_params
700007b8:	e59f0054 	ldr	r0, [pc, #84]	; 70000814 <__start+0x5c>
    b 2f

_primary_core:
#endif

    ldr r4, =z_prep_c
700007bc:	e59f4054 	ldr	r4, [pc, #84]	; 70000818 <__start+0x60>
    ldr r5, =(z_arm_fiq_stack + CONFIG_ARMV7_FIQ_STACK_SIZE)
700007c0:	e59f5054 	ldr	r5, [pc, #84]	; 7000081c <__start+0x64>
    ldr r6, =(z_interrupt_stacks + CONFIG_ISR_STACK_SIZE)
700007c4:	e59f6054 	ldr	r6, [pc, #84]	; 70000820 <__start+0x68>
    ldr r7, =(z_arm_abort_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
700007c8:	e59f7054 	ldr	r7, [pc, #84]	; 70000824 <__start+0x6c>
    ldr r8, =(z_arm_undef_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
700007cc:	e59f8054 	ldr	r8, [pc, #84]	; 70000828 <__start+0x70>
    ldr r9, =(z_arm_svc_stack + CONFIG_ARMV7_SVC_STACK_SIZE)
700007d0:	e59f9054 	ldr	r9, [pc, #84]	; 7000082c <__start+0x74>
    ldr r10, =(z_arm_sys_stack + CONFIG_ARMV7_SYS_STACK_SIZE)
700007d4:	e59fa054 	ldr	sl, [pc, #84]	; 70000830 <__start+0x78>
    /*
     * Configure stack.
     */

    /* FIQ mode stack */
    msr CPSR_c, #(MODE_FIQ | I_BIT | F_BIT)
700007d8:	e321f0d1 	msr	CPSR_c, #209	; 0xd1
    mov sp, r5
700007dc:	e1a0d005 	mov	sp, r5

    /* IRQ mode stack */
    msr CPSR_c, #(MODE_IRQ | I_BIT | F_BIT)
700007e0:	e321f0d2 	msr	CPSR_c, #210	; 0xd2
    mov sp, r6
700007e4:	e1a0d006 	mov	sp, r6

    /* ABT mode stack */
    msr CPSR_c, #(MODE_ABT | I_BIT | F_BIT)
700007e8:	e321f0d7 	msr	CPSR_c, #215	; 0xd7
    mov sp, r7
700007ec:	e1a0d007 	mov	sp, r7

    /* UND mode stack */
    msr CPSR_c, #(MODE_UND | I_BIT | F_BIT)
700007f0:	e321f0db 	msr	CPSR_c, #219	; 0xdb
    mov sp, r8
700007f4:	e1a0d008 	mov	sp, r8

    /* SVC mode stack */
    msr CPSR_c, #(MODE_SVC | I_BIT | F_BIT)
700007f8:	e321f0d3 	msr	CPSR_c, #211	; 0xd3
    mov sp, r9
700007fc:	e1a0d009 	mov	sp, r9

    /* SYS mode stack */
    msr CPSR_c, #(MODE_SYS | I_BIT | F_BIT)
70000800:	e321f0df 	msr	CPSR_c, #223	; 0xdf
    mov sp, r10
70000804:	e1a0d00a 	mov	sp, sl

#if defined(CONFIG_SOC_RESET_HOOK)
    /* Execute platform-specific initialisation if applicable */
    bl soc_reset_hook
70000808:	fa000733 	blx	700024dc <soc_reset_hook>

#if defined(CONFIG_DISABLE_TCM_ECC)
    bl z_arm_tcm_disable_ecc
#endif

    bl z_arm_relocate_vector_table
7000080c:	fa000763 	blx	700025a0 <z_arm_relocate_vector_table>

    bx r4
70000810:	e12fff14 	bx	r4
    ldr r0, =arm_cpu_boot_params
70000814:	7000a7cc 	.word	0x7000a7cc
    ldr r4, =z_prep_c
70000818:	70000835 	.word	0x70000835
    ldr r5, =(z_arm_fiq_stack + CONFIG_ARMV7_FIQ_STACK_SIZE)
7000081c:	70009650 	.word	0x70009650
    ldr r6, =(z_interrupt_stacks + CONFIG_ISR_STACK_SIZE)
70000820:	70009e50 	.word	0x70009e50
    ldr r7, =(z_arm_abort_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000824:	70009550 	.word	0x70009550
    ldr r8, =(z_arm_undef_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000828:	70009450 	.word	0x70009450
    ldr r9, =(z_arm_svc_stack + CONFIG_ARMV7_SVC_STACK_SIZE)
7000082c:	70009350 	.word	0x70009350
    ldr r10, =(z_arm_sys_stack + CONFIG_ARMV7_SYS_STACK_SIZE)
70000830:	70009150 	.word	0x70009150

70000834 <z_prep_c>:
 *
 * This routine prepares for the execution of and runs C code.
 *
 */
void z_prep_c(void)
{
70000834:	b508      	push	{r3, lr}
MAKE_REG_HELPER(prlar,	     0, 6, 3, 1);
MAKE_REG_HELPER(mair0,       0, 10, 2, 0);
MAKE_REG_HELPER(vbar,        0, 12, 0, 0);
MAKE_REG_HELPER(cntv_ctl,    0, 14,  3, 1);
MAKE_REG_HELPER(ctr,         0, 0, 0, 1);
MAKE_REG_HELPER(tpidruro,    0, 13, 0, 3);
70000836:	4b05      	ldr	r3, [pc, #20]	; (7000084c <z_prep_c+0x18>)
70000838:	ee0d 3f70 	mcr	15, 0, r3, cr13, cr0, {3}
	write_tpidruro((uintptr_t)&_kernel.cpus[0]);

#if defined(CONFIG_CPU_HAS_FPU)
	z_arm_floating_point_init();
#endif
	z_bss_zero();
7000083c:	f000 fb92 	bl	70000f64 <z_bss_zero>
	z_data_copy();
#if ((defined(CONFIG_ARMV7_R) || defined(CONFIG_ARMV7_A)) && defined(CONFIG_INIT_STACKS))
	z_arm_init_stacks();
#endif
	z_arm_interrupt_init();
70000840:	f001 feac 	bl	7000259c <z_arm_interrupt_init>
#if CONFIG_ARCH_CACHE
	arch_cache_init();
70000844:	f001 ff1c 	bl	70002680 <arch_cache_init>
	z_arm_mpu_init();
	z_arm_configure_static_mpu_regions();
#elif defined(CONFIG_ARM_AARCH32_MMU)
	z_arm_mmu_init();
#endif
	z_cstart();
70000848:	f000 fbcc 	bl	70000fe4 <z_cstart>
7000084c:	70005f18 	.word	0x70005f18

70000850 <arch_new_thread>:
	}
#else
	iframe->pc = (uint32_t)z_thread_entry;
#endif

	iframe->a1 = (uint32_t)entry;
70000850:	f842 3c20 	str.w	r3, [r2, #-32]
	iframe = Z_STACK_PTR_TO_FRAME(struct __basic_sf, stack_ptr);
70000854:	3a20      	subs	r2, #32
	iframe->a2 = (uint32_t)p1;
70000856:	9b00      	ldr	r3, [sp, #0]
70000858:	6053      	str	r3, [r2, #4]
	iframe->a3 = (uint32_t)p2;
7000085a:	9b01      	ldr	r3, [sp, #4]
7000085c:	6093      	str	r3, [r2, #8]
	iframe->a4 = (uint32_t)p3;
7000085e:	9b02      	ldr	r3, [sp, #8]
70000860:	60d3      	str	r3, [r2, #12]
#if defined(CONFIG_BIG_ENDIAN)
	iframe->xpsr |= E_BIT;
#endif /* CONFIG_BIG_ENDIAN */

#if defined(CONFIG_COMPILER_ISA_THUMB2)
	iframe->xpsr |= T_BIT;
70000862:	f240 133f 	movw	r3, #319	; 0x13f
	iframe->pc = (uint32_t)z_thread_entry;
70000866:	4903      	ldr	r1, [pc, #12]	; (70000874 <arch_new_thread+0x24>)
	iframe->xpsr |= T_BIT;
70000868:	61d3      	str	r3, [r2, #28]
		((uintptr_t)iframe - sizeof(struct __fpu_sf));
	memset(iframe, 0, sizeof(struct __fpu_sf));
#endif

	thread->callee_saved.psp = (uint32_t)iframe;
	thread->arch.basepri = 0;
7000086a:	2300      	movs	r3, #0
	iframe->pc = (uint32_t)z_thread_entry;
7000086c:	6191      	str	r1, [r2, #24]
	thread->callee_saved.psp = (uint32_t)iframe;
7000086e:	6502      	str	r2, [r0, #80]	; 0x50
	thread->arch.basepri = 0;
70000870:	66c3      	str	r3, [r0, #108]	; 0x6c
	thread->switch_handle = thread;
	/* thread birth happens through the exception return path */
	thread->arch.exception_depth = 1;
	thread->callee_saved.lr = (uint32_t)z_arm_cortex_ar_exit_exc;
#endif
}
70000872:	4770      	bx	lr
70000874:	70000659 	.word	0x70000659

70000878 <arch_cpu_idle>:

	/*
	 * Clear PRIMASK and flush instruction buffer to immediately service
	 * the wake-up interrupt.
	 */
	cpsie	i
70000878:	f1080080 	cpsie	i
	isb
7000087c:	f57ff06f 	isb	sy

	bx	lr
70000880:	e12fff1e 	bx	lr

70000884 <_isr_wrapper>:
	 * Save away r0-r3, r12 and lr_irq for the previous context to the
	 * process stack since they are clobbered here.  Also, save away lr
	 * and spsr_irq since we may swap processes and return to a different
	 * thread.
	 */
	sub lr, lr, #4
70000884:	e24ee004 	sub	lr, lr, #4
	srsdb #MODE_SYS!
70000888:	f96d051f 	srsdb	sp!, #31
	cps #MODE_SYS
7000088c:	f102001f 	cps	#31
	push {r0-r3, r12, lr}
70000890:	e92d500f 	push	{r0, r1, r2, r3, ip, lr}
	 * threads have high stack usage.
	 *
	 * When userspace is enabled, this also prevents leaking privileged
	 * information to the user mode.
	 */
	cps #MODE_SVC
70000894:	f1020013 	cps	#19
	/*
	 * Preserve lr_svc which may contain the branch return address of the
	 * interrupted context in case of a nested interrupt. This value will
	 * be restored prior to exiting the interrupt in z_arm_int_exit.
	 */
	push {lr}
70000898:	e52de004 	push	{lr}		; (str lr, [sp, #-4]!)

	/* Align stack at double-word boundary */
	and r3, sp, #4
7000089c:	e20d3004 	and	r3, sp, #4
	sub sp, sp, r3
700008a0:	e04dd003 	sub	sp, sp, r3
	push {r2, r3}
700008a4:	e92d000c 	push	{r2, r3}

	/* Increment interrupt nesting count */
	get_cpu r2
700008a8:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
700008ac:	e3c22003 	bic	r2, r2, #3
	ldr r0, [r2, #___cpu_t_nested_OFFSET]
700008b0:	e5920000 	ldr	r0, [r2]
	add r0, r0, #1
700008b4:	e2800001 	add	r0, r0, #1
	str r0, [r2, #___cpu_t_nested_OFFSET]
700008b8:	e5820000 	str	r0, [r2]

	/* Get active IRQ number from the interrupt controller */
#if !defined(CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER)
	bl arm_gic_get_active
#else
	bl z_soc_irq_get_active
700008bc:	fa000701 	blx	700024c8 <z_soc_irq_get_active>
#endif /* !CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER */
	push {r0, r1}
700008c0:	e92d0003 	push	{r0, r1}
	lsl r0, r0, #3	/* table is 8-byte wide */
700008c4:	e1a00180 	lsl	r0, r0, #3
	 * to note that most interrupt controllers require that the nested
	 * interrupts are handled after the active interrupt is acknowledged;
	 * this is be done through the `get_active` interrupt controller
	 * interface function.
	 */
	cpsie i
700008c8:	f1080080 	cpsie	i

	/*
	 * Skip calling the isr if it is a spurious interrupt.
	 */
	mov r1, #CONFIG_NUM_IRQS
700008cc:	e3a01c02 	mov	r1, #512	; 0x200
	lsl r1, r1, #3
700008d0:	e1a01181 	lsl	r1, r1, #3
	cmp r0, r1
700008d4:	e1500001 	cmp	r0, r1
	bge spurious_continue
700008d8:	aa000003 	bge	700008ec <spurious_continue>

	ldr r1, =_sw_isr_table
700008dc:	e59f1018 	ldr	r1, [pc, #24]	; 700008fc <spurious_continue+0x10>
	add r1, r1, r0	/* table entry: ISRs must have their MSB set to stay
700008e0:	e0811000 	add	r1, r1, r0
			 * in thumb mode */

	ldm r1!,{r0,r3}	/* arg in r0, ISR in r3 */
700008e4:	e8b10009 	ldm	r1!, {r0, r3}
	blx r3		/* call ISR */
700008e8:	e12fff33 	blx	r3

700008ec <spurious_continue>:

spurious_continue:
	/* Signal end-of-interrupt */
	pop {r0, r1}
700008ec:	e8bd0003 	pop	{r0, r1}
#if !defined(CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER)
	bl arm_gic_eoi
#else
	bl z_soc_irq_eoi
700008f0:	fa0006f5 	blx	700024cc <z_soc_irq_eoi>
#endif

	/* Use 'bx' instead of 'b' because 'bx' can jump further, and use
	 * 'bx' instead of 'blx' because exception return is done in
	 * z_arm_int_exit() */
	ldr r1, =z_arm_int_exit
700008f4:	e59f1004 	ldr	r1, [pc, #4]	; 70000900 <spurious_continue+0x14>
	bx r1
700008f8:	e12fff11 	bx	r1
	ldr r1, =_sw_isr_table
700008fc:	700030d8 	.word	0x700030d8
	ldr r1, =z_arm_int_exit
70000900:	70000a00 	.word	0x70000a00

70000904 <__aeabi_read_tp>:

SECTION_FUNC(text, __aeabi_read_tp)
	/*
	 * TPIDRURW will be used as a base pointer point to TLS aera.
	 */
	mrc p15, 0, r0, c13, c0, 2
70000904:	ee1d0f50 	mrc	15, 0, r0, cr13, cr0, {2}
	bx lr
70000908:	e12fff1e 	bx	lr

7000090c <z_arm_do_swap>:
    bl z_thread_mark_switched_out
    pop {r0, lr}
#endif /* CONFIG_INSTRUMENT_THREAD_SWITCHING */

    /* load current _cpu into r1 and current k_thread into r2 */
    get_cpu r1
7000090c:	ee1d1f70 	mrc	15, 0, r1, cr13, cr0, {3}
70000910:	e3c11003 	bic	r1, r1, #3
    ldr r2, [r1, #___cpu_t_current_OFFSET]
70000914:	e5912008 	ldr	r2, [r1, #8]
    /* Store LSB of LR (EXC_RETURN) to the thread's 'mode' word. */
    strb lr, [r2, #_thread_offset_to_mode_exc_return]
#endif

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
70000918:	e3a00030 	mov	r0, #48	; 0x30
    add r0, r2
7000091c:	e0800002 	add	r0, r0, r2

    /* Store rest of process context */
    cps #MODE_SYS
70000920:	f102001f 	cps	#31
    stm r0, {r4-r11, sp}
70000924:	e8802ff0 	stm	r0, {r4, r5, r6, r7, r8, r9, sl, fp, sp}
    cps #MODE_SVC
70000928:	f1020013 	cps	#19
    mov r0, #0
    str r0, [r1, #___cpu_t_fp_ctx_OFFSET]
#endif /* CONFIG_FPU_SHARING */

    /* fetch the thread to run from the ready queue cache */
    ldr r3, =_kernel
7000092c:	e59f3038 	ldr	r3, [pc, #56]	; 7000096c <z_arm_do_swap+0x60>
    ldr r2, [r3, #_kernel_offset_to_ready_q_cache]
70000930:	e5932014 	ldr	r2, [r3, #20]

    str r2, [r1, #___cpu_t_current_OFFSET]
70000934:	e5812008 	str	r2, [r1, #8]

#if defined(CONFIG_THREAD_LOCAL_STORAGE)
    /* Grab the TLS pointer */
    ldr r4, =_thread_offset_to_tls
70000938:	e3a04068 	mov	r4, #104	; 0x68
    adds r4, r2, r4
7000093c:	e0924004 	adds	r4, r2, r4
    ldr r0, [r4]
70000940:	e5940000 	ldr	r0, [r4]

    /* Store TLS pointer in the "Process ID" register.
     * TPIDRURW is used as a base pointer to all
     * thread variables with offsets added by toolchain.
     */
    mcr p15, 0, r0, c13, c0, 2
70000944:	ee0d0f50 	mcr	15, 0, r0, cr13, cr0, {2}
#endif

    /* Restore previous interrupt disable state (irq_lock key)
     * (We clear the arch.basepri field after restoring state)
     */
    ldr r0, [r2, #_thread_offset_to_basepri]
70000948:	e592006c 	ldr	r0, [r2, #108]	; 0x6c
    movs r3, #0
7000094c:	e3b03000 	movs	r3, #0
    str r3, [r2, #_thread_offset_to_basepri]
70000950:	e582306c 	str	r3, [r2, #108]	; 0x6c

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
70000954:	e3a00030 	mov	r0, #48	; 0x30
    add r0, r2
70000958:	e0800002 	add	r0, r0, r2

    /* restore r4-r11 and sp for incoming thread */
    cps #MODE_SYS
7000095c:	f102001f 	cps	#31
    ldm r0, {r4-r11, sp}
70000960:	e8902ff0 	ldm	r0, {r4, r5, r6, r7, r8, r9, sl, fp, sp}
    cps #MODE_SVC
70000964:	f1020013 	cps	#19
#endif /* CONFIG_INSTRUMENT_THREAD_SWITCHING */

    /*
     * Cortex-R: return to the caller (z_arm_{exc,int}_exit, or z_arm_svc)
     */
    bx lr
70000968:	e12fff1e 	bx	lr
    ldr r3, =_kernel
7000096c:	70005f18 	.word	0x70005f18

70000970 <z_arm_svc>:
    /*
     * Switch to system mode to store r0-r3 to the process stack pointer.
     * Save r12 and the lr as we could be swapping in another process and
     * returning to a different location.
     */
    srsdb #MODE_SYS!
70000970:	f96d051f 	srsdb	sp!, #31
    cps #MODE_SYS
70000974:	f102001f 	cps	#31
    push {r0-r3, r12, lr}
70000978:	e92d500f 	push	{r0, r1, r2, r3, ip, lr}
    ldr r0, [r2, #___cpu_t_fp_ctx_OFFSET]
    cmp r0, #0
    streq sp, [r2, #___cpu_t_fp_ctx_OFFSET]
#endif /* CONFIG_FPU_SHARING */

    mov ip, sp
7000097c:	e1a0c00d 	mov	ip, sp

    cps #MODE_SVC
70000980:	f1020013 	cps	#19

    /*
     * Store lr_svc to the SVC mode stack. This value will be restored prior to
     * exiting the SVC call in z_arm_int_exit.
     */
    push {lr}
70000984:	e52de004 	push	{lr}		; (str lr, [sp, #-4]!)

    /* Align stack at double-word boundary */
    /* TODO: Question, why push {r2, r3} here */
    and r3, sp, #4
70000988:	e20d3004 	and	r3, sp, #4
    sub sp, sp, r3
7000098c:	e04dd003 	sub	sp, sp, r3
    push {r2, r3}
70000990:	e92d000c 	push	{r2, r3}

    /* Increment interrupt nesting count */
    get_cpu r2
70000994:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000998:	e3c22003 	bic	r2, r2, #3
    ldr r0, [r2, #___cpu_t_nested_OFFSET]
7000099c:	e5920000 	ldr	r0, [r2]
    add r0, r0, #1
700009a0:	e2800001 	add	r0, r0, #1
    str r0, [r2, #___cpu_t_nested_OFFSET]
700009a4:	e5820000 	str	r0, [r2]

    /* Get SVC number */
    mrs r0, spsr
700009a8:	e14f0000 	mrs	r0, SPSR
    tst r0, #0x20
700009ac:	e3100020 	tst	r0, #32

    ldreq r1, [lr, #-4]
700009b0:	051e1004 	ldreq	r1, [lr, #-4]
    biceq r1, #0xff000000
700009b4:	03c114ff 	biceq	r1, r1, #-16777216	; 0xff000000
    beq demux
700009b8:	0a000001 	beq	700009c4 <demux>

    ldr r1, [lr, #-2]
700009bc:	e51e1002 	ldr	r1, [lr, #-2]
    and r1, #0xff
700009c0:	e20110ff 	and	r1, r1, #255	; 0xff

700009c4 <demux>:
#if defined(CONFIG_USERSPACE)
    cmp r1, #_SVC_CALL_SYSTEM_CALL
    beq _do_syscall
#endif

    cmp r1, #_SVC_CALL_CONTEXT_SWITCH
700009c4:	e3510000 	cmp	r1, #0
    beq _context_switch
700009c8:	0a000001 	beq	700009d4 <_context_switch>

    cmp r1, #_SVC_CALL_RUNTIME_EXCEPT
700009cc:	e3510002 	cmp	r1, #2
    beq _oops
700009d0:	0a000001 	beq	700009dc <_oops>

700009d4 <_context_switch>:
    b z_arm_int_exit
#endif

_context_switch:
    /* handler mode exit, to PendSV */
    bl z_arm_do_swap
700009d4:	ebffffcc 	bl	7000090c <z_arm_do_swap>

    b z_arm_int_exit
700009d8:	ea000008 	b	70000a00 <z_arm_int_exit>

700009dc <_oops>:

_oops:
    /*
     * Pass the exception frame to z_do_kernel_oops.
     */
    cps #MODE_SYS
700009dc:	f102001f 	cps	#31
    mov r0, sp
700009e0:	e1a0000d 	mov	r0, sp
    cps #MODE_SVC
700009e4:	f1020013 	cps	#19
    /* Zero callee_regs and exc_return (only used on Cortex-M) */
    mov r1, #0
700009e8:	e3a01000 	mov	r1, #0
    mov r2, #0
700009ec:	e3a02000 	mov	r2, #0
    bl z_do_kernel_oops
700009f0:	fb0006bd 	blx	700024ee <z_do_kernel_oops>
    b z_arm_int_exit
700009f4:	ea000001 	b	70000a00 <z_arm_int_exit>

700009f8 <z_arm_cortex_r_svc>:
    b z_arm_int_exit
#endif

GTEXT(z_arm_cortex_r_svc)
SECTION_FUNC(TEXT, z_arm_cortex_r_svc)
    svc #_SVC_CALL_CONTEXT_SWITCH
700009f8:	ef000000 	svc	0x00000000
    bx lr
700009fc:	e12fff1e 	bx	lr

70000a00 <z_arm_int_exit>:
#endif /* CONFIG_STACK_SENTINEL */

	/* Disable nested interrupts while exiting, this should happens
	 * before context switch also, to ensure interrupts are disabled.
	 */
	cpsid i
70000a00:	f10c0080 	cpsid	i

#ifdef CONFIG_PREEMPT_ENABLED
	/* Do not context switch if exiting a nested interrupt */
	get_cpu r3
70000a04:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70000a08:	e3c33003 	bic	r3, r3, #3
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
70000a0c:	e5930000 	ldr	r0, [r3]
	cmp r0, #1
70000a10:	e3500001 	cmp	r0, #1
	bhi __EXIT_INT
70000a14:	8a000004 	bhi	70000a2c <__EXIT_INT>

	ldr r1, [r3, #___cpu_t_current_OFFSET]
70000a18:	e5931008 	ldr	r1, [r3, #8]
	ldr r2, =_kernel
70000a1c:	e59f2094 	ldr	r2, [pc, #148]	; 70000ab8 <__EXIT_EXC+0x18>
	ldr r0, [r2, #_kernel_offset_to_ready_q_cache]
70000a20:	e5920014 	ldr	r0, [r2, #20]
	cmp r0, r1
70000a24:	e1500001 	cmp	r0, r1
	blne z_arm_do_swap
70000a28:	1bffffb7 	blne	7000090c <z_arm_do_swap>

70000a2c <__EXIT_INT>:
__EXIT_INT:
#endif /* CONFIG_PREEMPT_ENABLED */

	/* Decrement interrupt nesting count */
	get_cpu r2
70000a2c:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000a30:	e3c22003 	bic	r2, r2, #3
	ldr r0, [r2, #___cpu_t_nested_OFFSET]
70000a34:	e5920000 	ldr	r0, [r2]
	sub r0, r0, #1
70000a38:	e2400001 	sub	r0, r0, #1
	str r0, [r2, #___cpu_t_nested_OFFSET]
70000a3c:	e5820000 	str	r0, [r2]

	/* Restore previous stack pointer */
	pop {r2, r3}
70000a40:	e8bd000c 	pop	{r2, r3}
	add sp, sp, r3
70000a44:	e08dd003 	add	sp, sp, r3
	/*
	 * Restore lr_svc stored into the SVC mode stack by the mode entry
	 * function. This ensures that the return address of the interrupted
	 * context is preserved in case of interrupt nesting.
	 */
	pop {lr}
70000a48:	e49de004 	pop	{lr}		; (ldr lr, [sp], #4)
	 * IRQ mode and z_arm_svc for SVC mode.
	 *
	 * r0-r3 are either the values from the thread before it was switched
	 * out or they are the args to _new_thread for a new thread.
	 */
	cps #MODE_SYS
70000a4c:	f102001f 	cps	#31

#if defined(CONFIG_FPU_SHARING)
	fpu_exc_exit
#endif

	pop {r0-r3, r12, lr}
70000a50:	e8bd500f 	pop	{r0, r1, r2, r3, ip, lr}
	userspace_exc_exit
	rfeia sp!
70000a54:	f8bd0a00 	rfeia	sp!

70000a58 <z_arm_exc_exit>:
 *
 * @param fatal True if exiting from a fatal fault; otherwise, false
 */
SECTION_SUBSEC_FUNC(TEXT, _HandlerModeExit, z_arm_exc_exit)
	/* Do not context switch if exiting a nested exception */
	get_cpu r3
70000a58:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70000a5c:	e3c33003 	bic	r3, r3, #3
	ldr r1, [r3, #___cpu_t_nested_OFFSET]
70000a60:	e5931000 	ldr	r1, [r3]
	cmp r1, #1
70000a64:	e3510001 	cmp	r1, #1
	bhi __EXIT_EXC
70000a68:	8a00000c 	bhi	70000aa0 <__EXIT_EXC>

	/* If the fault is not fatal, return to the current thread context */
	cmp r0, #0
70000a6c:	e3500000 	cmp	r0, #0
	beq __EXIT_EXC
70000a70:	0a00000a 	beq	70000aa0 <__EXIT_EXC>

	/* Clean up exception stack frame */
#if defined(CONFIG_FPU_SHARING)
	add sp, sp, #___fpu_t_SIZEOF
#endif
	add sp, #32
70000a74:	e28dd020 	add	sp, sp, #32
	 *
	 * Note that z_arm_do_swap must be called in the SVC mode because it
	 * switches to the SVC mode during context switch and returns to the
	 * caller using lr_svc.
	 */
	cps #MODE_SVC
70000a78:	f1020013 	cps	#19
	bl z_arm_do_swap
70000a7c:	ebffffa2 	bl	7000090c <z_arm_do_swap>

	/* Decrement exception nesting count */
	get_cpu r3
70000a80:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70000a84:	e3c33003 	bic	r3, r3, #3
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
70000a88:	e5930000 	ldr	r0, [r3]
	sub r0, r0, #1
70000a8c:	e2400001 	sub	r0, r0, #1
	str r0, [r3, #___cpu_t_nested_OFFSET]
70000a90:	e5830000 	str	r0, [r3]

	/* Return to the switched thread */
	cps #MODE_SYS
70000a94:	f102001f 	cps	#31
#if defined(CONFIG_FPU_SHARING)
	fpu_exc_exit
#endif
	pop {r0-r3, r12, lr}
70000a98:	e8bd500f 	pop	{r0, r1, r2, r3, ip, lr}
	userspace_exc_exit
	rfeia sp!
70000a9c:	f8bd0a00 	rfeia	sp!

70000aa0 <__EXIT_EXC>:

__EXIT_EXC:
	/* Decrement exception nesting count */
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
70000aa0:	e5930000 	ldr	r0, [r3]
	sub r0, r0, #1
70000aa4:	e2400001 	sub	r0, r0, #1
	str r0, [r3, #___cpu_t_nested_OFFSET]
70000aa8:	e5830000 	str	r0, [r3]
#endif
	/*
	 * Restore r0-r3, r12, lr, lr_und and spsr_und from the exception stack
	 * and return to the current thread.
	 */
	ldmia sp, {r0-r3, r12, lr}^
70000aac:	e8dd500f 	ldm	sp, {r0, r1, r2, r3, ip, lr}^
	add sp, #24
70000ab0:	e28dd018 	add	sp, sp, #24
	rfeia sp!
70000ab4:	f8bd0a00 	rfeia	sp!
	ldr r2, =_kernel
70000ab8:	70005f18 	.word	0x70005f18

70000abc <z_impl_zephyr_fputc>:
#include "picolibc-hooks.h"

static LIBC_DATA int (*_stdout_hook)(int);

int z_impl_zephyr_fputc(int a, FILE *out)
{
70000abc:	b508      	push	{r3, lr}
	(*_stdout_hook)(a);
70000abe:	4b02      	ldr	r3, [pc, #8]	; (70000ac8 <z_impl_zephyr_fputc+0xc>)
70000ac0:	681b      	ldr	r3, [r3, #0]
70000ac2:	4798      	blx	r3
	return 0;
}
70000ac4:	2000      	movs	r0, #0
70000ac6:	bd08      	pop	{r3, pc}
70000ac8:	70005f04 	.word	0x70005f04

70000acc <__stdout_hook_install>:
FILE *const stdout = &__stdout;
STDIO_ALIAS(stderr);

void __stdout_hook_install(int (*hook)(int))
{
	_stdout_hook = hook;
70000acc:	4b03      	ldr	r3, [pc, #12]	; (70000adc <__stdout_hook_install+0x10>)
	__stdout.flags |= _FDEV_SETUP_WRITE;
70000ace:	4a04      	ldr	r2, [pc, #16]	; (70000ae0 <__stdout_hook_install+0x14>)
	_stdout_hook = hook;
70000ad0:	6018      	str	r0, [r3, #0]
	__stdout.flags |= _FDEV_SETUP_WRITE;
70000ad2:	7893      	ldrb	r3, [r2, #2]
70000ad4:	f043 0302 	orr.w	r3, r3, #2
70000ad8:	7093      	strb	r3, [r2, #2]
}
70000ada:	4770      	bx	lr
70000adc:	70005f04 	.word	0x70005f04
70000ae0:	7000a7f8 	.word	0x7000a7f8

70000ae4 <malloc_prepare>:
			break;
		}
		heap_size >>= 1;
	}
#else
	heap_base = UINT_TO_POINTER(HEAP_BASE);
70000ae4:	4906      	ldr	r1, [pc, #24]	; (70000b00 <malloc_prepare+0x1c>)
	z_malloc_partition.start = POINTER_TO_UINT(heap_base);
	z_malloc_partition.size = heap_size;
	z_malloc_partition.attr = K_MEM_PARTITION_P_RW_U_RW;
#endif

	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
70000ae6:	4807      	ldr	r0, [pc, #28]	; (70000b04 <malloc_prepare+0x20>)
	heap_base = UINT_TO_POINTER(HEAP_BASE);
70000ae8:	f021 0107 	bic.w	r1, r1, #7
	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
70000aec:	f1c1 42e0 	rsb	r2, r1, #1879048192	; 0x70000000
70000af0:	f502 3200 	add.w	r2, r2, #131072	; 0x20000
{
70000af4:	b508      	push	{r3, lr}
	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
70000af6:	f001 fc9a 	bl	7000242e <sys_heap_init>

	return 0;
}
70000afa:	2000      	movs	r0, #0
70000afc:	bd08      	pop	{r3, pc}
70000afe:	bf00      	nop
70000b00:	7000a833 	.word	0x7000a833
70000b04:	70005f08 	.word	0x70005f08

70000b08 <z_vim_irq_get_active>:

static ALWAYS_INLINE uint32_t sys_read32(mem_addr_t addr)
{
	uint32_t val;

	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000b08:	4b0e      	ldr	r3, [pc, #56]	; (70000b44 <z_vim_irq_get_active+0x3c>)
70000b0a:	681b      	ldr	r3, [r3, #0]
  \details Ensures the apparent order of the explicit memory operations before
           and after the instruction, without ensuring their completion.
 */
__STATIC_FORCEINLINE  void __DMB(void)
{
  __ASM volatile ("dmb 0xF":::"memory");
70000b0c:	f3bf 8f5f 	dmb	sy
70000b10:	4b0d      	ldr	r3, [pc, #52]	; (70000b48 <z_vim_irq_get_active+0x40>)
70000b12:	681b      	ldr	r3, [r3, #0]
70000b14:	f3bf 8f5f 	dmb	sy
	actirq = sys_read32(VIM_ACTIRQ);

	/* Check if the irq number is valid, else return invalid irq number.
	 * which will be considered as spurious interrupt
	 */
	if ((actirq & (VIM_ACTIRQ_VALID_MASK)) == 0) {
70000b18:	2b00      	cmp	r3, #0
70000b1a:	db02      	blt.n	70000b22 <z_vim_irq_get_active+0x1a>
		return CONFIG_NUM_IRQS + 1;
70000b1c:	f240 2001 	movw	r0, #513	; 0x201
70000b20:	4770      	bx	lr
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(actirq & VIM_PRIIRQ_NUM_MASK);
70000b22:	f3c3 0009 	ubfx	r0, r3, #0, #10
70000b26:	f3bf 8f5f 	dmb	sy
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(actirq & VIM_PRIIRQ_NUM_MASK);

	/* Ack the interrupt in IRQSTS register */
	sys_write32(BIT(irq_bit_num), VIM_IRQSTS(irq_group_num));
70000b2a:	2201      	movs	r2, #1
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(actirq & VIM_PRIIRQ_NUM_MASK);
70000b2c:	f003 011f 	and.w	r1, r3, #31
	sys_write32(BIT(irq_bit_num), VIM_IRQSTS(irq_group_num));
70000b30:	f403 7378 	and.w	r3, r3, #992	; 0x3e0
70000b34:	408a      	lsls	r2, r1
70000b36:	4905      	ldr	r1, [pc, #20]	; (70000b4c <z_vim_irq_get_active+0x44>)
70000b38:	4419      	add	r1, r3
}

static ALWAYS_INLINE void sys_write32(uint32_t data, mem_addr_t addr)
{
	barrier_dmem_fence_full();
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000b3a:	600a      	str	r2, [r1, #0]

	if (irq_group_num > VIM_MAX_GROUP_NUM) {
70000b3c:	f5b0 7f08 	cmp.w	r0, #544	; 0x220
70000b40:	d2ec      	bcs.n	70000b1c <z_vim_irq_get_active+0x14>
		return (CONFIG_NUM_IRQS + 1);
	}

	return (actirq & VIM_ACTIRQ_NUM_MASK);
}
70000b42:	4770      	bx	lr
70000b44:	2fff0018 	.word	0x2fff0018
70000b48:	2fff0020 	.word	0x2fff0020
70000b4c:	2fff0410 	.word	0x2fff0410

70000b50 <z_vim_irq_eoi>:
70000b50:	f3bf 8f5f 	dmb	sy
70000b54:	4a01      	ldr	r2, [pc, #4]	; (70000b5c <z_vim_irq_eoi+0xc>)
70000b56:	2300      	movs	r3, #0
70000b58:	6013      	str	r3, [r2, #0]

void z_vim_irq_eoi(unsigned int irq)
{
	sys_write32(0, VIM_IRQVEC);
}
70000b5a:	4770      	bx	lr
70000b5c:	2fff0018 	.word	0x2fff0018

70000b60 <z_vim_irq_init>:

void z_vim_irq_init(void)
{
70000b60:	b530      	push	{r4, r5, lr}
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000b62:	4b13      	ldr	r3, [pc, #76]	; (70000bb0 <z_vim_irq_init+0x50>)
70000b64:	681b      	ldr	r3, [r3, #0]
70000b66:	f3bf 8f5f 	dmb	sy
	LOG_DBG("VIM: Number of IRQs = %u\n", num_of_irqs);

	/* make sure all IRQs are initially disabled and cleared */
	for (irq = 0; irq < num_of_irqs; irq+=32)
	{
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
70000b6a:	4812      	ldr	r0, [pc, #72]	; (70000bb4 <z_vim_irq_init+0x54>)
	uint32_t num_of_irqs = sys_read32(VIM_INFO) & VIM_INFO_INTERRUPTS_MASK;
70000b6c:	f3c3 030a 	ubfx	r3, r3, #0, #11
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
70000b70:	4c11      	ldr	r4, [pc, #68]	; (70000bb8 <z_vim_irq_init+0x58>)
	for (irq = 0; irq < num_of_irqs; irq+=32)
70000b72:	2200      	movs	r2, #0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000b74:	f06f 4100 	mvn.w	r1, #2147483648	; 0x80000000
70000b78:	429a      	cmp	r2, r3
70000b7a:	d30f      	bcc.n	70000b9c <z_vim_irq_init+0x3c>
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000b7c:	4a0f      	ldr	r2, [pc, #60]	; (70000bbc <z_vim_irq_init+0x5c>)
70000b7e:	6813      	ldr	r3, [r2, #0]
70000b80:	f3bf 8f5f 	dmb	sy
70000b84:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000b88:	2300      	movs	r3, #0
70000b8a:	6013      	str	r3, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000b8c:	3204      	adds	r2, #4
70000b8e:	6811      	ldr	r1, [r2, #0]
70000b90:	f3bf 8f5f 	dmb	sy
70000b94:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000b98:	6013      	str	r3, [r2, #0]
	/* ACK and clear pending IRQs */
	(void) sys_read32(VIM_IRQVEC);
	sys_write32(0, VIM_IRQVEC);
	(void) sys_read32(VIM_FIQVEC);
	sys_write32(0, VIM_FIQVEC);
}
70000b9a:	bd30      	pop	{r4, r5, pc}
70000b9c:	f3bf 8f5f 	dmb	sy
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
70000ba0:	1815      	adds	r5, r2, r0
70000ba2:	6029      	str	r1, [r5, #0]
70000ba4:	f3bf 8f5f 	dmb	sy
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
70000ba8:	1915      	adds	r5, r2, r4
70000baa:	6029      	str	r1, [r5, #0]
	for (irq = 0; irq < num_of_irqs; irq+=32)
70000bac:	3220      	adds	r2, #32
70000bae:	e7e3      	b.n	70000b78 <z_vim_irq_init+0x18>
70000bb0:	2fff0004 	.word	0x2fff0004
70000bb4:	2fff040c 	.word	0x2fff040c
70000bb8:	2fff0404 	.word	0x2fff0404
70000bbc:	2fff0018 	.word	0x2fff0018

70000bc0 <z_vim_irq_priority_set>:

void z_vim_irq_priority_set(unsigned int irq, unsigned int prio, uint32_t flags)
{
	uint32_t irq_group_num, irq_bit_num, regval;

	if (irq > CONFIG_NUM_IRQS || prio > VIM_PRI_INT_MAX ||
70000bc0:	f5b0 7f00 	cmp.w	r0, #512	; 0x200
{
70000bc4:	b510      	push	{r4, lr}
	if (irq > CONFIG_NUM_IRQS || prio > VIM_PRI_INT_MAX ||
70000bc6:	d820      	bhi.n	70000c0a <z_vim_irq_priority_set+0x4a>
70000bc8:	290f      	cmp	r1, #15
70000bca:	d81e      	bhi.n	70000c0a <z_vim_irq_priority_set+0x4a>
70000bcc:	2a04      	cmp	r2, #4
70000bce:	d001      	beq.n	70000bd4 <z_vim_irq_priority_set+0x14>
	    (flags != IRQ_TYPE_EDGE && flags != IRQ_TYPE_LEVEL)) {
70000bd0:	2a02      	cmp	r2, #2
70000bd2:	d11a      	bne.n	70000c0a <z_vim_irq_priority_set+0x4a>
70000bd4:	f3bf 8f5f 	dmb	sy
		LOG_ERR("%s: Invalid argument irq = %u prio = %u flags = %u\n",
			__func__, irq, prio, flags);
		return;
	}

	sys_write8(prio, VIM_PRI_INT(irq));
70000bd8:	f100 6340 	add.w	r3, r0, #201326592	; 0xc000000
70000bdc:	f5a3 5370 	sub.w	r3, r3, #15360	; 0x3c00
70000be0:	009b      	lsls	r3, r3, #2
	__asm__ volatile("strb %0, [%1]" : : "r" (data), "r" (addr));
70000be2:	7019      	strb	r1, [r3, #0]

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	regval = sys_read32(VIM_INTTYPE(irq_group_num));
70000be4:	4909      	ldr	r1, [pc, #36]	; (70000c0c <z_vim_irq_priority_set+0x4c>)
70000be6:	f020 031f 	bic.w	r3, r0, #31
70000bea:	4419      	add	r1, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000bec:	680b      	ldr	r3, [r1, #0]
70000bee:	f3bf 8f5f 	dmb	sy

	if (flags == IRQ_TYPE_EDGE) {
		regval |= (BIT(irq_bit_num));
70000bf2:	2401      	movs	r4, #1
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
70000bf4:	f000 001f 	and.w	r0, r0, #31
	if (flags == IRQ_TYPE_EDGE) {
70000bf8:	2a04      	cmp	r2, #4
		regval |= (BIT(irq_bit_num));
70000bfa:	fa04 f000 	lsl.w	r0, r4, r0
70000bfe:	bf0c      	ite	eq
70000c00:	4303      	orreq	r3, r0
	} else {
		regval &= ~(BIT(irq_bit_num));
70000c02:	4383      	bicne	r3, r0
70000c04:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000c08:	600b      	str	r3, [r1, #0]
	}

	sys_write32(regval, VIM_INTTYPE(irq_group_num));
}
70000c0a:	bd10      	pop	{r4, pc}
70000c0c:	2fff041c 	.word	0x2fff041c

70000c10 <z_vim_irq_enable>:

void z_vim_irq_enable(unsigned int irq)
{
	uint32_t irq_group_num, irq_bit_num;

	if (irq > CONFIG_NUM_IRQS) {
70000c10:	f5b0 7f00 	cmp.w	r0, #512	; 0x200
70000c14:	d80a      	bhi.n	70000c2c <z_vim_irq_enable+0x1c>
70000c16:	f3bf 8f5f 	dmb	sy
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	sys_write32(BIT(irq_bit_num), VIM_INTR_EN_SET(irq_group_num));
70000c1a:	2301      	movs	r3, #1
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
70000c1c:	f000 021f 	and.w	r2, r0, #31
	sys_write32(BIT(irq_bit_num), VIM_INTR_EN_SET(irq_group_num));
70000c20:	f020 001f 	bic.w	r0, r0, #31
70000c24:	4093      	lsls	r3, r2
70000c26:	4a02      	ldr	r2, [pc, #8]	; (70000c30 <z_vim_irq_enable+0x20>)
70000c28:	4402      	add	r2, r0
70000c2a:	6013      	str	r3, [r2, #0]
}
70000c2c:	4770      	bx	lr
70000c2e:	bf00      	nop
70000c30:	2fff0408 	.word	0x2fff0408

70000c34 <uart_console_init>:
 * @brief Initialize one UART as the console/debug port
 *
 * @return 0 if successful, otherwise failed.
 */
static int uart_console_init(void)
{
70000c34:	b508      	push	{r3, lr}
		union { uintptr_t x; const struct device * val; } parm0 = { .val = dev };
		return (bool) arch_syscall_invoke1(parm0.x, K_SYSCALL_DEVICE_IS_READY);
	}
#endif
	compiler_barrier();
	return z_impl_device_is_ready(dev);
70000c36:	4807      	ldr	r0, [pc, #28]	; (70000c54 <uart_console_init+0x20>)
70000c38:	f001 ffb7 	bl	70002baa <z_impl_device_is_ready>
	if (!device_is_ready(uart_console_dev)) {
70000c3c:	b138      	cbz	r0, 70000c4e <uart_console_init+0x1a>
	__stdout_hook_install(console_out);
70000c3e:	4806      	ldr	r0, [pc, #24]	; (70000c58 <uart_console_init+0x24>)
70000c40:	f7ff ff44 	bl	70000acc <__stdout_hook_install>
	__printk_hook_install(console_out);
70000c44:	4804      	ldr	r0, [pc, #16]	; (70000c58 <uart_console_init+0x24>)
70000c46:	f7ff fce9 	bl	7000061c <__printk_hook_install>
		return -ENODEV;
	}

	uart_console_hook_install();

	return 0;
70000c4a:	2000      	movs	r0, #0
}
70000c4c:	bd08      	pop	{r3, pc}
		return -ENODEV;
70000c4e:	f06f 0012 	mvn.w	r0, #18
70000c52:	e7fb      	b.n	70000c4c <uart_console_init+0x18>
70000c54:	700030c4 	.word	0x700030c4
70000c58:	70000c5d 	.word	0x70000c5d

70000c5c <console_out>:
	if ('\n' == c) {
70000c5c:	280a      	cmp	r0, #10
{
70000c5e:	b538      	push	{r3, r4, r5, lr}
70000c60:	4d07      	ldr	r5, [pc, #28]	; (70000c80 <console_out+0x24>)
70000c62:	4604      	mov	r4, r0
	if ('\n' == c) {
70000c64:	d104      	bne.n	70000c70 <console_out+0x14>

static inline void z_impl_uart_poll_out(const struct device *dev, unsigned char out_char)
{
	const struct uart_driver_api *api = (const struct uart_driver_api *)dev->api;

	api->poll_out(dev, out_char);
70000c66:	68ab      	ldr	r3, [r5, #8]
70000c68:	210d      	movs	r1, #13
70000c6a:	4628      	mov	r0, r5
70000c6c:	685b      	ldr	r3, [r3, #4]
70000c6e:	4798      	blx	r3
70000c70:	68ab      	ldr	r3, [r5, #8]
70000c72:	b2e1      	uxtb	r1, r4
70000c74:	4802      	ldr	r0, [pc, #8]	; (70000c80 <console_out+0x24>)
70000c76:	685b      	ldr	r3, [r3, #4]
70000c78:	4798      	blx	r3
}
70000c7a:	4620      	mov	r0, r4
70000c7c:	bd38      	pop	{r3, r4, r5, pc}
70000c7e:	bf00      	nop
70000c80:	700030c4 	.word	0x700030c4

70000c84 <pinctrl_configure_pins>:

int pinctrl_configure_pins(const pinctrl_soc_pin_t *pins, uint8_t pin_cnt, uintptr_t reg)
{
	ARG_UNUSED(reg);
	const struct device *dev = DEVICE_DT_GET(PINCTRL_NODE);
	uintptr_t virt_reg_base = DEVICE_MMIO_GET(dev);
70000c84:	4b09      	ldr	r3, [pc, #36]	; (70000cac <pinctrl_configure_pins+0x28>)
{
70000c86:	b570      	push	{r4, r5, r6, lr}
	uintptr_t virt_reg_base = DEVICE_MMIO_GET(dev);
70000c88:	681c      	ldr	r4, [r3, #0]

	for (uint8_t i = 0; i < pin_cnt; i++) {
		sys_write32(pins[i].value, virt_reg_base + pins[i].offset);
70000c8a:	1d05      	adds	r5, r0, #4
	for (uint8_t i = 0; i < pin_cnt; i++) {
70000c8c:	2300      	movs	r3, #0
70000c8e:	b2da      	uxtb	r2, r3
70000c90:	4291      	cmp	r1, r2
70000c92:	d801      	bhi.n	70000c98 <pinctrl_configure_pins+0x14>
	}

	return 0;
}
70000c94:	2000      	movs	r0, #0
70000c96:	bd70      	pop	{r4, r5, r6, pc}
		sys_write32(pins[i].value, virt_reg_base + pins[i].offset);
70000c98:	f850 2033 	ldr.w	r2, [r0, r3, lsl #3]
70000c9c:	f855 6033 	ldr.w	r6, [r5, r3, lsl #3]
70000ca0:	4422      	add	r2, r4
70000ca2:	f3bf 8f5f 	dmb	sy
70000ca6:	6016      	str	r6, [r2, #0]
	for (uint8_t i = 0; i < pin_cnt; i++) {
70000ca8:	3301      	adds	r3, #1
70000caa:	e7f0      	b.n	70000c8e <pinctrl_configure_pins+0xa>
70000cac:	7000a808 	.word	0x7000a808

70000cb0 <ti_dmtimer_isr>:
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000cb0:	4a12      	ldr	r2, [pc, #72]	; (70000cfc <ti_dmtimer_isr+0x4c>)
	reg_val = (reg_val & ~(mask)) | (data << shift);
	sys_write32(reg_val, reg);
}

static void ti_dmtimer_isr(void *data)
{
70000cb2:	b430      	push	{r4, r5}
70000cb4:	6813      	ldr	r3, [r2, #0]
70000cb6:	f3bf 8f5f 	dmb	sy
	/* If no pending event */
	if (!TI_DM_TIMER_READ(IRQSTATUS)) {
70000cba:	b1eb      	cbz	r3, 70000cf8 <ti_dmtimer_isr+0x48>
	key = __get_BASEPRI();
	__set_BASEPRI_MAX(_EXC_IRQ_DEFAULT_PRIO);
	__ISB();
#elif defined(CONFIG_ARMV7_R) || defined(CONFIG_AARCH32_ARMV8_R) \
	|| defined(CONFIG_ARMV7_A)
	__asm__ volatile(
70000cbc:	f3ef 8400 	mrs	r4, CPSR
70000cc0:	f004 0480 	and.w	r4, r4, #128	; 0x80
70000cc4:	b672      	cpsid	i
70000cc6:	4b0e      	ldr	r3, [pc, #56]	; (70000d00 <ti_dmtimer_isr+0x50>)
70000cc8:	681b      	ldr	r3, [r3, #0]
70000cca:	f3bf 8f5f 	dmb	sy
	}

	k_spinlock_key_t key = k_spin_lock(&lock);

	uint32_t curr_cycle = TI_DM_TIMER_READ(TCRR);
	uint32_t delta_cycles = curr_cycle - last_cycle;
70000cce:	490d      	ldr	r1, [pc, #52]	; (70000d04 <ti_dmtimer_isr+0x54>)
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70000cd0:	f640 15c4 	movw	r5, #2500	; 0x9c4
	uint32_t delta_cycles = curr_cycle - last_cycle;
70000cd4:	6808      	ldr	r0, [r1, #0]

	last_cycle = curr_cycle;
70000cd6:	600b      	str	r3, [r1, #0]
	uint32_t delta_cycles = curr_cycle - last_cycle;
70000cd8:	1a18      	subs	r0, r3, r0
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70000cda:	fbb0 f0f5 	udiv	r0, r0, r5
70000cde:	6813      	ldr	r3, [r2, #0]
70000ce0:	f3bf 8f5f 	dmb	sy
70000ce4:	f3bf 8f5f 	dmb	sy
	reg_val = (reg_val & ~(mask)) | (data << shift);
70000ce8:	f043 0301 	orr.w	r3, r3, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000cec:	6013      	str	r3, [r2, #0]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	__set_BASEPRI(key);
	__ISB();
#elif defined(CONFIG_ARMV7_R) || defined(CONFIG_AARCH32_ARMV8_R) \
	|| defined(CONFIG_ARMV7_A)
	if (key != 0U) {
70000cee:	b904      	cbnz	r4, 70000cf2 <ti_dmtimer_isr+0x42>
  \details Enables IRQ interrupts by clearing the I-bit in the CPSR.
           Can only be executed in Privileged modes.
 */
__STATIC_FORCEINLINE void __enable_irq(void)
{
  __ASM volatile ("cpsie i" : : : "memory");
70000cf0:	b662      	cpsie	i
	}

	k_spin_unlock(&lock, key);

	sys_clock_announce(delta_ticks);
}
70000cf2:	bc30      	pop	{r4, r5}
	sys_clock_announce(delta_ticks);
70000cf4:	f000 beda 	b.w	70001aac <sys_clock_announce>
}
70000cf8:	bc30      	pop	{r4, r5}
70000cfa:	4770      	bx	lr
70000cfc:	02470028 	.word	0x02470028
70000d00:	0247003c 	.word	0x0247003c
70000d04:	70005f14 	.word	0x70005f14

70000d08 <sys_clock_driver_init>:

	return delta_ticks;
}

static int sys_clock_driver_init(void)
{
70000d08:	b510      	push	{r4, lr}
	last_cycle = 0;
70000d0a:	2400      	movs	r4, #0

	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
70000d0c:	2202      	movs	r2, #2
	last_cycle = 0;
70000d0e:	4b26      	ldr	r3, [pc, #152]	; (70000da8 <sys_clock_driver_init+0xa0>)
	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
70000d10:	210f      	movs	r1, #15
	last_cycle = 0;
70000d12:	601c      	str	r4, [r3, #0]
	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
70000d14:	209f      	movs	r0, #159	; 0x9f
70000d16:	f001 fbdd 	bl	700024d4 <z_soc_irq_priority_set>
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000d1a:	4b24      	ldr	r3, [pc, #144]	; (70000dac <sys_clock_driver_init+0xa4>)
70000d1c:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70000d1e:	f3bf 8f5f 	dmb	sy
70000d22:	f3bf 8f5f 	dmb	sy
	reg_val = (reg_val & ~(mask)) | (data << shift);
70000d26:	f022 0220 	bic.w	r2, r2, #32
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000d2a:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000d2c:	681a      	ldr	r2, [r3, #0]
70000d2e:	f3bf 8f5f 	dmb	sy
70000d32:	f3bf 8f5f 	dmb	sy
70000d36:	f042 0202 	orr.w	r2, r2, #2
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000d3a:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000d3c:	491c      	ldr	r1, [pc, #112]	; (70000db0 <sys_clock_driver_init+0xa8>)
70000d3e:	680a      	ldr	r2, [r1, #0]
70000d40:	f3bf 8f5f 	dmb	sy
70000d44:	f3bf 8f5f 	dmb	sy
70000d48:	f042 0201 	orr.w	r2, r2, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000d4c:	600a      	str	r2, [r1, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000d4e:	4a19      	ldr	r2, [pc, #100]	; (70000db4 <sys_clock_driver_init+0xac>)
70000d50:	6811      	ldr	r1, [r2, #0]
70000d52:	f3bf 8f5f 	dmb	sy
70000d56:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000d5a:	6014      	str	r4, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000d5c:	3204      	adds	r2, #4
70000d5e:	6811      	ldr	r1, [r2, #0]
70000d60:	f3bf 8f5f 	dmb	sy
70000d64:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000d68:	6014      	str	r4, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000d6a:	320c      	adds	r2, #12
70000d6c:	6811      	ldr	r1, [r2, #0]
70000d6e:	f3bf 8f5f 	dmb	sy
70000d72:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000d76:	f640 11c4 	movw	r1, #2500	; 0x9c4
70000d7a:	6011      	str	r1, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000d7c:	681a      	ldr	r2, [r3, #0]
70000d7e:	f3bf 8f5f 	dmb	sy
70000d82:	f3bf 8f5f 	dmb	sy
70000d86:	f042 0240 	orr.w	r2, r2, #64	; 0x40
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000d8a:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000d8c:	681a      	ldr	r2, [r3, #0]
70000d8e:	f3bf 8f5f 	dmb	sy
70000d92:	f3bf 8f5f 	dmb	sy
70000d96:	f042 0201 	orr.w	r2, r2, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000d9a:	601a      	str	r2, [r3, #0]
	TI_DM_TIMER_WRITE(1, TCLR, CE);

	/* Start the timer */
	TI_DM_TIMER_WRITE(1, TCLR, ST);

	irq_enable(TIMER_IRQ_NUM);
70000d9c:	209f      	movs	r0, #159	; 0x9f
70000d9e:	f001 fb9b 	bl	700024d8 <z_soc_irq_enable>

	return 0;
}
70000da2:	4620      	mov	r0, r4
70000da4:	bd10      	pop	{r4, pc}
70000da6:	bf00      	nop
70000da8:	70005f14 	.word	0x70005f14
70000dac:	02470038 	.word	0x02470038
70000db0:	0247002c 	.word	0x0247002c
70000db4:	0247003c 	.word	0x0247003c

70000db8 <sys_clock_set_timeout>:
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
70000db8:	1c43      	adds	r3, r0, #1
{
70000dba:	b510      	push	{r4, lr}
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
70000dbc:	d003      	beq.n	70000dc6 <sys_clock_set_timeout+0xe>
	ticks = CLAMP(ticks, 1, (int32_t)MAX_TICKS);
70000dbe:	2801      	cmp	r0, #1
70000dc0:	dc02      	bgt.n	70000dc8 <sys_clock_set_timeout+0x10>
70000dc2:	2001      	movs	r0, #1
70000dc4:	e004      	b.n	70000dd0 <sys_clock_set_timeout+0x18>
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
70000dc6:	480e      	ldr	r0, [pc, #56]	; (70000e00 <sys_clock_set_timeout+0x48>)
	ticks = CLAMP(ticks, 1, (int32_t)MAX_TICKS);
70000dc8:	4b0d      	ldr	r3, [pc, #52]	; (70000e00 <sys_clock_set_timeout+0x48>)
70000dca:	4298      	cmp	r0, r3
70000dcc:	bfa8      	it	ge
70000dce:	4618      	movge	r0, r3
	__asm__ volatile(
70000dd0:	f3ef 8100 	mrs	r1, CPSR
70000dd4:	f001 0180 	and.w	r1, r1, #128	; 0x80
70000dd8:	b672      	cpsid	i
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000dda:	4b0a      	ldr	r3, [pc, #40]	; (70000e04 <sys_clock_set_timeout+0x4c>)
70000ddc:	681b      	ldr	r3, [r3, #0]
70000dde:	f3bf 8f5f 	dmb	sy
70000de2:	4a09      	ldr	r2, [pc, #36]	; (70000e08 <sys_clock_set_timeout+0x50>)
70000de4:	6814      	ldr	r4, [r2, #0]
70000de6:	f3bf 8f5f 	dmb	sy
70000dea:	f3bf 8f5f 	dmb	sy
	uint32_t next_cycle = curr_cycle + (ticks * CYC_PER_TICK);
70000dee:	f640 14c4 	movw	r4, #2500	; 0x9c4
70000df2:	fb04 3300 	mla	r3, r4, r0, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70000df6:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
70000df8:	b901      	cbnz	r1, 70000dfc <sys_clock_set_timeout+0x44>
  __ASM volatile ("cpsie i" : : : "memory");
70000dfa:	b662      	cpsie	i
}
70000dfc:	bd10      	pop	{r4, pc}
70000dfe:	bf00      	nop
70000e00:	001a36e1 	.word	0x001a36e1
70000e04:	0247003c 	.word	0x0247003c
70000e08:	0247004c 	.word	0x0247004c

70000e0c <sys_clock_elapsed>:
	__asm__ volatile(
70000e0c:	f3ef 8300 	mrs	r3, CPSR
70000e10:	f003 0380 	and.w	r3, r3, #128	; 0x80
70000e14:	b672      	cpsid	i
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70000e16:	4807      	ldr	r0, [pc, #28]	; (70000e34 <sys_clock_elapsed+0x28>)
70000e18:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70000e1a:	f3bf 8f5f 	dmb	sy
	uint32_t delta_cycles = curr_cycle - last_cycle;
70000e1e:	4a06      	ldr	r2, [pc, #24]	; (70000e38 <sys_clock_elapsed+0x2c>)
70000e20:	6812      	ldr	r2, [r2, #0]
70000e22:	1a80      	subs	r0, r0, r2
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70000e24:	f640 12c4 	movw	r2, #2500	; 0x9c4
70000e28:	fbb0 f0f2 	udiv	r0, r0, r2
	if (key != 0U) {
70000e2c:	b903      	cbnz	r3, 70000e30 <sys_clock_elapsed+0x24>
  __ASM volatile ("cpsie i" : : : "memory");
70000e2e:	b662      	cpsie	i
}
70000e30:	4770      	bx	lr
70000e32:	bf00      	nop
70000e34:	0247003c 	.word	0x0247003c
70000e38:	70005f14 	.word	0x70005f14

70000e3c <z_fatal_error>:
	arch_system_halt(reason);
}
/* LCOV_EXCL_STOP */

void z_fatal_error(unsigned int reason, const struct arch_esf *esf)
{
70000e3c:	b538      	push	{r3, r4, r5, lr}
	__asm__ volatile(
70000e3e:	f3ef 8500 	mrs	r5, CPSR
70000e42:	f005 0580 	and.w	r5, r5, #128	; 0x80
70000e46:	b672      	cpsid	i

	struct k_thread *ret = _current_cpu->current;

	arch_irq_unlock(k);
#else
	struct k_thread *ret = _kernel.cpus[0].current;
70000e48:	4a09      	ldr	r2, [pc, #36]	; (70000e70 <z_fatal_error+0x34>)
70000e4a:	6894      	ldr	r4, [r2, #8]
	 * an IRQ or exception was being handled, or thread context.
	 *
	 * See #17656
	 */
#if defined(CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION)
	if ((esf != NULL) && arch_is_in_nested_exception(esf)) {
70000e4c:	b941      	cbnz	r1, 70000e60 <z_fatal_error+0x24>
		LOG_ERR("Current thread: %p (%s)", thread, thread_name_get(thread));
	}

	coredump(reason, esf, thread);

	k_sys_fatal_error_handler(reason, esf);
70000e4e:	f001 febd 	bl	70002bcc <k_sys_fatal_error_handler>
	if (key != 0U) {
70000e52:	b905      	cbnz	r5, 70000e56 <z_fatal_error+0x1a>
70000e54:	b662      	cpsie	i
70000e56:	4620      	mov	r0, r4
	arch_irq_unlock(key);

	if (IS_ENABLED(CONFIG_MULTITHREADING)) {
		k_thread_abort(thread);
	}
}
70000e58:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
70000e5c:	f001 bfc0 	b.w	70002de0 <z_impl_k_thread_abort>
70000e60:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
	k_sys_fatal_error_handler(reason, esf);
70000e64:	f001 feb2 	bl	70002bcc <k_sys_fatal_error_handler>
70000e68:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70000e6c:	e7f1      	b.n	70000e52 <z_fatal_error+0x16>
70000e6e:	bf00      	nop
70000e70:	70005f18 	.word	0x70005f18

70000e74 <z_sys_init_run_level>:
 * off and the next one begins.
 *
 * @param level init level to run.
 */
static void z_sys_init_run_level(enum init_level level)
{
70000e74:	b538      	push	{r3, r4, r5, lr}
		/* End marker */
		__init_end,
	};
	const struct init_entry *entry;

	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70000e76:	4b09      	ldr	r3, [pc, #36]	; (70000e9c <z_sys_init_run_level+0x28>)
70000e78:	f853 4020 	ldr.w	r4, [r3, r0, lsl #2]
70000e7c:	3001      	adds	r0, #1
70000e7e:	f853 5020 	ldr.w	r5, [r3, r0, lsl #2]
70000e82:	42a5      	cmp	r5, r4
70000e84:	d800      	bhi.n	70000e88 <z_sys_init_run_level+0x14>
		} else {
			result = entry->init_fn.sys();
		}
		sys_trace_sys_init_exit(entry, level, result);
	}
}
70000e86:	bd38      	pop	{r3, r4, r5, pc}
		if (dev != NULL) {
70000e88:	6863      	ldr	r3, [r4, #4]
70000e8a:	b123      	cbz	r3, 70000e96 <z_sys_init_run_level+0x22>
			result = do_device_init(entry);
70000e8c:	4620      	mov	r0, r4
70000e8e:	f001 fea0 	bl	70002bd2 <do_device_init>
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70000e92:	3408      	adds	r4, #8
70000e94:	e7f5      	b.n	70000e82 <z_sys_init_run_level+0xe>
			result = entry->init_fn.sys();
70000e96:	6823      	ldr	r3, [r4, #0]
70000e98:	4798      	blx	r3
70000e9a:	e7fa      	b.n	70000e92 <z_sys_init_run_level+0x1e>
70000e9c:	70004198 	.word	0x70004198

70000ea0 <bg_thread_main>:
	 * may perform memory management tasks (except for
	 * k_mem_map_phys_bare() which is allowed at any time)
	 */
	z_mem_manage_init();
#endif /* CONFIG_MMU */
	z_sys_post_kernel = true;
70000ea0:	2201      	movs	r2, #1

#if CONFIG_IRQ_OFFLOAD
	arch_irq_offload_init();
#endif
	z_sys_init_run_level(INIT_LEVEL_POST_KERNEL);
70000ea2:	2003      	movs	r0, #3
{
70000ea4:	b570      	push	{r4, r5, r6, lr}
	z_sys_post_kernel = true;
70000ea6:	4b2a      	ldr	r3, [pc, #168]	; (70000f50 <bg_thread_main+0xb0>)
{
70000ea8:	b086      	sub	sp, #24
	z_sys_post_kernel = true;
70000eaa:	701a      	strb	r2, [r3, #0]
	z_sys_init_run_level(INIT_LEVEL_POST_KERNEL);
70000eac:	f7ff ffe2 	bl	70000e74 <z_sys_init_run_level>
#endif

#if defined(CONFIG_STACK_POINTER_RANDOM) && (CONFIG_STACK_POINTER_RANDOM != 0)
	z_stack_adjust_initialized = 1;
#endif /* CONFIG_STACK_POINTER_RANDOM */
	boot_banner();
70000eb0:	f000 fe72 	bl	70001b98 <boot_banner>

	void z_init_static(void);
	z_init_static();
70000eb4:	f001 fea7 	bl	70002c06 <z_init_static>

	/* Final init level before app starts */
	z_sys_init_run_level(INIT_LEVEL_APPLICATION);
70000eb8:	4c26      	ldr	r4, [pc, #152]	; (70000f54 <bg_thread_main+0xb4>)
70000eba:	2004      	movs	r0, #4
70000ebc:	f7ff ffda 	bl	70000e74 <z_sys_init_run_level>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70000ec0:	4d25      	ldr	r5, [pc, #148]	; (70000f58 <bg_thread_main+0xb8>)
70000ec2:	4626      	mov	r6, r4
70000ec4:	3430      	adds	r4, #48	; 0x30
70000ec6:	42ae      	cmp	r6, r5
70000ec8:	d310      	bcc.n	70000eec <bg_thread_main+0x4c>
	k_sched_lock();
70000eca:	f000 fbc5 	bl	70001658 <k_sched_lock>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70000ece:	4c21      	ldr	r4, [pc, #132]	; (70000f54 <bg_thread_main+0xb4>)

extern void z_thread_timeout(struct _timeout *timeout);

static inline void z_add_thread_timeout(struct k_thread *thread, k_timeout_t ticks)
{
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
70000ed0:	4e22      	ldr	r6, [pc, #136]	; (70000f5c <bg_thread_main+0xbc>)
70000ed2:	42ac      	cmp	r4, r5
70000ed4:	d326      	bcc.n	70000f24 <bg_thread_main+0x84>
	k_sched_unlock();
70000ed6:	f000 fbcf 	bl	70001678 <k_sched_unlock>
	char **argv = prepare_main_args(&argc);
	(void)main(argc, argv);
#else
	extern int main(void);

	(void)main();
70000eda:	f001 fa4e 	bl	7000237a <main>
 * Exceptions raised by this thread may be recoverable.
 * (This is the default tag for a thread.)
 */
static inline void z_thread_essential_clear(struct k_thread *thread)
{
	thread->base.user_options &= ~K_ESSENTIAL;
70000ede:	4a20      	ldr	r2, [pc, #128]	; (70000f60 <bg_thread_main+0xc0>)
70000ee0:	7b13      	ldrb	r3, [r2, #12]
70000ee2:	f023 0301 	bic.w	r3, r3, #1
70000ee6:	7313      	strb	r3, [r2, #12]

#ifdef CONFIG_COVERAGE_DUMP
	/* Dump coverage data once the main() has exited. */
	gcov_coverage_dump();
#endif /* CONFIG_COVERAGE_DUMP */
} /* LCOV_EXCL_LINE ... because we just dumped final coverage data */
70000ee8:	b006      	add	sp, #24
70000eea:	bd70      	pop	{r4, r5, r6, pc}
		z_setup_new_thread(
70000eec:	f854 3c0c 	ldr.w	r3, [r4, #-12]
70000ef0:	9305      	str	r3, [sp, #20]
70000ef2:	f854 3c10 	ldr.w	r3, [r4, #-16]
70000ef6:	9304      	str	r3, [sp, #16]
70000ef8:	f854 3c14 	ldr.w	r3, [r4, #-20]
70000efc:	9303      	str	r3, [sp, #12]
70000efe:	f854 3c18 	ldr.w	r3, [r4, #-24]
70000f02:	9302      	str	r3, [sp, #8]
70000f04:	f854 3c1c 	ldr.w	r3, [r4, #-28]
70000f08:	9301      	str	r3, [sp, #4]
70000f0a:	f854 3c20 	ldr.w	r3, [r4, #-32]
70000f0e:	9300      	str	r3, [sp, #0]
70000f10:	e954 230a 	ldrd	r2, r3, [r4, #-40]	; 0x28
70000f14:	e954 010c 	ldrd	r0, r1, [r4, #-48]	; 0x30
70000f18:	f000 f94a 	bl	700011b0 <z_setup_new_thread>
		thread_data->init_thread->init_data = thread_data;
70000f1c:	f854 3c30 	ldr.w	r3, [r4, #-48]
70000f20:	655e      	str	r6, [r3, #84]	; 0x54
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70000f22:	e7ce      	b.n	70000ec2 <bg_thread_main+0x22>
		k_timeout_t init_delay = Z_THREAD_INIT_DELAY(thread_data);
70000f24:	e9d4 230a 	ldrd	r2, r3, [r4, #40]	; 0x28
		if (!K_TIMEOUT_EQ(init_delay, K_FOREVER)) {
70000f28:	f1b3 3fff 	cmp.w	r3, #4294967295	; 0xffffffff
70000f2c:	bf08      	it	eq
70000f2e:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
70000f32:	d005      	beq.n	70000f40 <bg_thread_main+0xa0>
			thread_schedule_new(thread_data->init_thread,
70000f34:	6820      	ldr	r0, [r4, #0]
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
70000f36:	ea52 0103 	orrs.w	r1, r2, r3
70000f3a:	d103      	bne.n	70000f44 <bg_thread_main+0xa4>
	z_impl_k_wakeup(thread);
70000f3c:	f000 fc4a 	bl	700017d4 <z_impl_k_wakeup>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70000f40:	3430      	adds	r4, #48	; 0x30
70000f42:	e7c6      	b.n	70000ed2 <bg_thread_main+0x32>
70000f44:	4631      	mov	r1, r6
70000f46:	3018      	adds	r0, #24
70000f48:	f000 fd3e 	bl	700019c8 <z_add_timeout>
70000f4c:	e7f8      	b.n	70000f40 <bg_thread_main+0xa0>
70000f4e:	bf00      	nop
70000f50:	7000634c 	.word	0x7000634c
70000f54:	700040d8 	.word	0x700040d8
70000f58:	70004108 	.word	0x70004108
70000f5c:	70002d57 	.word	0x70002d57
70000f60:	70004970 	.word	0x70004970

70000f64 <z_bss_zero>:
	z_early_memset(__bss_start, 0, __bss_end - __bss_start);
70000f64:	4803      	ldr	r0, [pc, #12]	; (70000f74 <z_bss_zero+0x10>)
70000f66:	2100      	movs	r1, #0
70000f68:	4a03      	ldr	r2, [pc, #12]	; (70000f78 <z_bss_zero+0x14>)
{
70000f6a:	b508      	push	{r3, lr}
	z_early_memset(__bss_start, 0, __bss_end - __bss_start);
70000f6c:	1a12      	subs	r2, r2, r0
70000f6e:	f001 fe48 	bl	70002c02 <z_early_memset>
}
70000f72:	bd08      	pop	{r3, pc}
70000f74:	700043d0 	.word	0x700043d0
70000f78:	70006350 	.word	0x70006350

70000f7c <z_init_cpu>:
	thread->base.is_idle = 1U;
#endif /* CONFIG_SMP */
}

void z_init_cpu(int id)
{
70000f7c:	b570      	push	{r4, r5, r6, lr}
	struct k_thread *thread = &z_idle_threads[i];
70000f7e:	4e14      	ldr	r6, [pc, #80]	; (70000fd0 <z_init_cpu+0x54>)
70000f80:	2378      	movs	r3, #120	; 0x78
	z_setup_new_thread(thread, stack,
70000f82:	2201      	movs	r2, #1
{
70000f84:	b086      	sub	sp, #24
			  stack_size, idle, &_kernel.cpus[i],
70000f86:	4d13      	ldr	r5, [pc, #76]	; (70000fd4 <z_init_cpu+0x58>)
{
70000f88:	4604      	mov	r4, r0
	struct k_thread *thread = &z_idle_threads[i];
70000f8a:	fb03 6600 	mla	r6, r3, r0, r6
	z_setup_new_thread(thread, stack,
70000f8e:	4912      	ldr	r1, [pc, #72]	; (70000fd8 <z_init_cpu+0x5c>)
70000f90:	2300      	movs	r3, #0
70000f92:	e9cd 2304 	strd	r2, r3, [sp, #16]
70000f96:	220f      	movs	r2, #15
70000f98:	9301      	str	r3, [sp, #4]
70000f9a:	eb01 2100 	add.w	r1, r1, r0, lsl #8
70000f9e:	e9cd 3202 	strd	r3, r2, [sp, #8]
			  stack_size, idle, &_kernel.cpus[i],
70000fa2:	2314      	movs	r3, #20
	z_setup_new_thread(thread, stack,
70000fa4:	f44f 7280 	mov.w	r2, #256	; 0x100
			  stack_size, idle, &_kernel.cpus[i],
70000fa8:	fb03 5500 	mla	r5, r3, r0, r5
	z_setup_new_thread(thread, stack,
70000fac:	4b0b      	ldr	r3, [pc, #44]	; (70000fdc <z_init_cpu+0x60>)
70000fae:	4630      	mov	r0, r6
70000fb0:	9500      	str	r5, [sp, #0]
70000fb2:	f000 f8fd 	bl	700011b0 <z_setup_new_thread>
	thread->base.thread_state &= ~_THREAD_SLEEPING;
70000fb6:	7b73      	ldrb	r3, [r6, #13]
	init_idle_thread(id);
	_kernel.cpus[id].idle_thread = &z_idle_threads[id];
	_kernel.cpus[id].id = id;
70000fb8:	742c      	strb	r4, [r5, #16]
70000fba:	f023 0304 	bic.w	r3, r3, #4
	_kernel.cpus[id].idle_thread = &z_idle_threads[id];
70000fbe:	60ee      	str	r6, [r5, #12]
	_kernel.cpus[id].irq_stack =
		(K_KERNEL_STACK_BUFFER(z_interrupt_stacks[id]) +
70000fc0:	3401      	adds	r4, #1
70000fc2:	7373      	strb	r3, [r6, #13]
70000fc4:	4b06      	ldr	r3, [pc, #24]	; (70000fe0 <z_init_cpu+0x64>)
70000fc6:	eb03 23c4 	add.w	r3, r3, r4, lsl #11
	_kernel.cpus[id].irq_stack =
70000fca:	606b      	str	r3, [r5, #4]
	k_obj_core_stats_register(K_OBJ_CORE(&_kernel.cpus[id]),
				  _kernel.cpus[id].usage,
				  sizeof(struct k_cycle_stats));
#endif
#endif
}
70000fcc:	b006      	add	sp, #24
70000fce:	bd70      	pop	{r4, r5, r6, pc}
70000fd0:	700048f8 	.word	0x700048f8
70000fd4:	70005f18 	.word	0x70005f18
70000fd8:	70009e50 	.word	0x70009e50
70000fdc:	70002c3d 	.word	0x70002c3d
70000fe0:	70009650 	.word	0x70009650

70000fe4 <z_cstart>:
 * @return Does not return
 */
__boot_func
FUNC_NO_STACK_PROTECTOR
FUNC_NORETURN void z_cstart(void)
{
70000fe4:	b57f      	push	{r0, r1, r2, r3, r4, r5, r6, lr}
	/* gcov hook needed to get the coverage report.*/
	gcov_static_init();

	/* initialize early init calls */
	z_sys_init_run_level(INIT_LEVEL_EARLY);
70000fe6:	2000      	movs	r0, #0
	dummy_thread->mem_domain_info.mem_domain = &k_mem_domain_default;
#endif /* CONFIG_USERSPACE */
#if (K_HEAP_MEM_POOL_SIZE > 0)
	k_thread_system_pool_assign(dummy_thread);
#else
	dummy_thread->resource_pool = NULL;
70000fe8:	2400      	movs	r4, #0
70000fea:	f7ff ff43 	bl	70000e74 <z_sys_init_run_level>
	return ret;
}

static ALWAYS_INLINE void arch_current_thread_set(struct k_thread *thread)
{
	_current_cpu->current = thread;
70000fee:	4e1c      	ldr	r6, [pc, #112]	; (70001060 <z_cstart+0x7c>)
	dummy_thread->base.user_options = K_ESSENTIAL;
70000ff0:	4b1c      	ldr	r3, [pc, #112]	; (70001064 <z_cstart+0x80>)
70000ff2:	f240 1201 	movw	r2, #257	; 0x101
	dummy_thread->resource_pool = NULL;
70000ff6:	665c      	str	r4, [r3, #100]	; 0x64
	dummy_thread->base.user_options = K_ESSENTIAL;
70000ff8:	819a      	strh	r2, [r3, #12]
70000ffa:	60b3      	str	r3, [r6, #8]

#if defined(CONFIG_MULTITHREADING)
	z_dummy_thread_init(&_thread_dummy);
#endif /* CONFIG_MULTITHREADING */
	/* do any necessary initialization of static devices */
	z_device_state_init();
70000ffc:	f001 fdd4 	bl	70002ba8 <z_device_state_init>
	_kernel.ready_q.cache = &z_main_thread;
70001000:	4d19      	ldr	r5, [pc, #100]	; (70001068 <z_cstart+0x84>)
#endif
#if CONFIG_BOARD_EARLY_INIT_HOOK
	board_early_init_hook();
#endif
	/* perform basic hardware initialization */
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_1);
70001002:	2001      	movs	r0, #1
70001004:	f7ff ff36 	bl	70000e74 <z_sys_init_run_level>
#if defined(CONFIG_SMP)
	arch_smp_init();
#endif
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_2);
70001008:	2002      	movs	r0, #2
7000100a:	f7ff ff33 	bl	70000e74 <z_sys_init_run_level>
	z_sched_init();
7000100e:	f000 fb5b 	bl	700016c8 <z_sched_init>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001012:	4b16      	ldr	r3, [pc, #88]	; (7000106c <z_cstart+0x88>)
70001014:	f44f 6280 	mov.w	r2, #1024	; 0x400
70001018:	9305      	str	r3, [sp, #20]
7000101a:	2301      	movs	r3, #1
7000101c:	4914      	ldr	r1, [pc, #80]	; (70001070 <z_cstart+0x8c>)
7000101e:	4628      	mov	r0, r5
70001020:	e9cd 4303 	strd	r4, r3, [sp, #12]
70001024:	e9cd 4401 	strd	r4, r4, [sp, #4]
70001028:	4b12      	ldr	r3, [pc, #72]	; (70001074 <z_cstart+0x90>)
7000102a:	9400      	str	r4, [sp, #0]
	_kernel.ready_q.cache = &z_main_thread;
7000102c:	6175      	str	r5, [r6, #20]
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
7000102e:	f000 f8bf 	bl	700011b0 <z_setup_new_thread>
70001032:	7b6b      	ldrb	r3, [r5, #13]
	z_ready_thread(&z_main_thread);
70001034:	4628      	mov	r0, r5
70001036:	f023 0304 	bic.w	r3, r3, #4
7000103a:	736b      	strb	r3, [r5, #13]
7000103c:	f001 fe5a 	bl	70002cf4 <z_ready_thread>
	z_init_cpu(0);
70001040:	4620      	mov	r0, r4
70001042:	f7ff ff9b 	bl	70000f7c <z_init_cpu>
	__asm__ volatile(
70001046:	f3ef 8200 	mrs	r2, CPSR
7000104a:	f002 0280 	and.w	r2, r2, #128	; 0x80
7000104e:	b672      	cpsid	i
	struct k_thread *ret = _kernel.cpus[0].current;
70001050:	68b3      	ldr	r3, [r6, #8]
#ifndef CONFIG_USE_SWITCH

static ALWAYS_INLINE int arch_swap(unsigned int key)
{
	/* store off key and return value */
	arch_current_thread()->arch.basepri = key;
70001052:	66da      	str	r2, [r3, #108]	; 0x6c
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
70001054:	f06f 020a 	mvn.w	r2, #10
70001058:	671a      	str	r2, [r3, #112]	; 0x70

	z_arm_cortex_r_svc();
7000105a:	f7ff ecce 	blx	700009f8 <z_arm_cortex_r_svc>
7000105e:	b662      	cpsie	i
	CODE_UNREACHABLE; /* LCOV_EXCL_LINE */
70001060:	70005f18 	.word	0x70005f18
70001064:	700049e8 	.word	0x700049e8
70001068:	70004970 	.word	0x70004970
7000106c:	70004378 	.word	0x70004378
70001070:	70009f50 	.word	0x70009f50
70001074:	70000ea1 	.word	0x70000ea1

70001078 <init_mem_slab_obj_core_list>:
 * Perform any initialization that wasn't done at build time.
 *
 * @return 0 on success, fails otherwise.
 */
static int init_mem_slab_obj_core_list(void)
{
70001078:	b538      	push	{r3, r4, r5, lr}
#endif /* CONFIG_OBJ_CORE_STATS_MEM_SLAB */
#endif /* CONFIG_OBJ_CORE_MEM_SLAB */

	/* Initialize statically defined mem_slabs */

	STRUCT_SECTION_FOREACH(k_mem_slab, slab) {
7000107a:	4c06      	ldr	r4, [pc, #24]	; (70001094 <init_mem_slab_obj_core_list+0x1c>)
	int rc = 0;
7000107c:	2000      	movs	r0, #0
	STRUCT_SECTION_FOREACH(k_mem_slab, slab) {
7000107e:	4d06      	ldr	r5, [pc, #24]	; (70001098 <init_mem_slab_obj_core_list+0x20>)
70001080:	42ac      	cmp	r4, r5
70001082:	d300      	bcc.n	70001086 <init_mem_slab_obj_core_list+0xe>
#endif /* CONFIG_OBJ_CORE_MEM_SLAB */
	}

out:
	return rc;
}
70001084:	bd38      	pop	{r3, r4, r5, pc}
		rc = create_free_list(slab);
70001086:	4620      	mov	r0, r4
70001088:	f001 fdbe 	bl	70002c08 <create_free_list>
		if (rc < 0) {
7000108c:	2800      	cmp	r0, #0
7000108e:	dbf9      	blt.n	70001084 <init_mem_slab_obj_core_list+0xc>
	STRUCT_SECTION_FOREACH(k_mem_slab, slab) {
70001090:	341c      	adds	r4, #28
70001092:	e7f5      	b.n	70001080 <init_mem_slab_obj_core_list+0x8>
70001094:	7000a82c 	.word	0x7000a82c
70001098:	7000a82c 	.word	0x7000a82c

7000109c <z_impl_k_msgq_put>:
	return 0;
}


int z_impl_k_msgq_put(struct k_msgq *msgq, const void *data, k_timeout_t timeout)
{
7000109c:	e92d 41f3 	stmdb	sp!, {r0, r1, r4, r5, r6, r7, r8, lr}
700010a0:	4604      	mov	r4, r0
700010a2:	460e      	mov	r6, r1

	struct k_thread *pending_thread;
	k_spinlock_key_t key;
	int result;

	key = k_spin_lock(&msgq->lock);
700010a4:	f100 0708 	add.w	r7, r0, #8
700010a8:	f3ef 8800 	mrs	r8, CPSR
700010ac:	f008 0880 	and.w	r8, r8, #128	; 0x80
700010b0:	b672      	cpsid	i

	SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_msgq, put, msgq, timeout);

	if (msgq->used_msgs < msgq->max_msgs) {
700010b2:	6a00      	ldr	r0, [r0, #32]
700010b4:	68e1      	ldr	r1, [r4, #12]
700010b6:	4288      	cmp	r0, r1
700010b8:	d231      	bcs.n	7000111e <z_impl_k_msgq_put+0x82>
 * @return true if empty, false otherwise
 */

static inline bool sys_dlist_is_empty(sys_dlist_t *list)
{
	return list->head == list;
700010ba:	6825      	ldr	r5, [r4, #0]
 * @return a pointer to the head element, NULL if list is empty
 */

static inline sys_dnode_t *sys_dlist_peek_head(sys_dlist_t *list)
{
	return sys_dlist_is_empty(list) ? NULL : list->head;
700010bc:	42ac      	cmp	r4, r5
700010be:	d016      	beq.n	700010ee <z_impl_k_msgq_put+0x52>
	__ASSERT_EVAL(, int key = arch_irq_lock(); arch_irq_unlock(key),
		      !arch_irq_unlocked(key), "");

	LOCK_SCHED_SPINLOCK {
		thread = _priq_wait_best(&wait_q->waitq);
		if (unlikely(thread != NULL)) {
700010c0:	b1ad      	cbz	r5, 700010ee <z_impl_k_msgq_put+0x52>
			unpend_thread_no_timeout(thread);
700010c2:	4628      	mov	r0, r5
700010c4:	f001 fdc3 	bl	70002c4e <unpend_thread_no_timeout>
}

static inline int z_abort_thread_timeout(struct k_thread *thread)
{
	return z_abort_timeout(&thread->base.timeout);
700010c8:	f105 0018 	add.w	r0, r5, #24
700010cc:	f001 fea8 	bl	70002e20 <z_abort_timeout>
		pending_thread = z_unpend_first_thread(&msgq->wait_q);
		if (unlikely(pending_thread != NULL)) {
			SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_msgq, put, msgq, timeout, 0);

			/* give message to waiting thread */
			(void)memcpy(pending_thread->base.swap_data, data,
700010d0:	68a2      	ldr	r2, [r4, #8]
}

static ALWAYS_INLINE void
arch_thread_return_value_set(struct k_thread *thread, unsigned int value)
{
	thread->arch.swap_return_value = value;
700010d2:	2400      	movs	r4, #0
700010d4:	4631      	mov	r1, r6
700010d6:	6968      	ldr	r0, [r5, #20]
700010d8:	f001 ff3c 	bl	70002f54 <memcpy>
700010dc:	672c      	str	r4, [r5, #112]	; 0x70
			       msgq->msg_size);
			/* wake up waiting thread */
			arch_thread_return_value_set(pending_thread, 0);
			z_ready_thread(pending_thread);
700010de:	4628      	mov	r0, r5
700010e0:	f001 fe08 	bl	70002cf4 <z_ready_thread>
		return result;
	}

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_msgq, put, msgq, timeout, result);

	z_reschedule(&msgq->lock, key);
700010e4:	4641      	mov	r1, r8
700010e6:	4638      	mov	r0, r7
700010e8:	f000 fa78 	bl	700015dc <z_reschedule>

	return result;
700010ec:	e025      	b.n	7000113a <z_impl_k_msgq_put+0x9e>
			(void)memcpy(msgq->write_ptr, (char *)data, msgq->msg_size);
700010ee:	68a2      	ldr	r2, [r4, #8]
700010f0:	4631      	mov	r1, r6
700010f2:	69e0      	ldr	r0, [r4, #28]
700010f4:	f001 ff2e 	bl	70002f54 <memcpy>
			msgq->write_ptr += msgq->msg_size;
700010f8:	69e3      	ldr	r3, [r4, #28]
700010fa:	68a2      	ldr	r2, [r4, #8]
	z_handle_obj_poll_events(&msgq->poll_events, state);
700010fc:	f104 0024 	add.w	r0, r4, #36	; 0x24
70001100:	2110      	movs	r1, #16
			msgq->write_ptr += msgq->msg_size;
70001102:	4413      	add	r3, r2
			if (msgq->write_ptr == msgq->buffer_end) {
70001104:	6962      	ldr	r2, [r4, #20]
			msgq->write_ptr += msgq->msg_size;
70001106:	61e3      	str	r3, [r4, #28]
			if (msgq->write_ptr == msgq->buffer_end) {
70001108:	4293      	cmp	r3, r2
				msgq->write_ptr = msgq->buffer_start;
7000110a:	bf04      	itt	eq
7000110c:	6923      	ldreq	r3, [r4, #16]
7000110e:	61e3      	streq	r3, [r4, #28]
			msgq->used_msgs++;
70001110:	6a23      	ldr	r3, [r4, #32]
70001112:	3301      	adds	r3, #1
70001114:	6223      	str	r3, [r4, #32]
		result = 0;
70001116:	2400      	movs	r4, #0
	z_handle_obj_poll_events(&msgq->poll_events, state);
70001118:	f001 fedd 	bl	70002ed6 <z_handle_obj_poll_events>
		result = 0;
7000111c:	e7e2      	b.n	700010e4 <z_impl_k_msgq_put+0x48>
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
7000111e:	ea52 0103 	orrs.w	r1, r2, r3
70001122:	d00e      	beq.n	70001142 <z_impl_k_msgq_put+0xa6>
70001124:	4908      	ldr	r1, [pc, #32]	; (70001148 <z_impl_k_msgq_put+0xac>)
		result = z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
70001126:	4638      	mov	r0, r7
		arch_current_thread()->base.swap_data = (void *) data;
70001128:	6889      	ldr	r1, [r1, #8]
7000112a:	614e      	str	r6, [r1, #20]
		result = z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
7000112c:	4641      	mov	r1, r8
7000112e:	e9cd 2300 	strd	r2, r3, [sp]
70001132:	4622      	mov	r2, r4
70001134:	f000 fa2c 	bl	70001590 <z_pend_curr>
70001138:	4604      	mov	r4, r0
}
7000113a:	4620      	mov	r0, r4
7000113c:	b002      	add	sp, #8
7000113e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		result = -ENOMSG;
70001142:	f06f 0422 	mvn.w	r4, #34	; 0x22
70001146:	e7cd      	b.n	700010e4 <z_impl_k_msgq_put+0x48>
70001148:	70005f18 	.word	0x70005f18

7000114c <z_impl_k_sem_give>:
	return false;
#endif /* CONFIG_POLL */
}

void z_impl_k_sem_give(struct k_sem *sem)
{
7000114c:	b570      	push	{r4, r5, r6, lr}
7000114e:	f3ef 8600 	mrs	r6, CPSR
70001152:	f006 0680 	and.w	r6, r6, #128	; 0x80
70001156:	b672      	cpsid	i
	return list->head == list;
70001158:	6804      	ldr	r4, [r0, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
7000115a:	42a0      	cmp	r0, r4
7000115c:	d01a      	beq.n	70001194 <z_impl_k_sem_give+0x48>
		if (unlikely(thread != NULL)) {
7000115e:	b1cc      	cbz	r4, 70001194 <z_impl_k_sem_give+0x48>
 */

static inline void sys_dlist_remove(sys_dnode_t *node)
{
	sys_dnode_t *const prev = node->prev;
	sys_dnode_t *const next = node->next;
70001160:	e9d4 3200 	ldrd	r3, r2, [r4]
	node->next = NULL;
70001164:	2500      	movs	r5, #0

	prev->next = next;
70001166:	6013      	str	r3, [r2, #0]
70001168:	f104 0018 	add.w	r0, r4, #24
	next->prev = prev;
7000116c:	605a      	str	r2, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
7000116e:	7b63      	ldrb	r3, [r4, #13]
	node->prev = NULL;
70001170:	e9c4 5500 	strd	r5, r5, [r4]
70001174:	f023 0302 	bic.w	r3, r3, #2
	thread->base.pended_on = NULL;
70001178:	60a5      	str	r5, [r4, #8]
7000117a:	7363      	strb	r3, [r4, #13]
7000117c:	f001 fe50 	bl	70002e20 <z_abort_timeout>
70001180:	6725      	str	r5, [r4, #112]	; 0x70

	thread = z_unpend_first_thread(&sem->wait_q);

	if (unlikely(thread != NULL)) {
		arch_thread_return_value_set(thread, 0);
		z_ready_thread(thread);
70001182:	4620      	mov	r0, r4
70001184:	f001 fdb6 	bl	70002cf4 <z_ready_thread>
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
		resched = handle_poll_events(sem);
	}

	if (unlikely(resched)) {
		z_reschedule(&lock, key);
70001188:	4808      	ldr	r0, [pc, #32]	; (700011ac <z_impl_k_sem_give+0x60>)
7000118a:	4631      	mov	r1, r6
	} else {
		k_spin_unlock(&lock, key);
	}

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_sem, give, sem);
}
7000118c:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		z_reschedule(&lock, key);
70001190:	f000 ba24 	b.w	700015dc <z_reschedule>
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
70001194:	e9d0 3202 	ldrd	r3, r2, [r0, #8]
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
70001198:	2102      	movs	r1, #2
7000119a:	3010      	adds	r0, #16
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
7000119c:	429a      	cmp	r2, r3
7000119e:	bf18      	it	ne
700011a0:	3301      	addne	r3, #1
700011a2:	f840 3c08 	str.w	r3, [r0, #-8]
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
700011a6:	f001 fe96 	bl	70002ed6 <z_handle_obj_poll_events>
	return true;
700011aa:	e7ed      	b.n	70001188 <z_impl_k_sem_give+0x3c>
700011ac:	7000634d 	.word	0x7000634d

700011b0 <z_setup_new_thread>:
char *z_setup_new_thread(struct k_thread *new_thread,
			 k_thread_stack_t *stack, size_t stack_size,
			 k_thread_entry_t entry,
			 void *p1, void *p2, void *p3,
			 int prio, uint32_t options, const char *name)
{
700011b0:	e92d 41ff 	stmdb	sp!, {r0, r1, r2, r3, r4, r5, r6, r7, r8, lr}
700011b4:	4698      	mov	r8, r3
	SYS_DLIST_FOR_EACH_CONTAINER(&((wq)->waitq), thread_ptr, \
				     base.qnode_dlist)

static inline void z_waitq_init(_wait_q_t *w)
{
	sys_dlist_init(&w->waitq);
700011b6:	f100 0358 	add.w	r3, r0, #88	; 0x58

void z_init_thread_base(struct _thread_base *thread_base, int priority,
		       uint32_t initial_state, unsigned int options)
{
	/* k_q_node is initialized upon first insertion in a list */
	thread_base->pended_on = NULL;
700011ba:	2600      	movs	r6, #0
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
700011bc:	1dd5      	adds	r5, r2, #7
	list->tail = (sys_dnode_t *)list;
700011be:	e9c0 3316 	strd	r3, r3, [r0, #88]	; 0x58
700011c2:	f025 0507 	bic.w	r5, r5, #7
	thread_base->user_options = (uint8_t)options;
700011c6:	9b0e      	ldr	r3, [sp, #56]	; 0x38
	stack_ptr = (char *)stack + stack_obj_size;
700011c8:	440d      	add	r5, r1
	thread_base->user_options = (uint8_t)options;
700011ca:	7303      	strb	r3, [r0, #12]
	thread_base->thread_state = (uint8_t)initial_state;
700011cc:	2304      	movs	r3, #4
{
700011ce:	460f      	mov	r7, r1
	delta += arch_tls_stack_setup(new_thread, stack_ptr);
700011d0:	4629      	mov	r1, r5
	thread_base->thread_state = (uint8_t)initial_state;
700011d2:	7343      	strb	r3, [r0, #13]
{
700011d4:	4604      	mov	r4, r0

	thread_base->prio = priority;
700011d6:	9b0d      	ldr	r3, [sp, #52]	; 0x34
	thread_base->pended_on = NULL;
700011d8:	6086      	str	r6, [r0, #8]
	thread_base->prio = priority;
700011da:	7383      	strb	r3, [r0, #14]

	thread_base->sched_locked = 0U;
700011dc:	73c6      	strb	r6, [r0, #15]
	node->prev = NULL;
700011de:	e9c0 6606 	strd	r6, r6, [r0, #24]
	delta += arch_tls_stack_setup(new_thread, stack_ptr);
700011e2:	f7ff fa61 	bl	700006a8 <arch_tls_stack_setup>
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
700011e6:	9b0c      	ldr	r3, [sp, #48]	; 0x30
700011e8:	9302      	str	r3, [sp, #8]
700011ea:	4639      	mov	r1, r7
700011ec:	9b0b      	ldr	r3, [sp, #44]	; 0x2c
700011ee:	9301      	str	r3, [sp, #4]
700011f0:	9b0a      	ldr	r3, [sp, #40]	; 0x28
700011f2:	9300      	str	r3, [sp, #0]
700011f4:	4643      	mov	r3, r8
	delta = ROUND_UP(delta, ARCH_STACK_PTR_ALIGN);
700011f6:	3007      	adds	r0, #7
700011f8:	f020 0007 	bic.w	r0, r0, #7
	stack_ptr -= delta;
700011fc:	1a2d      	subs	r5, r5, r0
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
700011fe:	462a      	mov	r2, r5
70001200:	4620      	mov	r0, r4
70001202:	f7ff fb25 	bl	70000850 <arch_new_thread>
70001206:	4b04      	ldr	r3, [pc, #16]	; (70001218 <z_setup_new_thread+0x68>)
	new_thread->init_data = NULL;
70001208:	6566      	str	r6, [r4, #84]	; 0x54
}
7000120a:	4628      	mov	r0, r5
	new_thread->resource_pool = arch_current_thread()->resource_pool;
7000120c:	689b      	ldr	r3, [r3, #8]
7000120e:	6e5b      	ldr	r3, [r3, #100]	; 0x64
70001210:	6663      	str	r3, [r4, #100]	; 0x64
}
70001212:	b004      	add	sp, #16
70001214:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
70001218:	70005f18 	.word	0x70005f18

7000121c <z_impl_k_thread_create>:
{
7000121c:	b5f0      	push	{r4, r5, r6, r7, lr}
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
7000121e:	2500      	movs	r5, #0
{
70001220:	b087      	sub	sp, #28
70001222:	4604      	mov	r4, r0
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
70001224:	9505      	str	r5, [sp, #20]
70001226:	9d10      	ldr	r5, [sp, #64]	; 0x40
70001228:	9504      	str	r5, [sp, #16]
7000122a:	9d0f      	ldr	r5, [sp, #60]	; 0x3c
7000122c:	9503      	str	r5, [sp, #12]
7000122e:	9d0e      	ldr	r5, [sp, #56]	; 0x38
{
70001230:	e9dd 7612 	ldrd	r7, r6, [sp, #72]	; 0x48
	z_setup_new_thread(new_thread, stack, stack_size, entry, p1, p2, p3,
70001234:	9502      	str	r5, [sp, #8]
70001236:	9d0d      	ldr	r5, [sp, #52]	; 0x34
70001238:	9501      	str	r5, [sp, #4]
7000123a:	9d0c      	ldr	r5, [sp, #48]	; 0x30
7000123c:	9500      	str	r5, [sp, #0]
7000123e:	f7ff ffb7 	bl	700011b0 <z_setup_new_thread>
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
70001242:	f1b6 3fff 	cmp.w	r6, #4294967295	; 0xffffffff
70001246:	bf08      	it	eq
70001248:	f1b7 3fff 	cmpeq.w	r7, #4294967295	; 0xffffffff
7000124c:	d005      	beq.n	7000125a <z_impl_k_thread_create+0x3e>
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
7000124e:	ea56 0307 	orrs.w	r3, r6, r7
70001252:	d105      	bne.n	70001260 <z_impl_k_thread_create+0x44>
70001254:	4620      	mov	r0, r4
70001256:	f000 fabd 	bl	700017d4 <z_impl_k_wakeup>
}
7000125a:	4620      	mov	r0, r4
7000125c:	b007      	add	sp, #28
7000125e:	bdf0      	pop	{r4, r5, r6, r7, pc}
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
70001260:	4903      	ldr	r1, [pc, #12]	; (70001270 <z_impl_k_thread_create+0x54>)
70001262:	463a      	mov	r2, r7
70001264:	4633      	mov	r3, r6
70001266:	f104 0018 	add.w	r0, r4, #24
7000126a:	f000 fbad 	bl	700019c8 <z_add_timeout>
7000126e:	e7f4      	b.n	7000125a <z_impl_k_thread_create+0x3e>
70001270:	70002d57 	.word	0x70002d57

70001274 <unready_thread>:
}
#include <zephyr/syscalls/k_thread_resume_mrsh.c>
#endif /* CONFIG_USERSPACE */

static void unready_thread(struct k_thread *thread)
{
70001274:	b538      	push	{r3, r4, r5, lr}
	if (z_is_thread_queued(thread)) {
70001276:	f990 200d 	ldrsb.w	r2, [r0, #13]
	return (thread->base.thread_state & state) != 0U;
7000127a:	7b43      	ldrb	r3, [r0, #13]
{
7000127c:	4601      	mov	r1, r0
	if (z_is_thread_queued(thread)) {
7000127e:	2a00      	cmp	r2, #0
70001280:	da04      	bge.n	7000128c <unready_thread+0x18>
	thread->base.thread_state &= ~_THREAD_QUEUED;
70001282:	f003 037f 	and.w	r3, r3, #127	; 0x7f
70001286:	7343      	strb	r3, [r0, #13]

static ALWAYS_INLINE void z_priq_dumb_remove(sys_dlist_t *pq, struct k_thread *thread)
{
	ARG_UNUSED(pq);

	sys_dlist_remove(&thread->base.qnode_dlist);
70001288:	f001 fcfa 	bl	70002c80 <sys_dlist_remove>
7000128c:	4d0c      	ldr	r5, [pc, #48]	; (700012c0 <unready_thread+0x4c>)
	return list->head == list;
7000128e:	462a      	mov	r2, r5
70001290:	68ab      	ldr	r3, [r5, #8]
70001292:	f852 4f18 	ldr.w	r4, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
70001296:	4294      	cmp	r4, r2
70001298:	d000      	beq.n	7000129c <unready_thread+0x28>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
7000129a:	b904      	cbnz	r4, 7000129e <unready_thread+0x2a>
7000129c:	68ec      	ldr	r4, [r5, #12]
					 int preempt_ok)
{
	/* Preemption is OK if it's being explicitly allowed by
	 * software state (e.g. the thread called k_yield())
	 */
	if (preempt_ok != 0) {
7000129e:	4299      	cmp	r1, r3
700012a0:	d005      	beq.n	700012ae <unready_thread+0x3a>
	}

	__ASSERT(arch_current_thread() != NULL, "");

	/* Or if we're pended/suspended/dummy (duh) */
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
700012a2:	7b5a      	ldrb	r2, [r3, #13]
700012a4:	06d2      	lsls	r2, r2, #27
700012a6:	d102      	bne.n	700012ae <unready_thread+0x3a>
	}

	/* Otherwise we have to be running a preemptible thread or
	 * switching to a metairq
	 */
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
700012a8:	89da      	ldrh	r2, [r3, #14]
700012aa:	2a7f      	cmp	r2, #127	; 0x7f
700012ac:	d805      	bhi.n	700012ba <unready_thread+0x46>
		if (thread != arch_current_thread()) {
700012ae:	429c      	cmp	r4, r3
700012b0:	d002      	beq.n	700012b8 <unready_thread+0x44>
			z_reset_time_slice(thread);
700012b2:	4620      	mov	r0, r4
700012b4:	f000 fafa 	bl	700018ac <z_reset_time_slice>
		_kernel.ready_q.cache = thread;
700012b8:	4623      	mov	r3, r4
		_kernel.ready_q.cache = arch_current_thread();
700012ba:	616b      	str	r3, [r5, #20]
		dequeue_thread(thread);
	}
	update_cache(thread == arch_current_thread());
}
700012bc:	bd38      	pop	{r3, r4, r5, pc}
700012be:	bf00      	nop
700012c0:	70005f18 	.word	0x70005f18

700012c4 <z_swap_irqlock>:
{
700012c4:	b538      	push	{r3, r4, r5, lr}
700012c6:	4d07      	ldr	r5, [pc, #28]	; (700012e4 <z_swap_irqlock+0x20>)
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700012c8:	f06f 020a 	mvn.w	r2, #10
700012cc:	4604      	mov	r4, r0
700012ce:	68ab      	ldr	r3, [r5, #8]
	arch_current_thread()->arch.basepri = key;
700012d0:	66d8      	str	r0, [r3, #108]	; 0x6c
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700012d2:	671a      	str	r2, [r3, #112]	; 0x70
	z_arm_cortex_r_svc();
700012d4:	f7ff eb90 	blx	700009f8 <z_arm_cortex_r_svc>
	if (key != 0U) {
700012d8:	b904      	cbnz	r4, 700012dc <z_swap_irqlock+0x18>
700012da:	b662      	cpsie	i
	return arch_current_thread()->arch.swap_return_value;
700012dc:	68ab      	ldr	r3, [r5, #8]
}
700012de:	6f18      	ldr	r0, [r3, #112]	; 0x70
700012e0:	bd38      	pop	{r3, r4, r5, pc}
700012e2:	bf00      	nop
700012e4:	70005f18 	.word	0x70005f18

700012e8 <ready_thread>:
{
700012e8:	b570      	push	{r4, r5, r6, lr}
	if (!z_is_thread_queued(thread) && z_is_thread_ready(thread)) {
700012ea:	f990 300d 	ldrsb.w	r3, [r0, #13]
	return (thread->base.thread_state & state) != 0U;
700012ee:	7b42      	ldrb	r2, [r0, #13]
700012f0:	2b00      	cmp	r3, #0
700012f2:	db2e      	blt.n	70001352 <ready_thread+0x6a>
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
700012f4:	06d1      	lsls	r1, r2, #27
700012f6:	d12c      	bne.n	70001352 <ready_thread+0x6a>
	return node->next != NULL;
700012f8:	6983      	ldr	r3, [r0, #24]
700012fa:	bb53      	cbnz	r3, 70001352 <ready_thread+0x6a>
	return list->head == list;
700012fc:	4c1b      	ldr	r4, [pc, #108]	; (7000136c <ready_thread+0x84>)
	thread->base.thread_state |= _THREAD_QUEUED;
700012fe:	f062 027f 	orn	r2, r2, #127	; 0x7f
70001302:	7342      	strb	r2, [r0, #13]
70001304:	4622      	mov	r2, r4
70001306:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
7000130a:	4291      	cmp	r1, r2
7000130c:	bf18      	it	ne
7000130e:	460b      	movne	r3, r1
	return (node == list->tail) ? NULL : node->next;
70001310:	69e1      	ldr	r1, [r4, #28]
static ALWAYS_INLINE void z_priq_dumb_add(sys_dlist_t *pq,
					  struct k_thread *thread)
{
	struct k_thread *t;

	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
70001312:	b923      	cbnz	r3, 7000131e <ready_thread+0x36>
	node->prev = tail;
70001314:	e9c0 2100 	strd	r2, r1, [r0]
	tail->next = node;
70001318:	6008      	str	r0, [r1, #0]
	list->tail = node;
7000131a:	61e0      	str	r0, [r4, #28]
}
7000131c:	e00c      	b.n	70001338 <ready_thread+0x50>
	int32_t b1 = thread_1->base.prio;
7000131e:	f990 500e 	ldrsb.w	r5, [r0, #14]
	int32_t b2 = thread_2->base.prio;
70001322:	f993 600e 	ldrsb.w	r6, [r3, #14]
	if (b1 != b2) {
70001326:	42b5      	cmp	r5, r6
70001328:	d014      	beq.n	70001354 <ready_thread+0x6c>
		if (z_sched_prio_cmp(thread, t) > 0) {
7000132a:	42ae      	cmp	r6, r5
7000132c:	dd12      	ble.n	70001354 <ready_thread+0x6c>
	sys_dnode_t *const prev = successor->prev;
7000132e:	6859      	ldr	r1, [r3, #4]
	node->next = successor;
70001330:	e9c0 3100 	strd	r3, r1, [r0]
	prev->next = node;
70001334:	6008      	str	r0, [r1, #0]
	successor->prev = node;
70001336:	6058      	str	r0, [r3, #4]
	return list->head == list;
70001338:	69a5      	ldr	r5, [r4, #24]
	return sys_dlist_is_empty(list) ? NULL : list->head;
7000133a:	4295      	cmp	r5, r2
7000133c:	d000      	beq.n	70001340 <ready_thread+0x58>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
7000133e:	b905      	cbnz	r5, 70001342 <ready_thread+0x5a>
70001340:	68e5      	ldr	r5, [r4, #12]
70001342:	68a3      	ldr	r3, [r4, #8]
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
70001344:	7b5a      	ldrb	r2, [r3, #13]
70001346:	06d2      	lsls	r2, r2, #27
70001348:	d108      	bne.n	7000135c <ready_thread+0x74>
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
7000134a:	89da      	ldrh	r2, [r3, #14]
7000134c:	2a7f      	cmp	r2, #127	; 0x7f
7000134e:	d905      	bls.n	7000135c <ready_thread+0x74>
		_kernel.ready_q.cache = arch_current_thread();
70001350:	6163      	str	r3, [r4, #20]
}
70001352:	bd70      	pop	{r4, r5, r6, pc}
	return (node == list->tail) ? NULL : node->next;
70001354:	4299      	cmp	r1, r3
70001356:	d0dd      	beq.n	70001314 <ready_thread+0x2c>
70001358:	681b      	ldr	r3, [r3, #0]
7000135a:	e7da      	b.n	70001312 <ready_thread+0x2a>
		if (thread != arch_current_thread()) {
7000135c:	42ab      	cmp	r3, r5
7000135e:	d002      	beq.n	70001366 <ready_thread+0x7e>
			z_reset_time_slice(thread);
70001360:	4628      	mov	r0, r5
70001362:	f000 faa3 	bl	700018ac <z_reset_time_slice>
		_kernel.ready_q.cache = thread;
70001366:	6165      	str	r5, [r4, #20]
}
70001368:	e7f3      	b.n	70001352 <ready_thread+0x6a>
7000136a:	bf00      	nop
7000136c:	70005f18 	.word	0x70005f18

70001370 <z_thread_halt>:
		halt_thread(thread, terminate ? _THREAD_DEAD : _THREAD_SUSPENDED);
70001370:	2a00      	cmp	r2, #0
{
70001372:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
	bool dummify = false;

	/* We hold the lock, and the thread is known not to be running
	 * anywhere.
	 */
	if ((thread->base.thread_state & new_state) == 0U) {
70001376:	7b42      	ldrb	r2, [r0, #13]
		halt_thread(thread, terminate ? _THREAD_DEAD : _THREAD_SUSPENDED);
70001378:	bf0c      	ite	eq
7000137a:	f04f 0910 	moveq.w	r9, #16
7000137e:	f04f 0908 	movne.w	r9, #8
{
70001382:	4604      	mov	r4, r0
	if ((thread->base.thread_state & new_state) == 0U) {
70001384:	ea19 0f02 	tst.w	r9, r2
{
70001388:	460f      	mov	r7, r1
	if ((thread->base.thread_state & new_state) == 0U) {
7000138a:	d121      	bne.n	700013d0 <z_thread_halt+0x60>
		thread->base.thread_state |= new_state;
7000138c:	ea49 0302 	orr.w	r3, r9, r2
		if (z_is_thread_queued(thread)) {
70001390:	09d2      	lsrs	r2, r2, #7
70001392:	d12d      	bne.n	700013f0 <z_thread_halt+0x80>
		thread->base.thread_state |= new_state;
70001394:	7343      	strb	r3, [r0, #13]
			dequeue_thread(thread);
		}

		if (new_state == _THREAD_DEAD) {
70001396:	f1b9 0f08 	cmp.w	r9, #8
7000139a:	d02f      	beq.n	700013fc <z_thread_halt+0x8c>
	bool dummify = false;
7000139c:	f04f 0800 	mov.w	r8, #0
	return list->head == list;
700013a0:	4e35      	ldr	r6, [pc, #212]	; (70001478 <z_thread_halt+0x108>)
700013a2:	4633      	mov	r3, r6
700013a4:	f853 5f18 	ldr.w	r5, [r3, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
700013a8:	429d      	cmp	r5, r3
700013aa:	d000      	beq.n	700013ae <z_thread_halt+0x3e>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700013ac:	b905      	cbnz	r5, 700013b0 <z_thread_halt+0x40>
700013ae:	68f5      	ldr	r5, [r6, #12]
		if (thread != arch_current_thread()) {
700013b0:	68b3      	ldr	r3, [r6, #8]
700013b2:	42ab      	cmp	r3, r5
700013b4:	d002      	beq.n	700013bc <z_thread_halt+0x4c>
			z_reset_time_slice(thread);
700013b6:	4628      	mov	r0, r5
700013b8:	f000 fa78 	bl	700018ac <z_reset_time_slice>
		_kernel.ready_q.cache = thread;
700013bc:	6175      	str	r5, [r6, #20]
#ifdef CONFIG_SMP
		unpend_all(&thread->halt_queue);
#endif /* CONFIG_SMP */
		update_cache(1);

		if (new_state == _THREAD_SUSPENDED) {
700013be:	f1b9 0f10 	cmp.w	r9, #16
700013c2:	d14a      	bne.n	7000145a <z_thread_halt+0xea>
  __ASM volatile ("dmb 0xF":::"memory");
700013c4:	f3bf 8f5f 	dmb	sy
	thread->base.thread_state &= ~(_THREAD_ABORTING | _THREAD_SUSPENDING);
700013c8:	7b63      	ldrb	r3, [r4, #13]
700013ca:	f023 0360 	bic.w	r3, r3, #96	; 0x60
700013ce:	7363      	strb	r3, [r4, #13]
700013d0:	4b29      	ldr	r3, [pc, #164]	; (70001478 <z_thread_halt+0x108>)
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
700013d2:	689b      	ldr	r3, [r3, #8]
700013d4:	429c      	cmp	r4, r3
700013d6:	d14b      	bne.n	70001470 <z_thread_halt+0x100>
700013d8:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
#include <zephyr/arch/arm/cortex_a_r/lib_helpers.h>
#include <zephyr/arch/arm/cortex_a_r/tpidruro.h>

static ALWAYS_INLINE _cpu_t *arch_curr_cpu(void)
{
	return (_cpu_t *)(read_tpidruro() & TPIDRURO_CURR_CPU);
700013dc:	f023 0303 	bic.w	r3, r3, #3
700013e0:	681b      	ldr	r3, [r3, #0]
700013e2:	2b00      	cmp	r3, #0
700013e4:	d144      	bne.n	70001470 <z_thread_halt+0x100>
	return z_swap_irqlock(key.key);
700013e6:	4638      	mov	r0, r7
}
700013e8:	e8bd 43f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
700013ec:	f7ff bf6a 	b.w	700012c4 <z_swap_irqlock>
	thread->base.thread_state &= ~_THREAD_QUEUED;
700013f0:	f003 037f 	and.w	r3, r3, #127	; 0x7f
700013f4:	7343      	strb	r3, [r0, #13]
	sys_dlist_remove(&thread->base.qnode_dlist);
700013f6:	f001 fc43 	bl	70002c80 <sys_dlist_remove>
}
700013fa:	e7cc      	b.n	70001396 <z_thread_halt+0x26>
			if (thread->base.pended_on != NULL) {
700013fc:	68a3      	ldr	r3, [r4, #8]
700013fe:	b113      	cbz	r3, 70001406 <z_thread_halt+0x96>
				unpend_thread_no_timeout(thread);
70001400:	4620      	mov	r0, r4
70001402:	f001 fc45 	bl	70002c90 <unpend_thread_no_timeout>
	return z_abort_timeout(&thread->base.timeout);
70001406:	f104 0018 	add.w	r0, r4, #24
7000140a:	f001 fd09 	bl	70002e20 <z_abort_timeout>
	return list->head == list;
7000140e:	6da5      	ldr	r5, [r4, #88]	; 0x58
}

static inline struct k_thread *z_waitq_head(_wait_q_t *w)
{
	return (struct k_thread *)sys_dlist_peek_head(&w->waitq);
70001410:	f104 0658 	add.w	r6, r4, #88	; 0x58
	return sys_dlist_is_empty(list) ? NULL : list->head;
70001414:	42ae      	cmp	r6, r5
70001416:	d011      	beq.n	7000143c <z_thread_halt+0xcc>
	thread->arch.swap_return_value = value;
70001418:	f04f 0800 	mov.w	r8, #0
	for (thread = z_waitq_head(wait_q); thread != NULL; thread = z_waitq_head(wait_q)) {
7000141c:	b175      	cbz	r5, 7000143c <z_thread_halt+0xcc>
		unpend_thread_no_timeout(thread);
7000141e:	4628      	mov	r0, r5
70001420:	f001 fc36 	bl	70002c90 <unpend_thread_no_timeout>
70001424:	f105 0018 	add.w	r0, r5, #24
70001428:	f001 fcfa 	bl	70002e20 <z_abort_timeout>
7000142c:	f8c5 8070 	str.w	r8, [r5, #112]	; 0x70
		ready_thread(thread);
70001430:	4628      	mov	r0, r5
70001432:	f7ff ff59 	bl	700012e8 <ready_thread>
	return list->head == list;
70001436:	6da5      	ldr	r5, [r4, #88]	; 0x58
	return sys_dlist_is_empty(list) ? NULL : list->head;
70001438:	42ae      	cmp	r6, r5
7000143a:	d1ef      	bne.n	7000141c <z_thread_halt+0xac>
7000143c:	4b0e      	ldr	r3, [pc, #56]	; (70001478 <z_thread_halt+0x108>)
			if (thread == arch_current_thread() && arch_is_in_isr()) {
7000143e:	689b      	ldr	r3, [r3, #8]
70001440:	429c      	cmp	r4, r3
70001442:	d1ab      	bne.n	7000139c <z_thread_halt+0x2c>
70001444:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70001448:	f023 0303 	bic.w	r3, r3, #3
7000144c:	681b      	ldr	r3, [r3, #0]
7000144e:	f1b3 0800 	subs.w	r8, r3, #0
70001452:	bf18      	it	ne
70001454:	f04f 0801 	movne.w	r8, #1
70001458:	e7a2      	b.n	700013a0 <z_thread_halt+0x30>
		 * code.  Note that we must leave a non-null switch
		 * handle for any threads spinning in join() (this can
		 * never be used, as our thread is flagged dead, but
		 * it must not be NULL otherwise join can deadlock).
		 */
		if (dummify && !IS_ENABLED(CONFIG_ARCH_POSIX)) {
7000145a:	f1b8 0f00 	cmp.w	r8, #0
7000145e:	d0b1      	beq.n	700013c4 <z_thread_halt+0x54>
	dummy_thread->base.user_options = K_ESSENTIAL;
70001460:	4b06      	ldr	r3, [pc, #24]	; (7000147c <z_thread_halt+0x10c>)
70001462:	f240 1201 	movw	r2, #257	; 0x101
	_current_cpu->current = thread;
70001466:	60b3      	str	r3, [r6, #8]
70001468:	819a      	strh	r2, [r3, #12]
	dummy_thread->resource_pool = NULL;
7000146a:	2200      	movs	r2, #0
7000146c:	665a      	str	r2, [r3, #100]	; 0x64
#ifdef CONFIG_TIMESLICE_PER_THREAD
	dummy_thread->base.slice_ticks = 0;
#endif /* CONFIG_TIMESLICE_PER_THREAD */

	arch_current_thread_set(dummy_thread);
}
7000146e:	e7a9      	b.n	700013c4 <z_thread_halt+0x54>
70001470:	b907      	cbnz	r7, 70001474 <z_thread_halt+0x104>
  __ASM volatile ("cpsie i" : : : "memory");
70001472:	b662      	cpsie	i
}
70001474:	e8bd 83f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
70001478:	70005f18 	.word	0x70005f18
7000147c:	700049e8 	.word	0x700049e8

70001480 <move_thread_to_end_of_prio_q>:
{
70001480:	b570      	push	{r4, r5, r6, lr}
	if (z_is_thread_queued(thread)) {
70001482:	f990 200d 	ldrsb.w	r2, [r0, #13]
	return (thread->base.thread_state & state) != 0U;
70001486:	7b43      	ldrb	r3, [r0, #13]
{
70001488:	4601      	mov	r1, r0
	if (z_is_thread_queued(thread)) {
7000148a:	2a00      	cmp	r2, #0
7000148c:	da04      	bge.n	70001498 <move_thread_to_end_of_prio_q+0x18>
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000148e:	f003 037f 	and.w	r3, r3, #127	; 0x7f
70001492:	7343      	strb	r3, [r0, #13]
70001494:	f001 fbf4 	bl	70002c80 <sys_dlist_remove>
	return list->head == list;
70001498:	4c1c      	ldr	r4, [pc, #112]	; (7000150c <move_thread_to_end_of_prio_q+0x8c>)
	thread->base.thread_state |= _THREAD_QUEUED;
7000149a:	7b4b      	ldrb	r3, [r1, #13]
7000149c:	4622      	mov	r2, r4
7000149e:	f063 037f 	orn	r3, r3, #127	; 0x7f
700014a2:	734b      	strb	r3, [r1, #13]
700014a4:	f852 3f18 	ldr.w	r3, [r2, #24]!
	return (node == list->tail) ? NULL : node->next;
700014a8:	69e0      	ldr	r0, [r4, #28]
	return sys_dlist_is_empty(list) ? NULL : list->head;
700014aa:	4293      	cmp	r3, r2
700014ac:	bf08      	it	eq
700014ae:	2300      	moveq	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
700014b0:	b923      	cbnz	r3, 700014bc <move_thread_to_end_of_prio_q+0x3c>
	node->prev = tail;
700014b2:	e9c1 2000 	strd	r2, r0, [r1]
	tail->next = node;
700014b6:	6001      	str	r1, [r0, #0]
	list->tail = node;
700014b8:	61e1      	str	r1, [r4, #28]
}
700014ba:	e00c      	b.n	700014d6 <move_thread_to_end_of_prio_q+0x56>
	int32_t b1 = thread_1->base.prio;
700014bc:	f991 500e 	ldrsb.w	r5, [r1, #14]
	int32_t b2 = thread_2->base.prio;
700014c0:	f993 600e 	ldrsb.w	r6, [r3, #14]
	if (b1 != b2) {
700014c4:	42b5      	cmp	r5, r6
700014c6:	d01c      	beq.n	70001502 <move_thread_to_end_of_prio_q+0x82>
		if (z_sched_prio_cmp(thread, t) > 0) {
700014c8:	42ae      	cmp	r6, r5
700014ca:	dd1a      	ble.n	70001502 <move_thread_to_end_of_prio_q+0x82>
	sys_dnode_t *const prev = successor->prev;
700014cc:	6858      	ldr	r0, [r3, #4]
	node->next = successor;
700014ce:	e9c1 3000 	strd	r3, r0, [r1]
	prev->next = node;
700014d2:	6001      	str	r1, [r0, #0]
	successor->prev = node;
700014d4:	6059      	str	r1, [r3, #4]
	return list->head == list;
700014d6:	69a5      	ldr	r5, [r4, #24]
	struct k_thread *ret = _kernel.cpus[0].current;
700014d8:	68a3      	ldr	r3, [r4, #8]
	return sys_dlist_is_empty(list) ? NULL : list->head;
700014da:	4295      	cmp	r5, r2
700014dc:	d000      	beq.n	700014e0 <move_thread_to_end_of_prio_q+0x60>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700014de:	b905      	cbnz	r5, 700014e2 <move_thread_to_end_of_prio_q+0x62>
700014e0:	68e5      	ldr	r5, [r4, #12]
	if (preempt_ok != 0) {
700014e2:	4299      	cmp	r1, r3
700014e4:	d005      	beq.n	700014f2 <move_thread_to_end_of_prio_q+0x72>
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
700014e6:	7b5a      	ldrb	r2, [r3, #13]
700014e8:	06d2      	lsls	r2, r2, #27
700014ea:	d102      	bne.n	700014f2 <move_thread_to_end_of_prio_q+0x72>
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
700014ec:	89da      	ldrh	r2, [r3, #14]
700014ee:	2a7f      	cmp	r2, #127	; 0x7f
700014f0:	d805      	bhi.n	700014fe <move_thread_to_end_of_prio_q+0x7e>
		if (thread != arch_current_thread()) {
700014f2:	429d      	cmp	r5, r3
700014f4:	d002      	beq.n	700014fc <move_thread_to_end_of_prio_q+0x7c>
			z_reset_time_slice(thread);
700014f6:	4628      	mov	r0, r5
700014f8:	f000 f9d8 	bl	700018ac <z_reset_time_slice>
		_kernel.ready_q.cache = thread;
700014fc:	462b      	mov	r3, r5
		_kernel.ready_q.cache = arch_current_thread();
700014fe:	6163      	str	r3, [r4, #20]
}
70001500:	bd70      	pop	{r4, r5, r6, pc}
	return (node == list->tail) ? NULL : node->next;
70001502:	4298      	cmp	r0, r3
70001504:	d0d5      	beq.n	700014b2 <move_thread_to_end_of_prio_q+0x32>
70001506:	681b      	ldr	r3, [r3, #0]
70001508:	e7d2      	b.n	700014b0 <move_thread_to_end_of_prio_q+0x30>
7000150a:	bf00      	nop
7000150c:	70005f18 	.word	0x70005f18

70001510 <z_impl_k_thread_suspend>:
{
70001510:	b570      	push	{r4, r5, r6, lr}
70001512:	4d1e      	ldr	r5, [pc, #120]	; (7000158c <z_impl_k_thread_suspend+0x7c>)
70001514:	4603      	mov	r3, r0
	if (thread == arch_current_thread() && !arch_is_in_isr() && !IS_ENABLED(CONFIG_SMP)) {
70001516:	68aa      	ldr	r2, [r5, #8]
70001518:	4282      	cmp	r2, r0
7000151a:	d125      	bne.n	70001568 <z_impl_k_thread_suspend+0x58>
7000151c:	ee1d 1f70 	mrc	15, 0, r1, cr13, cr0, {3}
70001520:	f021 0103 	bic.w	r1, r1, #3
70001524:	6809      	ldr	r1, [r1, #0]
70001526:	b9f9      	cbnz	r1, 70001568 <z_impl_k_thread_suspend+0x58>
	__asm__ volatile(
70001528:	f3ef 8600 	mrs	r6, CPSR
7000152c:	f006 0680 	and.w	r6, r6, #128	; 0x80
70001530:	b672      	cpsid	i
	thread->base.thread_state &= ~_THREAD_QUEUED;
70001532:	7b53      	ldrb	r3, [r2, #13]
70001534:	f003 037f 	and.w	r3, r3, #127	; 0x7f
70001538:	f043 0310 	orr.w	r3, r3, #16
7000153c:	7353      	strb	r3, [r2, #13]
	sys_dlist_remove(&thread->base.qnode_dlist);
7000153e:	f001 fb9f 	bl	70002c80 <sys_dlist_remove>
	return list->head == list;
70001542:	462b      	mov	r3, r5
70001544:	f853 4f18 	ldr.w	r4, [r3, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
70001548:	429c      	cmp	r4, r3
7000154a:	d000      	beq.n	7000154e <z_impl_k_thread_suspend+0x3e>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
7000154c:	b904      	cbnz	r4, 70001550 <z_impl_k_thread_suspend+0x40>
7000154e:	68ec      	ldr	r4, [r5, #12]
		if (thread != arch_current_thread()) {
70001550:	68ab      	ldr	r3, [r5, #8]
70001552:	429c      	cmp	r4, r3
70001554:	d002      	beq.n	7000155c <z_impl_k_thread_suspend+0x4c>
			z_reset_time_slice(thread);
70001556:	4620      	mov	r0, r4
70001558:	f000 f9a8 	bl	700018ac <z_reset_time_slice>
		_kernel.ready_q.cache = thread;
7000155c:	616c      	str	r4, [r5, #20]
	return z_swap_irqlock(key.key);
7000155e:	4630      	mov	r0, r6
}
70001560:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
70001564:	f7ff beae 	b.w	700012c4 <z_swap_irqlock>
70001568:	f3ef 8100 	mrs	r1, CPSR
7000156c:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001570:	b672      	cpsid	i
	if ((thread->base.thread_state & _THREAD_SUSPENDED) != 0U) {
70001572:	7b5a      	ldrb	r2, [r3, #13]
70001574:	f012 0210 	ands.w	r2, r2, #16
70001578:	d002      	beq.n	70001580 <z_impl_k_thread_suspend+0x70>
	if (key != 0U) {
7000157a:	b901      	cbnz	r1, 7000157e <z_impl_k_thread_suspend+0x6e>
7000157c:	b662      	cpsie	i
}
7000157e:	bd70      	pop	{r4, r5, r6, pc}
70001580:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	z_thread_halt(thread, key, false);
70001584:	4618      	mov	r0, r3
70001586:	f7ff bef3 	b.w	70001370 <z_thread_halt>
7000158a:	bf00      	nop
7000158c:	70005f18 	.word	0x70005f18

70001590 <z_pend_curr>:
{
70001590:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
70001592:	e9dd 7606 	ldrd	r7, r6, [sp, #24]
70001596:	460c      	mov	r4, r1
70001598:	4611      	mov	r1, r2
	__asm__ volatile(
7000159a:	f3ef 8300 	mrs	r3, CPSR
7000159e:	f003 0380 	and.w	r3, r3, #128	; 0x80
700015a2:	b672      	cpsid	i
700015a4:	4b0b      	ldr	r3, [pc, #44]	; (700015d4 <z_pend_curr+0x44>)
700015a6:	689d      	ldr	r5, [r3, #8]
	add_to_waitq_locked(thread, wait_q);
700015a8:	4628      	mov	r0, r5
700015aa:	f001 fb7b 	bl	70002ca4 <add_to_waitq_locked>
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
700015ae:	f1b6 3fff 	cmp.w	r6, #4294967295	; 0xffffffff
700015b2:	bf08      	it	eq
700015b4:	f1b7 3fff 	cmpeq.w	r7, #4294967295	; 0xffffffff
700015b8:	d006      	beq.n	700015c8 <z_pend_curr+0x38>
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
700015ba:	4907      	ldr	r1, [pc, #28]	; (700015d8 <z_pend_curr+0x48>)
700015bc:	463a      	mov	r2, r7
700015be:	4633      	mov	r3, r6
700015c0:	f105 0018 	add.w	r0, r5, #24
700015c4:	f000 fa00 	bl	700019c8 <z_add_timeout>
700015c8:	4620      	mov	r0, r4
}
700015ca:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
700015ce:	f7ff be79 	b.w	700012c4 <z_swap_irqlock>
700015d2:	bf00      	nop
700015d4:	70005f18 	.word	0x70005f18
700015d8:	70002d57 	.word	0x70002d57

700015dc <z_reschedule>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
700015dc:	b969      	cbnz	r1, 700015fa <z_reschedule+0x1e>
700015de:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
700015e2:	f023 0303 	bic.w	r3, r3, #3
700015e6:	6818      	ldr	r0, [r3, #0]
700015e8:	b930      	cbnz	r0, 700015f8 <z_reschedule+0x1c>
	new_thread = _kernel.ready_q.cache;
700015ea:	4b04      	ldr	r3, [pc, #16]	; (700015fc <z_reschedule+0x20>)
	if (resched(key.key) && need_swap()) {
700015ec:	695a      	ldr	r2, [r3, #20]
700015ee:	689b      	ldr	r3, [r3, #8]
700015f0:	429a      	cmp	r2, r3
700015f2:	d001      	beq.n	700015f8 <z_reschedule+0x1c>
700015f4:	f7ff be66 	b.w	700012c4 <z_swap_irqlock>
700015f8:	b662      	cpsie	i
}
700015fa:	4770      	bx	lr
700015fc:	70005f18 	.word	0x70005f18

70001600 <z_impl_k_thread_resume>:
{
70001600:	b510      	push	{r4, lr}
70001602:	f3ef 8400 	mrs	r4, CPSR
70001606:	f004 0480 	and.w	r4, r4, #128	; 0x80
7000160a:	b672      	cpsid	i
	return (thread->base.thread_state & _THREAD_SUSPENDED) != 0U;
7000160c:	7b42      	ldrb	r2, [r0, #13]
	if (!z_is_thread_suspended(thread)) {
7000160e:	06d1      	lsls	r1, r2, #27
70001610:	d402      	bmi.n	70001618 <z_impl_k_thread_resume+0x18>
	if (key != 0U) {
70001612:	b904      	cbnz	r4, 70001616 <z_impl_k_thread_resume+0x16>
70001614:	b662      	cpsie	i
}
70001616:	bd10      	pop	{r4, pc}
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
70001618:	f022 0210 	bic.w	r2, r2, #16
7000161c:	7342      	strb	r2, [r0, #13]
	ready_thread(thread);
7000161e:	f7ff fe63 	bl	700012e8 <ready_thread>
	z_reschedule(&_sched_spinlock, key);
70001622:	4803      	ldr	r0, [pc, #12]	; (70001630 <z_impl_k_thread_resume+0x30>)
70001624:	4621      	mov	r1, r4
}
70001626:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&_sched_spinlock, key);
7000162a:	f7ff bfd7 	b.w	700015dc <z_reschedule>
7000162e:	bf00      	nop
70001630:	7000634d 	.word	0x7000634d

70001634 <z_reschedule_irqlock>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
70001634:	b968      	cbnz	r0, 70001652 <z_reschedule_irqlock+0x1e>
70001636:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
7000163a:	f023 0303 	bic.w	r3, r3, #3
7000163e:	681b      	ldr	r3, [r3, #0]
70001640:	b933      	cbnz	r3, 70001650 <z_reschedule_irqlock+0x1c>
	new_thread = _kernel.ready_q.cache;
70001642:	4b04      	ldr	r3, [pc, #16]	; (70001654 <z_reschedule_irqlock+0x20>)
	if (resched(key) && need_swap()) {
70001644:	695a      	ldr	r2, [r3, #20]
70001646:	689b      	ldr	r3, [r3, #8]
70001648:	429a      	cmp	r2, r3
7000164a:	d001      	beq.n	70001650 <z_reschedule_irqlock+0x1c>
		z_swap_irqlock(key);
7000164c:	f7ff be3a 	b.w	700012c4 <z_swap_irqlock>
70001650:	b662      	cpsie	i
}
70001652:	4770      	bx	lr
70001654:	70005f18 	.word	0x70005f18

70001658 <k_sched_lock>:
	__asm__ volatile(
70001658:	f3ef 8100 	mrs	r1, CPSR
7000165c:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001660:	b672      	cpsid	i
70001662:	4b04      	ldr	r3, [pc, #16]	; (70001674 <k_sched_lock+0x1c>)
70001664:	689a      	ldr	r2, [r3, #8]
	--arch_current_thread()->base.sched_locked;
70001666:	7bd3      	ldrb	r3, [r2, #15]
70001668:	3b01      	subs	r3, #1
7000166a:	73d3      	strb	r3, [r2, #15]
	if (key != 0U) {
7000166c:	b901      	cbnz	r1, 70001670 <k_sched_lock+0x18>
7000166e:	b662      	cpsie	i
}
70001670:	4770      	bx	lr
70001672:	bf00      	nop
70001674:	70005f18 	.word	0x70005f18

70001678 <k_sched_unlock>:
{
70001678:	b570      	push	{r4, r5, r6, lr}
	__asm__ volatile(
7000167a:	f3ef 8600 	mrs	r6, CPSR
7000167e:	f006 0680 	and.w	r6, r6, #128	; 0x80
70001682:	b672      	cpsid	i
70001684:	4d0f      	ldr	r5, [pc, #60]	; (700016c4 <k_sched_unlock+0x4c>)
70001686:	68ab      	ldr	r3, [r5, #8]
		++arch_current_thread()->base.sched_locked;
70001688:	7bda      	ldrb	r2, [r3, #15]
7000168a:	3201      	adds	r2, #1
7000168c:	73da      	strb	r2, [r3, #15]
	return list->head == list;
7000168e:	462a      	mov	r2, r5
70001690:	f852 4f18 	ldr.w	r4, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
70001694:	4294      	cmp	r4, r2
70001696:	d000      	beq.n	7000169a <k_sched_unlock+0x22>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70001698:	b904      	cbnz	r4, 7000169c <k_sched_unlock+0x24>
7000169a:	68ec      	ldr	r4, [r5, #12]
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
7000169c:	7b5a      	ldrb	r2, [r3, #13]
7000169e:	06d2      	lsls	r2, r2, #27
700016a0:	d102      	bne.n	700016a8 <k_sched_unlock+0x30>
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
700016a2:	89da      	ldrh	r2, [r3, #14]
700016a4:	2a7f      	cmp	r2, #127	; 0x7f
700016a6:	d805      	bhi.n	700016b4 <k_sched_unlock+0x3c>
		if (thread != arch_current_thread()) {
700016a8:	429c      	cmp	r4, r3
700016aa:	d002      	beq.n	700016b2 <k_sched_unlock+0x3a>
			z_reset_time_slice(thread);
700016ac:	4620      	mov	r0, r4
700016ae:	f000 f8fd 	bl	700018ac <z_reset_time_slice>
		_kernel.ready_q.cache = thread;
700016b2:	4623      	mov	r3, r4
		_kernel.ready_q.cache = arch_current_thread();
700016b4:	616b      	str	r3, [r5, #20]
	if (key != 0U) {
700016b6:	b906      	cbnz	r6, 700016ba <k_sched_unlock+0x42>
700016b8:	b662      	cpsie	i
}
700016ba:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	z_reschedule_unlocked();
700016be:	f001 bb56 	b.w	70002d6e <z_reschedule_unlocked>
700016c2:	bf00      	nop
700016c4:	70005f18 	.word	0x70005f18

700016c8 <z_sched_init>:
	list->head = (sys_dnode_t *)list;
700016c8:	4b02      	ldr	r3, [pc, #8]	; (700016d4 <z_sched_init+0xc>)
700016ca:	f103 0218 	add.w	r2, r3, #24
	list->tail = (sys_dnode_t *)list;
700016ce:	e9c3 2206 	strd	r2, r2, [r3, #24]
}
700016d2:	4770      	bx	lr
700016d4:	70005f18 	.word	0x70005f18

700016d8 <z_impl_k_yield>:
{
700016d8:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	__asm__ volatile(
700016da:	f3ef 8600 	mrs	r6, CPSR
700016de:	f006 0680 	and.w	r6, r6, #128	; 0x80
700016e2:	b672      	cpsid	i
700016e4:	4c1d      	ldr	r4, [pc, #116]	; (7000175c <z_impl_k_yield+0x84>)
	return list->head == list;
700016e6:	4621      	mov	r1, r4
700016e8:	68a0      	ldr	r0, [r4, #8]
	thread->base.thread_state &= ~_THREAD_QUEUED;
700016ea:	7b43      	ldrb	r3, [r0, #13]
700016ec:	f003 037f 	and.w	r3, r3, #127	; 0x7f
700016f0:	7343      	strb	r3, [r0, #13]
700016f2:	f001 fac5 	bl	70002c80 <sys_dlist_remove>
700016f6:	68a3      	ldr	r3, [r4, #8]
	thread->base.thread_state |= _THREAD_QUEUED;
700016f8:	7b5a      	ldrb	r2, [r3, #13]
700016fa:	f062 027f 	orn	r2, r2, #127	; 0x7f
700016fe:	735a      	strb	r2, [r3, #13]
70001700:	f851 2f18 	ldr.w	r2, [r1, #24]!
	return (node == list->tail) ? NULL : node->next;
70001704:	69e0      	ldr	r0, [r4, #28]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70001706:	428a      	cmp	r2, r1
70001708:	bf08      	it	eq
7000170a:	2200      	moveq	r2, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
7000170c:	b922      	cbnz	r2, 70001718 <z_impl_k_yield+0x40>
	node->prev = tail;
7000170e:	e9c3 1000 	strd	r1, r0, [r3]
	tail->next = node;
70001712:	6003      	str	r3, [r0, #0]
	list->tail = node;
70001714:	61e3      	str	r3, [r4, #28]
}
70001716:	e00c      	b.n	70001732 <z_impl_k_yield+0x5a>
	int32_t b1 = thread_1->base.prio;
70001718:	f993 500e 	ldrsb.w	r5, [r3, #14]
	int32_t b2 = thread_2->base.prio;
7000171c:	f992 700e 	ldrsb.w	r7, [r2, #14]
	if (b1 != b2) {
70001720:	42bd      	cmp	r5, r7
70001722:	d017      	beq.n	70001754 <z_impl_k_yield+0x7c>
		if (z_sched_prio_cmp(thread, t) > 0) {
70001724:	42af      	cmp	r7, r5
70001726:	dd15      	ble.n	70001754 <z_impl_k_yield+0x7c>
	sys_dnode_t *const prev = successor->prev;
70001728:	6850      	ldr	r0, [r2, #4]
	node->next = successor;
7000172a:	e9c3 2000 	strd	r2, r0, [r3]
	prev->next = node;
7000172e:	6003      	str	r3, [r0, #0]
	successor->prev = node;
70001730:	6053      	str	r3, [r2, #4]
	return list->head == list;
70001732:	69a5      	ldr	r5, [r4, #24]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70001734:	428d      	cmp	r5, r1
70001736:	d000      	beq.n	7000173a <z_impl_k_yield+0x62>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70001738:	b905      	cbnz	r5, 7000173c <z_impl_k_yield+0x64>
7000173a:	68e5      	ldr	r5, [r4, #12]
		if (thread != arch_current_thread()) {
7000173c:	68a3      	ldr	r3, [r4, #8]
7000173e:	429d      	cmp	r5, r3
70001740:	d002      	beq.n	70001748 <z_impl_k_yield+0x70>
			z_reset_time_slice(thread);
70001742:	4628      	mov	r0, r5
70001744:	f000 f8b2 	bl	700018ac <z_reset_time_slice>
		_kernel.ready_q.cache = thread;
70001748:	6165      	str	r5, [r4, #20]
7000174a:	4630      	mov	r0, r6
}
7000174c:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
70001750:	f7ff bdb8 	b.w	700012c4 <z_swap_irqlock>
	return (node == list->tail) ? NULL : node->next;
70001754:	4282      	cmp	r2, r0
70001756:	d0da      	beq.n	7000170e <z_impl_k_yield+0x36>
70001758:	6812      	ldr	r2, [r2, #0]
7000175a:	e7d7      	b.n	7000170c <z_impl_k_yield+0x34>
7000175c:	70005f18 	.word	0x70005f18

70001760 <z_tick_sleep>:
	if (ticks == 0) {
70001760:	ea50 0301 	orrs.w	r3, r0, r1
{
70001764:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
70001768:	4605      	mov	r5, r0
7000176a:	460e      	mov	r6, r1
	if (ticks == 0) {
7000176c:	d104      	bne.n	70001778 <z_tick_sleep+0x18>
	z_impl_k_yield();
7000176e:	f7ff ffb3 	bl	700016d8 <z_impl_k_yield>
		return 0;
70001772:	2000      	movs	r0, #0
}
70001774:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	if (Z_TICK_ABS(ticks) <= 0) {
70001778:	1c83      	adds	r3, r0, #2
7000177a:	f171 33ff 	sbcs.w	r3, r1, #4294967295	; 0xffffffff
7000177e:	db20      	blt.n	700017c2 <z_tick_sleep+0x62>
		expected_wakeup_ticks = ticks + sys_clock_tick_get_32();
70001780:	f001 fb5f 	bl	70002e42 <sys_clock_tick_get_32>
70001784:	1944      	adds	r4, r0, r5
70001786:	f3ef 8800 	mrs	r8, CPSR
7000178a:	f008 0880 	and.w	r8, r8, #128	; 0x80
7000178e:	b672      	cpsid	i
70001790:	4f0e      	ldr	r7, [pc, #56]	; (700017cc <z_tick_sleep+0x6c>)
	unready_thread(arch_current_thread());
70001792:	68b8      	ldr	r0, [r7, #8]
70001794:	f7ff fd6e 	bl	70001274 <unready_thread>
70001798:	68b8      	ldr	r0, [r7, #8]
7000179a:	490d      	ldr	r1, [pc, #52]	; (700017d0 <z_tick_sleep+0x70>)
7000179c:	462a      	mov	r2, r5
7000179e:	4633      	mov	r3, r6
700017a0:	3018      	adds	r0, #24
700017a2:	f000 f911 	bl	700019c8 <z_add_timeout>
700017a6:	68ba      	ldr	r2, [r7, #8]
	thread->base.thread_state |= _THREAD_SLEEPING;
700017a8:	7b53      	ldrb	r3, [r2, #13]
700017aa:	4640      	mov	r0, r8
700017ac:	f043 0304 	orr.w	r3, r3, #4
700017b0:	7353      	strb	r3, [r2, #13]
700017b2:	f7ff fd87 	bl	700012c4 <z_swap_irqlock>
	uint32_t left_ticks = expected_wakeup_ticks - sys_clock_tick_get_32();
700017b6:	f001 fb44 	bl	70002e42 <sys_clock_tick_get_32>
700017ba:	1a20      	subs	r0, r4, r0
	if (ticks > 0) {
700017bc:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
700017c0:	e7d8      	b.n	70001774 <z_tick_sleep+0x14>
		expected_wakeup_ticks = Z_TICK_ABS(ticks);
700017c2:	f06f 0401 	mvn.w	r4, #1
700017c6:	1a24      	subs	r4, r4, r0
700017c8:	e7dd      	b.n	70001786 <z_tick_sleep+0x26>
700017ca:	bf00      	nop
700017cc:	70005f18 	.word	0x70005f18
700017d0:	70002d57 	.word	0x70002d57

700017d4 <z_impl_k_wakeup>:
{
700017d4:	b538      	push	{r3, r4, r5, lr}
700017d6:	4604      	mov	r4, r0
	return z_abort_timeout(&thread->base.timeout);
700017d8:	3018      	adds	r0, #24
700017da:	f001 fb21 	bl	70002e20 <z_abort_timeout>
700017de:	f3ef 8500 	mrs	r5, CPSR
700017e2:	f005 0580 	and.w	r5, r5, #128	; 0x80
700017e6:	b672      	cpsid	i
	return (thread->base.thread_state & _THREAD_SLEEPING) != 0U;
700017e8:	7b63      	ldrb	r3, [r4, #13]
	if (!z_is_thread_sleeping(thread)) {
700017ea:	075a      	lsls	r2, r3, #29
700017ec:	d402      	bmi.n	700017f4 <z_impl_k_wakeup+0x20>
	if (key != 0U) {
700017ee:	b905      	cbnz	r5, 700017f2 <z_impl_k_wakeup+0x1e>
700017f0:	b662      	cpsie	i
}
700017f2:	bd38      	pop	{r3, r4, r5, pc}
	ready_thread(thread);
700017f4:	4620      	mov	r0, r4
	thread->base.thread_state &= ~_THREAD_SLEEPING;
700017f6:	f023 0304 	bic.w	r3, r3, #4
700017fa:	7363      	strb	r3, [r4, #13]
700017fc:	f7ff fd74 	bl	700012e8 <ready_thread>
70001800:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70001804:	f023 0303 	bic.w	r3, r3, #3
	if (arch_is_in_isr()) {
70001808:	681b      	ldr	r3, [r3, #0]
7000180a:	2b00      	cmp	r3, #0
7000180c:	d1ef      	bne.n	700017ee <z_impl_k_wakeup+0x1a>
		z_reschedule(&_sched_spinlock, key);
7000180e:	4803      	ldr	r0, [pc, #12]	; (7000181c <z_impl_k_wakeup+0x48>)
70001810:	4629      	mov	r1, r5
}
70001812:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		z_reschedule(&_sched_spinlock, key);
70001816:	f7ff bee1 	b.w	700015dc <z_reschedule>
7000181a:	bf00      	nop
7000181c:	7000634d 	.word	0x7000634d

70001820 <z_impl_k_sched_current_thread_query>:
}
70001820:	4b01      	ldr	r3, [pc, #4]	; (70001828 <z_impl_k_sched_current_thread_query+0x8>)
70001822:	6898      	ldr	r0, [r3, #8]
70001824:	4770      	bx	lr
70001826:	bf00      	nop
70001828:	70005f18 	.word	0x70005f18

7000182c <z_sched_wait>:
	return ret;
}

int z_sched_wait(struct k_spinlock *lock, k_spinlock_key_t key,
		 _wait_q_t *wait_q, k_timeout_t timeout, void **data)
{
7000182c:	b5d3      	push	{r0, r1, r4, r6, r7, lr}
7000182e:	9c08      	ldr	r4, [sp, #32]
	int ret = z_pend_curr(lock, key, wait_q, timeout);
70001830:	e9dd 6706 	ldrd	r6, r7, [sp, #24]
70001834:	e9cd 6700 	strd	r6, r7, [sp]
70001838:	f7ff feaa 	bl	70001590 <z_pend_curr>

	if (data != NULL) {
7000183c:	b11c      	cbz	r4, 70001846 <z_sched_wait+0x1a>
7000183e:	4b03      	ldr	r3, [pc, #12]	; (7000184c <z_sched_wait+0x20>)
		*data = arch_current_thread()->base.swap_data;
70001840:	689b      	ldr	r3, [r3, #8]
70001842:	695b      	ldr	r3, [r3, #20]
70001844:	6023      	str	r3, [r4, #0]
	}
	return ret;
}
70001846:	b002      	add	sp, #8
70001848:	bdd0      	pop	{r4, r6, r7, pc}
7000184a:	bf00      	nop
7000184c:	70005f18 	.word	0x70005f18

70001850 <slice_timeout>:
	return ret;
}

static void slice_timeout(struct _timeout *timeout)
{
	int cpu = ARRAY_INDEX(slice_timeouts, timeout);
70001850:	4b04      	ldr	r3, [pc, #16]	; (70001864 <slice_timeout+0x14>)

	slice_expired[cpu] = true;
70001852:	2201      	movs	r2, #1
	int cpu = ARRAY_INDEX(slice_timeouts, timeout);
70001854:	1ac0      	subs	r0, r0, r3
70001856:	4b04      	ldr	r3, [pc, #16]	; (70001868 <slice_timeout+0x18>)
70001858:	10c0      	asrs	r0, r0, #3
7000185a:	4358      	muls	r0, r3
	slice_expired[cpu] = true;
7000185c:	4b03      	ldr	r3, [pc, #12]	; (7000186c <slice_timeout+0x1c>)
7000185e:	541a      	strb	r2, [r3, r0]
	 * for a different CPU.
	 */
	if (cpu != _current_cpu->id) {
		flag_ipi(IPI_CPU_MASK(cpu));
	}
}
70001860:	4770      	bx	lr
70001862:	bf00      	nop
70001864:	70004a60 	.word	0x70004a60
70001868:	aaaaaaab 	.word	0xaaaaaaab
7000186c:	7000634d 	.word	0x7000634d

70001870 <thread_is_sliceable>:
		&& !z_is_idle_thread_object(thread);
70001870:	89c3      	ldrh	r3, [r0, #14]
70001872:	2b7f      	cmp	r3, #127	; 0x7f
70001874:	d812      	bhi.n	7000189c <thread_is_sliceable+0x2c>
	int ret = slice_ticks;
70001876:	4b0a      	ldr	r3, [pc, #40]	; (700018a0 <thread_is_sliceable+0x30>)
70001878:	681b      	ldr	r3, [r3, #0]
		&& slice_time(thread) != 0
7000187a:	b163      	cbz	r3, 70001896 <thread_is_sliceable+0x26>
		&& !z_is_prio_higher(thread->base.prio, slice_max_prio)
7000187c:	4b09      	ldr	r3, [pc, #36]	; (700018a4 <thread_is_sliceable+0x34>)
7000187e:	f990 200e 	ldrsb.w	r2, [r0, #14]
70001882:	681b      	ldr	r3, [r3, #0]
70001884:	429a      	cmp	r2, r3
70001886:	db09      	blt.n	7000189c <thread_is_sliceable+0x2c>
		&& !z_is_thread_prevented_from_running(thread)
70001888:	7b43      	ldrb	r3, [r0, #13]
7000188a:	06db      	lsls	r3, r3, #27
7000188c:	d106      	bne.n	7000189c <thread_is_sliceable+0x2c>
		&& !z_is_idle_thread_object(thread);
7000188e:	4b06      	ldr	r3, [pc, #24]	; (700018a8 <thread_is_sliceable+0x38>)
70001890:	1ac3      	subs	r3, r0, r3
70001892:	bf18      	it	ne
70001894:	2301      	movne	r3, #1
}
70001896:	f003 0001 	and.w	r0, r3, #1
7000189a:	4770      	bx	lr
		&& !z_is_idle_thread_object(thread);
7000189c:	2300      	movs	r3, #0
7000189e:	e7fa      	b.n	70001896 <thread_is_sliceable+0x26>
700018a0:	70005f3c 	.word	0x70005f3c
700018a4:	70005f38 	.word	0x70005f38
700018a8:	700048f8 	.word	0x700048f8

700018ac <z_reset_time_slice>:

void z_reset_time_slice(struct k_thread *thread)
{
700018ac:	b570      	push	{r4, r5, r6, lr}
	int cpu = _current_cpu->id;
700018ae:	4b0e      	ldr	r3, [pc, #56]	; (700018e8 <z_reset_time_slice+0x3c>)
700018b0:	7c1e      	ldrb	r6, [r3, #16]

	z_abort_timeout(&slice_timeouts[cpu]);
700018b2:	4c0e      	ldr	r4, [pc, #56]	; (700018ec <z_reset_time_slice+0x40>)
700018b4:	eb06 0346 	add.w	r3, r6, r6, lsl #1
{
700018b8:	4605      	mov	r5, r0
	z_abort_timeout(&slice_timeouts[cpu]);
700018ba:	eb04 04c3 	add.w	r4, r4, r3, lsl #3
700018be:	4620      	mov	r0, r4
700018c0:	f001 faae 	bl	70002e20 <z_abort_timeout>
	slice_expired[cpu] = false;
700018c4:	2200      	movs	r2, #0
700018c6:	4b0a      	ldr	r3, [pc, #40]	; (700018f0 <z_reset_time_slice+0x44>)
	if (thread_is_sliceable(thread)) {
700018c8:	4628      	mov	r0, r5
	slice_expired[cpu] = false;
700018ca:	559a      	strb	r2, [r3, r6]
	if (thread_is_sliceable(thread)) {
700018cc:	f7ff ffd0 	bl	70001870 <thread_is_sliceable>
700018d0:	b148      	cbz	r0, 700018e6 <z_reset_time_slice+0x3a>
	int ret = slice_ticks;
700018d2:	4b08      	ldr	r3, [pc, #32]	; (700018f4 <z_reset_time_slice+0x48>)
		z_add_timeout(&slice_timeouts[cpu], slice_timeout,
700018d4:	4620      	mov	r0, r4
700018d6:	4908      	ldr	r1, [pc, #32]	; (700018f8 <z_reset_time_slice+0x4c>)
			      K_TICKS(slice_time(thread) - 1));
	}
}
700018d8:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
			      K_TICKS(slice_time(thread) - 1));
700018dc:	681a      	ldr	r2, [r3, #0]
700018de:	3a01      	subs	r2, #1
		z_add_timeout(&slice_timeouts[cpu], slice_timeout,
700018e0:	17d3      	asrs	r3, r2, #31
700018e2:	f000 b871 	b.w	700019c8 <z_add_timeout>
}
700018e6:	bd70      	pop	{r4, r5, r6, pc}
700018e8:	70005f18 	.word	0x70005f18
700018ec:	70004a60 	.word	0x70004a60
700018f0:	7000634d 	.word	0x7000634d
700018f4:	70005f3c 	.word	0x70005f3c
700018f8:	70001851 	.word	0x70001851

700018fc <z_time_slice>:
}
#endif

/* Called out of each timer interrupt */
void z_time_slice(void)
{
700018fc:	b538      	push	{r3, r4, r5, lr}
	__asm__ volatile(
700018fe:	f3ef 8500 	mrs	r5, CPSR
70001902:	f005 0580 	and.w	r5, r5, #128	; 0x80
70001906:	b672      	cpsid	i
		return;
	}
	pending_current = NULL;
#endif

	if (slice_expired[_current_cpu->id] && thread_is_sliceable(curr)) {
70001908:	4b0a      	ldr	r3, [pc, #40]	; (70001934 <z_time_slice+0x38>)
7000190a:	7c1a      	ldrb	r2, [r3, #16]
7000190c:	490a      	ldr	r1, [pc, #40]	; (70001938 <z_time_slice+0x3c>)
7000190e:	5c8a      	ldrb	r2, [r1, r2]
70001910:	b16a      	cbz	r2, 7000192e <z_time_slice+0x32>
70001912:	689c      	ldr	r4, [r3, #8]
70001914:	4620      	mov	r0, r4
70001916:	f7ff ffab 	bl	70001870 <thread_is_sliceable>
7000191a:	b140      	cbz	r0, 7000192e <z_time_slice+0x32>
			k_spin_unlock(&_sched_spinlock, key);
			curr->base.slice_expired(curr, curr->base.slice_data);
			key = k_spin_lock(&_sched_spinlock);
		}
#endif
		if (!z_is_thread_prevented_from_running(curr)) {
7000191c:	7b63      	ldrb	r3, [r4, #13]
7000191e:	06db      	lsls	r3, r3, #27
70001920:	d102      	bne.n	70001928 <z_time_slice+0x2c>
			move_thread_to_end_of_prio_q(curr);
70001922:	4620      	mov	r0, r4
70001924:	f7ff fdac 	bl	70001480 <move_thread_to_end_of_prio_q>
		}
		z_reset_time_slice(curr);
70001928:	4620      	mov	r0, r4
7000192a:	f7ff ffbf 	bl	700018ac <z_reset_time_slice>
	if (key != 0U) {
7000192e:	b905      	cbnz	r5, 70001932 <z_time_slice+0x36>
70001930:	b662      	cpsie	i
	}
	k_spin_unlock(&_sched_spinlock, key);
}
70001932:	bd38      	pop	{r3, r4, r5, pc}
70001934:	70005f18 	.word	0x70005f18
70001938:	7000634d 	.word	0x7000634d

7000193c <elapsed>:
	 *
	 * The distinction is implemented by looking at announce_remaining which
	 * will be non-zero while sys_clock_announce() is executing and zero
	 * otherwise.
	 */
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
7000193c:	4b03      	ldr	r3, [pc, #12]	; (7000194c <elapsed+0x10>)
7000193e:	681b      	ldr	r3, [r3, #0]
70001940:	b90b      	cbnz	r3, 70001946 <elapsed+0xa>
70001942:	f7ff ba63 	b.w	70000e0c <sys_clock_elapsed>
}
70001946:	2000      	movs	r0, #0
70001948:	4770      	bx	lr
7000194a:	bf00      	nop
7000194c:	70005f40 	.word	0x70005f40

70001950 <remove_timeout>:
{
70001950:	b530      	push	{r4, r5, lr}
	return (node != NULL) ? sys_dlist_peek_next_no_check(list, node) : NULL;
70001952:	b170      	cbz	r0, 70001972 <remove_timeout+0x22>
	return (node == list->tail) ? NULL : node->next;
70001954:	4b0b      	ldr	r3, [pc, #44]	; (70001984 <remove_timeout+0x34>)
70001956:	685b      	ldr	r3, [r3, #4]
70001958:	4298      	cmp	r0, r3
7000195a:	d00a      	beq.n	70001972 <remove_timeout+0x22>
7000195c:	6803      	ldr	r3, [r0, #0]
	if (next(t) != NULL) {
7000195e:	b143      	cbz	r3, 70001972 <remove_timeout+0x22>
		next(t)->dticks += t->dticks;
70001960:	e9d3 2104 	ldrd	r2, r1, [r3, #16]
70001964:	e9d0 4504 	ldrd	r4, r5, [r0, #16]
70001968:	1912      	adds	r2, r2, r4
7000196a:	eb41 0105 	adc.w	r1, r1, r5
7000196e:	e9c3 2104 	strd	r2, r1, [r3, #16]
	sys_dnode_t *const next = node->next;
70001972:	e9d0 3200 	ldrd	r3, r2, [r0]
	prev->next = next;
70001976:	6013      	str	r3, [r2, #0]
	next->prev = prev;
70001978:	605a      	str	r2, [r3, #4]
	node->next = NULL;
7000197a:	2300      	movs	r3, #0
	node->prev = NULL;
7000197c:	e9c0 3300 	strd	r3, r3, [r0]
}
70001980:	bd30      	pop	{r4, r5, pc}
70001982:	bf00      	nop
70001984:	7000a820 	.word	0x7000a820

70001988 <next_timeout>:
	return list->head == list;
70001988:	4b0e      	ldr	r3, [pc, #56]	; (700019c4 <next_timeout+0x3c>)

static int32_t next_timeout(void)
{
7000198a:	b510      	push	{r4, lr}
7000198c:	681c      	ldr	r4, [r3, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
7000198e:	429c      	cmp	r4, r3
70001990:	d104      	bne.n	7000199c <next_timeout+0x14>
	struct _timeout *to = first();
	int32_t ticks_elapsed = elapsed();
70001992:	f7ff ffd3 	bl	7000193c <elapsed>
	int32_t ret;

	if ((to == NULL) ||
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
		ret = MAX_WAIT;
70001996:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
	} else {
		ret = MAX(0, to->dticks - ticks_elapsed);
	}

	return ret;
}
7000199a:	bd10      	pop	{r4, pc}
	int32_t ticks_elapsed = elapsed();
7000199c:	f7ff ffce 	bl	7000193c <elapsed>
	if ((to == NULL) ||
700019a0:	2c00      	cmp	r4, #0
700019a2:	d0f8      	beq.n	70001996 <next_timeout+0xe>
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
700019a4:	e9d4 3204 	ldrd	r3, r2, [r4, #16]
700019a8:	1a1b      	subs	r3, r3, r0
700019aa:	eb62 72e0 	sbc.w	r2, r2, r0, asr #31
	if ((to == NULL) ||
700019ae:	f1b3 4f00 	cmp.w	r3, #2147483648	; 0x80000000
700019b2:	f172 0100 	sbcs.w	r1, r2, #0
700019b6:	daee      	bge.n	70001996 <next_timeout+0xe>
		ret = MAX(0, to->dticks - ticks_elapsed);
700019b8:	2a00      	cmp	r2, #0
700019ba:	bfac      	ite	ge
700019bc:	4618      	movge	r0, r3
700019be:	2000      	movlt	r0, #0
	return ret;
700019c0:	e7eb      	b.n	7000199a <next_timeout+0x12>
700019c2:	bf00      	nop
700019c4:	7000a820 	.word	0x7000a820

700019c8 <z_add_timeout>:

void z_add_timeout(struct _timeout *to, _timeout_func_t fn,
		   k_timeout_t timeout)
{
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
700019c8:	f1b3 3fff 	cmp.w	r3, #4294967295	; 0xffffffff
700019cc:	bf08      	it	eq
700019ce:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
{
700019d2:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
700019d4:	4604      	mov	r4, r0
700019d6:	461d      	mov	r5, r3
700019d8:	4617      	mov	r7, r2
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
700019da:	d056      	beq.n	70001a8a <z_add_timeout+0xc2>
#ifdef CONFIG_KERNEL_COHERENCE
	__ASSERT_NO_MSG(arch_mem_coherent(to));
#endif /* CONFIG_KERNEL_COHERENCE */

	__ASSERT(!sys_dnode_is_linked(&to->node), "");
	to->fn = fn;
700019dc:	6081      	str	r1, [r0, #8]
	__asm__ volatile(
700019de:	f3ef 8600 	mrs	r6, CPSR
700019e2:	f006 0680 	and.w	r6, r6, #128	; 0x80
700019e6:	b672      	cpsid	i

	K_SPINLOCK(&timeout_lock) {
		struct _timeout *t;

		if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) &&
700019e8:	3201      	adds	r2, #1
700019ea:	f175 33ff 	sbcs.w	r3, r5, #4294967295	; 0xffffffff
700019ee:	da22      	bge.n	70001a36 <z_add_timeout+0x6e>
		    (Z_TICK_ABS(timeout.ticks) >= 0)) {
			k_ticks_t ticks = Z_TICK_ABS(timeout.ticks) - curr_tick;
700019f0:	492b      	ldr	r1, [pc, #172]	; (70001aa0 <z_add_timeout+0xd8>)
700019f2:	f06f 0301 	mvn.w	r3, #1
700019f6:	e9d1 2000 	ldrd	r2, r0, [r1]
700019fa:	1a9b      	subs	r3, r3, r2
700019fc:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
70001a00:	eb62 0000 	sbc.w	r0, r2, r0
70001a04:	1bdf      	subs	r7, r3, r7
70001a06:	eb60 0005 	sbc.w	r0, r0, r5

			to->dticks = MAX(1, ticks);
70001a0a:	2f01      	cmp	r7, #1
70001a0c:	f170 0300 	sbcs.w	r3, r0, #0
70001a10:	da01      	bge.n	70001a16 <z_add_timeout+0x4e>
70001a12:	2701      	movs	r7, #1
70001a14:	2000      	movs	r0, #0
	return list->head == list;
70001a16:	4a23      	ldr	r2, [pc, #140]	; (70001aa4 <z_add_timeout+0xdc>)
70001a18:	e9c4 7004 	strd	r7, r0, [r4, #16]
70001a1c:	6813      	ldr	r3, [r2, #0]
	return (node == list->tail) ? NULL : node->next;
70001a1e:	f8d2 c004 	ldr.w	ip, [r2, #4]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70001a22:	4293      	cmp	r3, r2
70001a24:	bf08      	it	eq
70001a26:	2300      	moveq	r3, #0
		} else {
			to->dticks = timeout.ticks + 1 + elapsed();
		}

		for (t = first(); t != NULL; t = next(t)) {
70001a28:	b973      	cbnz	r3, 70001a48 <z_add_timeout+0x80>
	node->prev = tail;
70001a2a:	e9c4 2c00 	strd	r2, ip, [r4]
	tail->next = node;
70001a2e:	f8cc 4000 	str.w	r4, [ip]
	list->tail = node;
70001a32:	6054      	str	r4, [r2, #4]
}
70001a34:	e01a      	b.n	70001a6c <z_add_timeout+0xa4>
			to->dticks = timeout.ticks + 1 + elapsed();
70001a36:	f7ff ff81 	bl	7000193c <elapsed>
70001a3a:	3701      	adds	r7, #1
70001a3c:	f145 0500 	adc.w	r5, r5, #0
70001a40:	183f      	adds	r7, r7, r0
70001a42:	eb45 70e0 	adc.w	r0, r5, r0, asr #31
70001a46:	e7e6      	b.n	70001a16 <z_add_timeout+0x4e>
			if (t->dticks > to->dticks) {
70001a48:	e9d3 0704 	ldrd	r0, r7, [r3, #16]
70001a4c:	e9d4 1504 	ldrd	r1, r5, [r4, #16]
70001a50:	4281      	cmp	r1, r0
70001a52:	eb75 0e07 	sbcs.w	lr, r5, r7
70001a56:	da19      	bge.n	70001a8c <z_add_timeout+0xc4>
				t->dticks -= to->dticks;
70001a58:	1a40      	subs	r0, r0, r1
	sys_dnode_t *const prev = successor->prev;
70001a5a:	6859      	ldr	r1, [r3, #4]
70001a5c:	eb67 0705 	sbc.w	r7, r7, r5
70001a60:	e9c3 0704 	strd	r0, r7, [r3, #16]
	node->next = successor;
70001a64:	e9c4 3100 	strd	r3, r1, [r4]
	prev->next = node;
70001a68:	600c      	str	r4, [r1, #0]
	successor->prev = node;
70001a6a:	605c      	str	r4, [r3, #4]
	return list->head == list;
70001a6c:	6813      	ldr	r3, [r2, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70001a6e:	4293      	cmp	r3, r2
70001a70:	d009      	beq.n	70001a86 <z_add_timeout+0xbe>

		if (t == NULL) {
			sys_dlist_append(&timeout_list, &to->node);
		}

		if (to == first() && announce_remaining == 0) {
70001a72:	429c      	cmp	r4, r3
70001a74:	d107      	bne.n	70001a86 <z_add_timeout+0xbe>
70001a76:	4b0c      	ldr	r3, [pc, #48]	; (70001aa8 <z_add_timeout+0xe0>)
70001a78:	681c      	ldr	r4, [r3, #0]
70001a7a:	b924      	cbnz	r4, 70001a86 <z_add_timeout+0xbe>
			sys_clock_set_timeout(next_timeout(), false);
70001a7c:	f7ff ff84 	bl	70001988 <next_timeout>
70001a80:	4621      	mov	r1, r4
70001a82:	f7ff f999 	bl	70000db8 <sys_clock_set_timeout>
	if (key != 0U) {
70001a86:	b906      	cbnz	r6, 70001a8a <z_add_timeout+0xc2>
70001a88:	b662      	cpsie	i
		}
	}
}
70001a8a:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
			to->dticks -= t->dticks;
70001a8c:	1a09      	subs	r1, r1, r0
70001a8e:	eb65 0507 	sbc.w	r5, r5, r7
	return (node == list->tail) ? NULL : node->next;
70001a92:	4563      	cmp	r3, ip
70001a94:	e9c4 1504 	strd	r1, r5, [r4, #16]
70001a98:	d0c7      	beq.n	70001a2a <z_add_timeout+0x62>
70001a9a:	681b      	ldr	r3, [r3, #0]
70001a9c:	e7c4      	b.n	70001a28 <z_add_timeout+0x60>
70001a9e:	bf00      	nop
70001aa0:	70004a78 	.word	0x70004a78
70001aa4:	7000a820 	.word	0x7000a820
70001aa8:	70005f40 	.word	0x70005f40

70001aac <sys_clock_announce>:
	}
	return ret;
}

void sys_clock_announce(int32_t ticks)
{
70001aac:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
	__asm__ volatile(
70001ab0:	f3ef 8800 	mrs	r8, CPSR
70001ab4:	f008 0880 	and.w	r8, r8, #128	; 0x80
70001ab8:	b672      	cpsid	i
	return list->head == list;
70001aba:	f8df a0a8 	ldr.w	sl, [pc, #168]	; 70001b64 <sys_clock_announce+0xb8>
	     (t != NULL) && (t->dticks <= announce_remaining);
	     t = first()) {
		int dt = t->dticks;

		curr_tick += dt;
		t->dticks = 0;
70001abe:	2600      	movs	r6, #0
	announce_remaining = ticks;
70001ac0:	f8df 90a4 	ldr.w	r9, [pc, #164]	; 70001b68 <sys_clock_announce+0xbc>
		t->dticks = 0;
70001ac4:	2700      	movs	r7, #0
	announce_remaining = ticks;
70001ac6:	f8c9 0000 	str.w	r0, [r9]
70001aca:	f8da 0000 	ldr.w	r0, [sl]
		curr_tick += dt;
70001ace:	4d27      	ldr	r5, [pc, #156]	; (70001b6c <sys_clock_announce+0xc0>)
	return sys_dlist_is_empty(list) ? NULL : list->head;
70001ad0:	4550      	cmp	r0, sl
70001ad2:	bf08      	it	eq
70001ad4:	2000      	moveq	r0, #0
70001ad6:	e9d5 2100 	ldrd	r2, r1, [r5]
	     (t != NULL) && (t->dticks <= announce_remaining);
70001ada:	f8d9 3000 	ldr.w	r3, [r9]
70001ade:	b360      	cbz	r0, 70001b3a <sys_clock_announce+0x8e>
70001ae0:	e9d0 4c04 	ldrd	r4, ip, [r0, #16]
70001ae4:	ea4f 7ee3 	mov.w	lr, r3, asr #31
70001ae8:	42a3      	cmp	r3, r4
70001aea:	eb7e 0b0c 	sbcs.w	fp, lr, ip
70001aee:	da05      	bge.n	70001afc <sys_clock_announce+0x50>
		key = k_spin_lock(&timeout_lock);
		announce_remaining -= dt;
	}

	if (t != NULL) {
		t->dticks -= announce_remaining;
70001af0:	1ae4      	subs	r4, r4, r3
70001af2:	eb6c 060e 	sbc.w	r6, ip, lr
70001af6:	e9c0 4604 	strd	r4, r6, [r0, #16]
70001afa:	e01e      	b.n	70001b3a <sys_clock_announce+0x8e>
		t->dticks = 0;
70001afc:	e9c0 6704 	strd	r6, r7, [r0, #16]
		curr_tick += dt;
70001b00:	18a2      	adds	r2, r4, r2
70001b02:	eb41 71e4 	adc.w	r1, r1, r4, asr #31
70001b06:	e9c5 2100 	strd	r2, r1, [r5]
		remove_timeout(t);
70001b0a:	f7ff ff21 	bl	70001950 <remove_timeout>
	if (key != 0U) {
70001b0e:	f1b8 0f00 	cmp.w	r8, #0
70001b12:	d100      	bne.n	70001b16 <sys_clock_announce+0x6a>
70001b14:	b662      	cpsie	i
		t->fn(t);
70001b16:	6883      	ldr	r3, [r0, #8]
70001b18:	4798      	blx	r3
	__asm__ volatile(
70001b1a:	f3ef 8800 	mrs	r8, CPSR
70001b1e:	f008 0880 	and.w	r8, r8, #128	; 0x80
70001b22:	b672      	cpsid	i
		announce_remaining -= dt;
70001b24:	f8d9 3000 	ldr.w	r3, [r9]
	return list->head == list;
70001b28:	f8da 0000 	ldr.w	r0, [sl]
70001b2c:	1b1b      	subs	r3, r3, r4
	return sys_dlist_is_empty(list) ? NULL : list->head;
70001b2e:	4550      	cmp	r0, sl
70001b30:	f8c9 3000 	str.w	r3, [r9]
70001b34:	d1cf      	bne.n	70001ad6 <sys_clock_announce+0x2a>
		curr_tick += dt;
70001b36:	e9d5 2100 	ldrd	r2, r1, [r5]
	}

	curr_tick += announce_remaining;
	announce_remaining = 0;
70001b3a:	2400      	movs	r4, #0
	curr_tick += announce_remaining;
70001b3c:	189a      	adds	r2, r3, r2
70001b3e:	eb41 71e3 	adc.w	r1, r1, r3, asr #31
	announce_remaining = 0;
70001b42:	f8c9 4000 	str.w	r4, [r9]
	curr_tick += announce_remaining;
70001b46:	e9c5 2100 	strd	r2, r1, [r5]

	sys_clock_set_timeout(next_timeout(), false);
70001b4a:	f7ff ff1d 	bl	70001988 <next_timeout>
70001b4e:	4621      	mov	r1, r4
70001b50:	f7ff f932 	bl	70000db8 <sys_clock_set_timeout>
	if (key != 0U) {
70001b54:	f1b8 0f00 	cmp.w	r8, #0
70001b58:	d100      	bne.n	70001b5c <sys_clock_announce+0xb0>
70001b5a:	b662      	cpsie	i
	k_spin_unlock(&timeout_lock, key);

#ifdef CONFIG_TIMESLICING
	z_time_slice();
#endif /* CONFIG_TIMESLICING */
}
70001b5c:	e8bd 4ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
	z_time_slice();
70001b60:	f7ff becc 	b.w	700018fc <z_time_slice>
70001b64:	7000a820 	.word	0x7000a820
70001b68:	70005f40 	.word	0x70005f40
70001b6c:	70004a78 	.word	0x70004a78

70001b70 <sys_clock_tick_get>:

int64_t sys_clock_tick_get(void)
{
70001b70:	b510      	push	{r4, lr}
	__asm__ volatile(
70001b72:	f3ef 8400 	mrs	r4, CPSR
70001b76:	f004 0480 	and.w	r4, r4, #128	; 0x80
70001b7a:	b672      	cpsid	i
	uint64_t t = 0U;

	K_SPINLOCK(&timeout_lock) {
		t = curr_tick + elapsed();
70001b7c:	f7ff fede 	bl	7000193c <elapsed>
70001b80:	4a04      	ldr	r2, [pc, #16]	; (70001b94 <sys_clock_tick_get+0x24>)
70001b82:	4603      	mov	r3, r0
70001b84:	e9d2 0100 	ldrd	r0, r1, [r2]
70001b88:	1818      	adds	r0, r3, r0
70001b8a:	eb41 71e3 	adc.w	r1, r1, r3, asr #31
	if (key != 0U) {
70001b8e:	b904      	cbnz	r4, 70001b92 <sys_clock_tick_get+0x22>
70001b90:	b662      	cpsie	i
	}
	return t;
}
70001b92:	bd10      	pop	{r4, pc}
70001b94:	70004a78 	.word	0x70004a78

70001b98 <boot_banner>:
	  */
	printk("\x1b[3J\x1b[2J\x1b[H");
#endif /* CONFIG_BOOT_CLEAR_SCREEN */

#ifdef CONFIG_BOOT_BANNER
	printk("*** " CONFIG_BOOT_BANNER_STRING " " BANNER_VERSION BANNER_POSTFIX " ***\n");
70001b98:	4801      	ldr	r0, [pc, #4]	; (70001ba0 <boot_banner+0x8>)
70001b9a:	f000 bc87 	b.w	700024ac <printk>
70001b9e:	bf00      	nop
70001ba0:	7000437d 	.word	0x7000437d

70001ba4 <statics_init>:

	SYS_PORT_TRACING_OBJ_INIT(k_heap, heap);
}

static int statics_init(void)
{
70001ba4:	b538      	push	{r3, r4, r5, lr}
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70001ba6:	4c06      	ldr	r4, [pc, #24]	; (70001bc0 <statics_init+0x1c>)
70001ba8:	4d06      	ldr	r5, [pc, #24]	; (70001bc4 <statics_init+0x20>)
70001baa:	42ac      	cmp	r4, r5
70001bac:	d301      	bcc.n	70001bb2 <statics_init+0xe>
		{
			k_heap_init(heap, heap->heap.init_mem, heap->heap.init_bytes);
		}
	}
	return 0;
}
70001bae:	2000      	movs	r0, #0
70001bb0:	bd38      	pop	{r3, r4, r5, pc}
			k_heap_init(heap, heap->heap.init_mem, heap->heap.init_bytes);
70001bb2:	e9d4 1201 	ldrd	r1, r2, [r4, #4]
70001bb6:	4620      	mov	r0, r4
70001bb8:	f001 f9a3 	bl	70002f02 <k_heap_init>
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70001bbc:	3414      	adds	r4, #20
70001bbe:	e7f4      	b.n	70001baa <statics_init+0x6>
70001bc0:	7000a82c 	.word	0x7000a82c
70001bc4:	7000a82c 	.word	0x7000a82c

70001bc8 <k_sys_work_q_init>:
			     CONFIG_SYSTEM_WORKQUEUE_STACK_SIZE);

struct k_work_q k_sys_work_q;

static int k_sys_work_q_init(void)
{
70001bc8:	b51f      	push	{r0, r1, r2, r3, r4, lr}
	struct k_work_queue_config cfg = {
70001bca:	4a09      	ldr	r2, [pc, #36]	; (70001bf0 <k_sys_work_q_init+0x28>)
70001bcc:	ab02      	add	r3, sp, #8
70001bce:	e892 0003 	ldmia.w	r2, {r0, r1}
		.name = "sysworkq",
		.no_yield = IS_ENABLED(CONFIG_SYSTEM_WORKQUEUE_NO_YIELD),
		.essential = true,
	};

	k_work_queue_start(&k_sys_work_q,
70001bd2:	f44f 6280 	mov.w	r2, #1024	; 0x400
	struct k_work_queue_config cfg = {
70001bd6:	e883 0003 	stmia.w	r3, {r0, r1}
	k_work_queue_start(&k_sys_work_q,
70001bda:	9300      	str	r3, [sp, #0]
70001bdc:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
70001be0:	4904      	ldr	r1, [pc, #16]	; (70001bf4 <k_sys_work_q_init+0x2c>)
70001be2:	4805      	ldr	r0, [pc, #20]	; (70001bf8 <k_sys_work_q_init+0x30>)
70001be4:	f000 f902 	bl	70001dec <k_work_queue_start>
			    sys_work_q_stack,
			    K_KERNEL_STACK_SIZEOF(sys_work_q_stack),
			    CONFIG_SYSTEM_WORKQUEUE_PRIORITY, &cfg);
	return 0;
}
70001be8:	2000      	movs	r0, #0
70001bea:	b005      	add	sp, #20
70001bec:	f85d fb04 	ldr.w	pc, [sp], #4
70001bf0:	70004154 	.word	0x70004154
70001bf4:	7000a350 	.word	0x7000a350
70001bf8:	70004a80 	.word	0x70004a80

70001bfc <work_queue_main>:
/* Loop executed by a work queue thread.
 *
 * @param workq_ptr pointer to the work queue structure
 */
static void work_queue_main(void *workq_ptr, void *p2, void *p3)
{
70001bfc:	e92d 41ff 	stmdb	sp!, {r0, r1, r2, r3, r4, r5, r6, r7, r8, lr}
 *
 * @return A pointer on the first node of the list (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_head(sys_slist_t *list)
{
	return list->head;
70001c00:	4e4d      	ldr	r6, [pc, #308]	; (70001d38 <work_queue_main+0x13c>)
70001c02:	4604      	mov	r4, r0
			 * which should never happen, even line 'if (work != NULL)'
			 * ensures that.
			 * This means that if node is not NULL, then work will not be NULL.
			 */
			handler = work->handler;
		} else if (flag_test_and_clear(&queue->flags,
70001c04:	f100 0790 	add.w	r7, r0, #144	; 0x90
	__asm__ volatile(
70001c08:	f3ef 8800 	mrs	r8, CPSR
70001c0c:	f008 0880 	and.w	r8, r8, #128	; 0x80
70001c10:	b672      	cpsid	i
70001c12:	6fa5      	ldr	r5, [r4, #120]	; 0x78
 *
 * @return A pointer to the first node of the list (or NULL if empty)
 */
static inline sys_snode_t *sys_slist_get(sys_slist_t *list);

Z_GENLIST_GET(slist, snode)
70001c14:	b9ed      	cbnz	r5, 70001c52 <work_queue_main+0x56>
70001c16:	2102      	movs	r1, #2
70001c18:	4638      	mov	r0, r7
70001c1a:	f001 f97a 	bl	70002f12 <flag_test_and_clear>
70001c1e:	2800      	cmp	r0, #0
70001c20:	d065      	beq.n	70001cee <work_queue_main+0xf2>
			 *
			 * We don't touch K_WORK_QUEUE_PLUGGABLE, so getting
			 * here doesn't mean that the queue will allow new
			 * submissions.
			 */
			(void)z_sched_wake_all(&queue->drainq, 1, NULL);
70001c22:	f104 0588 	add.w	r5, r4, #136	; 0x88
static inline bool z_sched_wake_all(_wait_q_t *wait_q, int swap_retval,
				    void *swap_data)
{
	bool woken = false;

	while (z_sched_wake(wait_q, swap_retval, swap_data)) {
70001c26:	2200      	movs	r2, #0
70001c28:	2101      	movs	r1, #1
70001c2a:	4628      	mov	r0, r5
70001c2c:	f001 f8da 	bl	70002de4 <z_sched_wake>
70001c30:	2800      	cmp	r0, #0
70001c32:	d1f8      	bne.n	70001c26 <work_queue_main+0x2a>
			 * the lock, and we didn't find work nor got asked to
			 * stop.  Just go to sleep: when something happens the
			 * work thread will be woken and we can check again.
			 */

			(void)z_sched_wait(&lock, key, &queue->notifyq,
70001c34:	2300      	movs	r3, #0
70001c36:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
70001c3a:	4840      	ldr	r0, [pc, #256]	; (70001d3c <work_queue_main+0x140>)
70001c3c:	4641      	mov	r1, r8
70001c3e:	9302      	str	r3, [sp, #8]
70001c40:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
70001c44:	e9cd 2300 	strd	r2, r3, [sp]
70001c48:	f104 0280 	add.w	r2, r4, #128	; 0x80
70001c4c:	f7ff fdee 	bl	7000182c <z_sched_wait>
					   K_FOREVER, NULL);
			continue;
70001c50:	e7da      	b.n	70001c08 <work_queue_main+0xc>
Z_GENLIST_GET_NOT_EMPTY(slist, snode)
70001c52:	6fe2      	ldr	r2, [r4, #124]	; 0x7c
	return node->next;
70001c54:	682b      	ldr	r3, [r5, #0]
	list->head = node;
70001c56:	67a3      	str	r3, [r4, #120]	; 0x78
Z_GENLIST_GET_NOT_EMPTY(slist, snode)
70001c58:	4295      	cmp	r5, r2
	list->tail = node;
70001c5a:	bf08      	it	eq
70001c5c:	67e3      	streq	r3, [r4, #124]	; 0x7c
	*flagp |= BIT(bit);
70001c5e:	f8d4 3090 	ldr.w	r3, [r4, #144]	; 0x90
70001c62:	f043 0302 	orr.w	r3, r3, #2
70001c66:	f8c4 3090 	str.w	r3, [r4, #144]	; 0x90
	*flagp &= ~BIT(bit);
70001c6a:	68eb      	ldr	r3, [r5, #12]
70001c6c:	f023 0304 	bic.w	r3, r3, #4
70001c70:	f043 0301 	orr.w	r3, r3, #1
70001c74:	60eb      	str	r3, [r5, #12]
			handler = work->handler;
70001c76:	686b      	ldr	r3, [r5, #4]
	if (key != 0U) {
70001c78:	f1b8 0f00 	cmp.w	r8, #0
70001c7c:	d044      	beq.n	70001d08 <work_queue_main+0x10c>
		}

		k_spin_unlock(&lock, key);

		__ASSERT_NO_MSG(handler != NULL);
		handler(work);
70001c7e:	4628      	mov	r0, r5
70001c80:	4798      	blx	r3
	__asm__ volatile(
70001c82:	f3ef 8800 	mrs	r8, CPSR
70001c86:	f008 0880 	and.w	r8, r8, #128	; 0x80
70001c8a:	b672      	cpsid	i
	*flagp &= ~BIT(bit);
70001c8c:	68eb      	ldr	r3, [r5, #12]
		 * yield to prevent starving other threads.
		 */
		key = k_spin_lock(&lock);

		flag_clear(&work->flags, K_WORK_RUNNING_BIT);
		if (flag_test(&work->flags, K_WORK_FLUSHING_BIT)) {
70001c8e:	06d9      	lsls	r1, r3, #27
	*flagp &= ~BIT(bit);
70001c90:	f023 0201 	bic.w	r2, r3, #1
		if (flag_test(&work->flags, K_WORK_FLUSHING_BIT)) {
70001c94:	d43a      	bmi.n	70001d0c <work_queue_main+0x110>
	*flagp &= ~BIT(bit);
70001c96:	60ea      	str	r2, [r5, #12]
	return (*flagp & BIT(bit)) != 0U;
70001c98:	68eb      	ldr	r3, [r5, #12]
			finalize_flush_locked(work);
		}
		if (flag_test(&work->flags, K_WORK_CANCELING_BIT)) {
70001c9a:	079a      	lsls	r2, r3, #30
70001c9c:	d516      	bpl.n	70001ccc <work_queue_main+0xd0>
	return list->head;
70001c9e:	6830      	ldr	r0, [r6, #0]
	*flagp &= ~BIT(bit);
70001ca0:	f023 0302 	bic.w	r3, r3, #2
70001ca4:	60eb      	str	r3, [r5, #12]
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(&pending_cancels, wc, tmp, node) {
70001ca6:	b188      	cbz	r0, 70001ccc <work_queue_main+0xd0>
	return node->next;
70001ca8:	6803      	ldr	r3, [r0, #0]
70001caa:	2100      	movs	r1, #0
70001cac:	b170      	cbz	r0, 70001ccc <work_queue_main+0xd0>
		if (wc->work == work) {
70001cae:	6842      	ldr	r2, [r0, #4]
70001cb0:	4295      	cmp	r5, r2
70001cb2:	d139      	bne.n	70001d28 <work_queue_main+0x12c>
70001cb4:	6803      	ldr	r3, [r0, #0]
 */
static inline void sys_slist_remove(sys_slist_t *list,
				    sys_snode_t *prev_node,
				    sys_snode_t *node);

Z_GENLIST_REMOVE(slist, snode)
70001cb6:	bb89      	cbnz	r1, 70001d1c <work_queue_main+0x120>
70001cb8:	6872      	ldr	r2, [r6, #4]
	list->head = node;
70001cba:	6033      	str	r3, [r6, #0]
Z_GENLIST_REMOVE(slist, snode)
70001cbc:	4282      	cmp	r2, r0
70001cbe:	d100      	bne.n	70001cc2 <work_queue_main+0xc6>
	list->tail = node;
70001cc0:	6073      	str	r3, [r6, #4]
	parent->next = child;
70001cc2:	2300      	movs	r3, #0
70001cc4:	f840 3b08 	str.w	r3, [r0], #8
	z_impl_k_sem_give(sem);
70001cc8:	f7ff fa40 	bl	7000114c <z_impl_k_sem_give>
	*flagp &= ~BIT(bit);
70001ccc:	f8d4 3090 	ldr.w	r3, [r4, #144]	; 0x90
70001cd0:	f023 0302 	bic.w	r3, r3, #2
70001cd4:	f8c4 3090 	str.w	r3, [r4, #144]	; 0x90
	return (*flagp & BIT(bit)) != 0U;
70001cd8:	f3c3 2300 	ubfx	r3, r3, #8, #1
	if (key != 0U) {
70001cdc:	f1b8 0f00 	cmp.w	r8, #0
70001ce0:	d100      	bne.n	70001ce4 <work_queue_main+0xe8>
70001ce2:	b662      	cpsie	i
		k_spin_unlock(&lock, key);

		/* Optionally yield to prevent the work queue from
		 * starving other threads.
		 */
		if (yield) {
70001ce4:	2b00      	cmp	r3, #0
70001ce6:	d18f      	bne.n	70001c08 <work_queue_main+0xc>
	z_impl_k_yield();
70001ce8:	f7ff fcf6 	bl	700016d8 <z_impl_k_yield>
}
70001cec:	e78c      	b.n	70001c08 <work_queue_main+0xc>
	return (*flagp & BIT(bit)) != 0U;
70001cee:	f8d4 3090 	ldr.w	r3, [r4, #144]	; 0x90
		} else if (flag_test(&queue->flags, K_WORK_QUEUE_STOP_BIT)) {
70001cf2:	06dd      	lsls	r5, r3, #27
70001cf4:	d59e      	bpl.n	70001c34 <work_queue_main+0x38>
	*flagp = flags;
70001cf6:	f8c4 0090 	str.w	r0, [r4, #144]	; 0x90
70001cfa:	f1b8 0f00 	cmp.w	r8, #0
70001cfe:	d100      	bne.n	70001d02 <work_queue_main+0x106>
70001d00:	b662      	cpsie	i
			k_yield();
		}
	}
}
70001d02:	b004      	add	sp, #16
70001d04:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
70001d08:	b662      	cpsie	i
}
70001d0a:	e7b8      	b.n	70001c7e <work_queue_main+0x82>
	*flagp &= ~BIT(bit);
70001d0c:	f023 0311 	bic.w	r3, r3, #17
70001d10:	60eb      	str	r3, [r5, #12]
	z_impl_k_sem_give(sem);
70001d12:	f105 0010 	add.w	r0, r5, #16
70001d16:	f7ff fa19 	bl	7000114c <z_impl_k_sem_give>
}
70001d1a:	e7bd      	b.n	70001c98 <work_queue_main+0x9c>
70001d1c:	600b      	str	r3, [r1, #0]
Z_GENLIST_REMOVE(slist, snode)
70001d1e:	6873      	ldr	r3, [r6, #4]
70001d20:	4283      	cmp	r3, r0
	list->tail = node;
70001d22:	bf08      	it	eq
70001d24:	6071      	streq	r1, [r6, #4]
}
70001d26:	e7cc      	b.n	70001cc2 <work_queue_main+0xc6>
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(&pending_cancels, wc, tmp, node) {
70001d28:	b123      	cbz	r3, 70001d34 <work_queue_main+0x138>
	return node->next;
70001d2a:	681a      	ldr	r2, [r3, #0]
			sys_slist_remove(&pending_cancels, prev, &wc->node);
70001d2c:	4601      	mov	r1, r0
70001d2e:	4618      	mov	r0, r3
70001d30:	4613      	mov	r3, r2
70001d32:	e7bb      	b.n	70001cac <work_queue_main+0xb0>
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(&pending_cancels, wc, tmp, node) {
70001d34:	461a      	mov	r2, r3
70001d36:	e7f9      	b.n	70001d2c <work_queue_main+0x130>
70001d38:	70005f44 	.word	0x70005f44
70001d3c:	7000634e 	.word	0x7000634e

70001d40 <submit_to_queue_locked>:
{
70001d40:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	return (*flagp & BIT(bit)) != 0U;
70001d42:	68c3      	ldr	r3, [r0, #12]
{
70001d44:	4604      	mov	r4, r0
70001d46:	460f      	mov	r7, r1
	if (flag_test(&work->flags, K_WORK_CANCELING_BIT)) {
70001d48:	079a      	lsls	r2, r3, #30
70001d4a:	f3c3 0640 	ubfx	r6, r3, #1, #1
70001d4e:	d42b      	bmi.n	70001da8 <submit_to_queue_locked+0x68>
	} else if (!flag_test(&work->flags, K_WORK_QUEUED_BIT)) {
70001d50:	075b      	lsls	r3, r3, #29
70001d52:	d419      	bmi.n	70001d88 <submit_to_queue_locked+0x48>
		if (*queuep == NULL) {
70001d54:	680b      	ldr	r3, [r1, #0]
70001d56:	b90b      	cbnz	r3, 70001d5c <submit_to_queue_locked+0x1c>
			*queuep = work->queue;
70001d58:	6883      	ldr	r3, [r0, #8]
70001d5a:	600b      	str	r3, [r1, #0]
	return (*flagp & BIT(bit)) != 0U;
70001d5c:	68e3      	ldr	r3, [r4, #12]
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70001d5e:	07dd      	lsls	r5, r3, #31
			ret = 2;
70001d60:	bf49      	itett	mi
70001d62:	2602      	movmi	r6, #2
		ret = 1;
70001d64:	2601      	movpl	r6, #1
			*queuep = work->queue;
70001d66:	68a3      	ldrmi	r3, [r4, #8]
70001d68:	603b      	strmi	r3, [r7, #0]
		int rc = queue_submit_locked(*queuep, work);
70001d6a:	683d      	ldr	r5, [r7, #0]
	if (queue == NULL) {
70001d6c:	2d00      	cmp	r5, #0
70001d6e:	d038      	beq.n	70001de2 <submit_to_queue_locked+0xa2>
70001d70:	4b1d      	ldr	r3, [pc, #116]	; (70001de8 <submit_to_queue_locked+0xa8>)
	bool chained = (arch_current_thread() == &queue->thread) && !k_is_in_isr();
70001d72:	689b      	ldr	r3, [r3, #8]
70001d74:	42ab      	cmp	r3, r5
70001d76:	d00a      	beq.n	70001d8e <submit_to_queue_locked+0x4e>
	return (*flagp & BIT(bit)) != 0U;
70001d78:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
	if (!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT)) {
70001d7c:	07d8      	lsls	r0, r3, #31
	return (*flagp & BIT(bit)) != 0U;
70001d7e:	f3c3 0280 	ubfx	r2, r3, #2, #1
	if (!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT)) {
70001d82:	d414      	bmi.n	70001dae <submit_to_queue_locked+0x6e>
		ret = -EBUSY;
70001d84:	f06f 0612 	mvn.w	r6, #18
		*queuep = NULL;
70001d88:	2300      	movs	r3, #0
70001d8a:	603b      	str	r3, [r7, #0]
	return ret;
70001d8c:	e024      	b.n	70001dd8 <submit_to_queue_locked+0x98>
	bool chained = (arch_current_thread() == &queue->thread) && !k_is_in_isr();
70001d8e:	f000 ff6b 	bl	70002c68 <k_is_in_isr>
70001d92:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
70001d96:	2800      	cmp	r0, #0
70001d98:	d1f0      	bne.n	70001d7c <submit_to_queue_locked+0x3c>
	if (!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT)) {
70001d9a:	07d9      	lsls	r1, r3, #31
	return (*flagp & BIT(bit)) != 0U;
70001d9c:	f3c3 02c0 	ubfx	r2, r3, #3, #1
	if (!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT)) {
70001da0:	d5f0      	bpl.n	70001d84 <submit_to_queue_locked+0x44>
	} else if (plugged && !draining) {
70001da2:	b152      	cbz	r2, 70001dba <submit_to_queue_locked+0x7a>
70001da4:	075b      	lsls	r3, r3, #29
70001da6:	d408      	bmi.n	70001dba <submit_to_queue_locked+0x7a>
		ret = -EBUSY;
70001da8:	f06f 060f 	mvn.w	r6, #15
70001dac:	e7ec      	b.n	70001d88 <submit_to_queue_locked+0x48>
	} else if (draining && !chained) {
70001dae:	2a00      	cmp	r2, #0
70001db0:	d1fa      	bne.n	70001da8 <submit_to_queue_locked+0x68>
	return (*flagp & BIT(bit)) != 0U;
70001db2:	f3c3 03c0 	ubfx	r3, r3, #3, #1
	} else if (plugged && !draining) {
70001db6:	2b00      	cmp	r3, #0
70001db8:	d1f6      	bne.n	70001da8 <submit_to_queue_locked+0x68>
	parent->next = child;
70001dba:	2300      	movs	r3, #0
70001dbc:	6023      	str	r3, [r4, #0]
	return list->tail;
70001dbe:	6feb      	ldr	r3, [r5, #124]	; 0x7c
Z_GENLIST_APPEND(slist, snode)
70001dc0:	b963      	cbnz	r3, 70001ddc <submit_to_queue_locked+0x9c>
	list->head = node;
70001dc2:	e9c5 441e 	strd	r4, r4, [r5, #120]	; 0x78
		(void)notify_queue_locked(queue);
70001dc6:	4628      	mov	r0, r5
70001dc8:	f001 f8ae 	bl	70002f28 <notify_queue_locked.isra.0>
	*flagp |= BIT(bit);
70001dcc:	68e3      	ldr	r3, [r4, #12]
70001dce:	f043 0304 	orr.w	r3, r3, #4
70001dd2:	60e3      	str	r3, [r4, #12]
			work->queue = *queuep;
70001dd4:	683b      	ldr	r3, [r7, #0]
70001dd6:	60a3      	str	r3, [r4, #8]
}
70001dd8:	4630      	mov	r0, r6
70001dda:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	parent->next = child;
70001ddc:	601c      	str	r4, [r3, #0]
	list->tail = node;
70001dde:	67ec      	str	r4, [r5, #124]	; 0x7c
}
70001de0:	e7f1      	b.n	70001dc6 <submit_to_queue_locked+0x86>
		return -EINVAL;
70001de2:	f06f 0615 	mvn.w	r6, #21
70001de6:	e7cf      	b.n	70001d88 <submit_to_queue_locked+0x48>
70001de8:	70005f18 	.word	0x70005f18

70001dec <k_work_queue_start>:
void k_work_queue_start(struct k_work_q *queue,
			k_thread_stack_t *stack,
			size_t stack_size,
			int prio,
			const struct k_work_queue_config *cfg)
{
70001dec:	b5f0      	push	{r4, r5, r6, r7, lr}
70001dee:	4604      	mov	r4, r0
70001df0:	b089      	sub	sp, #36	; 0x24
	list->head = NULL;
70001df2:	2000      	movs	r0, #0
	list->tail = NULL;
70001df4:	e9c4 001e 	strd	r0, r0, [r4, #120]	; 0x78
	sys_dlist_init(&w->waitq);
70001df8:	f104 0080 	add.w	r0, r4, #128	; 0x80
70001dfc:	9d0e      	ldr	r5, [sp, #56]	; 0x38
	list->tail = (sys_dnode_t *)list;
70001dfe:	e9c4 0020 	strd	r0, r0, [r4, #128]	; 0x80
70001e02:	f104 0088 	add.w	r0, r4, #136	; 0x88
70001e06:	e9c4 0022 	strd	r0, r0, [r4, #136]	; 0x88

	sys_slist_init(&queue->pending);
	z_waitq_init(&queue->notifyq);
	z_waitq_init(&queue->drainq);

	if ((cfg != NULL) && cfg->no_yield) {
70001e0a:	b34d      	cbz	r5, 70001e60 <k_work_queue_start+0x74>
70001e0c:	7928      	ldrb	r0, [r5, #4]
		flags |= K_WORK_QUEUE_NO_YIELD;
70001e0e:	2800      	cmp	r0, #0
70001e10:	f240 1001 	movw	r0, #257	; 0x101
70001e14:	bf08      	it	eq
70001e16:	2001      	moveq	r0, #1
	*flagp = flags;
70001e18:	f8c4 0090 	str.w	r0, [r4, #144]	; 0x90
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
70001e1c:	2000      	movs	r0, #0
70001e1e:	f04f 36ff 	mov.w	r6, #4294967295	; 0xffffffff
70001e22:	9400      	str	r4, [sp, #0]
70001e24:	f04f 37ff 	mov.w	r7, #4294967295	; 0xffffffff
70001e28:	e9cd 3003 	strd	r3, r0, [sp, #12]
70001e2c:	e9cd 0001 	strd	r0, r0, [sp, #4]
70001e30:	4620      	mov	r0, r4
70001e32:	4b0c      	ldr	r3, [pc, #48]	; (70001e64 <k_work_queue_start+0x78>)
70001e34:	e9cd 6706 	strd	r6, r7, [sp, #24]
70001e38:	f7ff f9f0 	bl	7000121c <z_impl_k_thread_create>

	(void)k_thread_create(&queue->thread, stack, stack_size,
			      work_queue_main, queue, NULL, NULL,
			      prio, 0, K_FOREVER);

	if ((cfg != NULL) && (cfg->name != NULL)) {
70001e3c:	b155      	cbz	r5, 70001e54 <k_work_queue_start+0x68>
70001e3e:	6829      	ldr	r1, [r5, #0]
70001e40:	b111      	cbz	r1, 70001e48 <k_work_queue_start+0x5c>
	return z_impl_k_thread_name_set(thread, str);
70001e42:	4620      	mov	r0, r4
70001e44:	f000 ff19 	bl	70002c7a <z_impl_k_thread_name_set>
		k_thread_name_set(&queue->thread, cfg->name);
	}

	if ((cfg != NULL) && (cfg->essential)) {
70001e48:	796b      	ldrb	r3, [r5, #5]
70001e4a:	b11b      	cbz	r3, 70001e54 <k_work_queue_start+0x68>
		queue->thread.base.user_options |= K_ESSENTIAL;
70001e4c:	7b23      	ldrb	r3, [r4, #12]
70001e4e:	f043 0301 	orr.w	r3, r3, #1
70001e52:	7323      	strb	r3, [r4, #12]
	z_impl_k_wakeup(thread);
70001e54:	4620      	mov	r0, r4
	}

	k_thread_start(&queue->thread);

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_work_queue, start, queue);
}
70001e56:	b009      	add	sp, #36	; 0x24
70001e58:	e8bd 40f0 	ldmia.w	sp!, {r4, r5, r6, r7, lr}
70001e5c:	f7ff bcba 	b.w	700017d4 <z_impl_k_wakeup>
	uint32_t flags = K_WORK_QUEUE_STARTED;
70001e60:	2001      	movs	r0, #1
70001e62:	e7d9      	b.n	70001e18 <k_work_queue_start+0x2c>
70001e64:	70001bfd 	.word	0x70001bfd

70001e68 <snprintf>:
70001e68:	b40c      	push	{r2, r3}
70001e6a:	221c      	movs	r2, #28
70001e6c:	b530      	push	{r4, r5, lr}
70001e6e:	4605      	mov	r5, r0
70001e70:	460c      	mov	r4, r1
70001e72:	b089      	sub	sp, #36	; 0x24
70001e74:	2100      	movs	r1, #0
70001e76:	a801      	add	r0, sp, #4
70001e78:	f001 f879 	bl	70002f6e <memset>
70001e7c:	2302      	movs	r3, #2
70001e7e:	f88d 3006 	strb.w	r3, [sp, #6]
70001e82:	4b0e      	ldr	r3, [pc, #56]	; (70001ebc <snprintf+0x54>)
70001e84:	9302      	str	r3, [sp, #8]
70001e86:	4623      	mov	r3, r4
70001e88:	9505      	str	r5, [sp, #20]
70001e8a:	b12c      	cbz	r4, 70001e98 <snprintf+0x30>
70001e8c:	f1b4 4f00 	cmp.w	r4, #2147483648	; 0x80000000
70001e90:	bf28      	it	cs
70001e92:	f04f 4300 	movcs.w	r3, #2147483648	; 0x80000000
70001e96:	3b01      	subs	r3, #1
70001e98:	aa0d      	add	r2, sp, #52	; 0x34
70001e9a:	990c      	ldr	r1, [sp, #48]	; 0x30
70001e9c:	a801      	add	r0, sp, #4
70001e9e:	441d      	add	r5, r3
70001ea0:	9200      	str	r2, [sp, #0]
70001ea2:	9506      	str	r5, [sp, #24]
70001ea4:	f000 f80c 	bl	70001ec0 <__l_vfprintf>
70001ea8:	b114      	cbz	r4, 70001eb0 <snprintf+0x48>
70001eaa:	9b05      	ldr	r3, [sp, #20]
70001eac:	2200      	movs	r2, #0
70001eae:	701a      	strb	r2, [r3, #0]
70001eb0:	b009      	add	sp, #36	; 0x24
70001eb2:	e8bd 4030 	ldmia.w	sp!, {r4, r5, lr}
70001eb6:	b002      	add	sp, #8
70001eb8:	4770      	bx	lr
70001eba:	bf00      	nop
70001ebc:	70003043 	.word	0x70003043

70001ec0 <__l_vfprintf>:
70001ec0:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
70001ec4:	4615      	mov	r5, r2
70001ec6:	6843      	ldr	r3, [r0, #4]
70001ec8:	b08d      	sub	sp, #52	; 0x34
70001eca:	4680      	mov	r8, r0
70001ecc:	9302      	str	r3, [sp, #8]
70001ece:	7883      	ldrb	r3, [r0, #2]
70001ed0:	079a      	lsls	r2, r3, #30
70001ed2:	f140 810e 	bpl.w	700020f2 <__l_vfprintf+0x232>
70001ed6:	2400      	movs	r4, #0
70001ed8:	780e      	ldrb	r6, [r1, #0]
70001eda:	2e00      	cmp	r6, #0
70001edc:	f000 810b 	beq.w	700020f6 <__l_vfprintf+0x236>
70001ee0:	2e25      	cmp	r6, #37	; 0x25
70001ee2:	d00b      	beq.n	70001efc <__l_vfprintf+0x3c>
70001ee4:	1c4b      	adds	r3, r1, #1
70001ee6:	9303      	str	r3, [sp, #12]
70001ee8:	3401      	adds	r4, #1
70001eea:	9b02      	ldr	r3, [sp, #8]
70001eec:	4641      	mov	r1, r8
70001eee:	4630      	mov	r0, r6
70001ef0:	4798      	blx	r3
70001ef2:	2800      	cmp	r0, #0
70001ef4:	f2c0 80f7 	blt.w	700020e6 <__l_vfprintf+0x226>
70001ef8:	9903      	ldr	r1, [sp, #12]
70001efa:	e7ed      	b.n	70001ed8 <__l_vfprintf+0x18>
70001efc:	784e      	ldrb	r6, [r1, #1]
70001efe:	1c8b      	adds	r3, r1, #2
70001f00:	9303      	str	r3, [sp, #12]
70001f02:	2e25      	cmp	r6, #37	; 0x25
70001f04:	d0f0      	beq.n	70001ee8 <__l_vfprintf+0x28>
70001f06:	2700      	movs	r7, #0
70001f08:	46b9      	mov	r9, r7
70001f0a:	46bb      	mov	fp, r7
70001f0c:	f1bb 0f1f 	cmp.w	fp, #31
70001f10:	d838      	bhi.n	70001f84 <__l_vfprintf+0xc4>
70001f12:	f1a6 0320 	sub.w	r3, r6, #32
70001f16:	2b10      	cmp	r3, #16
70001f18:	d80a      	bhi.n	70001f30 <__l_vfprintf+0x70>
70001f1a:	e8df f003 	tbb	[pc, r3]
70001f1e:	092a      	.short	0x092a
70001f20:	09093009 	.word	0x09093009
70001f24:	09092109 	.word	0x09092109
70001f28:	2d092809 	.word	0x2d092809
70001f2c:	0909      	.short	0x0909
70001f2e:	1f          	.byte	0x1f
70001f2f:	00          	.byte	0x00
70001f30:	f1a6 0330 	sub.w	r3, r6, #48	; 0x30
70001f34:	2b09      	cmp	r3, #9
70001f36:	d933      	bls.n	70001fa0 <__l_vfprintf+0xe0>
70001f38:	2e2a      	cmp	r6, #42	; 0x2a
70001f3a:	d137      	bne.n	70001fac <__l_vfprintf+0xec>
70001f3c:	f855 3b04 	ldr.w	r3, [r5], #4
70001f40:	f01b 0f40 	tst.w	fp, #64	; 0x40
70001f44:	f040 8082 	bne.w	7000204c <__l_vfprintf+0x18c>
70001f48:	2b00      	cmp	r3, #0
70001f4a:	bfa7      	ittee	ge
70001f4c:	f04b 0b20 	orrge.w	fp, fp, #32
70001f50:	4699      	movge	r9, r3
70001f52:	f1c3 0900 	rsblt	r9, r3, #0
70001f56:	f04b 0b28 	orrlt.w	fp, fp, #40	; 0x28
70001f5a:	e001      	b.n	70001f60 <__l_vfprintf+0xa0>
70001f5c:	f04b 0b01 	orr.w	fp, fp, #1
70001f60:	9b03      	ldr	r3, [sp, #12]
70001f62:	f813 6b01 	ldrb.w	r6, [r3], #1
70001f66:	9303      	str	r3, [sp, #12]
70001f68:	2e00      	cmp	r6, #0
70001f6a:	d1cf      	bne.n	70001f0c <__l_vfprintf+0x4c>
70001f6c:	e030      	b.n	70001fd0 <__l_vfprintf+0x110>
70001f6e:	f04b 0b02 	orr.w	fp, fp, #2
70001f72:	f04b 0b04 	orr.w	fp, fp, #4
70001f76:	e7f3      	b.n	70001f60 <__l_vfprintf+0xa0>
70001f78:	f04b 0b08 	orr.w	fp, fp, #8
70001f7c:	e7f0      	b.n	70001f60 <__l_vfprintf+0xa0>
70001f7e:	f04b 0b10 	orr.w	fp, fp, #16
70001f82:	e7ed      	b.n	70001f60 <__l_vfprintf+0xa0>
70001f84:	f1bb 0f7f 	cmp.w	fp, #127	; 0x7f
70001f88:	d819      	bhi.n	70001fbe <__l_vfprintf+0xfe>
70001f8a:	f1a6 0330 	sub.w	r3, r6, #48	; 0x30
70001f8e:	2b09      	cmp	r3, #9
70001f90:	d8d2      	bhi.n	70001f38 <__l_vfprintf+0x78>
70001f92:	f01b 0f40 	tst.w	fp, #64	; 0x40
70001f96:	d003      	beq.n	70001fa0 <__l_vfprintf+0xe0>
70001f98:	210a      	movs	r1, #10
70001f9a:	fb01 3707 	mla	r7, r1, r7, r3
70001f9e:	e7df      	b.n	70001f60 <__l_vfprintf+0xa0>
70001fa0:	210a      	movs	r1, #10
70001fa2:	f04b 0b20 	orr.w	fp, fp, #32
70001fa6:	fb01 3909 	mla	r9, r1, r9, r3
70001faa:	e7d9      	b.n	70001f60 <__l_vfprintf+0xa0>
70001fac:	2e2e      	cmp	r6, #46	; 0x2e
70001fae:	d106      	bne.n	70001fbe <__l_vfprintf+0xfe>
70001fb0:	f01b 0f40 	tst.w	fp, #64	; 0x40
70001fb4:	f040 809f 	bne.w	700020f6 <__l_vfprintf+0x236>
70001fb8:	f04b 0b40 	orr.w	fp, fp, #64	; 0x40
70001fbc:	e7d0      	b.n	70001f60 <__l_vfprintf+0xa0>
70001fbe:	2e6c      	cmp	r6, #108	; 0x6c
70001fc0:	d031      	beq.n	70002026 <__l_vfprintf+0x166>
70001fc2:	d82b      	bhi.n	7000201c <__l_vfprintf+0x15c>
70001fc4:	2e68      	cmp	r6, #104	; 0x68
70001fc6:	d036      	beq.n	70002036 <__l_vfprintf+0x176>
70001fc8:	2e6a      	cmp	r6, #106	; 0x6a
70001fca:	d03c      	beq.n	70002046 <__l_vfprintf+0x186>
70001fcc:	2e4c      	cmp	r6, #76	; 0x4c
70001fce:	d03a      	beq.n	70002046 <__l_vfprintf+0x186>
70001fd0:	2f00      	cmp	r7, #0
70001fd2:	f046 0320 	orr.w	r3, r6, #32
70001fd6:	bfb8      	it	lt
70001fd8:	f02b 0240 	biclt.w	r2, fp, #64	; 0x40
70001fdc:	f1a3 0165 	sub.w	r1, r3, #101	; 0x65
70001fe0:	bfbc      	itt	lt
70001fe2:	2700      	movlt	r7, #0
70001fe4:	fa1f fb82 	uxthlt.w	fp, r2
70001fe8:	2902      	cmp	r1, #2
70001fea:	d901      	bls.n	70001ff0 <__l_vfprintf+0x130>
70001fec:	2b61      	cmp	r3, #97	; 0x61
70001fee:	d12f      	bne.n	70002050 <__l_vfprintf+0x190>
70001ff0:	3507      	adds	r5, #7
70001ff2:	f8df a2b4 	ldr.w	sl, [pc, #692]	; 700022a8 <__l_vfprintf+0x3e8>
70001ff6:	f025 0507 	bic.w	r5, r5, #7
70001ffa:	2707      	movs	r7, #7
70001ffc:	3508      	adds	r5, #8
70001ffe:	f01b 0f08 	tst.w	fp, #8
70002002:	d067      	beq.n	700020d4 <__l_vfprintf+0x214>
70002004:	eb0a 0b07 	add.w	fp, sl, r7
70002008:	4656      	mov	r6, sl
7000200a:	455e      	cmp	r6, fp
7000200c:	d164      	bne.n	700020d8 <__l_vfprintf+0x218>
7000200e:	eba4 0a0a 	sub.w	sl, r4, sl
70002012:	eba9 0907 	sub.w	r9, r9, r7
70002016:	eb06 020a 	add.w	r2, r6, sl
7000201a:	e171      	b.n	70002300 <__l_vfprintf+0x440>
7000201c:	2e74      	cmp	r6, #116	; 0x74
7000201e:	d09f      	beq.n	70001f60 <__l_vfprintf+0xa0>
70002020:	2e7a      	cmp	r6, #122	; 0x7a
70002022:	d09d      	beq.n	70001f60 <__l_vfprintf+0xa0>
70002024:	e7d4      	b.n	70001fd0 <__l_vfprintf+0x110>
70002026:	f01b 0f80 	tst.w	fp, #128	; 0x80
7000202a:	bf18      	it	ne
7000202c:	f44b 7b00 	orrne.w	fp, fp, #512	; 0x200
70002030:	f04b 0b80 	orr.w	fp, fp, #128	; 0x80
70002034:	e794      	b.n	70001f60 <__l_vfprintf+0xa0>
70002036:	f41b 7f80 	tst.w	fp, #256	; 0x100
7000203a:	bf18      	it	ne
7000203c:	f44b 7b00 	orrne.w	fp, fp, #512	; 0x200
70002040:	f44b 7b80 	orr.w	fp, fp, #256	; 0x100
70002044:	e78c      	b.n	70001f60 <__l_vfprintf+0xa0>
70002046:	f44b 7b20 	orr.w	fp, fp, #640	; 0x280
7000204a:	e789      	b.n	70001f60 <__l_vfprintf+0xa0>
7000204c:	461f      	mov	r7, r3
7000204e:	e787      	b.n	70001f60 <__l_vfprintf+0xa0>
70002050:	f1a6 0163 	sub.w	r1, r6, #99	; 0x63
70002054:	2912      	cmp	r1, #18
70002056:	f200 80f1 	bhi.w	7000223c <__l_vfprintf+0x37c>
7000205a:	e8df f011 	tbh	[pc, r1, lsl #1]
7000205e:	0013      	.short	0x0013
70002060:	00ef0050 	.word	0x00ef0050
70002064:	00ef00ef 	.word	0x00ef00ef
70002068:	005000ef 	.word	0x005000ef
7000206c:	00ef00ef 	.word	0x00ef00ef
70002070:	00ef00ef 	.word	0x00ef00ef
70002074:	00ff00ef 	.word	0x00ff00ef
70002078:	00ef00ea 	.word	0x00ef00ea
7000207c:	001b00ef 	.word	0x001b00ef
70002080:	00b000ef 	.word	0x00b000ef
70002084:	f855 3b04 	ldr.w	r3, [r5], #4
70002088:	f10d 0a18 	add.w	sl, sp, #24
7000208c:	f88d 3018 	strb.w	r3, [sp, #24]
70002090:	2701      	movs	r7, #1
70002092:	e7b4      	b.n	70001ffe <__l_vfprintf+0x13e>
70002094:	f855 ab04 	ldr.w	sl, [r5], #4
70002098:	4b84      	ldr	r3, [pc, #528]	; (700022ac <__l_vfprintf+0x3ec>)
7000209a:	f1ba 0f00 	cmp.w	sl, #0
7000209e:	bf08      	it	eq
700020a0:	469a      	moveq	sl, r3
700020a2:	f01b 0f40 	tst.w	fp, #64	; 0x40
700020a6:	bf18      	it	ne
700020a8:	4639      	movne	r1, r7
700020aa:	4650      	mov	r0, sl
700020ac:	bf08      	it	eq
700020ae:	f04f 31ff 	moveq.w	r1, #4294967295	; 0xffffffff
700020b2:	f000 ff64 	bl	70002f7e <strnlen>
700020b6:	4607      	mov	r7, r0
700020b8:	e7a1      	b.n	70001ffe <__l_vfprintf+0x13e>
700020ba:	9b02      	ldr	r3, [sp, #8]
700020bc:	4641      	mov	r1, r8
700020be:	2020      	movs	r0, #32
700020c0:	4798      	blx	r3
700020c2:	2800      	cmp	r0, #0
700020c4:	db0f      	blt.n	700020e6 <__l_vfprintf+0x226>
700020c6:	3e01      	subs	r6, #1
700020c8:	42b7      	cmp	r7, r6
700020ca:	d3f6      	bcc.n	700020ba <__l_vfprintf+0x1fa>
700020cc:	444c      	add	r4, r9
700020ce:	46b1      	mov	r9, r6
700020d0:	1ba4      	subs	r4, r4, r6
700020d2:	e797      	b.n	70002004 <__l_vfprintf+0x144>
700020d4:	464e      	mov	r6, r9
700020d6:	e7f7      	b.n	700020c8 <__l_vfprintf+0x208>
700020d8:	f816 0b01 	ldrb.w	r0, [r6], #1
700020dc:	4641      	mov	r1, r8
700020de:	9b02      	ldr	r3, [sp, #8]
700020e0:	4798      	blx	r3
700020e2:	2800      	cmp	r0, #0
700020e4:	da91      	bge.n	7000200a <__l_vfprintf+0x14a>
700020e6:	f898 3002 	ldrb.w	r3, [r8, #2]
700020ea:	f043 0304 	orr.w	r3, r3, #4
700020ee:	f888 3002 	strb.w	r3, [r8, #2]
700020f2:	f04f 34ff 	mov.w	r4, #4294967295	; 0xffffffff
700020f6:	4620      	mov	r0, r4
700020f8:	b00d      	add	sp, #52	; 0x34
700020fa:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
700020fe:	f01b 0f80 	tst.w	fp, #128	; 0x80
70002102:	d034      	beq.n	7000216e <__l_vfprintf+0x2ae>
70002104:	f41b 7f00 	tst.w	fp, #512	; 0x200
70002108:	d02c      	beq.n	70002164 <__l_vfprintf+0x2a4>
7000210a:	3507      	adds	r5, #7
7000210c:	f025 0507 	bic.w	r5, r5, #7
70002110:	46aa      	mov	sl, r5
70002112:	6869      	ldr	r1, [r5, #4]
70002114:	f85a 0b08 	ldr.w	r0, [sl], #8
70002118:	f02b 0510 	bic.w	r5, fp, #16
7000211c:	2900      	cmp	r1, #0
7000211e:	b2ad      	uxth	r5, r5
70002120:	da37      	bge.n	70002192 <__l_vfprintf+0x2d2>
70002122:	4240      	negs	r0, r0
70002124:	f445 6580 	orr.w	r5, r5, #1024	; 0x400
70002128:	eb61 0141 	sbc.w	r1, r1, r1, lsl #1
7000212c:	f10d 0b18 	add.w	fp, sp, #24
70002130:	230a      	movs	r3, #10
70002132:	465a      	mov	r2, fp
70002134:	f000 ff2f 	bl	70002f96 <__ultoa_invert>
70002138:	eba0 030b 	sub.w	r3, r0, fp
7000213c:	9301      	str	r3, [sp, #4]
7000213e:	066b      	lsls	r3, r5, #25
70002140:	d562      	bpl.n	70002208 <__l_vfprintf+0x348>
70002142:	9b01      	ldr	r3, [sp, #4]
70002144:	f025 0101 	bic.w	r1, r5, #1
70002148:	429f      	cmp	r7, r3
7000214a:	b289      	uxth	r1, r1
7000214c:	f340 80a1 	ble.w	70002292 <__l_vfprintf+0x3d2>
70002150:	2e00      	cmp	r6, #0
70002152:	f000 8099 	beq.w	70002288 <__l_vfprintf+0x3c8>
70002156:	f015 0210 	ands.w	r2, r5, #16
7000215a:	f040 809c 	bne.w	70002296 <__l_vfprintf+0x3d6>
7000215e:	46bb      	mov	fp, r7
70002160:	460d      	mov	r5, r1
70002162:	e023      	b.n	700021ac <__l_vfprintf+0x2ec>
70002164:	46aa      	mov	sl, r5
70002166:	f85a 0b04 	ldr.w	r0, [sl], #4
7000216a:	17c1      	asrs	r1, r0, #31
7000216c:	e7d4      	b.n	70002118 <__l_vfprintf+0x258>
7000216e:	46aa      	mov	sl, r5
70002170:	f41b 7f80 	tst.w	fp, #256	; 0x100
70002174:	f85a 1b04 	ldr.w	r1, [sl], #4
70002178:	d101      	bne.n	7000217e <__l_vfprintf+0x2be>
7000217a:	4608      	mov	r0, r1
7000217c:	e7f5      	b.n	7000216a <__l_vfprintf+0x2aa>
7000217e:	f41b 7f00 	tst.w	fp, #512	; 0x200
70002182:	bf15      	itete	ne
70002184:	b248      	sxtbne	r0, r1
70002186:	b208      	sxtheq	r0, r1
70002188:	f341 11c0 	sbfxne	r1, r1, #7, #1
7000218c:	f341 31c0 	sbfxeq	r1, r1, #15, #1
70002190:	e7c2      	b.n	70002118 <__l_vfprintf+0x258>
70002192:	ea50 0301 	orrs.w	r3, r0, r1
70002196:	d1c9      	bne.n	7000212c <__l_vfprintf+0x26c>
70002198:	f01b 0f40 	tst.w	fp, #64	; 0x40
7000219c:	d0c6      	beq.n	7000212c <__l_vfprintf+0x26c>
7000219e:	2f00      	cmp	r7, #0
700021a0:	d1c4      	bne.n	7000212c <__l_vfprintf+0x26c>
700021a2:	f02b 0211 	bic.w	r2, fp, #17
700021a6:	46bb      	mov	fp, r7
700021a8:	9701      	str	r7, [sp, #4]
700021aa:	b295      	uxth	r5, r2
700021ac:	f240 4106 	movw	r1, #1030	; 0x406
700021b0:	ea15 0201 	ands.w	r2, r5, r1
700021b4:	bf1c      	itt	ne
700021b6:	f10b 0b01 	addne.w	fp, fp, #1
700021ba:	2200      	movne	r2, #0
700021bc:	e02c      	b.n	70002218 <__l_vfprintf+0x358>
700021be:	f02b 0210 	bic.w	r2, fp, #16
700021c2:	230a      	movs	r3, #10
700021c4:	fa1f fb82 	uxth.w	fp, r2
700021c8:	f01b 0c80 	ands.w	ip, fp, #128	; 0x80
700021cc:	d049      	beq.n	70002262 <__l_vfprintf+0x3a2>
700021ce:	f41b 7100 	ands.w	r1, fp, #512	; 0x200
700021d2:	bf17      	itett	ne
700021d4:	3507      	addne	r5, #7
700021d6:	46aa      	moveq	sl, r5
700021d8:	f025 0507 	bicne.w	r5, r5, #7
700021dc:	46aa      	movne	sl, r5
700021de:	bf0e      	itee	eq
700021e0:	f85a 0b04 	ldreq.w	r0, [sl], #4
700021e4:	6869      	ldrne	r1, [r5, #4]
700021e6:	f85a 0b08 	ldrne.w	r0, [sl], #8
700021ea:	ea50 0501 	orrs.w	r5, r0, r1
700021ee:	d145      	bne.n	7000227c <__l_vfprintf+0x3bc>
700021f0:	f02b 0516 	bic.w	r5, fp, #22
700021f4:	f01b 0f40 	tst.w	fp, #64	; 0x40
700021f8:	b2ad      	uxth	r5, r5
700021fa:	d042      	beq.n	70002282 <__l_vfprintf+0x3c2>
700021fc:	2f00      	cmp	r7, #0
700021fe:	d140      	bne.n	70002282 <__l_vfprintf+0x3c2>
70002200:	f02b 0217 	bic.w	r2, fp, #23
70002204:	9701      	str	r7, [sp, #4]
70002206:	b295      	uxth	r5, r2
70002208:	f015 0210 	ands.w	r2, r5, #16
7000220c:	d048      	beq.n	700022a0 <__l_vfprintf+0x3e0>
7000220e:	9b01      	ldr	r3, [sp, #4]
70002210:	2e00      	cmp	r6, #0
70002212:	d142      	bne.n	7000229a <__l_vfprintf+0x3da>
70002214:	f103 0b01 	add.w	fp, r3, #1
70002218:	0729      	lsls	r1, r5, #28
7000221a:	d45b      	bmi.n	700022d4 <__l_vfprintf+0x414>
7000221c:	07eb      	lsls	r3, r5, #31
7000221e:	d506      	bpl.n	7000222e <__l_vfprintf+0x36e>
70002220:	45d9      	cmp	r9, fp
70002222:	dd70      	ble.n	70002306 <__l_vfprintf+0x446>
70002224:	9901      	ldr	r1, [sp, #4]
70002226:	eba9 030b 	sub.w	r3, r9, fp
7000222a:	46cb      	mov	fp, r9
7000222c:	185f      	adds	r7, r3, r1
7000222e:	465b      	mov	r3, fp
70002230:	e04a      	b.n	700022c8 <__l_vfprintf+0x408>
70002232:	f04b 0b10 	orr.w	fp, fp, #16
70002236:	2310      	movs	r3, #16
70002238:	2678      	movs	r6, #120	; 0x78
7000223a:	e7c5      	b.n	700021c8 <__l_vfprintf+0x308>
7000223c:	2b78      	cmp	r3, #120	; 0x78
7000223e:	d104      	bne.n	7000224a <__l_vfprintf+0x38a>
70002240:	f1c6 0378 	rsb	r3, r6, #120	; 0x78
70002244:	f043 0310 	orr.w	r3, r3, #16
70002248:	e7be      	b.n	700021c8 <__l_vfprintf+0x308>
7000224a:	9b02      	ldr	r3, [sp, #8]
7000224c:	4641      	mov	r1, r8
7000224e:	2025      	movs	r0, #37	; 0x25
70002250:	4798      	blx	r3
70002252:	2800      	cmp	r0, #0
70002254:	f6ff af47 	blt.w	700020e6 <__l_vfprintf+0x226>
70002258:	3402      	adds	r4, #2
7000225a:	e646      	b.n	70001eea <__l_vfprintf+0x2a>
7000225c:	2308      	movs	r3, #8
7000225e:	2600      	movs	r6, #0
70002260:	e7b2      	b.n	700021c8 <__l_vfprintf+0x308>
70002262:	46aa      	mov	sl, r5
70002264:	f41b 7180 	ands.w	r1, fp, #256	; 0x100
70002268:	f85a 0b04 	ldr.w	r0, [sl], #4
7000226c:	d0bd      	beq.n	700021ea <__l_vfprintf+0x32a>
7000226e:	f41b 7100 	ands.w	r1, fp, #512	; 0x200
70002272:	bf1a      	itte	ne
70002274:	b2c0      	uxtbne	r0, r0
70002276:	4661      	movne	r1, ip
70002278:	b280      	uxtheq	r0, r0
7000227a:	e7b6      	b.n	700021ea <__l_vfprintf+0x32a>
7000227c:	f02b 0206 	bic.w	r2, fp, #6
70002280:	b295      	uxth	r5, r2
70002282:	f10d 0b18 	add.w	fp, sp, #24
70002286:	e754      	b.n	70002132 <__l_vfprintf+0x272>
70002288:	f025 0511 	bic.w	r5, r5, #17
7000228c:	46bb      	mov	fp, r7
7000228e:	b2ad      	uxth	r5, r5
70002290:	e78c      	b.n	700021ac <__l_vfprintf+0x2ec>
70002292:	460d      	mov	r5, r1
70002294:	e7b8      	b.n	70002208 <__l_vfprintf+0x348>
70002296:	463b      	mov	r3, r7
70002298:	460d      	mov	r5, r1
7000229a:	f103 0b02 	add.w	fp, r3, #2
7000229e:	e7bb      	b.n	70002218 <__l_vfprintf+0x358>
700022a0:	f8dd b004 	ldr.w	fp, [sp, #4]
700022a4:	e782      	b.n	700021ac <__l_vfprintf+0x2ec>
700022a6:	bf00      	nop
700022a8:	700043c8 	.word	0x700043c8
700022ac:	700043c1 	.word	0x700043c1
700022b0:	e9cd 3204 	strd	r3, r2, [sp, #16]
700022b4:	4641      	mov	r1, r8
700022b6:	9b02      	ldr	r3, [sp, #8]
700022b8:	2020      	movs	r0, #32
700022ba:	4798      	blx	r3
700022bc:	2800      	cmp	r0, #0
700022be:	f6ff af12 	blt.w	700020e6 <__l_vfprintf+0x226>
700022c2:	9b04      	ldr	r3, [sp, #16]
700022c4:	9a05      	ldr	r2, [sp, #20]
700022c6:	3301      	adds	r3, #1
700022c8:	4599      	cmp	r9, r3
700022ca:	dcf1      	bgt.n	700022b0 <__l_vfprintf+0x3f0>
700022cc:	eba4 010b 	sub.w	r1, r4, fp
700022d0:	469b      	mov	fp, r3
700022d2:	18cc      	adds	r4, r1, r3
700022d4:	b30a      	cbz	r2, 7000231a <__l_vfprintf+0x45a>
700022d6:	9b02      	ldr	r3, [sp, #8]
700022d8:	4641      	mov	r1, r8
700022da:	2030      	movs	r0, #48	; 0x30
700022dc:	4798      	blx	r3
700022de:	2800      	cmp	r0, #0
700022e0:	f6ff af01 	blt.w	700020e6 <__l_vfprintf+0x226>
700022e4:	b98e      	cbnz	r6, 7000230a <__l_vfprintf+0x44a>
700022e6:	3401      	adds	r4, #1
700022e8:	4427      	add	r7, r4
700022ea:	9b01      	ldr	r3, [sp, #4]
700022ec:	1b39      	subs	r1, r7, r4
700022ee:	4299      	cmp	r1, r3
700022f0:	dc24      	bgt.n	7000233c <__l_vfprintf+0x47c>
700022f2:	461d      	mov	r5, r3
700022f4:	bb55      	cbnz	r5, 7000234c <__l_vfprintf+0x48c>
700022f6:	9a01      	ldr	r2, [sp, #4]
700022f8:	eba9 090b 	sub.w	r9, r9, fp
700022fc:	4655      	mov	r5, sl
700022fe:	4422      	add	r2, r4
70002300:	4614      	mov	r4, r2
70002302:	4491      	add	r9, r2
70002304:	e033      	b.n	7000236e <__l_vfprintf+0x4ae>
70002306:	9f01      	ldr	r7, [sp, #4]
70002308:	e791      	b.n	7000222e <__l_vfprintf+0x36e>
7000230a:	3402      	adds	r4, #2
7000230c:	4641      	mov	r1, r8
7000230e:	4630      	mov	r0, r6
70002310:	9b02      	ldr	r3, [sp, #8]
70002312:	4798      	blx	r3
70002314:	2800      	cmp	r0, #0
70002316:	dae7      	bge.n	700022e8 <__l_vfprintf+0x428>
70002318:	e6e5      	b.n	700020e6 <__l_vfprintf+0x226>
7000231a:	f240 4106 	movw	r1, #1030	; 0x406
7000231e:	420d      	tst	r5, r1
70002320:	d0e2      	beq.n	700022e8 <__l_vfprintf+0x428>
70002322:	f015 0f02 	tst.w	r5, #2
70002326:	f104 0401 	add.w	r4, r4, #1
7000232a:	4641      	mov	r1, r8
7000232c:	bf14      	ite	ne
7000232e:	202b      	movne	r0, #43	; 0x2b
70002330:	2020      	moveq	r0, #32
70002332:	f415 6f80 	tst.w	r5, #1024	; 0x400
70002336:	bf18      	it	ne
70002338:	202d      	movne	r0, #45	; 0x2d
7000233a:	e7e9      	b.n	70002310 <__l_vfprintf+0x450>
7000233c:	9b02      	ldr	r3, [sp, #8]
7000233e:	4641      	mov	r1, r8
70002340:	2030      	movs	r0, #48	; 0x30
70002342:	3401      	adds	r4, #1
70002344:	4798      	blx	r3
70002346:	2800      	cmp	r0, #0
70002348:	dacf      	bge.n	700022ea <__l_vfprintf+0x42a>
7000234a:	e6cc      	b.n	700020e6 <__l_vfprintf+0x226>
7000234c:	ab06      	add	r3, sp, #24
7000234e:	3d01      	subs	r5, #1
70002350:	4641      	mov	r1, r8
70002352:	5d58      	ldrb	r0, [r3, r5]
70002354:	9b02      	ldr	r3, [sp, #8]
70002356:	4798      	blx	r3
70002358:	2800      	cmp	r0, #0
7000235a:	dacb      	bge.n	700022f4 <__l_vfprintf+0x434>
7000235c:	e6c3      	b.n	700020e6 <__l_vfprintf+0x226>
7000235e:	9b02      	ldr	r3, [sp, #8]
70002360:	4641      	mov	r1, r8
70002362:	2020      	movs	r0, #32
70002364:	3401      	adds	r4, #1
70002366:	4798      	blx	r3
70002368:	2800      	cmp	r0, #0
7000236a:	f6ff aebc 	blt.w	700020e6 <__l_vfprintf+0x226>
7000236e:	eba9 0304 	sub.w	r3, r9, r4
70002372:	2b00      	cmp	r3, #0
70002374:	dcf3      	bgt.n	7000235e <__l_vfprintf+0x49e>
70002376:	e5bf      	b.n	70001ef8 <__l_vfprintf+0x38>

70002378 <_OffsetAbsSyms>:

#include <gen_offset.h>

#include "offsets_aarch32.c"

GEN_ABS_SYM_END
70002378:	4770      	bx	lr

7000237a <main>:

int main(void)
{
#ifdef USING_ZEPHYR
   extern int rtos_main_zephyr(void);
   return rtos_main_zephyr();
7000237a:	f7fd bfb1 	b.w	700002e0 <rtos_main_zephyr>

7000237e <setup_interrupt>:
{
7000237e:	b508      	push	{r3, lr}
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
70002380:	2204      	movs	r2, #4
70002382:	2101      	movs	r1, #1
70002384:	200a      	movs	r0, #10
70002386:	f7fe fc1b 	bl	70000bc0 <z_vim_irq_priority_set>
   IRQ_CONNECT(SOFTWARE_INTERRUPT_ID, 1, tm_interrupt_handler, NULL, 0);
7000238a:	2200      	movs	r2, #0
7000238c:	2101      	movs	r1, #1
7000238e:	200a      	movs	r0, #10
70002390:	f000 f8a0 	bl	700024d4 <z_soc_irq_priority_set>
   irq_enable(SOFTWARE_INTERRUPT_ID);
70002394:	200a      	movs	r0, #10
70002396:	f000 f89f 	bl	700024d8 <z_soc_irq_enable>
}
7000239a:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
   z_vim_irq_enable(irq);
7000239e:	200a      	movs	r0, #10
700023a0:	f7fe bc36 	b.w	70000c10 <z_vim_irq_enable>

700023a4 <compute_checksum>:
   for (int i = 0; i < size; i++)
700023a4:	2300      	movs	r3, #0
{
700023a6:	4602      	mov	r2, r0
   unsigned long checksum = 0;
700023a8:	4618      	mov	r0, r3
{
700023aa:	b510      	push	{r4, lr}
   for (int i = 0; i < size; i++)
700023ac:	428b      	cmp	r3, r1
700023ae:	db00      	blt.n	700023b2 <compute_checksum+0xe>
}
700023b0:	bd10      	pop	{r4, pc}
      checksum += msg[i];
700023b2:	f852 4023 	ldr.w	r4, [r2, r3, lsl #2]
   for (int i = 0; i < size; i++)
700023b6:	3301      	adds	r3, #1
      checksum += msg[i];
700023b8:	4420      	add	r0, r4
   for (int i = 0; i < size; i++)
700023ba:	e7f7      	b.n	700023ac <compute_checksum+0x8>

700023bc <tm_initialize>:
   test_initialization_function();
700023bc:	4700      	bx	r0

700023be <tm_thread_sleep>:
   k_sleep(K_SECONDS(seconds));
700023be:	f44f 737a 	mov.w	r3, #1000	; 0x3e8
700023c2:	210a      	movs	r1, #10
700023c4:	4358      	muls	r0, r3
700023c6:	fba0 0101 	umull	r0, r1, r0, r1
	return z_impl_k_sleep(timeout);
700023ca:	f000 bcd7 	b.w	70002d7c <z_impl_k_sleep>

700023ce <tm_suspend_scheduler>:
   k_sched_lock();
700023ce:	f7ff b943 	b.w	70001658 <k_sched_lock>

700023d2 <tm_resume_scheduler>:
   k_sched_unlock();
700023d2:	f7ff b951 	b.w	70001678 <k_sched_unlock>

700023d6 <chunk_size>:
	void *cmem = &buf[c];

	if (big_heap(h)) {
		return ((uint32_t *)cmem)[f];
	} else {
		return ((uint16_t *)cmem)[f];
700023d6:	eb00 00c1 	add.w	r0, r0, r1, lsl #3
700023da:	8840      	ldrh	r0, [r0, #2]
}

static inline chunksz_t chunk_size(struct z_heap *h, chunkid_t c)
{
	return chunk_field(h, c, SIZE_AND_USED) >> 1;
}
700023dc:	0840      	lsrs	r0, r0, #1
700023de:	4770      	bx	lr

700023e0 <free_list_add>:
	h->free_bytes += chunksz_to_bytes(h, chunk_size(h, c));
#endif
}

static void free_list_add(struct z_heap *h, chunkid_t c)
{
700023e0:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
700023e2:	4603      	mov	r3, r0
	if (!solo_free_header(h, c)) {
		int bidx = bucket_idx(h, chunk_size(h, c));
700023e4:	f7ff fff7 	bl	700023d6 <chunk_size>
{
700023e8:	460c      	mov	r4, r1
	void *cmem = &buf[c];
700023ea:	00ca      	lsls	r2, r1, #3
		((uint16_t *)cmem)[f] = val;
700023ec:	1d17      	adds	r7, r2, #4
700023ee:	b28d      	uxth	r5, r1
700023f0:	3206      	adds	r2, #6
}

static inline int bucket_idx(struct z_heap *h, chunksz_t sz)
{
	unsigned int usable_sz = sz - min_chunk_size(h) + 1;
	return 31 - __builtin_clz(usable_sz);
700023f2:	fab0 f080 	clz	r0, r0
700023f6:	f1c0 001f 	rsb	r0, r0, #31
	if (b->next == 0U) {
700023fa:	eb03 0c80 	add.w	ip, r3, r0, lsl #2
700023fe:	f8dc 6010 	ldr.w	r6, [ip, #16]
70002402:	b956      	cbnz	r6, 7000241a <free_list_add+0x3a>
		h->avail_buckets |= BIT(bidx);
70002404:	2101      	movs	r1, #1
70002406:	fa01 f000 	lsl.w	r0, r1, r0
7000240a:	68d9      	ldr	r1, [r3, #12]
7000240c:	4301      	orrs	r1, r0
7000240e:	60d9      	str	r1, [r3, #12]
		b->next = c;
70002410:	f8cc 4010 	str.w	r4, [ip, #16]
		((uint16_t *)cmem)[f] = val;
70002414:	53dd      	strh	r5, [r3, r7]
70002416:	529d      	strh	r5, [r3, r2]
		free_list_add_bidx(h, c, bidx);
	}
}
70002418:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	void *cmem = &buf[c];
7000241a:	00f1      	lsls	r1, r6, #3
		return ((uint16_t *)cmem)[f];
7000241c:	3104      	adds	r1, #4
7000241e:	5a58      	ldrh	r0, [r3, r1]
		((uint16_t *)cmem)[f] = val;
70002420:	53d8      	strh	r0, [r3, r7]
70002422:	eb03 00c0 	add.w	r0, r3, r0, lsl #3
70002426:	529e      	strh	r6, [r3, r2]
70002428:	80c5      	strh	r5, [r0, #6]
7000242a:	525d      	strh	r5, [r3, r1]
7000242c:	e7f4      	b.n	70002418 <free_list_add+0x38>

7000242e <sys_heap_init>:
		__ASSERT(bytes / CHUNK_UNIT <= 0x7fffffffU, "heap size is too big");
	}

	/* Reserve the end marker chunk's header */
	__ASSERT(bytes > heap_footer_bytes(bytes), "heap size is too small");
	bytes -= heap_footer_bytes(bytes);
7000242e:	3a04      	subs	r2, #4
{
70002430:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	__ASSERT(heap_sz > chunksz(sizeof(struct z_heap)), "heap size is too small");

	struct z_heap *h = (struct z_heap *)addr;
	heap->heap = h;
	h->end_chunk = heap_sz;
	h->avail_buckets = 0;
70002434:	f04f 0800 	mov.w	r8, #0
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
70002438:	1dcc      	adds	r4, r1, #7
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
7000243a:	4411      	add	r1, r2
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
7000243c:	f024 0407 	bic.w	r4, r4, #7
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
70002440:	f021 0107 	bic.w	r1, r1, #7
	heap->heap = h;
70002444:	6004      	str	r4, [r0, #0]
	chunksz_t heap_sz = (end - addr) / CHUNK_UNIT;
70002446:	1b0e      	subs	r6, r1, r4
	h->avail_buckets = 0;
70002448:	f8c4 800c 	str.w	r8, [r4, #12]
				     nb_buckets * sizeof(struct z_heap_bucket));

	__ASSERT(chunk0_size + min_chunk_size(h) <= heap_sz, "heap size is too small");

	for (int i = 0; i < nb_buckets; i++) {
		h->buckets[i].next = 0;
7000244c:	4641      	mov	r1, r8
	chunksz_t heap_sz = (end - addr) / CHUNK_UNIT;
7000244e:	08f7      	lsrs	r7, r6, #3
	return 31 - __builtin_clz(usable_sz);
70002450:	fab7 f287 	clz	r2, r7
	chunksz_t chunk0_size = chunksz(sizeof(struct z_heap) +
70002454:	f1c2 0524 	rsb	r5, r2, #36	; 0x24
	int nb_buckets = bucket_idx(h, heap_sz) + 1;
70002458:	f1c2 0220 	rsb	r2, r2, #32
	chunksz_t chunk0_size = chunksz(sizeof(struct z_heap) +
7000245c:	00ad      	lsls	r5, r5, #2
	return (bytes + CHUNK_UNIT - 1U) / CHUNK_UNIT;
7000245e:	3507      	adds	r5, #7
		h->buckets[i].next = 0;
70002460:	0092      	lsls	r2, r2, #2
70002462:	08ed      	lsrs	r5, r5, #3
	h->end_chunk = heap_sz;
70002464:	60a7      	str	r7, [r4, #8]
		h->buckets[i].next = 0;
70002466:	f104 0010 	add.w	r0, r4, #16
7000246a:	f000 fd80 	bl	70002f6e <memset>
	chunk_set(h, c, SIZE_AND_USED, size << 1);
7000246e:	006b      	lsls	r3, r5, #1
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
70002470:	f043 0301 	orr.w	r3, r3, #1
		((uint16_t *)cmem)[f] = val;
70002474:	f8a4 8000 	strh.w	r8, [r4]
70002478:	eb04 02c5 	add.w	r2, r4, r5, lsl #3
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
7000247c:	8063      	strh	r3, [r4, #2]
	set_chunk_size(h, 0, chunk0_size);
	set_left_chunk_size(h, 0, 0);
	set_chunk_used(h, 0, true);

	/* chunk containing the free heap */
	set_chunk_size(h, chunk0_size, heap_sz - chunk0_size);
7000247e:	1b7b      	subs	r3, r7, r5
	/* the end marker chunk */
	set_chunk_size(h, heap_sz, 0);
	set_left_chunk_size(h, heap_sz, heap_sz - chunk0_size);
	set_chunk_used(h, heap_sz, true);

	free_list_add(h, chunk0_size);
70002480:	4620      	mov	r0, r4
	chunk_set(h, c, SIZE_AND_USED, size << 1);
70002482:	0059      	lsls	r1, r3, #1
		((uint16_t *)cmem)[f] = val;
70002484:	8051      	strh	r1, [r2, #2]
70002486:	19a2      	adds	r2, r4, r6
70002488:	f824 5035 	strh.w	r5, [r4, r5, lsl #3]
7000248c:	4629      	mov	r1, r5
7000248e:	f8a2 8002 	strh.w	r8, [r2, #2]
70002492:	53a3      	strh	r3, [r4, r6]
	void *cmem = &buf[c];
70002494:	eb04 03c7 	add.w	r3, r4, r7, lsl #3
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
70002498:	885a      	ldrh	r2, [r3, #2]
7000249a:	f042 0201 	orr.w	r2, r2, #1
7000249e:	805a      	strh	r2, [r3, #2]
}
700024a0:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
	free_list_add(h, chunk0_size);
700024a4:	f7ff bf9c 	b.w	700023e0 <free_list_add>

700024a8 <arch_printk_char_out>:
}
700024a8:	2000      	movs	r0, #0
700024aa:	4770      	bx	lr

700024ac <printk>:
 *
 * @param fmt formatted string to output
 */

void printk(const char *fmt, ...)
{
700024ac:	b40f      	push	{r0, r1, r2, r3}
700024ae:	b507      	push	{r0, r1, r2, lr}
700024b0:	a904      	add	r1, sp, #16
700024b2:	f851 0b04 	ldr.w	r0, [r1], #4
	va_list ap;

	va_start(ap, fmt);
700024b6:	9101      	str	r1, [sp, #4]

	vprintk(fmt, ap);
700024b8:	f7fe f8b6 	bl	70000628 <vprintk>

	va_end(ap);
}
700024bc:	b003      	add	sp, #12
700024be:	f85d eb04 	ldr.w	lr, [sp], #4
700024c2:	b004      	add	sp, #16
700024c4:	4770      	bx	lr

700024c6 <_ConfigAbsSyms>:
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_WARN_DEPRECATED, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_ENFORCE_ZEPHYR_STDINT, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_LEGACY_GENERATED_INCLUDE_PATH, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_BENCHMARK_NUM_ITERATIONS, 1000);

GEN_ABS_SYM_END
700024c6:	4770      	bx	lr

700024c8 <z_soc_irq_get_active>:

#include "soc.h"

unsigned int z_soc_irq_get_active(void)
{
	return z_vim_irq_get_active();
700024c8:	f7fe bb1e 	b.w	70000b08 <z_vim_irq_get_active>

700024cc <z_soc_irq_eoi>:
}

void z_soc_irq_eoi(unsigned int irq)
{
	z_vim_irq_eoi(irq);
700024cc:	f7fe bb40 	b.w	70000b50 <z_vim_irq_eoi>

700024d0 <z_soc_irq_init>:
}

void z_soc_irq_init(void)
{
	z_vim_irq_init();
700024d0:	f7fe bb46 	b.w	70000b60 <z_vim_irq_init>

700024d4 <z_soc_irq_priority_set>:
}

void z_soc_irq_priority_set(unsigned int irq, unsigned int prio, uint32_t flags)
{
	/* Configure interrupt type and priority */
	z_vim_irq_priority_set(irq, prio, flags);
700024d4:	f7fe bb74 	b.w	70000bc0 <z_vim_irq_priority_set>

700024d8 <z_soc_irq_enable>:
}

void z_soc_irq_enable(unsigned int irq)
{
	/* Enable interrupt */
	z_vim_irq_enable(irq);
700024d8:	f7fe bb9a 	b.w	70000c10 <z_vim_irq_enable>

700024dc <soc_reset_hook>:
	/* Check if interrupt is enabled */
	return z_vim_irq_is_enabled(irq);
}

void soc_reset_hook(void)
{
700024dc:	b508      	push	{r3, lr}
 *
 */
static ALWAYS_INLINE void sys_cache_instr_enable(void)
{
#if defined(CONFIG_CACHE_MANAGEMENT) && defined(CONFIG_ICACHE)
	cache_instr_enable();
700024de:	f000 f8c3 	bl	70002668 <arch_icache_enable>
	/*
	 * Enable the caches only if configured to do so.
	 */
	sys_cache_instr_enable();
	sys_cache_data_enable();
700024e2:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	cache_data_enable();
700024e6:	f000 b8a9 	b.w	7000263c <arch_dcache_enable>

700024ea <z_arm_fatal_error>:

		LOG_ERR("Unhandled IRQn: %d", irqn);
	}
#endif

	z_fatal_error(reason, esf);
700024ea:	f7fe bca7 	b.w	70000e3c <z_fatal_error>

700024ee <z_do_kernel_oops>:
 * @param esf exception frame
 * @param callee_regs Callee-saved registers (R4-R11)
 * @param exc_return EXC_RETURN value present in LR after exception entry.
 */
void z_do_kernel_oops(const struct arch_esf *esf, _callee_saved_t *callee_regs, uint32_t exc_return)
{
700024ee:	4601      	mov	r1, r0
	z_fatal_error(reason, esf);
700024f0:	6800      	ldr	r0, [r0, #0]
700024f2:	f7fe bca3 	b.w	70000e3c <z_fatal_error>

700024f6 <dump_fault.constprop.0>:
	/*
	 * Dump fault status and, if applicable, status-specific information.
	 * Note that the fault address is only displayed for the synchronous
	 * faults because it is unpredictable for asynchronous faults.
	 */
	switch (status) {
700024f6:	280d      	cmp	r0, #13
700024f8:	d80e      	bhi.n	70002518 <dump_fault.constprop.0+0x22>
700024fa:	280d      	cmp	r0, #13
700024fc:	d80a      	bhi.n	70002514 <dump_fault.constprop.0+0x1e>
700024fe:	e8df f000 	tbb	[pc, r0]
70002502:	1c1a      	.short	0x1c1a
70002504:	09090916 	.word	0x09090916
70002508:	09140909 	.word	0x09140909
7000250c:	07090909 	.word	0x07090909
	case FSR_FS_ALIGNMENT_FAULT:
		reason = K_ERR_ARM_ALIGNMENT_FAULT;
		LOG_ERR("Alignment Fault @ 0x%08x", addr);
		break;
	case FSR_FS_PERMISSION_FAULT:
		reason = K_ERR_ARM_PERMISSION_FAULT;
70002510:	2030      	movs	r0, #48	; 0x30
70002512:	4770      	bx	lr
	uint32_t reason = K_ERR_CPU_EXCEPTION;
70002514:	2000      	movs	r0, #0
70002516:	4770      	bx	lr
	switch (status) {
70002518:	2818      	cmp	r0, #24
7000251a:	d010      	beq.n	7000253e <dump_fault.constprop.0+0x48>
7000251c:	2819      	cmp	r0, #25
7000251e:	d010      	beq.n	70002542 <dump_fault.constprop.0+0x4c>
	uint32_t reason = K_ERR_CPU_EXCEPTION;
70002520:	2816      	cmp	r0, #22
70002522:	bf0c      	ite	eq
70002524:	2032      	moveq	r0, #50	; 0x32
70002526:	2000      	movne	r0, #0
70002528:	4770      	bx	lr
		LOG_ERR("Permission Fault @ 0x%08x", addr);
		break;
	case FSR_FS_SYNC_EXTERNAL_ABORT:
		reason = K_ERR_ARM_SYNC_EXTERNAL_ABORT;
7000252a:	2031      	movs	r0, #49	; 0x31
		LOG_ERR("Synchronous External Abort @ 0x%08x", addr);
		break;
7000252c:	4770      	bx	lr
	__get_CP(14, 0, result, 0, 1, 0);
7000252e:	ee10 3e11 	mrc	14, 0, r3, cr0, cr1, {0}
	case FSR_FS_ASYNC_PARITY_ERROR:
		reason = K_ERR_ARM_ASYNC_PARITY_ERROR;
		LOG_ERR("Asynchronous Parity/ECC Error");
		break;
	case FSR_FS_DEBUG_EVENT:
		reason = K_ERR_ARM_DEBUG_EVENT;
70002532:	2035      	movs	r0, #53	; 0x35
}
70002534:	4770      	bx	lr
		reason = K_ERR_ARM_UNSUPPORTED_EXCLUSIVE_ACCESS_FAULT;
		LOG_ERR("Unsupported Exclusive Access Fault @ 0x%08x", addr);
		break;
#else
	case FSR_FS_BACKGROUND_FAULT:
		reason = K_ERR_ARM_BACKGROUND_FAULT;
70002536:	202f      	movs	r0, #47	; 0x2f
		LOG_ERR("Background Fault @ 0x%08x", addr);
		break;
70002538:	4770      	bx	lr
	switch (status) {
7000253a:	202e      	movs	r0, #46	; 0x2e
7000253c:	4770      	bx	lr
		reason = K_ERR_ARM_ASYNC_PARITY_ERROR;
7000253e:	2034      	movs	r0, #52	; 0x34
70002540:	4770      	bx	lr
		reason = K_ERR_ARM_SYNC_PARITY_ERROR;
70002542:	2033      	movs	r0, #51	; 0x33
#endif
	default:
		LOG_ERR("Unknown (%u)", status);
	}
	return reason;
}
70002544:	4770      	bx	lr

70002546 <z_arm_fault_undef_instruction>:
 * @brief Undefined instruction fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_undef_instruction(struct arch_esf *esf)
{
70002546:	4601      	mov	r1, r0
	uint32_t reason = IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) ?
			  K_ERR_CPU_EXCEPTION :
			  K_ERR_ARM_UNDEFINED_INSTRUCTION;

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70002548:	202d      	movs	r0, #45	; 0x2d
{
7000254a:	b508      	push	{r3, lr}
	z_arm_fatal_error(reason, esf);
7000254c:	f7ff ffcd 	bl	700024ea <z_arm_fatal_error>

	/* All undefined instructions are treated as fatal for now */
	return true;
}
70002550:	2001      	movs	r0, #1
70002552:	bd08      	pop	{r3, pc}

70002554 <z_arm_fault_prefetch>:
 * @brief Prefetch abort fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_prefetch(struct arch_esf *esf)
{
70002554:	b508      	push	{r3, lr}
70002556:	4601      	mov	r1, r0
    \return               Instruction Fault Status Register value
 */
__STATIC_FORCEINLINE uint32_t __get_IFSR(void)
{
  uint32_t result;
  __get_CP(15, 0, result, 5, 0, 1);
70002558:	ee15 3f30 	mrc	15, 0, r3, cr5, cr0, {1}
	__get_CP(15, 0, result, 6, 0, 2);
7000255c:	ee16 2f50 	mrc	15, 0, r2, cr6, cr0, {2}
	/* Read and parse Instruction Fault Status Register (IFSR) */
	uint32_t ifsr = __get_IFSR();
#if defined(CONFIG_AARCH32_ARMV8_R)
	uint32_t fs = ifsr & IFSR_STATUS_Msk;
#else
	uint32_t fs = ((ifsr & IFSR_FS1_Msk) >> 6) | (ifsr & IFSR_FS0_Msk);
70002560:	0998      	lsrs	r0, r3, #6
70002562:	f000 0010 	and.w	r0, r0, #16
70002566:	f003 030f 	and.w	r3, r3, #15
	return false;
#endif
	/* Print fault information*/
	LOG_ERR("***** PREFETCH ABORT *****");
	if (FAULT_DUMP_VERBOSE) {
		reason = dump_fault(fs, ifar);
7000256a:	4318      	orrs	r0, r3
7000256c:	f7ff ffc3 	bl	700024f6 <dump_fault.constprop.0>
	if (IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) && (reason >= K_ERR_ARCH_START)) {
		reason = K_ERR_CPU_EXCEPTION;
	}

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70002570:	f7ff ffbb 	bl	700024ea <z_arm_fatal_error>

	/* All prefetch aborts are treated as fatal for now */
	return true;
}
70002574:	2001      	movs	r0, #1
70002576:	bd08      	pop	{r3, pc}

70002578 <z_arm_fault_data>:
 * @brief Data abort fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_data(struct arch_esf *esf)
{
70002578:	b508      	push	{r3, lr}
7000257a:	4601      	mov	r1, r0
  __get_CP(15, 0, result, 5, 0, 0);
7000257c:	ee15 3f10 	mrc	15, 0, r3, cr5, cr0, {0}
	__get_CP(15, 0, result, 6, 0, 0);
70002580:	ee16 2f10 	mrc	15, 0, r2, cr6, cr0, {0}
	/* Read and parse Data Fault Status Register (DFSR) */
	uint32_t dfsr = __get_DFSR();
#if defined(CONFIG_AARCH32_ARMV8_R)
	uint32_t fs = dfsr & DFSR_STATUS_Msk;
#else
	uint32_t fs = ((dfsr & DFSR_FS1_Msk) >> 6) | (dfsr & DFSR_FS0_Msk);
70002584:	0998      	lsrs	r0, r3, #6
70002586:	f000 0010 	and.w	r0, r0, #16
7000258a:	f003 030f 	and.w	r3, r3, #15
#endif

	/* Print fault information*/
	LOG_ERR("***** DATA ABORT *****");
	if (FAULT_DUMP_VERBOSE) {
		reason = dump_fault(fs, dfar);
7000258e:	4318      	orrs	r0, r3
70002590:	f7ff ffb1 	bl	700024f6 <dump_fault.constprop.0>
	if (IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) && (reason >= K_ERR_ARCH_START)) {
		reason = K_ERR_CPU_EXCEPTION;
	}

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70002594:	f7ff ffa9 	bl	700024ea <z_arm_fatal_error>

	/* All data aborts are treated as fatal for now */
	return true;
}
70002598:	2001      	movs	r0, #1
7000259a:	bd08      	pop	{r3, pc}

7000259c <z_arm_interrupt_init>:
	/*
	 * Initialise interrupt controller.
	 */
#ifdef CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER
	/* Invoke SoC-specific interrupt controller initialisation */
	z_soc_irq_init();
7000259c:	f7ff bf98 	b.w	700024d0 <z_soc_irq_init>

700025a0 <z_arm_relocate_vector_table>:
#endif

#endif /* !CONFIG_AARCH32_ARMV8_R */

void z_arm_relocate_vector_table(void)
{
700025a0:	b508      	push	{r3, lr}
	relocate_vector_table();
700025a2:	f7fe f8f9 	bl	70000798 <relocate_vector_table>
}
700025a6:	bd08      	pop	{r3, pc}

700025a8 <z_irq_spurious>:
 */
void z_irq_spurious(const void *unused)
{
	ARG_UNUSED(unused);

	z_arm_fatal_error(K_ERR_SPURIOUS_IRQ, NULL);
700025a8:	2100      	movs	r1, #0
700025aa:	2001      	movs	r0, #1
700025ac:	f7ff bf9d 	b.w	700024ea <z_arm_fatal_error>

700025b0 <arch_dcache_invd_all>:

	return 0;
}

int arch_dcache_invd_all(void)
{
700025b0:	b5f0      	push	{r4, r5, r6, r7, lr}
 */
__STATIC_FORCEINLINE uint32_t __get_CLIDR(void)
{
  uint32_t result;
//  __ASM volatile("MRC p15, 1, %0, c0, c0, 1" : "=r"(result) : : "memory");
  __get_CP(15, 1, result, 0, 0, 1);
700025b2:	ee30 5f30 	mrc	15, 1, r5, cr0, cr0, {1}
*/
__STATIC_FORCEINLINE void L1C_CleanInvalidateCache(uint32_t op) {
  uint32_t clidr;
  uint32_t cache_type;
  clidr =  __get_CLIDR();
  for(uint32_t i = 0U; i<7U; i++)
700025b6:	2000      	movs	r0, #0
  {
    cache_type = (clidr >> i*3U) & 0x7UL;
700025b8:	eb00 0340 	add.w	r3, r0, r0, lsl #1
700025bc:	fa25 f303 	lsr.w	r3, r5, r3
700025c0:	f003 0307 	and.w	r3, r3, #7
    if ((cache_type >= 2U) && (cache_type <= 4U))
700025c4:	3b02      	subs	r3, #2
700025c6:	2b02      	cmp	r3, #2
    cache_type = (clidr >> i*3U) & 0x7UL;
700025c8:	ea4f 0440 	mov.w	r4, r0, lsl #1
    if ((cache_type >= 2U) && (cache_type <= 4U))
700025cc:	d817      	bhi.n	700025fe <arch_dcache_invd_all+0x4e>
  __set_CP(15, 2, value, 0, 0, 0);
700025ce:	ee40 4f10 	mcr	15, 2, r4, cr0, cr0, {0}
  __get_CP(15, 1, result, 0, 0, 0);
700025d2:	ee30 1f10 	mrc	15, 1, r1, cr0, cr0, {0}
  num_ways = ((ccsidr & 0x00001FF8U) >> 3U) + 1U;
700025d6:	f3c1 02c9 	ubfx	r2, r1, #3, #10
700025da:	f102 0c01 	add.w	ip, r2, #1
  if (n < 2U) {
700025de:	b19a      	cbz	r2, 70002608 <arch_dcache_invd_all+0x58>
700025e0:	4667      	mov	r7, ip
  uint8_t log = 0U;
700025e2:	2300      	movs	r3, #0
    log++;
700025e4:	461e      	mov	r6, r3
    t >>= 1U;
700025e6:	087f      	lsrs	r7, r7, #1
    log++;
700025e8:	3301      	adds	r3, #1
  while(t > 1U)
700025ea:	2f01      	cmp	r7, #1
    log++;
700025ec:	b2db      	uxtb	r3, r3
  while(t > 1U)
700025ee:	d1f9      	bne.n	700025e4 <arch_dcache_invd_all+0x34>
  if (n & 1U) { log++; }
700025f0:	f01c 0f01 	tst.w	ip, #1
700025f4:	bf1c      	itt	ne
700025f6:	3602      	addne	r6, #2
700025f8:	b2f3      	uxtbne	r3, r6
  if ((log2_num_ways < 0) || (log2_num_ways > 32)) {
700025fa:	2b20      	cmp	r3, #32
700025fc:	d905      	bls.n	7000260a <arch_dcache_invd_all+0x5a>
  for(uint32_t i = 0U; i<7U; i++)
700025fe:	3001      	adds	r0, #1
70002600:	2807      	cmp	r0, #7
70002602:	d1d9      	bne.n	700025b8 <arch_dcache_invd_all+0x8>
	L1C_InvalidateDCacheAll();

	return 0;
}
70002604:	2000      	movs	r0, #0
70002606:	bdf0      	pop	{r4, r5, r6, r7, pc}
    return 0U;
70002608:	2300      	movs	r3, #0
  num_sets = ((ccsidr & 0x0FFFE000U) >> 13U) + 1U;
7000260a:	f3c1 3c4e 	ubfx	ip, r1, #13, #15
  log2_linesize = (ccsidr & 0x00000007U) + 2U + 2U;
7000260e:	f001 0107 	and.w	r1, r1, #7
70002612:	3104      	adds	r1, #4
  shift_way = 32U - (uint32_t)log2_num_ways;
70002614:	f1c3 0320 	rsb	r3, r3, #32
    for(int32_t set = num_sets-1; set >= 0; set--)
70002618:	4666      	mov	r6, ip
      Dummy = (level << 1U) | (((uint32_t)set) << log2_linesize) | (((uint32_t)way) << shift_way);
7000261a:	fa02 fe03 	lsl.w	lr, r2, r3
7000261e:	ea4e 0e04 	orr.w	lr, lr, r4
70002622:	fa06 f701 	lsl.w	r7, r6, r1
70002626:	ea47 070e 	orr.w	r7, r7, lr
/** \brief  Set DCISW
 */
__STATIC_FORCEINLINE void __set_DCISW(uint32_t value)
{
//  __ASM volatile("MCR p15, 0, %0, c7, c6, 2" : : "r"(value) : "memory")
  __set_CP(15, 0, value, 7, 6, 2);
7000262a:	ee07 7f56 	mcr	15, 0, r7, cr7, cr6, {2}
    for(int32_t set = num_sets-1; set >= 0; set--)
7000262e:	3e01      	subs	r6, #1
70002630:	d2f7      	bcs.n	70002622 <arch_dcache_invd_all+0x72>
  for(int32_t way = num_ways-1; way >= 0; way--)
70002632:	3a01      	subs	r2, #1
70002634:	d2f0      	bcs.n	70002618 <arch_dcache_invd_all+0x68>
  __ASM volatile ("dmb 0xF":::"memory");
70002636:	f3bf 8f5f 	dmb	sy
}
7000263a:	e7e0      	b.n	700025fe <arch_dcache_invd_all+0x4e>

7000263c <arch_dcache_enable>:
{
7000263c:	b508      	push	{r3, lr}
	arch_dcache_invd_all();
7000263e:	f7ff ffb7 	bl	700025b0 <arch_dcache_invd_all>
  __get_CP(15, 0, result, 1, 0, 0);
70002642:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}
  __ASM volatile ("dsb 0xF":::"memory");
70002646:	f3bf 8f4f 	dsb	sy
	val |= SCTLR_C_Msk;
7000264a:	f043 0304 	orr.w	r3, r3, #4
  __set_CP(15, 0, sctlr, 1, 0, 0);
7000264e:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
  __ASM volatile ("isb 0xF":::"memory");
70002652:	f3bf 8f6f 	isb	sy
}
70002656:	bd08      	pop	{r3, pc}

70002658 <arch_icache_invd_all>:
  __set_CP(15, 0, value, 7, 5, 0);
70002658:	2000      	movs	r0, #0
7000265a:	ee07 0f15 	mcr	15, 0, r0, cr7, cr5, {0}
  __ASM volatile ("dsb 0xF":::"memory");
7000265e:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
70002662:	f3bf 8f6f 	isb	sy
int arch_icache_invd_all(void)
{
	L1C_InvalidateICacheAll();

	return 0;
}
70002666:	4770      	bx	lr

70002668 <arch_icache_enable>:
{
70002668:	b508      	push	{r3, lr}
	arch_icache_invd_all();
7000266a:	f7ff fff5 	bl	70002658 <arch_icache_invd_all>
  __get_CP(15, 0, result, 1, 0, 0);
7000266e:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}
	__set_SCTLR(__get_SCTLR() | SCTLR_I_Msk);
70002672:	f443 5380 	orr.w	r3, r3, #4096	; 0x1000
  __set_CP(15, 0, sctlr, 1, 0, 0);
70002676:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
7000267a:	f3bf 8f6f 	isb	sy
}
7000267e:	bd08      	pop	{r3, pc}

70002680 <arch_cache_init>:

#endif

void arch_cache_init(void)
{
}
70002680:	4770      	bx	lr

70002682 <picolibc_put>:
{
70002682:	b508      	push	{r3, lr}
		union { uintptr_t x; FILE * val; } parm1 = { .val = stream };
		return (int) arch_syscall_invoke2(parm0.x, parm1.x, K_SYSCALL_ZEPHYR_FPUTC);
	}
#endif
	compiler_barrier();
	return z_impl_zephyr_fputc(c, stream);
70002684:	f7fe fa1a 	bl	70000abc <z_impl_zephyr_fputc>
}
70002688:	2000      	movs	r0, #0
7000268a:	bd08      	pop	{r3, pc}

7000268c <pinctrl_lookup_state>:

#include <zephyr/drivers/pinctrl.h>

int pinctrl_lookup_state(const struct pinctrl_dev_config *config, uint8_t id,
			 const struct pinctrl_state **state)
{
7000268c:	b530      	push	{r4, r5, lr}
	*state = &config->states[0];
7000268e:	6803      	ldr	r3, [r0, #0]
70002690:	6013      	str	r3, [r2, #0]
	while (*state < &config->states[config->state_cnt]) {
70002692:	7905      	ldrb	r5, [r0, #4]
70002694:	6804      	ldr	r4, [r0, #0]
70002696:	eb04 04c5 	add.w	r4, r4, r5, lsl #3
7000269a:	42a3      	cmp	r3, r4
7000269c:	d302      	bcc.n	700026a4 <pinctrl_lookup_state+0x18>
		}

		(*state)++;
	}

	return -ENOENT;
7000269e:	f06f 0001 	mvn.w	r0, #1
}
700026a2:	bd30      	pop	{r4, r5, pc}
		if (id == (*state)->id) {
700026a4:	795c      	ldrb	r4, [r3, #5]
700026a6:	428c      	cmp	r4, r1
700026a8:	d001      	beq.n	700026ae <pinctrl_lookup_state+0x22>
		(*state)++;
700026aa:	3308      	adds	r3, #8
700026ac:	e7f0      	b.n	70002690 <pinctrl_lookup_state+0x4>
			return 0;
700026ae:	2000      	movs	r0, #0
700026b0:	e7f7      	b.n	700026a2 <pinctrl_lookup_state+0x16>

700026b2 <pinctrl_ti_k3_init>:

static int pinctrl_ti_k3_init(const struct device *dev)
{
	DEVICE_MMIO_MAP(dev, K_MEM_CACHE_NONE);
	return 0;
}
700026b2:	2000      	movs	r0, #0
700026b4:	4770      	bx	lr

700026b6 <ns16550_read_char>:
	return divisor;
}
#endif

static inline int ns16550_read_char(const struct device *dev, unsigned char *c)
{
700026b6:	b510      	push	{r4, lr}
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
700026b8:	6843      	ldr	r3, [r0, #4]

	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
700026ba:	7d1c      	ldrb	r4, [r3, #20]
700026bc:	681a      	ldr	r2, [r3, #0]
700026be:	2305      	movs	r3, #5
700026c0:	fb13 2304 	smlabb	r3, r3, r4, r2
700026c4:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700026c6:	f3bf 8f5f 	dmb	sy
700026ca:	07db      	lsls	r3, r3, #31
700026cc:	d507      	bpl.n	700026de <ns16550_read_char+0x28>
		port = DEVICE_MMIO_GET(dev);
700026ce:	6843      	ldr	r3, [r0, #4]
700026d0:	681b      	ldr	r3, [r3, #0]
700026d2:	681b      	ldr	r3, [r3, #0]
700026d4:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
700026d8:	700b      	strb	r3, [r1, #0]
		*c = ns16550_inbyte(dev_cfg, RDR(dev));
		return 0;
700026da:	2000      	movs	r0, #0
	}

	return -1;
}
700026dc:	bd10      	pop	{r4, pc}
	return -1;
700026de:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
700026e2:	e7fb      	b.n	700026dc <ns16550_read_char+0x26>

700026e4 <uart_ns16550_config_get>:

#ifdef CONFIG_UART_USE_RUNTIME_CONFIGURE
static int uart_ns16550_config_get(const struct device *dev,
				   struct uart_config *cfg)
{
	struct uart_ns16550_dev_data *data = dev->data;
700026e4:	6903      	ldr	r3, [r0, #16]
	cfg->stop_bits = data->uart_config.stop_bits;
	cfg->data_bits = data->uart_config.data_bits;
	cfg->flow_ctrl = data->uart_config.flow_ctrl;

	return 0;
}
700026e6:	2000      	movs	r0, #0
	cfg->baudrate = data->uart_config.baudrate;
700026e8:	681a      	ldr	r2, [r3, #0]
700026ea:	600a      	str	r2, [r1, #0]
	cfg->parity = data->uart_config.parity;
700026ec:	791a      	ldrb	r2, [r3, #4]
700026ee:	710a      	strb	r2, [r1, #4]
	cfg->stop_bits = data->uart_config.stop_bits;
700026f0:	795a      	ldrb	r2, [r3, #5]
700026f2:	714a      	strb	r2, [r1, #5]
	cfg->data_bits = data->uart_config.data_bits;
700026f4:	799a      	ldrb	r2, [r3, #6]
700026f6:	718a      	strb	r2, [r1, #6]
	cfg->flow_ctrl = data->uart_config.flow_ctrl;
700026f8:	79db      	ldrb	r3, [r3, #7]
700026fa:	71cb      	strb	r3, [r1, #7]
}
700026fc:	4770      	bx	lr

700026fe <uart_ns16550_poll_in>:
 * @param c Pointer to character
 *
 * @return 0 if a character arrived, -1 if the input buffer if empty.
 */
static int uart_ns16550_poll_in(const struct device *dev, unsigned char *c)
{
700026fe:	b510      	push	{r4, lr}
	__asm__ volatile(
70002700:	f3ef 8400 	mrs	r4, CPSR
70002704:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002708:	b672      	cpsid	i
	struct uart_ns16550_dev_data *data = dev->data;
	int ret = -1;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ret = ns16550_read_char(dev, c);
7000270a:	f7ff ffd4 	bl	700026b6 <ns16550_read_char>
	if (key != 0U) {
7000270e:	b904      	cbnz	r4, 70002712 <uart_ns16550_poll_in+0x14>
  __ASM volatile ("cpsie i" : : : "memory");
70002710:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
70002712:	bd10      	pop	{r4, pc}

70002714 <uart_ns16550_poll_out>:
 * @param dev UART device struct
 * @param c Character to send
 */
static void uart_ns16550_poll_out(const struct device *dev,
					   unsigned char c)
{
70002714:	b530      	push	{r4, r5, lr}
	__asm__ volatile(
70002716:	f3ef 8400 	mrs	r4, CPSR
7000271a:	f004 0480 	and.w	r4, r4, #128	; 0x80
7000271e:	b672      	cpsid	i
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	while ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_THRE) == 0) {
70002720:	2505      	movs	r5, #5
		port = DEVICE_MMIO_GET(dev);
70002722:	6842      	ldr	r2, [r0, #4]
	while ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_THRE) == 0) {
70002724:	7d13      	ldrb	r3, [r2, #20]
70002726:	6812      	ldr	r2, [r2, #0]
70002728:	fb15 2303 	smlabb	r3, r5, r3, r2
7000272c:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
7000272e:	f3bf 8f5f 	dmb	sy
70002732:	069b      	lsls	r3, r3, #26
70002734:	d5f5      	bpl.n	70002722 <uart_ns16550_poll_out+0xe>
		port = DEVICE_MMIO_GET(dev);
70002736:	6843      	ldr	r3, [r0, #4]
70002738:	681b      	ldr	r3, [r3, #0]
7000273a:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000273e:	6019      	str	r1, [r3, #0]
	if (key != 0U) {
70002740:	b904      	cbnz	r4, 70002744 <uart_ns16550_poll_out+0x30>
  __ASM volatile ("cpsie i" : : : "memory");
70002742:	b662      	cpsie	i
	}

	ns16550_outbyte(dev_cfg, THR(dev), c);

	k_spin_unlock(&data->lock, key);
}
70002744:	bd30      	pop	{r4, r5, pc}

70002746 <uart_ns16550_err_check>:
	__asm__ volatile(
70002746:	f3ef 8200 	mrs	r2, CPSR
7000274a:	f002 0280 	and.w	r2, r2, #128	; 0x80
7000274e:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70002750:	6843      	ldr	r3, [r0, #4]
static int uart_ns16550_err_check(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);
	int check = (ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_EOB_MASK);
70002752:	7d19      	ldrb	r1, [r3, #20]
70002754:	2005      	movs	r0, #5
70002756:	681b      	ldr	r3, [r3, #0]
70002758:	fb10 3001 	smlabb	r0, r0, r1, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000275c:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("dmb 0xF":::"memory");
7000275e:	f3bf 8f5f 	dmb	sy
	if (key != 0U) {
70002762:	b902      	cbnz	r2, 70002766 <uart_ns16550_err_check+0x20>
  __ASM volatile ("cpsie i" : : : "memory");
70002764:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return check >> 1;
}
70002766:	f3c0 0043 	ubfx	r0, r0, #1, #4
7000276a:	4770      	bx	lr

7000276c <uart_ns16550_fifo_fill>:
 * @return Number of bytes sent
 */
static int uart_ns16550_fifo_fill(const struct device *dev,
				  const uint8_t *tx_data,
				  int size)
{
7000276c:	b5f0      	push	{r4, r5, r6, r7, lr}
	struct uart_ns16550_dev_data *data = dev->data;
7000276e:	6906      	ldr	r6, [r0, #16]
{
70002770:	4603      	mov	r3, r0
	__asm__ volatile(
70002772:	f3ef 8400 	mrs	r4, CPSR
70002776:	f004 0480 	and.w	r4, r4, #128	; 0x80
7000277a:	b672      	cpsid	i
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	int i;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
7000277c:	2000      	movs	r0, #0
7000277e:	4290      	cmp	r0, r2
70002780:	db01      	blt.n	70002786 <uart_ns16550_fifo_fill+0x1a>
	if (key != 0U) {
70002782:	b15c      	cbz	r4, 7000279c <uart_ns16550_fifo_fill+0x30>
	}

	k_spin_unlock(&data->lock, key);

	return i;
}
70002784:	bdf0      	pop	{r4, r5, r6, r7, pc}
	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
70002786:	7a35      	ldrb	r5, [r6, #8]
70002788:	4285      	cmp	r5, r0
7000278a:	ddfa      	ble.n	70002782 <uart_ns16550_fifo_fill+0x16>
		port = DEVICE_MMIO_GET(dev);
7000278c:	685d      	ldr	r5, [r3, #4]
7000278e:	682f      	ldr	r7, [r5, #0]
			sys_write32(val, port);
70002790:	5c0d      	ldrb	r5, [r1, r0]
  __ASM volatile ("dmb 0xF":::"memory");
70002792:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70002796:	603d      	str	r5, [r7, #0]
	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
70002798:	3001      	adds	r0, #1
7000279a:	e7f0      	b.n	7000277e <uart_ns16550_fifo_fill+0x12>
  __ASM volatile ("cpsie i" : : : "memory");
7000279c:	b662      	cpsie	i
	return i;
7000279e:	e7f1      	b.n	70002784 <uart_ns16550_fifo_fill+0x18>

700027a0 <uart_ns16550_fifo_read>:
 *
 * @return Number of bytes read
 */
static int uart_ns16550_fifo_read(const struct device *dev, uint8_t *rx_data,
				  const int size)
{
700027a0:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
700027a4:	4605      	mov	r5, r0
700027a6:	460e      	mov	r6, r1
700027a8:	4617      	mov	r7, r2
	__asm__ volatile(
700027aa:	f3ef 8800 	mrs	r8, CPSR
700027ae:	f008 0880 	and.w	r8, r8, #128	; 0x80
700027b2:	b672      	cpsid	i
	struct uart_ns16550_dev_data *data = dev->data;
	int i;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
700027b4:	2400      	movs	r4, #0
700027b6:	42bc      	cmp	r4, r7
700027b8:	db05      	blt.n	700027c6 <uart_ns16550_fifo_read+0x26>
	if (key != 0U) {
700027ba:	f1b8 0f00 	cmp.w	r8, #0
700027be:	d00a      	beq.n	700027d6 <uart_ns16550_fifo_read+0x36>
	}

	k_spin_unlock(&data->lock, key);

	return i;
}
700027c0:	4620      	mov	r0, r4
700027c2:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
700027c6:	4628      	mov	r0, r5
700027c8:	1931      	adds	r1, r6, r4
700027ca:	f7ff ff74 	bl	700026b6 <ns16550_read_char>
700027ce:	3001      	adds	r0, #1
700027d0:	d0f3      	beq.n	700027ba <uart_ns16550_fifo_read+0x1a>
700027d2:	3401      	adds	r4, #1
700027d4:	e7ef      	b.n	700027b6 <uart_ns16550_fifo_read+0x16>
700027d6:	b662      	cpsie	i
	return i;
700027d8:	e7f2      	b.n	700027c0 <uart_ns16550_fifo_read+0x20>

700027da <uart_ns16550_irq_tx_enable>:
	__asm__ volatile(
700027da:	f3ef 8100 	mrs	r1, CPSR
700027de:	f001 0180 	and.w	r1, r1, #128	; 0x80
700027e2:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700027e4:	6843      	ldr	r3, [r0, #4]
		for (uint8_t i = 0U; i < num_cpu_states; i++) {
			pm_policy_state_lock_get(cpu_states[i].state, PM_ALL_SUBSTATES);
		}
	}
#endif
	ns16550_outbyte(dev_cfg, IER(dev), ns16550_inbyte(dev_cfg, IER(dev)) | IER_TBE);
700027e6:	7d1a      	ldrb	r2, [r3, #20]
700027e8:	681b      	ldr	r3, [r3, #0]
700027ea:	441a      	add	r2, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700027ec:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700027ee:	f3bf 8f5f 	dmb	sy
700027f2:	f3bf 8f5f 	dmb	sy
700027f6:	f043 0302 	orr.w	r3, r3, #2
			sys_write32(val, port);
700027fa:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700027fc:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
700027fe:	b901      	cbnz	r1, 70002802 <uart_ns16550_irq_tx_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
70002800:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);
}
70002802:	4770      	bx	lr

70002804 <uart_ns16550_irq_tx_disable>:
	__asm__ volatile(
70002804:	f3ef 8100 	mrs	r1, CPSR
70002808:	f001 0180 	and.w	r1, r1, #128	; 0x80
7000280c:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000280e:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
70002810:	7d13      	ldrb	r3, [r2, #20]
70002812:	6812      	ldr	r2, [r2, #0]
70002814:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70002816:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70002818:	f3bf 8f5f 	dmb	sy
7000281c:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
70002820:	f002 02fd 	and.w	r2, r2, #253	; 0xfd
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70002824:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
70002826:	b901      	cbnz	r1, 7000282a <uart_ns16550_irq_tx_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
70002828:	b662      	cpsie	i
			pm_policy_state_lock_put(cpu_states[i].state, PM_ALL_SUBSTATES);
		}
	}
#endif
	k_spin_unlock(&data->lock, key);
}
7000282a:	4770      	bx	lr

7000282c <uart_ns16550_irq_tx_ready>:
	__asm__ volatile(
7000282c:	f3ef 8300 	mrs	r3, CPSR
70002830:	f003 0380 	and.w	r3, r3, #128	; 0x80
70002834:	b672      	cpsid	i
static int uart_ns16550_irq_tx_ready(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((IIRC(dev) & IIR_ID) == IIR_THRE) ? 1 : 0;
70002836:	6902      	ldr	r2, [r0, #16]
70002838:	7a50      	ldrb	r0, [r2, #9]
7000283a:	f000 0006 	and.w	r0, r0, #6
7000283e:	1e82      	subs	r2, r0, #2
70002840:	4250      	negs	r0, r2
70002842:	4150      	adcs	r0, r2
	if (key != 0U) {
70002844:	b903      	cbnz	r3, 70002848 <uart_ns16550_irq_tx_ready+0x1c>
70002846:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
70002848:	4770      	bx	lr

7000284a <uart_ns16550_irq_tx_complete>:
	__asm__ volatile(
7000284a:	f3ef 8200 	mrs	r2, CPSR
7000284e:	f002 0280 	and.w	r2, r2, #128	; 0x80
70002852:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70002854:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((ns16550_inbyte(dev_cfg, LSR(dev)) & (LSR_TEMT | LSR_THRE))
70002856:	7d19      	ldrb	r1, [r3, #20]
70002858:	2005      	movs	r0, #5
7000285a:	681b      	ldr	r3, [r3, #0]
7000285c:	fb10 3001 	smlabb	r0, r0, r1, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70002860:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70002862:	f3bf 8f5f 	dmb	sy
				== (LSR_TEMT | LSR_THRE)) ? 1 : 0;
70002866:	f000 0060 	and.w	r0, r0, #96	; 0x60
7000286a:	f1a0 0360 	sub.w	r3, r0, #96	; 0x60
7000286e:	4258      	negs	r0, r3
70002870:	4158      	adcs	r0, r3
	if (key != 0U) {
70002872:	b902      	cbnz	r2, 70002876 <uart_ns16550_irq_tx_complete+0x2c>
  __ASM volatile ("cpsie i" : : : "memory");
70002874:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
70002876:	4770      	bx	lr

70002878 <uart_ns16550_irq_rx_enable>:
	__asm__ volatile(
70002878:	f3ef 8100 	mrs	r1, CPSR
7000287c:	f001 0180 	and.w	r1, r1, #128	; 0x80
70002880:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70002882:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev), ns16550_inbyte(dev_cfg, IER(dev)) | IER_RXRDY);
70002884:	7d1a      	ldrb	r2, [r3, #20]
70002886:	681b      	ldr	r3, [r3, #0]
70002888:	441a      	add	r2, r3
7000288a:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
7000288c:	f3bf 8f5f 	dmb	sy
70002890:	f3bf 8f5f 	dmb	sy
70002894:	f043 0301 	orr.w	r3, r3, #1
			sys_write32(val, port);
70002898:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000289a:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
7000289c:	b901      	cbnz	r1, 700028a0 <uart_ns16550_irq_rx_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
7000289e:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);
}
700028a0:	4770      	bx	lr

700028a2 <uart_ns16550_irq_rx_disable>:
	__asm__ volatile(
700028a2:	f3ef 8100 	mrs	r1, CPSR
700028a6:	f001 0180 	and.w	r1, r1, #128	; 0x80
700028aa:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700028ac:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
700028ae:	7d13      	ldrb	r3, [r2, #20]
700028b0:	6812      	ldr	r2, [r2, #0]
700028b2:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700028b4:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700028b6:	f3bf 8f5f 	dmb	sy
700028ba:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
700028be:	f002 02fe 	and.w	r2, r2, #254	; 0xfe
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700028c2:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
700028c4:	b901      	cbnz	r1, 700028c8 <uart_ns16550_irq_rx_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
700028c6:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) & (~IER_RXRDY));

	k_spin_unlock(&data->lock, key);
}
700028c8:	4770      	bx	lr

700028ca <uart_ns16550_irq_rx_ready>:
	__asm__ volatile(
700028ca:	f3ef 8300 	mrs	r3, CPSR
700028ce:	f003 0380 	and.w	r3, r3, #128	; 0x80
700028d2:	b672      	cpsid	i
static int uart_ns16550_irq_rx_ready(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((IIRC(dev) & IIR_ID) == IIR_RBRF) ? 1 : 0;
700028d4:	6902      	ldr	r2, [r0, #16]
700028d6:	7a50      	ldrb	r0, [r2, #9]
700028d8:	f000 0006 	and.w	r0, r0, #6
700028dc:	1f02      	subs	r2, r0, #4
700028de:	4250      	negs	r0, r2
700028e0:	4150      	adcs	r0, r2
	if (key != 0U) {
700028e2:	b903      	cbnz	r3, 700028e6 <uart_ns16550_irq_rx_ready+0x1c>
700028e4:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
700028e6:	4770      	bx	lr

700028e8 <uart_ns16550_irq_err_enable>:
	__asm__ volatile(
700028e8:	f3ef 8100 	mrs	r1, CPSR
700028ec:	f001 0180 	and.w	r1, r1, #128	; 0x80
700028f0:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700028f2:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
700028f4:	7d1a      	ldrb	r2, [r3, #20]
700028f6:	681b      	ldr	r3, [r3, #0]
700028f8:	441a      	add	r2, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700028fa:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700028fc:	f3bf 8f5f 	dmb	sy
70002900:	f3bf 8f5f 	dmb	sy
70002904:	f043 0304 	orr.w	r3, r3, #4
			sys_write32(val, port);
70002908:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000290a:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
7000290c:	b901      	cbnz	r1, 70002910 <uart_ns16550_irq_err_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
7000290e:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) | IER_LSR);

	k_spin_unlock(&data->lock, key);
}
70002910:	4770      	bx	lr

70002912 <uart_ns16550_irq_err_disable>:
	__asm__ volatile(
70002912:	f3ef 8100 	mrs	r1, CPSR
70002916:	f001 0180 	and.w	r1, r1, #128	; 0x80
7000291a:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000291c:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
7000291e:	7d13      	ldrb	r3, [r2, #20]
70002920:	6812      	ldr	r2, [r2, #0]
70002922:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70002924:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70002926:	f3bf 8f5f 	dmb	sy
7000292a:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
7000292e:	f002 02fb 	and.w	r2, r2, #251	; 0xfb
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70002932:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
70002934:	b901      	cbnz	r1, 70002938 <uart_ns16550_irq_err_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
70002936:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) & (~IER_LSR));

	k_spin_unlock(&data->lock, key);
}
70002938:	4770      	bx	lr

7000293a <uart_ns16550_irq_is_pending>:
	__asm__ volatile(
7000293a:	f3ef 8300 	mrs	r3, CPSR
7000293e:	f003 0380 	and.w	r3, r3, #128	; 0x80
70002942:	b672      	cpsid	i
static int uart_ns16550_irq_is_pending(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = (!(IIRC(dev) & IIR_NIP)) ? 1 : 0;
70002944:	6902      	ldr	r2, [r0, #16]
70002946:	7a50      	ldrb	r0, [r2, #9]
70002948:	43c0      	mvns	r0, r0
7000294a:	f000 0001 	and.w	r0, r0, #1
	if (key != 0U) {
7000294e:	b903      	cbnz	r3, 70002952 <uart_ns16550_irq_is_pending+0x18>
70002950:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
70002952:	4770      	bx	lr

70002954 <uart_ns16550_irq_update>:
	__asm__ volatile(
70002954:	f3ef 8200 	mrs	r2, CPSR
70002958:	f002 0280 	and.w	r2, r2, #128	; 0x80
7000295c:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000295e:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	IIRC(dev) = ns16550_inbyte(dev_cfg, IIR(dev));
70002960:	6901      	ldr	r1, [r0, #16]
70002962:	7d18      	ldrb	r0, [r3, #20]
70002964:	681b      	ldr	r3, [r3, #0]
70002966:	eb03 0340 	add.w	r3, r3, r0, lsl #1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000296a:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
7000296c:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
70002970:	724b      	strb	r3, [r1, #9]
	if (key != 0U) {
70002972:	b902      	cbnz	r2, 70002976 <uart_ns16550_irq_update+0x22>
  __ASM volatile ("cpsie i" : : : "memory");
70002974:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return 1;
}
70002976:	2001      	movs	r0, #1
70002978:	4770      	bx	lr

7000297a <uart_ns16550_irq_callback_set>:
 */
static void uart_ns16550_irq_callback_set(const struct device *dev,
					  uart_irq_callback_user_data_t cb,
					  void *cb_data)
{
	struct uart_ns16550_dev_data * const dev_data = dev->data;
7000297a:	6903      	ldr	r3, [r0, #16]
	__asm__ volatile(
7000297c:	f3ef 8000 	mrs	r0, CPSR
70002980:	f000 0080 	and.w	r0, r0, #128	; 0x80
70002984:	b672      	cpsid	i
	k_spinlock_key_t key = k_spin_lock(&dev_data->lock);

	dev_data->cb = cb;
	dev_data->cb_data = cb_data;
70002986:	e9c3 1203 	strd	r1, r2, [r3, #12]
	if (key != 0U) {
7000298a:	b900      	cbnz	r0, 7000298e <uart_ns16550_irq_callback_set+0x14>
7000298c:	b662      	cpsie	i

	k_spin_unlock(&dev_data->lock, key);
}
7000298e:	4770      	bx	lr

70002990 <uart_ns16550_isr>:
 *
 * @param arg Argument to ISR.
 */
static void uart_ns16550_isr(const struct device *dev)
{
	struct uart_ns16550_dev_data * const dev_data = dev->data;
70002990:	6902      	ldr	r2, [r0, #16]
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;

	if (dev_data->cb) {
70002992:	68d3      	ldr	r3, [r2, #12]
70002994:	b10b      	cbz	r3, 7000299a <uart_ns16550_isr+0xa>
		dev_data->cb(dev, dev_data->cb_data);
70002996:	6911      	ldr	r1, [r2, #16]
70002998:	4718      	bx	r3
	uint8_t cached_ier = ns16550_inbyte(dev_cfg, IER(dev));

	ns16550_outbyte(dev_cfg, IER(dev), 0U);
	ns16550_outbyte(dev_cfg, IER(dev), cached_ier);
#endif
}
7000299a:	4770      	bx	lr

7000299c <uart_ns16550_irq_config_func0>:
#define UART_NS16550_DEVICE_INIT(n)                                                  \
	COND_CODE_1(DT_INST_ON_BUS(n, pcie),                                         \
		    (UART_NS16550_DEVICE_PCIE_INIT(n)),                              \
		    (UART_NS16550_DEVICE_IO_MMIO_INIT(n)))

DT_INST_FOREACH_STATUS_OKAY(UART_NS16550_DEVICE_INIT)
7000299c:	20d2      	movs	r0, #210	; 0xd2
7000299e:	2200      	movs	r2, #0
700029a0:	b508      	push	{r3, lr}
700029a2:	210f      	movs	r1, #15
700029a4:	f7ff fd96 	bl	700024d4 <z_soc_irq_priority_set>
700029a8:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
700029ac:	20d2      	movs	r0, #210	; 0xd2
700029ae:	f7ff bd93 	b.w	700024d8 <z_soc_irq_enable>

700029b2 <uart_ns16550_configure>:
{
700029b2:	e92d 43f7 	stmdb	sp!, {r0, r1, r2, r4, r5, r6, r7, r8, r9, lr}
	uint32_t pclk = 0U;
700029b6:	f04f 0900 	mov.w	r9, #0
{
700029ba:	4604      	mov	r4, r0
	struct uart_ns16550_dev_data * const dev_data = dev->data;
700029bc:	6907      	ldr	r7, [r0, #16]
{
700029be:	460d      	mov	r5, r1
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
700029c0:	f8d0 8004 	ldr.w	r8, [r0, #4]
	uint32_t pclk = 0U;
700029c4:	f8cd 9000 	str.w	r9, [sp]
	__asm__ volatile(
700029c8:	f3ef 8600 	mrs	r6, CPSR
700029cc:	f006 0680 	and.w	r6, r6, #128	; 0x80
700029d0:	b672      	cpsid	i
	if (dev_cfg->pincfg != NULL) {
700029d2:	f8d8 0018 	ldr.w	r0, [r8, #24]
700029d6:	b158      	cbz	r0, 700029f0 <uart_ns16550_configure+0x3e>
				      uint8_t id)
{
	int ret;
	const struct pinctrl_state *state;

	ret = pinctrl_lookup_state(config, id, &state);
700029d8:	4649      	mov	r1, r9
700029da:	aa01      	add	r2, sp, #4
700029dc:	f7ff fe56 	bl	7000268c <pinctrl_lookup_state>
	if (ret < 0) {
700029e0:	4548      	cmp	r0, r9
700029e2:	db05      	blt.n	700029f0 <uart_ns16550_configure+0x3e>
		return ret;
	}

	return pinctrl_apply_state_direct(config, state);
700029e4:	9b01      	ldr	r3, [sp, #4]
	return pinctrl_configure_pins(state->pins, state->pin_cnt, reg);
700029e6:	464a      	mov	r2, r9
700029e8:	7919      	ldrb	r1, [r3, #4]
700029ea:	6818      	ldr	r0, [r3, #0]
700029ec:	f7fe f94a 	bl	70000c84 <pinctrl_configure_pins>
	dev_data->iir_cache = 0U;
700029f0:	2300      	movs	r3, #0
	uint32_t mdr = ns16550_inbyte(dev_cfg, MDR1(dev));
700029f2:	2208      	movs	r2, #8
	dev_data->iir_cache = 0U;
700029f4:	727b      	strb	r3, [r7, #9]
		port = DEVICE_MMIO_GET(dev);
700029f6:	6861      	ldr	r1, [r4, #4]
	uint32_t mdr = ns16550_inbyte(dev_cfg, MDR1(dev));
700029f8:	7d0b      	ldrb	r3, [r1, #20]
700029fa:	6809      	ldr	r1, [r1, #0]
700029fc:	fb12 1303 	smlabb	r3, r2, r3, r1
70002a00:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70002a02:	f3bf 8f5f 	dmb	sy
		port = DEVICE_MMIO_GET(dev);
70002a06:	6861      	ldr	r1, [r4, #4]
	ns16550_outbyte(dev_cfg, MDR1(dev), mdr);
70002a08:	7d08      	ldrb	r0, [r1, #20]
70002a0a:	6809      	ldr	r1, [r1, #0]
70002a0c:	fb12 1200 	smlabb	r2, r2, r0, r1
70002a10:	f3bf 8f5f 	dmb	sy
	mdr = ((mdr & ~MDR1_MODE_SELECT_FIELD_MASK) | ((((MDR1_STD_MODE) <<
70002a14:	f003 03f8 	and.w	r3, r3, #248	; 0xf8
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70002a18:	6013      	str	r3, [r2, #0]
	if (dev_cfg->sys_clk_freq != 0U) {
70002a1a:	f8d8 3004 	ldr.w	r3, [r8, #4]
70002a1e:	2b00      	cmp	r3, #0
70002a20:	f000 8097 	beq.w	70002b52 <uart_ns16550_configure+0x1a0>
		pclk = dev_cfg->sys_clk_freq;
70002a24:	9300      	str	r3, [sp, #0]
	set_baud_rate(dev, cfg->baudrate, pclk);
70002a26:	6829      	ldr	r1, [r5, #0]
	if ((baud_rate != 0U) && (pclk != 0U)) {
70002a28:	2900      	cmp	r1, #0
70002a2a:	d03f      	beq.n	70002aac <uart_ns16550_configure+0xfa>
	set_baud_rate(dev, cfg->baudrate, pclk);
70002a2c:	9b00      	ldr	r3, [sp, #0]
	if ((baud_rate != 0U) && (pclk != 0U)) {
70002a2e:	2b00      	cmp	r3, #0
70002a30:	d03c      	beq.n	70002aac <uart_ns16550_configure+0xfa>
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
70002a32:	6860      	ldr	r0, [r4, #4]
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
70002a34:	7d02      	ldrb	r2, [r0, #20]
70002a36:	f04f 0e03 	mov.w	lr, #3
	return ((pclk + (baud_rate << 3)) / baud_rate) >> 4;
70002a3a:	eb03 03c1 	add.w	r3, r3, r1, lsl #3
	struct uart_ns16550_dev_data * const dev_data = dev->data;
70002a3e:	f8d4 c010 	ldr.w	ip, [r4, #16]
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
70002a42:	6800      	ldr	r0, [r0, #0]
	return ((pclk + (baud_rate << 3)) / baud_rate) >> 4;
70002a44:	fbb3 f3f1 	udiv	r3, r3, r1
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
70002a48:	fb1e 0202 	smlabb	r2, lr, r2, r0
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70002a4c:	6812      	ldr	r2, [r2, #0]
70002a4e:	f3bf 8f5f 	dmb	sy
		port = DEVICE_MMIO_GET(dev);
70002a52:	6860      	ldr	r0, [r4, #4]
		ns16550_outbyte(dev_cfg, LCR(dev), LCR_DLAB | lcr_cache);
70002a54:	f890 8014 	ldrb.w	r8, [r0, #20]
70002a58:	6800      	ldr	r0, [r0, #0]
70002a5a:	fb1e 0808 	smlabb	r8, lr, r8, r0
70002a5e:	f3bf 8f5f 	dmb	sy
70002a62:	f062 007f 	orn	r0, r2, #127	; 0x7f
			sys_write32(val, port);
70002a66:	b2c0      	uxtb	r0, r0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70002a68:	f8c8 0000 	str.w	r0, [r8]
		port = DEVICE_MMIO_GET(dev);
70002a6c:	6860      	ldr	r0, [r4, #4]
70002a6e:	f8d0 8000 	ldr.w	r8, [r0]
70002a72:	f3bf 8f5f 	dmb	sy
70002a76:	f3c3 1007 	ubfx	r0, r3, #4, #8
70002a7a:	f8c8 0000 	str.w	r0, [r8]
70002a7e:	f8d4 8004 	ldr.w	r8, [r4, #4]
		ns16550_outbyte(dev_cfg, BRDH(dev), (unsigned char)((divisor >> 8) & 0xff));
70002a82:	f898 0014 	ldrb.w	r0, [r8, #20]
70002a86:	f8d8 8000 	ldr.w	r8, [r8]
70002a8a:	4440      	add	r0, r8
70002a8c:	f3bf 8f5f 	dmb	sy
70002a90:	f3c3 3307 	ubfx	r3, r3, #12, #8
70002a94:	6003      	str	r3, [r0, #0]
		port = DEVICE_MMIO_GET(dev);
70002a96:	6863      	ldr	r3, [r4, #4]
		ns16550_outbyte(dev_cfg, LCR(dev), lcr_cache);
70002a98:	7d18      	ldrb	r0, [r3, #20]
70002a9a:	681b      	ldr	r3, [r3, #0]
70002a9c:	fb1e 3300 	smlabb	r3, lr, r0, r3
70002aa0:	f3bf 8f5f 	dmb	sy
70002aa4:	b2d2      	uxtb	r2, r2
70002aa6:	601a      	str	r2, [r3, #0]
		dev_data->uart_config.baudrate = baud_rate;
70002aa8:	f8cc 1000 	str.w	r1, [ip]
	switch (cfg->data_bits) {
70002aac:	79aa      	ldrb	r2, [r5, #6]
70002aae:	2a03      	cmp	r2, #3
70002ab0:	d86a      	bhi.n	70002b88 <uart_ns16550_configure+0x1d6>
	switch (cfg->stop_bits) {
70002ab2:	796b      	ldrb	r3, [r5, #5]
70002ab4:	2b01      	cmp	r3, #1
70002ab6:	d064      	beq.n	70002b82 <uart_ns16550_configure+0x1d0>
70002ab8:	2b03      	cmp	r3, #3
70002aba:	d165      	bne.n	70002b88 <uart_ns16550_configure+0x1d6>
70002abc:	f04f 0c04 	mov.w	ip, #4
	switch (cfg->parity) {
70002ac0:	792b      	ldrb	r3, [r5, #4]
70002ac2:	b113      	cbz	r3, 70002aca <uart_ns16550_configure+0x118>
70002ac4:	2b02      	cmp	r3, #2
70002ac6:	d15f      	bne.n	70002b88 <uart_ns16550_configure+0x1d6>
70002ac8:	2310      	movs	r3, #16
	dev_data->uart_config = *cfg;
70002aca:	e895 0003 	ldmia.w	r5, {r0, r1}
70002ace:	e887 0003 	stmia.w	r7, {r0, r1}
		port = DEVICE_MMIO_GET(dev);
70002ad2:	6861      	ldr	r1, [r4, #4]
	ns16550_outbyte(dev_cfg, LCR(dev),
70002ad4:	f891 e014 	ldrb.w	lr, [r1, #20]
70002ad8:	6808      	ldr	r0, [r1, #0]
70002ada:	2103      	movs	r1, #3
70002adc:	fb11 010e 	smlabb	r1, r1, lr, r0
70002ae0:	f3bf 8f5f 	dmb	sy
70002ae4:	ea42 020c 	orr.w	r2, r2, ip
			sys_write32(val, port);
70002ae8:	4313      	orrs	r3, r2
70002aea:	600b      	str	r3, [r1, #0]
	if (cfg->flow_ctrl == UART_CFG_FLOW_CTRL_RTS_CTS) {
70002aec:	79eb      	ldrb	r3, [r5, #7]
	mdc = MCR_OUT2 | MCR_RTS | MCR_DTR;
70002aee:	2b01      	cmp	r3, #1
		port = DEVICE_MMIO_GET(dev);
70002af0:	6863      	ldr	r3, [r4, #4]
	ns16550_outbyte(dev_cfg, MDC(dev), mdc);
70002af2:	7d19      	ldrb	r1, [r3, #20]
	mdc = MCR_OUT2 | MCR_RTS | MCR_DTR;
70002af4:	bf0c      	ite	eq
70002af6:	222b      	moveq	r2, #43	; 0x2b
70002af8:	220b      	movne	r2, #11
	ns16550_outbyte(dev_cfg, MDC(dev), mdc);
70002afa:	681b      	ldr	r3, [r3, #0]
70002afc:	eb03 0381 	add.w	r3, r3, r1, lsl #2
70002b00:	f3bf 8f5f 	dmb	sy
70002b04:	601a      	str	r2, [r3, #0]
		port = DEVICE_MMIO_GET(dev);
70002b06:	6861      	ldr	r1, [r4, #4]
	ns16550_outbyte(dev_cfg, FCR(dev),
70002b08:	7d0a      	ldrb	r2, [r1, #20]
70002b0a:	2302      	movs	r3, #2
70002b0c:	6809      	ldr	r1, [r1, #0]
70002b0e:	fb13 1202 	smlabb	r2, r3, r2, r1
70002b12:	f3bf 8f5f 	dmb	sy
70002b16:	21a7      	movs	r1, #167	; 0xa7
70002b18:	6011      	str	r1, [r2, #0]
		port = DEVICE_MMIO_GET(dev);
70002b1a:	6862      	ldr	r2, [r4, #4]
	if ((ns16550_inbyte(dev_cfg, IIR(dev)) & IIR_FE) == IIR_FE) {
70002b1c:	7d11      	ldrb	r1, [r2, #20]
70002b1e:	6812      	ldr	r2, [r2, #0]
70002b20:	fb13 2301 	smlabb	r3, r3, r1, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70002b24:	681b      	ldr	r3, [r3, #0]
70002b26:	f3bf 8f5f 	dmb	sy
70002b2a:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
		dev_data->fifo_size = 64;
70002b2e:	2bc0      	cmp	r3, #192	; 0xc0
70002b30:	bf14      	ite	ne
70002b32:	2301      	movne	r3, #1
70002b34:	2340      	moveq	r3, #64	; 0x40
	(void)ns16550_read_char(dev, &c);
70002b36:	4620      	mov	r0, r4
70002b38:	a901      	add	r1, sp, #4
70002b3a:	723b      	strb	r3, [r7, #8]
70002b3c:	f7ff fdbb 	bl	700026b6 <ns16550_read_char>
		port = DEVICE_MMIO_GET(dev);
70002b40:	6862      	ldr	r2, [r4, #4]
	ns16550_outbyte(dev_cfg, IER(dev), 0x00);
70002b42:	7d13      	ldrb	r3, [r2, #20]
70002b44:	6812      	ldr	r2, [r2, #0]
70002b46:	4413      	add	r3, r2
70002b48:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70002b4c:	2000      	movs	r0, #0
70002b4e:	6018      	str	r0, [r3, #0]
}
70002b50:	e006      	b.n	70002b60 <uart_ns16550_configure+0x1ae>
		if (!device_is_ready(dev_cfg->clock_dev)) {
70002b52:	f8d8 0008 	ldr.w	r0, [r8, #8]
70002b56:	f000 f828 	bl	70002baa <z_impl_device_is_ready>
70002b5a:	b930      	cbnz	r0, 70002b6a <uart_ns16550_configure+0x1b8>
			ret = -EINVAL;
70002b5c:	f06f 0015 	mvn.w	r0, #21
	if (key != 0U) {
70002b60:	b906      	cbnz	r6, 70002b64 <uart_ns16550_configure+0x1b2>
  __ASM volatile ("cpsie i" : : : "memory");
70002b62:	b662      	cpsie	i
};
70002b64:	b003      	add	sp, #12
70002b66:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
					   dev_cfg->clock_subsys,
70002b6a:	e9d8 0102 	ldrd	r0, r1, [r8, #8]
					 uint32_t *rate)
{
	const struct clock_control_driver_api *api =
		(const struct clock_control_driver_api *)dev->api;

	if (api->get_rate == NULL) {
70002b6e:	6883      	ldr	r3, [r0, #8]
70002b70:	68db      	ldr	r3, [r3, #12]
70002b72:	2b00      	cmp	r3, #0
70002b74:	d0f2      	beq.n	70002b5c <uart_ns16550_configure+0x1aa>
		return -ENOSYS;
	}

	return api->get_rate(dev, sys, rate);
70002b76:	466a      	mov	r2, sp
70002b78:	4798      	blx	r3
		if (clock_control_get_rate(dev_cfg->clock_dev,
70002b7a:	2800      	cmp	r0, #0
70002b7c:	f43f af53 	beq.w	70002a26 <uart_ns16550_configure+0x74>
70002b80:	e7ec      	b.n	70002b5c <uart_ns16550_configure+0x1aa>
		uart_cfg.stop_bits = LCR_1_STB;
70002b82:	f04f 0c00 	mov.w	ip, #0
70002b86:	e79b      	b.n	70002ac0 <uart_ns16550_configure+0x10e>
	switch (cfg->parity) {
70002b88:	f06f 0085 	mvn.w	r0, #133	; 0x85
70002b8c:	e7e8      	b.n	70002b60 <uart_ns16550_configure+0x1ae>

70002b8e <uart_ns16550_init>:
{
70002b8e:	b570      	push	{r4, r5, r6, lr}
	ret = uart_ns16550_configure(dev, &data->uart_config);
70002b90:	6901      	ldr	r1, [r0, #16]
{
70002b92:	4604      	mov	r4, r0
	const struct uart_ns16550_dev_config *dev_cfg = dev->config;
70002b94:	6846      	ldr	r6, [r0, #4]
	ret = uart_ns16550_configure(dev, &data->uart_config);
70002b96:	f7ff ff0c 	bl	700029b2 <uart_ns16550_configure>
	if (ret != 0) {
70002b9a:	4605      	mov	r5, r0
70002b9c:	b910      	cbnz	r0, 70002ba4 <uart_ns16550_init+0x16>
	dev_cfg->irq_config_func(dev);
70002b9e:	6933      	ldr	r3, [r6, #16]
70002ba0:	4620      	mov	r0, r4
70002ba2:	4798      	blx	r3
}
70002ba4:	4628      	mov	r0, r5
70002ba6:	bd70      	pop	{r4, r5, r6, pc}

70002ba8 <z_device_state_init>:
void z_device_state_init(void)
{
	STRUCT_SECTION_FOREACH(device, dev) {
		k_object_init(dev);
	}
}
70002ba8:	4770      	bx	lr

70002baa <z_impl_device_is_ready>:
{
	/*
	 * if an invalid device pointer is passed as argument, this call
	 * reports the `device` as not ready for usage.
	 */
	if (dev == NULL) {
70002baa:	b140      	cbz	r0, 70002bbe <z_impl_device_is_ready+0x14>
		return false;
	}

	return dev->state->initialized && (dev->state->init_res == 0U);
70002bac:	68c3      	ldr	r3, [r0, #12]
70002bae:	7858      	ldrb	r0, [r3, #1]
70002bb0:	f010 0001 	ands.w	r0, r0, #1
70002bb4:	bf1e      	ittt	ne
70002bb6:	7818      	ldrbne	r0, [r3, #0]
70002bb8:	fab0 f080 	clzne	r0, r0
70002bbc:	0940      	lsrne	r0, r0, #5
}
70002bbe:	4770      	bx	lr

70002bc0 <arch_system_halt>:
	__asm__ volatile(
70002bc0:	f3ef 8300 	mrs	r3, CPSR
70002bc4:	f003 0380 	and.w	r3, r3, #128	; 0x80
70002bc8:	b672      	cpsid	i
	for (;;) {
70002bca:	e7fe      	b.n	70002bca <arch_system_halt+0xa>

70002bcc <k_sys_fatal_error_handler>:
{
70002bcc:	b508      	push	{r3, lr}
	arch_system_halt(reason);
70002bce:	f7ff fff7 	bl	70002bc0 <arch_system_halt>

70002bd2 <do_device_init>:
{
70002bd2:	b510      	push	{r4, lr}
	if (entry->init_fn.dev != NULL) {
70002bd4:	e9d0 3400 	ldrd	r3, r4, [r0]
70002bd8:	b933      	cbnz	r3, 70002be8 <do_device_init+0x16>
	int rc = 0;
70002bda:	2000      	movs	r0, #0
	dev->state->initialized = true;
70002bdc:	68e2      	ldr	r2, [r4, #12]
70002bde:	7853      	ldrb	r3, [r2, #1]
70002be0:	f043 0301 	orr.w	r3, r3, #1
70002be4:	7053      	strb	r3, [r2, #1]
}
70002be6:	bd10      	pop	{r4, pc}
		rc = entry->init_fn.dev(dev);
70002be8:	4620      	mov	r0, r4
70002bea:	4798      	blx	r3
		if (rc != 0) {
70002bec:	2800      	cmp	r0, #0
70002bee:	d0f4      	beq.n	70002bda <do_device_init+0x8>
			dev->state->init_res = rc;
70002bf0:	68e3      	ldr	r3, [r4, #12]
			if (rc < 0) {
70002bf2:	2800      	cmp	r0, #0
70002bf4:	bfb8      	it	lt
70002bf6:	4240      	neglt	r0, r0
			if (rc > UINT8_MAX) {
70002bf8:	28ff      	cmp	r0, #255	; 0xff
70002bfa:	bfa8      	it	ge
70002bfc:	20ff      	movge	r0, #255	; 0xff
			dev->state->init_res = rc;
70002bfe:	7018      	strb	r0, [r3, #0]
70002c00:	e7ec      	b.n	70002bdc <do_device_init+0xa>

70002c02 <z_early_memset>:
	(void) memset(dst, c, n);
70002c02:	f000 b9b4 	b.w	70002f6e <memset>

70002c06 <z_init_static>:
	__do_global_ctors_aux();
	__do_init_array_aux();
#elif defined(__CCAC__) /* ARC MWDT */
	__do_global_ctors_aux();
#endif
}
70002c06:	4770      	bx	lr

70002c08 <create_free_list>:
	CHECKIF(((slab->info.block_size | (uintptr_t)slab->buffer) &
70002c08:	6941      	ldr	r1, [r0, #20]
70002c0a:	6883      	ldr	r3, [r0, #8]
70002c0c:	ea43 0201 	orr.w	r2, r3, r1
70002c10:	f012 0203 	ands.w	r2, r2, #3
70002c14:	d10f      	bne.n	70002c36 <create_free_list+0x2e>
	slab->free_list = NULL;
70002c16:	60c2      	str	r2, [r0, #12]
	p = slab->buffer + slab->info.block_size * (slab->info.num_blocks - 1);
70002c18:	6902      	ldr	r2, [r0, #16]
70002c1a:	3a01      	subs	r2, #1
70002c1c:	fb01 3302 	mla	r3, r1, r2, r3
	while (p >= slab->buffer) {
70002c20:	6882      	ldr	r2, [r0, #8]
70002c22:	429a      	cmp	r2, r3
70002c24:	d901      	bls.n	70002c2a <create_free_list+0x22>
	return 0;
70002c26:	2000      	movs	r0, #0
70002c28:	4770      	bx	lr
		*(char **)p = slab->free_list;
70002c2a:	68c2      	ldr	r2, [r0, #12]
70002c2c:	601a      	str	r2, [r3, #0]
		p -= slab->info.block_size;
70002c2e:	6942      	ldr	r2, [r0, #20]
		slab->free_list = p;
70002c30:	60c3      	str	r3, [r0, #12]
		p -= slab->info.block_size;
70002c32:	1a9b      	subs	r3, r3, r2
70002c34:	e7f4      	b.n	70002c20 <create_free_list+0x18>
		return -EINVAL;
70002c36:	f06f 0015 	mvn.w	r0, #21
}
70002c3a:	4770      	bx	lr

70002c3c <idle>:
#include <wait_q.h>

LOG_MODULE_DECLARE(os, CONFIG_KERNEL_LOG_LEVEL);

void idle(void *unused1, void *unused2, void *unused3)
{
70002c3c:	b508      	push	{r3, lr}
70002c3e:	f3ef 8300 	mrs	r3, CPSR
70002c42:	f003 0380 	and.w	r3, r3, #128	; 0x80
70002c46:	b672      	cpsid	i
 * @note In some architectures, before returning, the function unmasks interrupts
 * unconditionally.
 */
static inline void k_cpu_idle(void)
{
	arch_cpu_idle();
70002c48:	f7fd ee16 	blx	70000878 <arch_cpu_idle>
70002c4c:	e7f7      	b.n	70002c3e <idle+0x2>

70002c4e <unpend_thread_no_timeout>:
	sys_dnode_t *const next = node->next;
70002c4e:	e9d0 3200 	ldrd	r3, r2, [r0]
	prev->next = next;
70002c52:	6013      	str	r3, [r2, #0]
	next->prev = prev;
70002c54:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70002c56:	2300      	movs	r3, #0
	thread->base.thread_state &= ~_THREAD_PENDING;
70002c58:	7b42      	ldrb	r2, [r0, #13]
70002c5a:	f022 0202 	bic.w	r2, r2, #2
	node->prev = NULL;
70002c5e:	e9c0 3300 	strd	r3, r3, [r0]
70002c62:	7342      	strb	r2, [r0, #13]
	thread->base.pended_on = NULL;
70002c64:	6083      	str	r3, [r0, #8]
}
70002c66:	4770      	bx	lr

70002c68 <k_is_in_isr>:
70002c68:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70002c6c:	f023 0303 	bic.w	r3, r3, #3
#endif

/* Check the CPSR mode bits to see if we are in IRQ or FIQ mode */
static ALWAYS_INLINE bool arch_is_in_isr(void)
{
	return (arch_curr_cpu()->nested != 0U);
70002c70:	6818      	ldr	r0, [r3, #0]
}
70002c72:	3800      	subs	r0, #0
70002c74:	bf18      	it	ne
70002c76:	2001      	movne	r0, #1
70002c78:	4770      	bx	lr

70002c7a <z_impl_k_thread_name_set>:
}
70002c7a:	f06f 0057 	mvn.w	r0, #87	; 0x57
70002c7e:	4770      	bx	lr

70002c80 <sys_dlist_remove>:
	sys_dnode_t *const next = node->next;
70002c80:	e9d0 3200 	ldrd	r3, r2, [r0]
	prev->next = next;
70002c84:	6013      	str	r3, [r2, #0]
	next->prev = prev;
70002c86:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70002c88:	2300      	movs	r3, #0
	node->prev = NULL;
70002c8a:	e9c0 3300 	strd	r3, r3, [r0]
	sys_dnode_init(node);
}
70002c8e:	4770      	bx	lr

70002c90 <unpend_thread_no_timeout>:
{
70002c90:	b508      	push	{r3, lr}
	sys_dlist_remove(&thread->base.qnode_dlist);
70002c92:	f7ff fff5 	bl	70002c80 <sys_dlist_remove>
70002c96:	7b43      	ldrb	r3, [r0, #13]
70002c98:	f023 0302 	bic.w	r3, r3, #2
70002c9c:	7343      	strb	r3, [r0, #13]
	thread->base.pended_on = NULL;
70002c9e:	2300      	movs	r3, #0
70002ca0:	6083      	str	r3, [r0, #8]
}
70002ca2:	bd08      	pop	{r3, pc}

70002ca4 <add_to_waitq_locked>:
{
70002ca4:	b538      	push	{r3, r4, r5, lr}
70002ca6:	4604      	mov	r4, r0
70002ca8:	460d      	mov	r5, r1
	unready_thread(thread);
70002caa:	f7fe fae3 	bl	70001274 <unready_thread>
	thread->base.thread_state |= _THREAD_PENDING;
70002cae:	7b63      	ldrb	r3, [r4, #13]
70002cb0:	f043 0302 	orr.w	r3, r3, #2
70002cb4:	7363      	strb	r3, [r4, #13]
	if (wait_q != NULL) {
70002cb6:	b1e5      	cbz	r5, 70002cf2 <add_to_waitq_locked+0x4e>
		thread->base.pended_on = wait_q;
70002cb8:	60a5      	str	r5, [r4, #8]
	return list->head == list;
70002cba:	682b      	ldr	r3, [r5, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002cbc:	429d      	cmp	r5, r3
70002cbe:	d109      	bne.n	70002cd4 <add_to_waitq_locked+0x30>
	sys_dnode_t *const tail = list->tail;
70002cc0:	686b      	ldr	r3, [r5, #4]
	node->prev = tail;
70002cc2:	e9c4 5300 	strd	r5, r3, [r4]
	tail->next = node;
70002cc6:	601c      	str	r4, [r3, #0]
	list->tail = node;
70002cc8:	606c      	str	r4, [r5, #4]
}
70002cca:	e012      	b.n	70002cf2 <add_to_waitq_locked+0x4e>
	return (node == list->tail) ? NULL : node->next;
70002ccc:	686a      	ldr	r2, [r5, #4]
70002cce:	429a      	cmp	r2, r3
70002cd0:	d0f6      	beq.n	70002cc0 <add_to_waitq_locked+0x1c>
70002cd2:	681b      	ldr	r3, [r3, #0]
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
70002cd4:	2b00      	cmp	r3, #0
70002cd6:	d0f3      	beq.n	70002cc0 <add_to_waitq_locked+0x1c>
	int32_t b1 = thread_1->base.prio;
70002cd8:	f994 200e 	ldrsb.w	r2, [r4, #14]
	int32_t b2 = thread_2->base.prio;
70002cdc:	f993 100e 	ldrsb.w	r1, [r3, #14]
	if (b1 != b2) {
70002ce0:	428a      	cmp	r2, r1
70002ce2:	d0f3      	beq.n	70002ccc <add_to_waitq_locked+0x28>
		if (z_sched_prio_cmp(thread, t) > 0) {
70002ce4:	4291      	cmp	r1, r2
70002ce6:	ddf1      	ble.n	70002ccc <add_to_waitq_locked+0x28>
	sys_dnode_t *const prev = successor->prev;
70002ce8:	685a      	ldr	r2, [r3, #4]
	node->next = successor;
70002cea:	e9c4 3200 	strd	r3, r2, [r4]
	prev->next = node;
70002cee:	6014      	str	r4, [r2, #0]
	successor->prev = node;
70002cf0:	605c      	str	r4, [r3, #4]
}
70002cf2:	bd38      	pop	{r3, r4, r5, pc}

70002cf4 <z_ready_thread>:
{
70002cf4:	b510      	push	{r4, lr}
70002cf6:	f3ef 8400 	mrs	r4, CPSR
70002cfa:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002cfe:	b672      	cpsid	i
			ready_thread(thread);
70002d00:	f7fe faf2 	bl	700012e8 <ready_thread>
	if (key != 0U) {
70002d04:	b904      	cbnz	r4, 70002d08 <z_ready_thread+0x14>
70002d06:	b662      	cpsie	i
}
70002d08:	bd10      	pop	{r4, pc}

70002d0a <z_unpend_thread_no_timeout>:
{
70002d0a:	b508      	push	{r3, lr}
	__asm__ volatile(
70002d0c:	f3ef 8100 	mrs	r1, CPSR
70002d10:	f001 0180 	and.w	r1, r1, #128	; 0x80
70002d14:	b672      	cpsid	i
		if (thread->base.pended_on != NULL) {
70002d16:	6883      	ldr	r3, [r0, #8]
70002d18:	b10b      	cbz	r3, 70002d1e <z_unpend_thread_no_timeout+0x14>
			unpend_thread_no_timeout(thread);
70002d1a:	f7ff ffb9 	bl	70002c90 <unpend_thread_no_timeout>
	if (key != 0U) {
70002d1e:	b901      	cbnz	r1, 70002d22 <z_unpend_thread_no_timeout+0x18>
70002d20:	b662      	cpsie	i
}
70002d22:	bd08      	pop	{r3, pc}

70002d24 <z_sched_wake_thread>:
{
70002d24:	4601      	mov	r1, r0
70002d26:	b510      	push	{r4, lr}
	__asm__ volatile(
70002d28:	f3ef 8400 	mrs	r4, CPSR
70002d2c:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002d30:	b672      	cpsid	i
		if (!killed) {
70002d32:	7b43      	ldrb	r3, [r0, #13]
70002d34:	f013 0f28 	tst.w	r3, #40	; 0x28
70002d38:	d10a      	bne.n	70002d50 <z_sched_wake_thread+0x2c>
			if (thread->base.pended_on != NULL) {
70002d3a:	6883      	ldr	r3, [r0, #8]
70002d3c:	b10b      	cbz	r3, 70002d42 <z_sched_wake_thread+0x1e>
				unpend_thread_no_timeout(thread);
70002d3e:	f7ff ffa7 	bl	70002c90 <unpend_thread_no_timeout>
	thread->base.thread_state &= ~_THREAD_SLEEPING;
70002d42:	7b4b      	ldrb	r3, [r1, #13]
			ready_thread(thread);
70002d44:	4608      	mov	r0, r1
70002d46:	f023 0304 	bic.w	r3, r3, #4
70002d4a:	734b      	strb	r3, [r1, #13]
70002d4c:	f7fe facc 	bl	700012e8 <ready_thread>
	if (key != 0U) {
70002d50:	b904      	cbnz	r4, 70002d54 <z_sched_wake_thread+0x30>
70002d52:	b662      	cpsie	i
}
70002d54:	bd10      	pop	{r4, pc}

70002d56 <z_thread_timeout>:
	z_sched_wake_thread(thread, true);
70002d56:	2101      	movs	r1, #1
70002d58:	3818      	subs	r0, #24
70002d5a:	f7ff bfe3 	b.w	70002d24 <z_sched_wake_thread>

70002d5e <z_unpend_thread>:
{
70002d5e:	b510      	push	{r4, lr}
	z_unpend_thread_no_timeout(thread);
70002d60:	f7ff ffd3 	bl	70002d0a <z_unpend_thread_no_timeout>
}
70002d64:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
70002d68:	3018      	adds	r0, #24
70002d6a:	f000 b859 	b.w	70002e20 <z_abort_timeout>

70002d6e <z_reschedule_unlocked>:
	__asm__ volatile(
70002d6e:	f3ef 8000 	mrs	r0, CPSR
70002d72:	f000 0080 	and.w	r0, r0, #128	; 0x80
70002d76:	b672      	cpsid	i
	(void) z_reschedule_irqlock(arch_irq_lock());
70002d78:	f7fe bc5c 	b.w	70001634 <z_reschedule_irqlock>

70002d7c <z_impl_k_sleep>:
{
70002d7c:	b538      	push	{r3, r4, r5, lr}
70002d7e:	4605      	mov	r5, r0
70002d80:	460c      	mov	r4, r1
	ticks = z_tick_sleep(ticks);
70002d82:	f7fe fced 	bl	70001760 <z_tick_sleep>
	int32_t ret = K_TIMEOUT_EQ(timeout, K_FOREVER) ? K_TICKS_FOREVER :
70002d86:	f1b4 3fff 	cmp.w	r4, #4294967295	; 0xffffffff
70002d8a:	bf08      	it	eq
70002d8c:	f1b5 3fff 	cmpeq.w	r5, #4294967295	; 0xffffffff
70002d90:	d008      	beq.n	70002da4 <z_impl_k_sleep+0x28>
		      k_ticks_to_ms_ceil64(ticks);
70002d92:	220a      	movs	r2, #10
70002d94:	17c1      	asrs	r1, r0, #31
70002d96:	2300      	movs	r3, #0
70002d98:	3009      	adds	r0, #9
70002d9a:	f141 0100 	adc.w	r1, r1, #0
70002d9e:	f7fd f94f 	bl	70000040 <__aeabi_uldivmod>
}
70002da2:	bd38      	pop	{r3, r4, r5, pc}
	int32_t ret = K_TIMEOUT_EQ(timeout, K_FOREVER) ? K_TICKS_FOREVER :
70002da4:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
	return ret;
70002da8:	e7fb      	b.n	70002da2 <z_impl_k_sleep+0x26>

70002daa <z_thread_abort>:
70002daa:	f3ef 8100 	mrs	r1, CPSR
70002dae:	f001 0180 	and.w	r1, r1, #128	; 0x80
70002db2:	b672      	cpsid	i
	return (thread->base.user_options & K_ESSENTIAL) == K_ESSENTIAL;
70002db4:	7b02      	ldrb	r2, [r0, #12]
	if (z_is_thread_essential(thread)) {
70002db6:	07d2      	lsls	r2, r2, #31
70002db8:	d508      	bpl.n	70002dcc <z_thread_abort+0x22>
	if (key != 0U) {
70002dba:	b901      	cbnz	r1, 70002dbe <z_thread_abort+0x14>
70002dbc:	b662      	cpsie	i
		k_panic();
70002dbe:	2004      	movs	r0, #4
70002dc0:	b500      	push	{lr}
70002dc2:	b662      	cpsie	i
70002dc4:	df02      	svc	2
70002dc6:	f85d eb04 	ldr.w	lr, [sp], #4
		return;
70002dca:	4770      	bx	lr
	if ((thread->base.thread_state & _THREAD_DEAD) != 0U) {
70002dcc:	7b43      	ldrb	r3, [r0, #13]
70002dce:	071b      	lsls	r3, r3, #28
70002dd0:	d502      	bpl.n	70002dd8 <z_thread_abort+0x2e>
70002dd2:	b921      	cbnz	r1, 70002dde <z_thread_abort+0x34>
70002dd4:	b662      	cpsie	i
}
70002dd6:	4770      	bx	lr
	z_thread_halt(thread, key, true);
70002dd8:	2201      	movs	r2, #1
70002dda:	f7fe bac9 	b.w	70001370 <z_thread_halt>
}
70002dde:	4770      	bx	lr

70002de0 <z_impl_k_thread_abort>:
	z_thread_abort(thread);
70002de0:	f7ff bfe3 	b.w	70002daa <z_thread_abort>

70002de4 <z_sched_wake>:
{
70002de4:	b538      	push	{r3, r4, r5, lr}
	__asm__ volatile(
70002de6:	f3ef 8500 	mrs	r5, CPSR
70002dea:	f005 0580 	and.w	r5, r5, #128	; 0x80
70002dee:	b672      	cpsid	i
	return list->head == list;
70002df0:	6804      	ldr	r4, [r0, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002df2:	42a0      	cmp	r0, r4
70002df4:	d010      	beq.n	70002e18 <z_sched_wake+0x34>
		if (thread != NULL) {
70002df6:	b18c      	cbz	r4, 70002e1c <z_sched_wake+0x38>
70002df8:	6721      	str	r1, [r4, #112]	; 0x70
			unpend_thread_no_timeout(thread);
70002dfa:	4620      	mov	r0, r4
z_thread_return_value_set_with_data(struct k_thread *thread,
				   unsigned int value,
				   void *data)
{
	arch_thread_return_value_set(thread, value);
	thread->base.swap_data = data;
70002dfc:	6162      	str	r2, [r4, #20]
70002dfe:	f7ff ff47 	bl	70002c90 <unpend_thread_no_timeout>
70002e02:	f104 0018 	add.w	r0, r4, #24
70002e06:	f000 f80b 	bl	70002e20 <z_abort_timeout>
			ready_thread(thread);
70002e0a:	4620      	mov	r0, r4
70002e0c:	f7fe fa6c 	bl	700012e8 <ready_thread>
			ret = true;
70002e10:	2001      	movs	r0, #1
	if (key != 0U) {
70002e12:	b905      	cbnz	r5, 70002e16 <z_sched_wake+0x32>
  __ASM volatile ("cpsie i" : : : "memory");
70002e14:	b662      	cpsie	i
}
70002e16:	bd38      	pop	{r3, r4, r5, pc}
	bool ret = false;
70002e18:	2000      	movs	r0, #0
70002e1a:	e7fa      	b.n	70002e12 <z_sched_wake+0x2e>
70002e1c:	4620      	mov	r0, r4
70002e1e:	e7f8      	b.n	70002e12 <z_sched_wake+0x2e>

70002e20 <z_abort_timeout>:
{
70002e20:	b510      	push	{r4, lr}
	__asm__ volatile(
70002e22:	f3ef 8400 	mrs	r4, CPSR
70002e26:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002e2a:	b672      	cpsid	i
		if (sys_dnode_is_linked(&to->node)) {
70002e2c:	6803      	ldr	r3, [r0, #0]
70002e2e:	b12b      	cbz	r3, 70002e3c <z_abort_timeout+0x1c>
			remove_timeout(to);
70002e30:	f7fe fd8e 	bl	70001950 <remove_timeout>
			ret = 0;
70002e34:	2000      	movs	r0, #0
	if (key != 0U) {
70002e36:	b904      	cbnz	r4, 70002e3a <z_abort_timeout+0x1a>
70002e38:	b662      	cpsie	i
}
70002e3a:	bd10      	pop	{r4, pc}
	int ret = -EINVAL;
70002e3c:	f06f 0015 	mvn.w	r0, #21
70002e40:	e7f9      	b.n	70002e36 <z_abort_timeout+0x16>

70002e42 <sys_clock_tick_get_32>:

uint32_t sys_clock_tick_get_32(void)
{
70002e42:	b508      	push	{r3, lr}
#ifdef CONFIG_TICKLESS_KERNEL
	return (uint32_t)sys_clock_tick_get();
70002e44:	f7fe fe94 	bl	70001b70 <sys_clock_tick_get>
#else
	return (uint32_t)curr_tick;
#endif /* CONFIG_TICKLESS_KERNEL */
}
70002e48:	bd08      	pop	{r3, pc}

70002e4a <signal_poll_event>:
#include <zephyr/syscalls/k_poll_mrsh.c>
#endif /* CONFIG_USERSPACE */

/* must be called with interrupts locked */
static int signal_poll_event(struct k_poll_event *event, uint32_t state)
{
70002e4a:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	struct z_poller *poller = event->poller;
70002e4e:	6884      	ldr	r4, [r0, #8]
{
70002e50:	4605      	mov	r5, r0
70002e52:	460e      	mov	r6, r1
	int retcode = 0;

	if (poller != NULL) {
70002e54:	b1ec      	cbz	r4, 70002e92 <signal_poll_event+0x48>
		if (poller->mode == MODE_POLL) {
70002e56:	7863      	ldrb	r3, [r4, #1]
70002e58:	2b01      	cmp	r3, #1
70002e5a:	d125      	bne.n	70002ea8 <signal_poll_event+0x5e>
	if (!z_is_thread_pending(thread)) {
70002e5c:	f814 3c53 	ldrb.w	r3, [r4, #-83]
70002e60:	079a      	lsls	r2, r3, #30
70002e62:	d514      	bpl.n	70002e8e <signal_poll_event+0x44>
	return p ? CONTAINER_OF(p, struct k_thread, poller) : NULL;
70002e64:	f1a4 0760 	sub.w	r7, r4, #96	; 0x60
	z_unpend_thread(thread);
70002e68:	4638      	mov	r0, r7
70002e6a:	f7ff ff78 	bl	70002d5e <z_unpend_thread>
	arch_thread_return_value_set(thread,
70002e6e:	2e08      	cmp	r6, #8
70002e70:	bf14      	ite	ne
70002e72:	2300      	movne	r3, #0
70002e74:	f06f 0303 	mvneq.w	r3, #3
70002e78:	6123      	str	r3, [r4, #16]
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
70002e7a:	f814 3c53 	ldrb.w	r3, [r4, #-83]
70002e7e:	06db      	lsls	r3, r3, #27
70002e80:	d105      	bne.n	70002e8e <signal_poll_event+0x44>
70002e82:	f854 3c48 	ldr.w	r3, [r4, #-72]
70002e86:	b913      	cbnz	r3, 70002e8e <signal_poll_event+0x44>
	z_ready_thread(thread);
70002e88:	4638      	mov	r0, r7
70002e8a:	f7ff ff33 	bl	70002cf4 <z_ready_thread>
		} else {
			/* Poller is not poll or triggered mode. No action needed.*/
			;
		}

		poller->is_polling = false;
70002e8e:	2300      	movs	r3, #0
70002e90:	7023      	strb	r3, [r4, #0]
	event->state |= state;
70002e92:	68eb      	ldr	r3, [r5, #12]
	event->poller = NULL;
70002e94:	2000      	movs	r0, #0
70002e96:	60a8      	str	r0, [r5, #8]
	event->state |= state;
70002e98:	f3c3 3286 	ubfx	r2, r3, #14, #7
70002e9c:	4316      	orrs	r6, r2
70002e9e:	f366 3394 	bfi	r3, r6, #14, #7
70002ea2:	60eb      	str	r3, [r5, #12]
		}
	}

	set_event_ready(event, state);
	return retcode;
}
70002ea4:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		} else if (poller->mode == MODE_TRIGGERED) {
70002ea8:	2b02      	cmp	r3, #2
70002eaa:	d1f0      	bne.n	70002e8e <signal_poll_event+0x44>
{
	struct z_poller *poller = event->poller;
	struct k_work_poll *twork =
		CONTAINER_OF(poller, struct k_work_poll, poller);

	if (poller->is_polling && twork->workq != NULL) {
70002eac:	7823      	ldrb	r3, [r4, #0]
70002eae:	2b00      	cmp	r3, #0
70002eb0:	d0ed      	beq.n	70002e8e <signal_poll_event+0x44>
70002eb2:	f854 8c04 	ldr.w	r8, [r4, #-4]
70002eb6:	f1b8 0f00 	cmp.w	r8, #0
70002eba:	d0e8      	beq.n	70002e8e <signal_poll_event+0x44>
		struct k_work_q *work_q = twork->workq;

		z_abort_timeout(&twork->timeout);
70002ebc:	f104 0014 	add.w	r0, r4, #20
70002ec0:	f7ff ffae 	bl	70002e20 <z_abort_timeout>
		twork->poll_result = 0;
70002ec4:	2300      	movs	r3, #0
		z_work_submit_to_queue(work_q, &twork->work);
70002ec6:	4640      	mov	r0, r8
		z_abort_timeout(&twork->timeout);
70002ec8:	f1a4 0714 	sub.w	r7, r4, #20
		twork->poll_result = 0;
70002ecc:	62e3      	str	r3, [r4, #44]	; 0x2c
		z_work_submit_to_queue(work_q, &twork->work);
70002ece:	4639      	mov	r1, r7
70002ed0:	f000 f831 	bl	70002f36 <z_work_submit_to_queue>
70002ed4:	e7db      	b.n	70002e8e <signal_poll_event+0x44>

70002ed6 <z_handle_obj_poll_events>:
{
70002ed6:	4603      	mov	r3, r0
70002ed8:	b510      	push	{r4, lr}
	__asm__ volatile(
70002eda:	f3ef 8400 	mrs	r4, CPSR
70002ede:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002ee2:	b672      	cpsid	i
	return list->head == list;
70002ee4:	6800      	ldr	r0, [r0, #0]

static inline sys_dnode_t *sys_dlist_get(sys_dlist_t *list)
{
	sys_dnode_t *node = NULL;

	if (!sys_dlist_is_empty(list)) {
70002ee6:	4283      	cmp	r3, r0
70002ee8:	d008      	beq.n	70002efc <z_handle_obj_poll_events+0x26>
	sys_dnode_t *const next = node->next;
70002eea:	e9d0 3200 	ldrd	r3, r2, [r0]
	prev->next = next;
70002eee:	6013      	str	r3, [r2, #0]
	next->prev = prev;
70002ef0:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70002ef2:	2300      	movs	r3, #0
	node->prev = NULL;
70002ef4:	e9c0 3300 	strd	r3, r3, [r0]
		(void) signal_poll_event(poll_event, state);
70002ef8:	f7ff ffa7 	bl	70002e4a <signal_poll_event>
	if (key != 0U) {
70002efc:	b904      	cbnz	r4, 70002f00 <z_handle_obj_poll_events+0x2a>
70002efe:	b662      	cpsie	i
}
70002f00:	bd10      	pop	{r4, pc}

70002f02 <k_heap_init>:
{
70002f02:	b410      	push	{r4}
70002f04:	f100 040c 	add.w	r4, r0, #12
	list->tail = (sys_dnode_t *)list;
70002f08:	e9c0 4403 	strd	r4, r4, [r0, #12]
}
70002f0c:	bc10      	pop	{r4}
	sys_heap_init(&heap->heap, mem, bytes);
70002f0e:	f7ff ba8e 	b.w	7000242e <sys_heap_init>

70002f12 <flag_test_and_clear>:
	return (*flagp & BIT(bit)) != 0U;
70002f12:	6802      	ldr	r2, [r0, #0]
	*flagp &= ~BIT(bit);
70002f14:	2301      	movs	r3, #1
70002f16:	408b      	lsls	r3, r1
70002f18:	ea22 0303 	bic.w	r3, r2, r3
70002f1c:	6003      	str	r3, [r0, #0]
	return (*flagp & BIT(bit)) != 0U;
70002f1e:	fa22 f001 	lsr.w	r0, r2, r1
}
70002f22:	f000 0001 	and.w	r0, r0, #1
70002f26:	4770      	bx	lr

70002f28 <notify_queue_locked.isra.0>:
	if (queue != NULL) {
70002f28:	b120      	cbz	r0, 70002f34 <notify_queue_locked.isra.0+0xc>
		rv = z_sched_wake(&queue->notifyq, 0, NULL);
70002f2a:	2200      	movs	r2, #0
70002f2c:	3080      	adds	r0, #128	; 0x80
70002f2e:	4611      	mov	r1, r2
70002f30:	f7ff bf58 	b.w	70002de4 <z_sched_wake>
}
70002f34:	4770      	bx	lr

70002f36 <z_work_submit_to_queue>:
{
70002f36:	b513      	push	{r0, r1, r4, lr}
70002f38:	9001      	str	r0, [sp, #4]
70002f3a:	4608      	mov	r0, r1
	__asm__ volatile(
70002f3c:	f3ef 8400 	mrs	r4, CPSR
70002f40:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002f44:	b672      	cpsid	i
	int ret = submit_to_queue_locked(work, &queue);
70002f46:	a901      	add	r1, sp, #4
70002f48:	f7fe fefa 	bl	70001d40 <submit_to_queue_locked>
	if (key != 0U) {
70002f4c:	b904      	cbnz	r4, 70002f50 <z_work_submit_to_queue+0x1a>
70002f4e:	b662      	cpsie	i
}
70002f50:	b002      	add	sp, #8
70002f52:	bd10      	pop	{r4, pc}

70002f54 <memcpy>:
70002f54:	440a      	add	r2, r1
70002f56:	1e43      	subs	r3, r0, #1
70002f58:	4291      	cmp	r1, r2
70002f5a:	d100      	bne.n	70002f5e <memcpy+0xa>
70002f5c:	4770      	bx	lr
70002f5e:	b510      	push	{r4, lr}
70002f60:	f811 4b01 	ldrb.w	r4, [r1], #1
70002f64:	f803 4f01 	strb.w	r4, [r3, #1]!
70002f68:	4291      	cmp	r1, r2
70002f6a:	d1f9      	bne.n	70002f60 <memcpy+0xc>
70002f6c:	bd10      	pop	{r4, pc}

70002f6e <memset>:
70002f6e:	4402      	add	r2, r0
70002f70:	4603      	mov	r3, r0
70002f72:	4293      	cmp	r3, r2
70002f74:	d100      	bne.n	70002f78 <memset+0xa>
70002f76:	4770      	bx	lr
70002f78:	f803 1b01 	strb.w	r1, [r3], #1
70002f7c:	e7f9      	b.n	70002f72 <memset+0x4>

70002f7e <strnlen>:
70002f7e:	4602      	mov	r2, r0
70002f80:	4401      	add	r1, r0
70002f82:	b510      	push	{r4, lr}
70002f84:	4613      	mov	r3, r2
70002f86:	428a      	cmp	r2, r1
70002f88:	d003      	beq.n	70002f92 <strnlen+0x14>
70002f8a:	781c      	ldrb	r4, [r3, #0]
70002f8c:	3201      	adds	r2, #1
70002f8e:	2c00      	cmp	r4, #0
70002f90:	d1f8      	bne.n	70002f84 <strnlen+0x6>
70002f92:	1a18      	subs	r0, r3, r0
70002f94:	bd10      	pop	{r4, pc}

70002f96 <__ultoa_invert>:
70002f96:	b5f0      	push	{r4, r5, r6, r7, lr}
70002f98:	f1c3 0737 	rsb	r7, r3, #55	; 0x37
70002f9c:	4604      	mov	r4, r0
70002f9e:	b2ff      	uxtb	r7, r7
70002fa0:	f003 031f 	and.w	r3, r3, #31
70002fa4:	4610      	mov	r0, r2
70002fa6:	b2e6      	uxtb	r6, r4
70002fa8:	2b08      	cmp	r3, #8
70002faa:	d032      	beq.n	70003012 <__ultoa_invert+0x7c>
70002fac:	2b10      	cmp	r3, #16
70002fae:	d03d      	beq.n	7000302c <__ultoa_invert+0x96>
70002fb0:	0865      	lsrs	r5, r4, #1
70002fb2:	08a4      	lsrs	r4, r4, #2
70002fb4:	ea44 7481 	orr.w	r4, r4, r1, lsl #30
70002fb8:	ea45 75c1 	orr.w	r5, r5, r1, lsl #31
70002fbc:	192d      	adds	r5, r5, r4
70002fbe:	ea4f 0291 	mov.w	r2, r1, lsr #2
70002fc2:	eb42 0251 	adc.w	r2, r2, r1, lsr #1
70002fc6:	0929      	lsrs	r1, r5, #4
70002fc8:	ea41 7102 	orr.w	r1, r1, r2, lsl #28
70002fcc:	186d      	adds	r5, r5, r1
70002fce:	eb42 1212 	adc.w	r2, r2, r2, lsr #4
70002fd2:	0a29      	lsrs	r1, r5, #8
70002fd4:	ea41 6102 	orr.w	r1, r1, r2, lsl #24
70002fd8:	186d      	adds	r5, r5, r1
70002fda:	eb42 2212 	adc.w	r2, r2, r2, lsr #8
70002fde:	0c29      	lsrs	r1, r5, #16
70002fe0:	ea41 4102 	orr.w	r1, r1, r2, lsl #16
70002fe4:	186d      	adds	r5, r5, r1
70002fe6:	eb42 4212 	adc.w	r2, r2, r2, lsr #16
70002fea:	18ad      	adds	r5, r5, r2
70002fec:	f142 0200 	adc.w	r2, r2, #0
70002ff0:	08ec      	lsrs	r4, r5, #3
70002ff2:	ea44 7442 	orr.w	r4, r4, r2, lsl #29
70002ff6:	08d1      	lsrs	r1, r2, #3
70002ff8:	eb04 0284 	add.w	r2, r4, r4, lsl #2
70002ffc:	eba6 0542 	sub.w	r5, r6, r2, lsl #1
70003000:	b2ed      	uxtb	r5, r5
70003002:	2d09      	cmp	r5, #9
70003004:	d90b      	bls.n	7000301e <__ultoa_invert+0x88>
70003006:	3d0a      	subs	r5, #10
70003008:	3401      	adds	r4, #1
7000300a:	f141 0100 	adc.w	r1, r1, #0
7000300e:	b2ed      	uxtb	r5, r5
70003010:	e012      	b.n	70003038 <__ultoa_invert+0xa2>
70003012:	08e4      	lsrs	r4, r4, #3
70003014:	f006 0507 	and.w	r5, r6, #7
70003018:	ea44 7441 	orr.w	r4, r4, r1, lsl #29
7000301c:	08c9      	lsrs	r1, r1, #3
7000301e:	3530      	adds	r5, #48	; 0x30
70003020:	ea54 0201 	orrs.w	r2, r4, r1
70003024:	f800 5b01 	strb.w	r5, [r0], #1
70003028:	d1bd      	bne.n	70002fa6 <__ultoa_invert+0x10>
7000302a:	bdf0      	pop	{r4, r5, r6, r7, pc}
7000302c:	0924      	lsrs	r4, r4, #4
7000302e:	f006 050f 	and.w	r5, r6, #15
70003032:	ea44 7401 	orr.w	r4, r4, r1, lsl #28
70003036:	0909      	lsrs	r1, r1, #4
70003038:	2d09      	cmp	r5, #9
7000303a:	bf84      	itt	hi
7000303c:	19ed      	addhi	r5, r5, r7
7000303e:	b2ed      	uxtbhi	r5, r5
70003040:	e7ed      	b.n	7000301e <__ultoa_invert+0x88>

70003042 <__file_str_put>:
70003042:	e9d1 3204 	ldrd	r3, r2, [r1, #16]
70003046:	4293      	cmp	r3, r2
70003048:	bf1e      	ittt	ne
7000304a:	1c5a      	addne	r2, r3, #1
7000304c:	610a      	strne	r2, [r1, #16]
7000304e:	7018      	strbne	r0, [r3, #0]
70003050:	4770      	bx	lr
70003052:	0000      	movs	r0, r0
70003054:	0000      	movs	r0, r0
	...

70003058 <__z_arm_int_exit_from_thumb>:
70003058:	4778      	bx	pc
7000305a:	e7fd      	b.n	70003058 <__z_arm_int_exit_from_thumb>
7000305c:	eafff667 	b	70000a00 <z_arm_int_exit>

Disassembly of section .boot_section:

00000000 <__boot_spring>:
 * @brief Initialisation of fault handling
 */
void z_arm_fault_init(void)
{
	/* Nothing to do for now */
}
   0:	e59fd004 	ldr	sp, [pc, #4]	; c <___thread_base_t_user_options_OFFSET>
   z_vim_arm_enter_irq(irq);
   4:	fa000022 	blx	94 <MpuP_init>
}
   8:	ea000053 	b	15c <____start_veneer>

void rsc_table_get(struct fw_resource_table **table_ptr, int *length)
{
	*table_ptr = &resource_table;
	*length = sizeof(resource_table);
}
   c:	70009150 	.word	0x70009150

00000010 <MpuP_setRegion>:
	cmp	r0, #0
	bne	_irq_disabled
	cpsie	i
_irq_disabled:

	bx	lr
  10:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
		_char_out(c[i]);
  14:	781d      	ldrb	r5, [r3, #0]
	for (i = 0; i < n; i++) {
  16:	791c      	ldrb	r4, [r3, #4]
  18:	f002 021f 	and.w	r2, r2, #31
	if (irq > CONFIG_NUM_IRQS) {
		LOG_ERR("%s: Invalid irq number = %u\n", __func__, irq);
		return;
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
  1c:	4606      	mov	r6, r0
  1e:	f005 0501 	and.w	r5, r5, #1
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	sys_write32(BIT(irq_bit_num), VIM_RAW(irq_group_num));
  22:	79d8      	ldrb	r0, [r3, #7]
  24:	ea45 2500 	orr.w	r5, r5, r0, lsl #8
  28:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
  2c:	ea45 0542 	orr.w	r5, r5, r2, lsl #1
}
  30:	3201      	adds	r2, #1
}
  32:	fa00 f202 	lsl.w	r2, r0, r2
	}

	malloc_unlock();

	return ret;
}
  36:	ea01 0702 	and.w	r7, r1, r2
	STRUCT_SECTION_FOREACH(device, dev) {
  3a:	799a      	ldrb	r2, [r3, #6]
		return NULL;
  3c:	0324      	lsls	r4, r4, #12
  3e:	0212      	lsls	r2, r2, #8
  40:	f402 62e0 	and.w	r2, r2, #1792	; 0x700
  44:	f404 5480 	and.w	r4, r4, #4096	; 0x1000
			break;
		}
		arch_thread_return_value_set(thread, -EAGAIN);
		z_ready_thread(thread);
	}
	sem->count = 0;
  48:	4314      	orrs	r4, r2
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
  4a:	789a      	ldrb	r2, [r3, #2]
  4c:	f002 0201 	and.w	r2, r2, #1
	sem->count = 0;
  50:	4314      	orrs	r4, r2
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
  52:	795a      	ldrb	r2, [r3, #5]
  54:	00d2      	lsls	r2, r2, #3

	SYS_PORT_TRACING_OBJ_FUNC(k_sem, reset, sem);

	handle_poll_events(sem);

	z_reschedule(&lock, key);
  56:	f002 0238 	and.w	r2, r2, #56	; 0x38
}
  5a:	4314      	orrs	r4, r2
  5c:	78da      	ldrb	r2, [r3, #3]
	z_reschedule(&lock, key);
  5e:	0092      	lsls	r2, r2, #2
  60:	785b      	ldrb	r3, [r3, #1]
  62:	f002 0204 	and.w	r2, r2, #4
  66:	005b      	lsls	r3, r3, #1
	slab->info.num_used--;

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_mem_slab, free, slab);

	k_spin_unlock(&slab->lock, key);
}
  68:	4314      	orrs	r4, r2
   {
      TM_PMUProfilePoint* p = &gProfileObject.point[i];
      printk("Profile Entry #%u: %s\r\n", i, p->name);
      printk("Cycle Count: %u\r\n", p->cycleCountValue);

      for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
  6a:	f003 0302 	and.w	r3, r3, #2
  6e:	431c      	orrs	r4, r3
}
  70:	f000 e85c 	blx	12c <MpuP_isEnableAsm>
	}
#endif /* CONFIG_TICKET_SPINLOCKS */
#endif /* CONFIG_SMP */
	z_spinlock_validate_post(l);

	return k;
  74:	4623      	mov	r3, r4
  __ASM volatile ("cpsie i" : : : "memory");
  76:	462a      	mov	r2, r5
}
  78:	4639      	mov	r1, r7
			break;
		}
		j++;
	}
	if (i == cpu_count) {
		printk("Can't find CPU Core %d from dts and failed to boot it\n", cpu_num);
  7a:	4680      	mov	r8, r0
  7c:	4630      	mov	r0, r6
  7e:	f000 e860 	blx	140 <MpuP_setRegionAsm>
  82:	f1b8 0f00 	cmp.w	r8, #0
  __ASM volatile ("dmb 0xF":::"memory");
  86:	d003      	beq.n	90 <CONFIG_CONSOLE_INPUT_MAX_LINE_LEN+0x10>
  88:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
	return (node == list->tail) ? NULL : node->next;
  8c:	f000 b862 	b.w	154 <__MpuP_enableAsm_from_thumb>
  90:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

00000094 <MpuP_init>:
      // tm_pmu_profile_print(pmu_recv_names[i]);
      printf("Send Latency: ");
      tm_pmu_profile_print(pmu_send_names[i]);
   }

   tm_thread_suspend(0);
  94:	b570      	push	{r4, r5, r6, lr}
  96:	f000 e82e 	blx	f4 <MpuP_disableBRAsm>
  9a:	4d0e      	ldr	r5, [pc, #56]	; (d4 <MpuP_init+0x40>)
  9c:	2400      	movs	r4, #0
  9e:	4b0e      	ldr	r3, [pc, #56]	; (d8 <__data_size>)
  a0:	682a      	ldr	r2, [r5, #0]
  a2:	f103 0610 	add.w	r6, r3, #16
  a6:	42a2      	cmp	r2, r4
  a8:	d809      	bhi.n	be <MpuP_init+0x2a>
  aa:	686b      	ldr	r3, [r5, #4]
  ac:	b10b      	cbz	r3, b2 <MpuP_init+0x1e>
  ae:	f000 e836 	blx	11c <MpuP_enableBRAsm>
}
  b2:	68ab      	ldr	r3, [r5, #8]
			return 0;
		}
		result = 0;
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
		/* don't wait for a message to become available */
		result = -ENOMSG;
  b4:	b163      	cbz	r3, d0 <MpuP_init+0x3c>
  b6:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
  ba:	f000 b84b 	b.w	154 <__MpuP_enableAsm_from_thumb>
  be:	4620      	mov	r0, r4
    /*
     * Initialize MPU regions
     */
    for (i = 0; i < gMpuConfig.numRegions; i++)
    {
        MpuP_setRegion(i,
  c0:	3308      	adds	r3, #8
  c2:	e956 1204 	ldrd	r1, r2, [r6, #-16]
    for (i = 0; i < gMpuConfig.numRegions; i++)
  c6:	3401      	adds	r4, #1
        MpuP_setRegion(i,
  c8:	f7ff ffa2 	bl	10 <MpuP_setRegion>
    for (i = 0; i < gMpuConfig.numRegions; i++)
  cc:	4633      	mov	r3, r6
  ce:	e7e7      	b.n	a0 <MpuP_init+0xc>
    }

    if (gMpuConfig.enableMpu) {
	    MpuP_enableAsm();
    }
}
  d0:	bd70      	pop	{r4, r5, r6, pc}
  d2:	bf00      	nop
  d4:	7000a7bc 	.word	0x7000a7bc
  d8:	7000a76c 	.word	0x7000a76c

000000dc <MpuP_disableAsm>:
_ASM_FILE_PROLOGUE

/* FUNCTION DEF: void MpuP_disableAsm(void) */
GTEXT(MpuP_disableAsm)
SECTION_FUNC(boot_section, MpuP_disableAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
  dc:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        bic     r0, r0, #0x1             // clear bit 0 in r0
  e0:	e3c00001 	bic	r0, r0, #1
        dsb
  e4:	f57ff04f 	dsb	sy
        mcr     p15, #0, r0, c1, c0, #0  // MPU disabled (bit 0 = 0)
  e8:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        isb                              // flush instruction pipeline
  ec:	f57ff06f 	isb	sy
        bx      LR
  f0:	e12fff1e 	bx	lr

000000f4 <MpuP_disableBRAsm>:

/* FUNCTION DEF: void MpuP_disableBRAsm(void) */
GTEXT(MpuP_disableBRAsm)
SECTION_FUNC(boot_section, MpuP_disableBRAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
  f4:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        bic     r0, r0, #0x20000         // clear bit 17 in r0
  f8:	e3c00802 	bic	r0, r0, #131072	; 0x20000
        mcr     p15, #0, r0, c1, c0, #0  // disable background region
  fc:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        bx      LR
 100:	e12fff1e 	bx	lr

00000104 <MpuP_enableAsm>:

/* FUNCTION DEF: void MpuP_enableAsm(void) */
GTEXT(MpuP_enableAsm)
SECTION_FUNC(boot_section, MpuP_enableAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 104:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        orr     r0, r0, #0x1             // set bit 0 in r0
 108:	e3800001 	orr	r0, r0, #1
        dsb
 10c:	f57ff04f 	dsb	sy
        mcr     p15, #0, r0, c1, c0, #0  // MPU enabled (bit 0 = 1)
 110:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        isb                              // flush instruction pipeline
 114:	f57ff06f 	isb	sy
        bx      LR
 118:	e12fff1e 	bx	lr

0000011c <MpuP_enableBRAsm>:

/* FUNCTION DEF: void MpuP_enableBRAsm(void) */
GTEXT(MpuP_enableBRAsm)
SECTION_FUNC(boot_section, MpuP_enableBRAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 11c:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        orr     r0, r0, #0x20000         // set bit 17 in r0
 120:	e3800802 	orr	r0, r0, #131072	; 0x20000
        mcr     p15, #0, r0, c1, c0, #0  // background region enabled
 124:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        bx      LR
 128:	e12fff1e 	bx	lr

0000012c <MpuP_isEnableAsm>:

/* FUNCTION DEF: uint32_t MpuP_isEnableAsm(void) */
GTEXT(MpuP_isEnableAsm)
SECTION_FUNC(boot_section, MpuP_isEnableAsm)
        mov     r0, #0
 12c:	e3a00000 	mov	r0, #0
        mrc     p15, #0, r1, c1, c0, #0  // read SCTLR register to r1
 130:	ee111f10 	mrc	15, 0, r1, cr1, cr0, {0}
        tst     r1, #0x1                 // test bit 0
 134:	e3110001 	tst	r1, #1
        movne   r0, #1                   // if not 0, MPU is enabled
 138:	13a00001 	movne	r0, #1
        bx      LR
 13c:	e12fff1e 	bx	lr

00000140 <MpuP_setRegionAsm>:
 * r2 = sizeAndEnable
 * r3 = regionAttrs
 */
GTEXT(MpuP_setRegionAsm)
SECTION_FUNC(boot_section, MpuP_setRegionAsm)
        mcr     p15, #0, r0, c6, c2, #0  // select MPU region
 140:	ee060f12 	mcr	15, 0, r0, cr6, cr2, {0}
        mcr     p15, #0, r1, c6, c1, #0  // set region base address
 144:	ee061f11 	mcr	15, 0, r1, cr6, cr1, {0}
        mcr     p15, #0, r2, c6, c1, #2  // set region size and enable it
 148:	ee062f51 	mcr	15, 0, r2, cr6, cr1, {2}
        mcr     p15, #0, r3, c6, c1, #4  // set protection attributes
 14c:	ee063f91 	mcr	15, 0, r3, cr6, cr1, {4}
        bx      LR
 150:	e12fff1e 	bx	lr

00000154 <__MpuP_enableAsm_from_thumb>:
 154:	4778      	bx	pc
 156:	e7fd      	b.n	154 <__MpuP_enableAsm_from_thumb>
 158:	eaffffe9 	b	104 <MpuP_enableAsm>

0000015c <____start_veneer>:
 15c:	e51ff004 	ldr	pc, [pc, #-4]	; 160 <____start_veneer+0x4>
 160:	700007b8 	.word	0x700007b8
