
files/zephyr.elf:     file format elf32-littlearm


Disassembly of section rom_start:

70000000 <_vector_table>:
#include "macro_priv.inc"

_ASM_FILE_PROLOGUE

SECTION_SUBSEC_FUNC(exc_vector_table,_vector_table_section,_vector_table)
	ldr pc, =z_arm_reset             /*                   offset 0 */
70000000:	18 f0 9f e5 18 f0 9f e5 18 f0 9f e5 18 f0 9f e5     ................
	ldr pc, =z_arm_undef_instruction /* undef instruction offset 4 */
	ldr pc, =z_arm_svc               /* svc               offset 8 */
	ldr pc, =z_arm_prefetch_abort    /* prefetch abort offset  0xc */
	ldr pc, =z_arm_data_abort        /* data abort     offset 0x10 */
70000010:	18 f0 9f e5 00 f0 20 e3 14 f0 9f e5 14 f0 9f e5     ...... .........
	ldr pc, =z_arm_reset             /*                   offset 0 */
70000020:	b8 0c 00 70 a0 0a 00 70 4c 0f 00 70 e4 0a 00 70     ...p...pL..p...p
	ldr pc, =z_arm_data_abort        /* data abort     offset 0x10 */
70000030:	14 0b 00 70 a4 0d 00 70 81 0a 00 70                 ...p...p...p

Disassembly of section text:

70000040 <strcmp>:
	.fnstart
	.cfi_sections .debug_frame
	.cfi_startproc
	prologue push_ip=HAVE_PAC_LEAF
#ifndef STRCMP_NO_PRECHECK
	ldrb	r2, [src1]
70000040:	7802      	ldrb	r2, [r0, #0]
	ldrb	r3, [src2]
70000042:	780b      	ldrb	r3, [r1, #0]
	cmp	r2, #1
70000044:	2a01      	cmp	r2, #1
	it	cs
70000046:	bf28      	it	cs
	cmpcs	r2, r3
70000048:	429a      	cmpcs	r2, r3
	bne	.Lfastpath_exit
7000004a:	f040 80d8 	bne.w	700001fe <strcmp+0x1be>
#endif
	strd	r4, r5, [sp, #-16]!
7000004e:	e96d 4504 	strd	r4, r5, [sp, #-16]!
	.cfi_adjust_cfa_offset 16
	.cfi_rel_offset 4, 0
	.cfi_rel_offset 5, 4
	orr	tmp1, src1, src2
70000052:	ea40 0401 	orr.w	r4, r0, r1
	strd	r6, r7, [sp, #8]
70000056:	e9cd 6702 	strd	r6, r7, [sp, #8]
	.cfi_rel_offset 6, 8
	.cfi_rel_offset 7, 12
	mvn	const_m1, #0
7000005a:	f06f 0c00 	mvn.w	ip, #0
	lsl	r2, tmp1, #29
7000005e:	ea4f 7244 	mov.w	r2, r4, lsl #29
	cbz	r2, .Lloop_aligned8
70000062:	b31a      	cbz	r2, 700000ac <strcmp+0x6c>

.Lnot_aligned:
	eor	tmp1, src1, src2
70000064:	ea80 0401 	eor.w	r4, r0, r1
	tst	tmp1, #7
70000068:	f014 0f07 	tst.w	r4, #7
	bne	.Lmisaligned8
7000006c:	d16b      	bne.n	70000146 <strcmp+0x106>

	/* Deal with mutual misalignment by aligning downwards and then
	   masking off the unwanted loaded data to prevent a difference.  */
	and	tmp1, src1, #7
7000006e:	f000 0407 	and.w	r4, r0, #7
	bic	src1, src1, #7
70000072:	f020 0007 	bic.w	r0, r0, #7
	and	tmp2, tmp1, #3
70000076:	f004 0503 	and.w	r5, r4, #3
	bic	src2, src2, #7
7000007a:	f021 0107 	bic.w	r1, r1, #7
	lsl	tmp2, tmp2, #3	/* Bytes -> bits.  */
7000007e:	ea4f 05c5 	mov.w	r5, r5, lsl #3
	ldrd	data1a, data1b, [src1], #16
70000082:	e8f0 2304 	ldrd	r2, r3, [r0], #16
	tst	tmp1, #4
70000086:	f014 0f04 	tst.w	r4, #4
	ldrd	data2a, data2b, [src2], #16
7000008a:	e8f1 6704 	ldrd	r6, r7, [r1], #16
	/* In thumb code we can't use MVN with a register shift, but
	   we do have ORN.  */
	S2HI	tmp1, const_m1, tmp2
7000008e:	fa0c f405 	lsl.w	r4, ip, r5
	orn	data1a, data1a, tmp1
70000092:	ea62 0204 	orn	r2, r2, r4
	orn	data2a, data2a, tmp1
70000096:	ea66 0604 	orn	r6, r6, r4
	beq	.Lstart_realigned8
7000009a:	d00b      	beq.n	700000b4 <strcmp+0x74>
	orn	data1b, data1b, tmp1
7000009c:	ea63 0304 	orn	r3, r3, r4
	mov	data1a, const_m1
700000a0:	4662      	mov	r2, ip
	orn	data2b, data2b, tmp1
700000a2:	ea67 0704 	orn	r7, r7, r4
	mov	data2a, const_m1
700000a6:	4666      	mov	r6, ip
	b	.Lstart_realigned8
700000a8:	e004      	b.n	700000b4 <strcmp+0x74>
700000aa:	bf00      	nop
	/* Unwind the inner loop by a factor of 2, giving 16 bytes per
	   pass.  */
	.p2align 5,,12  /* Don't start in the tail bytes of a cache line.  */
	.p2align 2	/* Always word aligned.  */
.Lloop_aligned8:
	ldrd	data1a, data1b, [src1], #16
700000ac:	e8f0 2304 	ldrd	r2, r3, [r0], #16
	ldrd	data2a, data2b, [src2], #16
700000b0:	e8f1 6704 	ldrd	r6, r7, [r1], #16
.Lstart_realigned8:
	uadd8	syndrome_b, data1a, const_m1	/* Only want GE bits,  */
700000b4:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome_a, data1a, data2a
700000b8:	ea82 0406 	eor.w	r4, r2, r6
	sel	syndrome_a, syndrome_a, const_m1
700000bc:	faa4 f48c 	sel	r4, r4, ip
	cbnz	syndrome_a, .Ldiff_in_a
700000c0:	bb6c      	cbnz	r4, 7000011e <strcmp+0xde>
	uadd8	syndrome_b, data1b, const_m1	/* Only want GE bits.  */
700000c2:	fa83 f54c 	uadd8	r5, r3, ip
	eor	syndrome_b, data1b, data2b
700000c6:	ea83 0507 	eor.w	r5, r3, r7
	sel	syndrome_b, syndrome_b, const_m1
700000ca:	faa5 f58c 	sel	r5, r5, ip
	cbnz	syndrome_b, .Ldiff_in_b
700000ce:	b995      	cbnz	r5, 700000f6 <strcmp+0xb6>

	ldrd	data1a, data1b, [src1, #-8]
700000d0:	e950 2302 	ldrd	r2, r3, [r0, #-8]
	ldrd	data2a, data2b, [src2, #-8]
700000d4:	e951 6702 	ldrd	r6, r7, [r1, #-8]
	uadd8	syndrome_b, data1a, const_m1	/* Only want GE bits,  */
700000d8:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome_a, data1a, data2a
700000dc:	ea82 0406 	eor.w	r4, r2, r6
	sel	syndrome_a, syndrome_a, const_m1
700000e0:	faa4 f48c 	sel	r4, r4, ip
	uadd8	syndrome_b, data1b, const_m1	/* Only want GE bits.  */
700000e4:	fa83 f54c 	uadd8	r5, r3, ip
	eor	syndrome_b, data1b, data2b
700000e8:	ea83 0507 	eor.w	r5, r3, r7
	sel	syndrome_b, syndrome_b, const_m1
700000ec:	faa5 f58c 	sel	r5, r5, ip
	/* Can't use CBZ for backwards branch.  */
	orrs	syndrome_b, syndrome_b, syndrome_a /* Only need if s_a == 0 */
700000f0:	4325      	orrs	r5, r4
	beq	.Lloop_aligned8
700000f2:	d0db      	beq.n	700000ac <strcmp+0x6c>

.Ldiff_found:
	cbnz	syndrome_a, .Ldiff_in_a
700000f4:	b99c      	cbnz	r4, 7000011e <strcmp+0xde>

.Ldiff_in_b:
	strcmp_epilogue_aligned syndrome_b, data1b, data2b 1
700000f6:	ba2d      	rev	r5, r5
700000f8:	fab5 f485 	clz	r4, r5
700000fc:	f024 0407 	bic.w	r4, r4, #7
70000100:	fa27 f104 	lsr.w	r1, r7, r4
70000104:	e9dd 6702 	ldrd	r6, r7, [sp, #8]
70000108:	fa23 f304 	lsr.w	r3, r3, r4
7000010c:	f003 00ff 	and.w	r0, r3, #255	; 0xff
70000110:	f001 01ff 	and.w	r1, r1, #255	; 0xff
70000114:	e8fd 4504 	ldrd	r4, r5, [sp], #16
70000118:	eba0 0001 	sub.w	r0, r0, r1
7000011c:	4770      	bx	lr

.Ldiff_in_a:
	.cfi_restore_state
	strcmp_epilogue_aligned syndrome_a, data1a, data2a 1
7000011e:	ba24      	rev	r4, r4
70000120:	fab4 f484 	clz	r4, r4
70000124:	f024 0407 	bic.w	r4, r4, #7
70000128:	fa26 f104 	lsr.w	r1, r6, r4
7000012c:	e9dd 6702 	ldrd	r6, r7, [sp, #8]
70000130:	fa22 f204 	lsr.w	r2, r2, r4
70000134:	f002 00ff 	and.w	r0, r2, #255	; 0xff
70000138:	f001 01ff 	and.w	r1, r1, #255	; 0xff
7000013c:	e8fd 4504 	ldrd	r4, r5, [sp], #16
70000140:	eba0 0001 	sub.w	r0, r0, r1
70000144:	4770      	bx	lr

	.cfi_restore_state
.Lmisaligned8:
	tst	tmp1, #3
70000146:	f014 0f03 	tst.w	r4, #3
	bne	.Lmisaligned4
7000014a:	d13c      	bne.n	700001c6 <strcmp+0x186>
	ands	tmp1, src1, #3
7000014c:	f010 0403 	ands.w	r4, r0, #3
	bne	.Lmutual_align4
70000150:	d128      	bne.n	700001a4 <strcmp+0x164>

	/* Unrolled by a factor of 2, to reduce the number of post-increment
	   operations.  */
.Lloop_aligned4:
	ldr	data1, [src1], #8
70000152:	f850 2b08 	ldr.w	r2, [r0], #8
	ldr	data2, [src2], #8
70000156:	f851 3b08 	ldr.w	r3, [r1], #8
.Lstart_realigned4:
	uadd8	syndrome, data1, const_m1	/* Only need GE bits.  */
7000015a:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome, data1, data2
7000015e:	ea82 0503 	eor.w	r5, r2, r3
	sel	syndrome, syndrome, const_m1
70000162:	faa5 f58c 	sel	r5, r5, ip
	cbnz	syndrome, .Laligned4_done
70000166:	b95d      	cbnz	r5, 70000180 <strcmp+0x140>
	ldr	data1, [src1, #-4]
70000168:	f850 2c04 	ldr.w	r2, [r0, #-4]
	ldr	data2, [src2, #-4]
7000016c:	f851 3c04 	ldr.w	r3, [r1, #-4]
	uadd8	syndrome, data1, const_m1
70000170:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome, data1, data2
70000174:	ea82 0503 	eor.w	r5, r2, r3
	sel	syndrome, syndrome, const_m1
70000178:	faa5 f58c 	sel	r5, r5, ip
	cmp	syndrome, #0
7000017c:	2d00      	cmp	r5, #0
	beq	.Lloop_aligned4
7000017e:	d0e8      	beq.n	70000152 <strcmp+0x112>

.Laligned4_done:
	strcmp_epilogue_aligned syndrome, data1, data2, 0
70000180:	ba2d      	rev	r5, r5
70000182:	fab5 f485 	clz	r4, r5
70000186:	f024 0407 	bic.w	r4, r4, #7
7000018a:	fa23 f104 	lsr.w	r1, r3, r4
7000018e:	fa22 f204 	lsr.w	r2, r2, r4
70000192:	f002 00ff 	and.w	r0, r2, #255	; 0xff
70000196:	f001 01ff 	and.w	r1, r1, #255	; 0xff
7000019a:	e8fd 4504 	ldrd	r4, r5, [sp], #16
7000019e:	eba0 0001 	sub.w	r0, r0, r1
700001a2:	4770      	bx	lr

.Lmutual_align4:
	.cfi_restore_state
	/* Deal with mutual misalignment by aligning downwards and then
	   masking off the unwanted loaded data to prevent a difference.  */
	lsl	tmp1, tmp1, #3	/* Bytes -> bits.  */
700001a4:	ea4f 04c4 	mov.w	r4, r4, lsl #3
	bic	src1, src1, #3
700001a8:	f020 0003 	bic.w	r0, r0, #3
	ldr	data1, [src1], #8
700001ac:	f850 2b08 	ldr.w	r2, [r0], #8
	bic	src2, src2, #3
700001b0:	f021 0103 	bic.w	r1, r1, #3
	ldr	data2, [src2], #8
700001b4:	f851 3b08 	ldr.w	r3, [r1], #8

	/* In thumb code we can't use MVN with a register shift, but
	   we do have ORN.  */
	S2HI	tmp1, const_m1, tmp1
700001b8:	fa0c f404 	lsl.w	r4, ip, r4
	orn	data1, data1, tmp1
700001bc:	ea62 0204 	orn	r2, r2, r4
	orn	data2, data2, tmp1
700001c0:	ea63 0304 	orn	r3, r3, r4
	b	.Lstart_realigned4
700001c4:	e7c9      	b.n	7000015a <strcmp+0x11a>

.Lmisaligned4:
	ands	tmp1, src1, #3
700001c6:	f010 0403 	ands.w	r4, r0, #3
	beq	.Lsrc1_aligned
700001ca:	d01d      	beq.n	70000208 <strcmp+0x1c8>
	sub	src2, src2, tmp1
700001cc:	eba1 0104 	sub.w	r1, r1, r4
	bic	src1, src1, #3
700001d0:	f020 0003 	bic.w	r0, r0, #3
	lsls	tmp1, tmp1, #31
700001d4:	07e4      	lsls	r4, r4, #31
	ldr	data1, [src1], #4
700001d6:	f850 2b04 	ldr.w	r2, [r0], #4
	beq	.Laligned_m2
700001da:	d006      	beq.n	700001ea <strcmp+0x1aa>
	bcs	.Laligned_m1
700001dc:	d212      	bcs.n	70000204 <strcmp+0x1c4>
	add	src2, src2, #4
	cbnz	data2, .Lsrc1_aligned
#else  /* STRCMP_NO_PRECHECK */
	/* If we've done the pre-check, then we don't need to check the
	   first byte again here.  */
	ldrb	data2, [src2, #2]
700001de:	788b      	ldrb	r3, [r1, #2]
	uxtb	tmp1, data1, ror #BYTE2_OFFSET
700001e0:	fa5f f4a2 	uxtb.w	r4, r2, ror #16
	subs	tmp1, tmp1, data2
700001e4:	1ae4      	subs	r4, r4, r3
	bne	.Lmisaligned_exit
700001e6:	d106      	bne.n	700001f6 <strcmp+0x1b6>
	cbz	data2, .Lmisaligned_exit
700001e8:	b12b      	cbz	r3, 700001f6 <strcmp+0x1b6>

.Laligned_m2:
	ldrb	data2, [src2, #3]
700001ea:	78cb      	ldrb	r3, [r1, #3]
	uxtb	tmp1, data1, ror #BYTE3_OFFSET
700001ec:	fa5f f4b2 	uxtb.w	r4, r2, ror #24
	subs	tmp1, tmp1, data2
700001f0:	1ae4      	subs	r4, r4, r3
	bne	.Lmisaligned_exit
700001f2:	d100      	bne.n	700001f6 <strcmp+0x1b6>
	cbnz	data2, .Laligned_m1
700001f4:	b933      	cbnz	r3, 70000204 <strcmp+0x1c4>
#endif

.Lmisaligned_exit:
	.cfi_remember_state
	mov	result, tmp1
700001f6:	4620      	mov	r0, r4
	ldr	r4, [sp], #16
700001f8:	f85d 4b10 	ldr.w	r4, [sp], #16
	.cfi_restore 4
	.cfi_adjust_cfa_offset -16
	epilogue push_ip=HAVE_PAC_LEAF
700001fc:	4770      	bx	lr

#ifndef STRCMP_NO_PRECHECK
.Lfastpath_exit:
	.cfi_restore_state
	.cfi_remember_state
	sub	r0, r2, r3
700001fe:	eba2 0003 	sub.w	r0, r2, r3
	epilogue push_ip=HAVE_PAC_LEAF
70000202:	4770      	bx	lr

.Laligned_m1:
	.cfi_restore_state
	.cfi_remember_state
	add	src2, src2, #4
70000204:	f101 0104 	add.w	r1, r1, #4
#endif
.Lsrc1_aligned:
	.cfi_restore_state
	/* src1 is word aligned, but src2 has no common alignment
	   with it.  */
	ldr	data1, [src1], #4
70000208:	f850 2b04 	ldr.w	r2, [r0], #4
	lsls	tmp1, src2, #31		/* C=src2[1], Z=src2[0].  */
7000020c:	07cc      	lsls	r4, r1, #31

	bic	src2, src2, #3
7000020e:	f021 0103 	bic.w	r1, r1, #3
	ldr	data2, [src2], #4
70000212:	f851 3b04 	ldr.w	r3, [r1], #4
	bhi	.Loverlap1		/* C=1, Z=0 => src2[1:0] = 0b11.  */
70000216:	d848      	bhi.n	700002aa <strcmp+0x26a>
	bcs	.Loverlap2		/* C=1, Z=1 => src2[1:0] = 0b10.  */
70000218:	d224      	bcs.n	70000264 <strcmp+0x224>

	/* (overlap3) C=0, Z=0 => src2[1:0] = 0b01.  */
.Loverlap3:
	bic	tmp1, data1, #MSB
7000021a:	f022 447f 	bic.w	r4, r2, #4278190080	; 0xff000000
	uadd8	syndrome, data1, const_m1
7000021e:	fa82 f54c 	uadd8	r5, r2, ip
	eors	syndrome, tmp1, data2, S2LO #8
70000222:	ea94 2513 	eors.w	r5, r4, r3, lsr #8
	sel	syndrome, syndrome, const_m1
70000226:	faa5 f58c 	sel	r5, r5, ip
	bne	4f
7000022a:	d10a      	bne.n	70000242 <strcmp+0x202>
	cbnz	syndrome, 5f
7000022c:	b965      	cbnz	r5, 70000248 <strcmp+0x208>
	ldr	data2, [src2], #4
7000022e:	f851 3b04 	ldr.w	r3, [r1], #4
	eor	tmp1, tmp1, data1
70000232:	ea84 0402 	eor.w	r4, r4, r2
	cmp	tmp1, data2, S2HI #24
70000236:	ebb4 6f03 	cmp.w	r4, r3, lsl #24
	bne	6f
7000023a:	d10e      	bne.n	7000025a <strcmp+0x21a>
	ldr	data1, [src1], #4
7000023c:	f850 2b04 	ldr.w	r2, [r0], #4
	b	.Loverlap3
70000240:	e7eb      	b.n	7000021a <strcmp+0x1da>
4:
	S2LO	data2, data2, #8
70000242:	ea4f 2313 	mov.w	r3, r3, lsr #8
	b	.Lstrcmp_tail
70000246:	e055      	b.n	700002f4 <strcmp+0x2b4>

5:
	bics	syndrome, syndrome, #MSB
70000248:	f035 457f 	bics.w	r5, r5, #4278190080	; 0xff000000
	bne	.Lstrcmp_done_equal
7000024c:	d14d      	bne.n	700002ea <strcmp+0x2aa>

	/* We can only get here if the MSB of data1 contains 0, so
	   fast-path the exit.  */
	ldrb	result, [src2]
7000024e:	7808      	ldrb	r0, [r1, #0]
	.cfi_remember_state
	ldrd	r4, r5, [sp], #16
70000250:	e8fd 4504 	ldrd	r4, r5, [sp], #16
	.cfi_restore 5
	/* R6/7 Not used in this sequence.  */
	.cfi_restore 6
	.cfi_restore 7
	.cfi_adjust_cfa_offset -16
	neg	result, result
70000254:	f1c0 0000 	rsb	r0, r0, #0
	epilogue push_ip=HAVE_PAC_LEAF
70000258:	4770      	bx	lr

6:
	.cfi_restore_state
	S2LO	data1, data1, #24
7000025a:	ea4f 6212 	mov.w	r2, r2, lsr #24
	and	data2, data2, #LSB
7000025e:	f003 03ff 	and.w	r3, r3, #255	; 0xff
	b	.Lstrcmp_tail
70000262:	e047      	b.n	700002f4 <strcmp+0x2b4>

	.p2align 5,,12	/* Ensure at least 3 instructions in cache line.  */
.Loverlap2:
	and	tmp1, data1, const_m1, S2LO #16
70000264:	ea02 441c 	and.w	r4, r2, ip, lsr #16
	uadd8	syndrome, data1, const_m1
70000268:	fa82 f54c 	uadd8	r5, r2, ip
	eors	syndrome, tmp1, data2, S2LO #16
7000026c:	ea94 4513 	eors.w	r5, r4, r3, lsr #16
	sel	syndrome, syndrome, const_m1
70000270:	faa5 f58c 	sel	r5, r5, ip
	bne	4f
70000274:	d10a      	bne.n	7000028c <strcmp+0x24c>
	cbnz	syndrome, 5f
70000276:	b965      	cbnz	r5, 70000292 <strcmp+0x252>
	ldr	data2, [src2], #4
70000278:	f851 3b04 	ldr.w	r3, [r1], #4
	eor	tmp1, tmp1, data1
7000027c:	ea84 0402 	eor.w	r4, r4, r2
	cmp	tmp1, data2, S2HI #16
70000280:	ebb4 4f03 	cmp.w	r4, r3, lsl #16
	bne	6f
70000284:	d10c      	bne.n	700002a0 <strcmp+0x260>
	ldr	data1, [src1], #4
70000286:	f850 2b04 	ldr.w	r2, [r0], #4
	b	.Loverlap2
7000028a:	e7eb      	b.n	70000264 <strcmp+0x224>
4:
	S2LO	data2, data2, #16
7000028c:	ea4f 4313 	mov.w	r3, r3, lsr #16
	b	.Lstrcmp_tail
70000290:	e030      	b.n	700002f4 <strcmp+0x2b4>
5:
	ands	syndrome, syndrome, const_m1, S2LO #16
70000292:	ea15 451c 	ands.w	r5, r5, ip, lsr #16
	bne	.Lstrcmp_done_equal
70000296:	d128      	bne.n	700002ea <strcmp+0x2aa>

	ldrh	data2, [src2]
70000298:	880b      	ldrh	r3, [r1, #0]
	S2LO	data1, data1, #16
7000029a:	ea4f 4212 	mov.w	r2, r2, lsr #16
#ifdef __ARM_BIG_ENDIAN
	lsl	data2, data2, #16
#endif
	b	.Lstrcmp_tail
7000029e:	e029      	b.n	700002f4 <strcmp+0x2b4>

6:
	S2LO	data1, data1, #16
700002a0:	ea4f 4212 	mov.w	r2, r2, lsr #16
	and	data2, data2, const_m1, S2LO #16
700002a4:	ea03 431c 	and.w	r3, r3, ip, lsr #16
	b	.Lstrcmp_tail
700002a8:	e024      	b.n	700002f4 <strcmp+0x2b4>

	.p2align 5,,12	/* Ensure at least 3 instructions in cache line.  */
.Loverlap1:
	and	tmp1, data1, #LSB
700002aa:	f002 04ff 	and.w	r4, r2, #255	; 0xff
	uadd8	syndrome, data1, const_m1
700002ae:	fa82 f54c 	uadd8	r5, r2, ip
	eors	syndrome, tmp1, data2, S2LO #24
700002b2:	ea94 6513 	eors.w	r5, r4, r3, lsr #24
	sel	syndrome, syndrome, const_m1
700002b6:	faa5 f58c 	sel	r5, r5, ip
	bne	4f
700002ba:	d10a      	bne.n	700002d2 <strcmp+0x292>
	cbnz	syndrome, 5f
700002bc:	b965      	cbnz	r5, 700002d8 <strcmp+0x298>
	ldr	data2, [src2], #4
700002be:	f851 3b04 	ldr.w	r3, [r1], #4
	eor	tmp1, tmp1, data1
700002c2:	ea84 0402 	eor.w	r4, r4, r2
	cmp	tmp1, data2, S2HI #8
700002c6:	ebb4 2f03 	cmp.w	r4, r3, lsl #8
	bne	6f
700002ca:	d109      	bne.n	700002e0 <strcmp+0x2a0>
	ldr	data1, [src1], #4
700002cc:	f850 2b04 	ldr.w	r2, [r0], #4
	b	.Loverlap1
700002d0:	e7eb      	b.n	700002aa <strcmp+0x26a>
4:
	S2LO	data2, data2, #24
700002d2:	ea4f 6313 	mov.w	r3, r3, lsr #24
	b	.Lstrcmp_tail
700002d6:	e00d      	b.n	700002f4 <strcmp+0x2b4>
5:
	tst	syndrome, #LSB
700002d8:	f015 0fff 	tst.w	r5, #255	; 0xff
	bne	.Lstrcmp_done_equal
700002dc:	d105      	bne.n	700002ea <strcmp+0x2aa>
	ldr	data2, [src2]
700002de:	680b      	ldr	r3, [r1, #0]
6:
	S2LO	data1, data1, #8
700002e0:	ea4f 2212 	mov.w	r2, r2, lsr #8
	bic	data2, data2, #MSB
700002e4:	f023 437f 	bic.w	r3, r3, #4278190080	; 0xff000000
	b	.Lstrcmp_tail
700002e8:	e004      	b.n	700002f4 <strcmp+0x2b4>

.Lstrcmp_done_equal:
	mov	result, #0
700002ea:	f04f 0000 	mov.w	r0, #0
	.cfi_remember_state
	ldrd	r4, r5, [sp], #16
700002ee:	e8fd 4504 	ldrd	r4, r5, [sp], #16
	.cfi_restore 5
	/* R6/7 not used in this sequence.  */
	.cfi_restore 6
	.cfi_restore 7
	.cfi_adjust_cfa_offset -16
	epilogue push_ip=HAVE_PAC_LEAF
700002f2:	4770      	bx	lr

.Lstrcmp_tail:
	.cfi_restore_state
#ifndef __ARM_BIG_ENDIAN
	rev	data1, data1
700002f4:	ba12      	rev	r2, r2
	rev	data2, data2
700002f6:	ba1b      	rev	r3, r3
	/* Now everything looks big-endian...  */
#endif
	uadd8	tmp1, data1, const_m1
700002f8:	fa82 f44c 	uadd8	r4, r2, ip
	eor	tmp1, data1, data2
700002fc:	ea82 0403 	eor.w	r4, r2, r3
	sel	syndrome, tmp1, const_m1
70000300:	faa4 f58c 	sel	r5, r4, ip
	clz	tmp1, syndrome
70000304:	fab5 f485 	clz	r4, r5
	lsl	data1, data1, tmp1
70000308:	fa02 f204 	lsl.w	r2, r2, r4
	lsl	data2, data2, tmp1
7000030c:	fa03 f304 	lsl.w	r3, r3, r4
	lsr	result, data1, #24
70000310:	ea4f 6012 	mov.w	r0, r2, lsr #24
	ldrd	r4, r5, [sp], #16
70000314:	e8fd 4504 	ldrd	r4, r5, [sp], #16
	.cfi_restore 5
	/* R6/7 not used in this sequence.  */
	.cfi_restore 6
	.cfi_restore 7
	.cfi_adjust_cfa_offset -16
	sub	result, result, data2, lsr #24
70000318:	eba0 6013 	sub.w	r0, r0, r3, lsr #24
	epilogue push_ip=HAVE_PAC_LEAF
7000031c:	4770      	bx	lr
7000031e:	bf00      	nop

70000320 <_OffsetAbsSyms>:

#include <gen_offset.h>

#include "offsets_aarch32.c"

GEN_ABS_SYM_END
70000320:	4770      	bx	lr
70000322:	bf00      	nop

70000324 <main>:

int main(void)
{
#ifdef USING_ZEPHYR
   extern int rtos_main_zephyr(void);
   return rtos_main_zephyr();
70000324:	f000 b830 	b.w	70000388 <rtos_main_zephyr>

70000328 <tm_interrupt_handler>:
void* test_interrupt_handler = NULL;

/* Define the interrupt handler */
void tm_interrupt_handler(void* args)
{
   if (test_interrupt_handler != NULL)
70000328:	f245 5310 	movw	r3, #21776	; 0x5510
7000032c:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000330:	681b      	ldr	r3, [r3, #0]
70000332:	b103      	cbz	r3, 70000336 <tm_interrupt_handler+0xe>
   {
      /* Call the assigned handler function */
      ((void (*)(void)) test_interrupt_handler)();
70000334:	4718      	bx	r3
   }
}
70000336:	4770      	bx	lr

70000338 <main_task>:
}

void main_task(void* pvParameters)
{
   /* Start Thread-Metric tests */
   printk("Starting Thread-Metric tests...\r\n");
70000338:	f644 20ec 	movw	r0, #19180	; 0x4aec
{
7000033c:	b510      	push	{r4, lr}

   /* Initialize custom interrupts*/
   test_interrupt_handler = tm_isr_message_handler;
7000033e:	f240 34b5 	movw	r4, #949	; 0x3b5
   printk("Starting Thread-Metric tests...\r\n");
70000342:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000346:	f000 fb59 	bl	700009fc <printk>
   test_interrupt_handler = tm_isr_message_handler;
7000034a:	f245 5310 	movw	r3, #21776	; 0x5510
7000034e:	f2c7 0300 	movt	r3, #28672	; 0x7000
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
70000352:	2204      	movs	r2, #4
   test_interrupt_handler = tm_isr_message_handler;
70000354:	f2c7 0400 	movt	r4, #28672	; 0x7000
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
70000358:	2101      	movs	r1, #1
7000035a:	200a      	movs	r0, #10
   test_interrupt_handler = tm_isr_message_handler;
7000035c:	601c      	str	r4, [r3, #0]
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
7000035e:	f000 ff2b 	bl	700011b8 <z_vim_irq_priority_set>
   IRQ_CONNECT(SOFTWARE_INTERRUPT_ID, 1, tm_interrupt_handler, NULL, 0);
70000362:	2200      	movs	r2, #0
70000364:	2101      	movs	r1, #1
70000366:	200a      	movs	r0, #10
70000368:	f000 fb78 	bl	70000a5c <z_soc_irq_priority_set>
   irq_enable(SOFTWARE_INTERRUPT_ID);
7000036c:	200a      	movs	r0, #10
7000036e:	f000 fb77 	bl	70000a60 <z_soc_irq_enable>
   z_vim_irq_enable(irq);
70000372:	200a      	movs	r0, #10
70000374:	f000 ff4c 	bl	70001210 <z_vim_irq_enable>
   setup_interrupt();

   /* Call the main Thread-Metric function */
   main_sync();
70000378:	f000 f8da 	bl	70000530 <main_sync>
	if (z_syscall_trap()) {
		return (k_tid_t) arch_syscall_invoke0(K_SYSCALL_K_SCHED_CURRENT_THREAD_QUERY);
	}
#endif
	compiler_barrier();
	return z_impl_k_sched_current_thread_query();
7000037c:	f002 f9c8 	bl	70002710 <z_impl_k_sched_current_thread_query>

   /* Delete thread after completion */
   k_thread_abort(k_current_get());
}
70000380:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_ABORT);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_abort(thread);
70000384:	f002 b9ca 	b.w	7000271c <z_impl_k_thread_abort>

70000388 <rtos_main_zephyr>:
/* Thread definition */
K_THREAD_DEFINE(main_thread, 512 /* STACKSIZE */, main_task, NULL, NULL, NULL, MAIN_TASK_PRI, K_USER, -1);

int rtos_main_zephyr(void)
{
   printk("Initializing Zephyr system...\r\n");
70000388:	f644 3010 	movw	r0, #19216	; 0x4b10
{
7000038c:	b508      	push	{r3, lr}
   printk("Initializing Zephyr system...\r\n");
7000038e:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000392:	f000 fb33 	bl	700009fc <printk>
	z_impl_k_wakeup(thread);
70000396:	f644 50d8 	movw	r0, #19928	; 0x4dd8
7000039a:	f2c7 0000 	movt	r0, #28672	; 0x7000
7000039e:	f002 f991 	bl	700026c4 <z_impl_k_wakeup>

   /* Create main task */
   k_thread_start(main_thread);

   printk("Main task created and running...\r\n");
700003a2:	f644 3030 	movw	r0, #19248	; 0x4b30
700003a6:	f2c7 0000 	movt	r0, #28672	; 0x7000
700003aa:	f000 fb27 	bl	700009fc <printk>

   return 0;
}
700003ae:	2000      	movs	r0, #0
700003b0:	bd08      	pop	{r3, pc}
700003b2:	bf00      	nop

700003b4 <tm_isr_message_handler>:
   tm_thread_resume(0);
}

/* Minimal ISR: No prints, no dynamic formatting */
void tm_isr_message_handler(void)
{
700003b4:	b538      	push	{r3, r4, r5, lr}
   int i;
   tm_isr_counter++;
700003b6:	f245 7320 	movw	r3, #22304	; 0x5720
      [0] : Producer ID (1)
      [1] : Message counter (isr_message_counter)
      [2..MESSAGE_SIZE-2] : Pattern = 1000 + (isr_message_counter * 10) + index
      [MESSAGE_SIZE-1] : Checksum over first (MESSAGE_SIZE-1) words */
   message[0] = 1;
   message[1] = isr_message_counter;
700003ba:	f245 741c 	movw	r4, #22300	; 0x571c
   tm_isr_counter++;
700003be:	f2c7 0300 	movt	r3, #28672	; 0x7000
   message[0] = 1;
700003c2:	2101      	movs	r1, #1
   message[1] = isr_message_counter;
700003c4:	f2c7 0400 	movt	r4, #28672	; 0x7000
   message[0] = 1;
700003c8:	f245 7514 	movw	r5, #22292	; 0x5714
   tm_isr_counter++;
700003cc:	681a      	ldr	r2, [r3, #0]
   message[0] = 1;
700003ce:	f2c7 0500 	movt	r5, #28672	; 0x7000
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
   {
      message[i] = 1000 + (isr_message_counter * 10) + i;
   }
   message[MESSAGE_SIZE - 1] = compute_checksum(message, MESSAGE_SIZE - 1);
700003d2:	e9c5 1100 	strd	r1, r1, [r5]
   tm_isr_counter++;
700003d6:	440a      	add	r2, r1
700003d8:	601a      	str	r2, [r3, #0]
   message[1] = isr_message_counter;
700003da:	6823      	ldr	r3, [r4, #0]

   /* Measure send latency using a precomputed PMU name */
   tm_pmu_profile_start(pmu_send_names[isr_message_counter]);
700003dc:	f245 5314 	movw	r3, #21780	; 0x5514
700003e0:	6820      	ldr	r0, [r4, #0]
700003e2:	f2c7 0300 	movt	r3, #28672	; 0x7000
700003e6:	eb03 1000 	add.w	r0, r3, r0, lsl #4
700003ea:	f000 f9b1 	bl	70000750 <tm_pmu_profile_start>
   tm_queue_send_from_isr(0, message);
700003ee:	4629      	mov	r1, r5
700003f0:	2000      	movs	r0, #0
700003f2:	f000 f953 	bl	7000069c <tm_queue_send_from_isr>
   // tm_pmu_profile_end(pmu_send_names[isr_message_counter]);

   isr_message_counter++; /* Prepare for next iteration */
700003f6:	6823      	ldr	r3, [r4, #0]
700003f8:	3301      	adds	r3, #1
700003fa:	6023      	str	r3, [r4, #0]
}
700003fc:	bd38      	pop	{r3, r4, r5, pc}
700003fe:	bf00      	nop

70000400 <task_synchronisation_initialize>:
 * TEST INITIALIZATION FUNCTION
 * Called by tm_initialize() from main().
 * This function sets up the mutex and creates/resumes the tasks.
 ********************************************************************************/
static void task_synchronisation_initialize(void)
{
70000400:	b508      	push	{r3, lr}
   /* initialze PMU */
   tm_setup_pmu();
70000402:	f000 f8ab 	bl	7000055c <tm_setup_pmu>
   /* Create the UART mutex. */
   tm_mutex_create(MUTEX_ID);
70000406:	2001      	movs	r0, #1
70000408:	f000 f990 	bl	7000072c <tm_mutex_create>
   /* Create the semaphore to snychronize tasks.
      The implementation calls a semaphore_get()
      to make it available from the start */
   tm_semaphore_create(SEM_A);
7000040c:	2001      	movs	r0, #1
7000040e:	f000 f953 	bl	700006b8 <tm_semaphore_create>
   tm_semaphore_create(SEM_B);
70000412:	2002      	movs	r0, #2
70000414:	f000 f950 	bl	700006b8 <tm_semaphore_create>
   /* guarantee that the semaphore A is blocked so Task2 can start first.*/
   tm_semaphore_get(SEM_A);
70000418:	2001      	movs	r0, #1
7000041a:	f000 f959 	bl	700006d0 <tm_semaphore_get>

   /* Create two tasks, each with a unique ID. Priority is arbitrary.
      Without synchronisation Task1 would start operating before task2.
      we use synchronisation to ensure that task2 can finish printing first*/
   tm_thread_create(1, 5, writer_task1);
7000041e:	f240 5205 	movw	r2, #1285	; 0x505
70000422:	2105      	movs	r1, #5
70000424:	f2c7 0200 	movt	r2, #28672	; 0x7000
70000428:	2001      	movs	r0, #1
7000042a:	f000 f8f3 	bl	70000614 <tm_thread_create>
   tm_thread_create(2, 5, writer_task2);
7000042e:	f240 42d9 	movw	r2, #1241	; 0x4d9
70000432:	2105      	movs	r1, #5
70000434:	f2c7 0200 	movt	r2, #28672	; 0x7000
70000438:	2002      	movs	r0, #2
7000043a:	f000 f8eb 	bl	70000614 <tm_thread_create>
   tm_thread_create(3, 1, reporting_thread);
7000043e:	f240 4265 	movw	r2, #1125	; 0x465
70000442:	2101      	movs	r1, #1
70000444:	f2c7 0200 	movt	r2, #28672	; 0x7000
70000448:	2003      	movs	r0, #3
7000044a:	f000 f8e3 	bl	70000614 <tm_thread_create>

   /* Start (resume) both tasks. */
   tm_thread_resume(1);
7000044e:	2001      	movs	r0, #1
70000450:	f000 f90e 	bl	70000670 <tm_thread_resume>
   tm_thread_resume(2);
70000454:	2002      	movs	r0, #2
70000456:	f000 f90b 	bl	70000670 <tm_thread_resume>
   tm_thread_resume(3);
}
7000045a:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
   tm_thread_resume(3);
7000045e:	2003      	movs	r0, #3
70000460:	f000 b906 	b.w	70000670 <tm_thread_resume>

70000464 <reporting_thread>:
{
70000464:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   last_total = 0;
70000468:	2700      	movs	r7, #0
7000046a:	f245 7628 	movw	r6, #22312	; 0x5728
7000046e:	f245 7524 	movw	r5, #22308	; 0x5724
      printf("**** Task Synchronistation Test **** Relative Time: %lu\r\n", relative_time);
70000472:	f644 3a60 	movw	sl, #19296	; 0x4b60
      printf("Time Period Total:  %lu\r\n", total - last_total);
70000476:	f644 399c 	movw	r9, #19356	; 0x4b9c
      printf("Task1 Counter:  %lu\r\n", task1_counter);
7000047a:	f644 38b8 	movw	r8, #19384	; 0x4bb8
   relative_time = 0;
7000047e:	463c      	mov	r4, r7
70000480:	f2c7 0600 	movt	r6, #28672	; 0x7000
70000484:	f2c7 0500 	movt	r5, #28672	; 0x7000
      printf("**** Task Synchronistation Test **** Relative Time: %lu\r\n", relative_time);
70000488:	f2c7 0a00 	movt	sl, #28672	; 0x7000
      printf("Time Period Total:  %lu\r\n", total - last_total);
7000048c:	f2c7 0900 	movt	r9, #28672	; 0x7000
      printf("Task1 Counter:  %lu\r\n", task1_counter);
70000490:	f2c7 0800 	movt	r8, #28672	; 0x7000
      tm_thread_sleep(TM_TEST_DURATION);
70000494:	201e      	movs	r0, #30
      relative_time = relative_time + TM_TEST_DURATION;
70000496:	4404      	add	r4, r0
      tm_thread_sleep(TM_TEST_DURATION);
70000498:	f000 f8f8 	bl	7000068c <tm_thread_sleep>
      printf("**** Task Synchronistation Test **** Relative Time: %lu\r\n", relative_time);
7000049c:	4621      	mov	r1, r4
7000049e:	4650      	mov	r0, sl
700004a0:	f000 faac 	bl	700009fc <printk>
      total = task1_counter + task2_counter;
700004a4:	682a      	ldr	r2, [r5, #0]
700004a6:	6833      	ldr	r3, [r6, #0]
      printf("Time Period Total:  %lu\r\n", total - last_total);
700004a8:	4648      	mov	r0, r9
      total = task1_counter + task2_counter;
700004aa:	4413      	add	r3, r2
      printf("Time Period Total:  %lu\r\n", total - last_total);
700004ac:	1bd9      	subs	r1, r3, r7
      last_total = total;
700004ae:	461f      	mov	r7, r3
      printf("Time Period Total:  %lu\r\n", total - last_total);
700004b0:	f000 faa4 	bl	700009fc <printk>
      printf("Task1 Counter:  %lu\r\n", task1_counter);
700004b4:	6831      	ldr	r1, [r6, #0]
700004b6:	4640      	mov	r0, r8
700004b8:	f000 faa0 	bl	700009fc <printk>
      printf("Task2 Counter:  %lu\r\n", task2_counter);
700004bc:	6829      	ldr	r1, [r5, #0]
700004be:	f644 30d0 	movw	r0, #19408	; 0x4bd0
700004c2:	f2c7 0000 	movt	r0, #28672	; 0x7000
700004c6:	f000 fa99 	bl	700009fc <printk>
      tm_pmu_profile_print("SEM_A_perf");
700004ca:	f644 30e8 	movw	r0, #19432	; 0x4be8
700004ce:	f2c7 0000 	movt	r0, #28672	; 0x7000
700004d2:	f000 f9c9 	bl	70000868 <tm_pmu_profile_print>
   while (1)
700004d6:	e7dd      	b.n	70000494 <reporting_thread+0x30>

700004d8 <writer_task2>:
{
700004d8:	f245 7424 	movw	r4, #22308	; 0x5724
      tm_pmu_profile_start("SEM_A_perf");
700004dc:	f644 35e8 	movw	r5, #19432	; 0x4be8
700004e0:	f2c7 0400 	movt	r4, #28672	; 0x7000
700004e4:	f2c7 0500 	movt	r5, #28672	; 0x7000
{
700004e8:	b508      	push	{r3, lr}
      tm_semaphore_wait(SEM_B);
700004ea:	2002      	movs	r0, #2
700004ec:	f000 f8fc 	bl	700006e8 <tm_semaphore_wait>
      task2_counter++;
700004f0:	6823      	ldr	r3, [r4, #0]
      tm_pmu_profile_start("SEM_A_perf");
700004f2:	4628      	mov	r0, r5
      task2_counter++;
700004f4:	3301      	adds	r3, #1
700004f6:	6023      	str	r3, [r4, #0]
      tm_pmu_profile_start("SEM_A_perf");
700004f8:	f000 f92a 	bl	70000750 <tm_pmu_profile_start>
      tm_semaphore_put(SEM_A);
700004fc:	2001      	movs	r0, #1
700004fe:	f000 f907 	bl	70000710 <tm_semaphore_put>
   while (1)
70000502:	e7f2      	b.n	700004ea <writer_task2+0x12>

70000504 <writer_task1>:
{
70000504:	f245 7428 	movw	r4, #22312	; 0x5728
      tm_pmu_profile_end("SEM_A_perf");
70000508:	f644 35e8 	movw	r5, #19432	; 0x4be8
7000050c:	f2c7 0400 	movt	r4, #28672	; 0x7000
70000510:	f2c7 0500 	movt	r5, #28672	; 0x7000
{
70000514:	b508      	push	{r3, lr}
      tm_semaphore_wait(SEM_A);
70000516:	2001      	movs	r0, #1
70000518:	f000 f8e6 	bl	700006e8 <tm_semaphore_wait>
      tm_pmu_profile_end("SEM_A_perf");
7000051c:	4628      	mov	r0, r5
7000051e:	f000 f957 	bl	700007d0 <tm_pmu_profile_end>
      task1_counter++;
70000522:	6823      	ldr	r3, [r4, #0]
      tm_semaphore_put(SEM_B);
70000524:	2002      	movs	r0, #2
      task1_counter++;
70000526:	3301      	adds	r3, #1
70000528:	6023      	str	r3, [r4, #0]
      tm_semaphore_put(SEM_B);
7000052a:	f000 f8f1 	bl	70000710 <tm_semaphore_put>
   while (1)
7000052e:	e7f2      	b.n	70000516 <writer_task1+0x12>

70000530 <main_sync>:
/********************************************************************************
 * MAIN ENTRY POINT
 ********************************************************************************/
int main_sync(void)
{
   printf("[Main] Starting Synchronisation Test.\r\n");
70000530:	f644 30f4 	movw	r0, #19444	; 0x4bf4
{
70000534:	b508      	push	{r3, lr}
   printf("[Main] Starting Synchronisation Test.\r\n");
70000536:	f2c7 0000 	movt	r0, #28672	; 0x7000
7000053a:	f000 fa5f 	bl	700009fc <printk>

   /* Call tm_initialize(), passing our task_synchronisation_initialize.
    * The real implementation of tm_initialize() will do RTOS setup,
    * then call task_synchronisation_initialize(), then start scheduling tasks.
    */
   tm_initialize(task_synchronisation_initialize);
7000053e:	f240 4001 	movw	r0, #1025	; 0x401
70000542:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000546:	f000 f863 	bl	70000610 <tm_initialize>

   /* In many RTOSes, tm_initialize() might not return. If it does here,
    * we just print a message. */
   printf("[Main] tm_initialize returned, threads started.\r\n");
7000054a:	f644 401c 	movw	r0, #19484	; 0x4c1c
7000054e:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000552:	f000 fa53 	bl	700009fc <printk>
   return 0;
}
70000556:	2000      	movs	r0, #0
70000558:	bd08      	pop	{r3, pc}
7000055a:	bf00      	nop

7000055c <tm_setup_pmu>:
/* --------------------------------------------------------------------------
 * PMU Initialization (called at system boot)
 * -------------------------------------------------------------------------- */
int tm_setup_pmu(void)
{
   printk("Initializing PMU...\r\n");
7000055c:	f644 4050 	movw	r0, #19536	; 0x4c50
{
70000560:	b538      	push	{r3, r4, r5, lr}
   printk("Initializing PMU...\r\n");
70000562:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000566:	f000 fa49 	bl	700009fc <printk>

/* Performance Monitor Control Register (PMCR) */
__STATIC_FORCEINLINE uint32_t pmu_read_pmcr(void)
{
    uint32_t val;
    __asm__ volatile ("mrc p15, 0, %0, c9, c12, 0" : "=r" (val));
7000056a:	ee19 3f1c 	mrc	15, 0, r3, cr9, cr12, {0}

   /* Disable all counters (PMCR.E=0) */
   uint32_t pmcr = pmu_read_pmcr();
   pmcr &= ~0x1;
7000056e:	f023 0301 	bic.w	r3, r3, #1
    return val;
}

__STATIC_FORCEINLINE void pmu_write_pmcr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
70000572:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}
}

/* Performance Monitor Count Enable Clear Register (PMCNTENCLR) */
__STATIC_FORCEINLINE void pmu_write_cntenclr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 2" : : "r" (val));
70000576:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
7000057a:	ee09 3f5c 	mcr	15, 0, r3, cr9, cr12, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
7000057e:	2306      	movs	r3, #6
70000580:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}
    return val;
}

__STATIC_FORCEINLINE void pmu_write_pmccntr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 0" : : "r" (val));
70000584:	2400      	movs	r4, #0
70000586:	ee09 4f1d 	mcr	15, 0, r4, cr9, cr13, {0}
}

/* Event Counter Selection Register (PMSELR) */
__STATIC_FORCEINLINE void pmu_select_event_counter(uint32_t counter_idx)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
7000058a:	ee09 4fbc 	mcr	15, 0, r4, cr9, cr12, {5}

   /* Configure event counters */
   for (uint32_t i = 0; i < gPmuConfig.numEventCounters; i++)
   {
      pmu_select_event_counter(i);
      pmu_write_evtyper(gPmuConfig.eventCounters[i].type);
7000058e:	f64a 73e8 	movw	r3, #45032	; 0xafe8
70000592:	f2c7 0300 	movt	r3, #28672	; 0x7000
}

/* Event Type Register (PMXEVTYPER) */
__STATIC_FORCEINLINE void pmu_write_evtyper(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
70000596:	685a      	ldr	r2, [r3, #4]
70000598:	ee09 2f3d 	mcr	15, 0, r2, cr9, cr13, {1}
    return val;
}

__STATIC_FORCEINLINE void pmu_write_evcounter(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
7000059c:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
700005a0:	2501      	movs	r5, #1
700005a2:	ee09 5fbc 	mcr	15, 0, r5, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
700005a6:	68da      	ldr	r2, [r3, #12]
700005a8:	ee09 2f3d 	mcr	15, 0, r2, cr9, cr13, {1}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
700005ac:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
700005b0:	2202      	movs	r2, #2
700005b2:	ee09 2fbc 	mcr	15, 0, r2, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
700005b6:	695b      	ldr	r3, [r3, #20]
700005b8:	ee09 3f3d 	mcr	15, 0, r3, cr9, cr13, {1}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
700005bc:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 1" : : "r" (val));
700005c0:	2307      	movs	r3, #7
700005c2:	f2c8 0300 	movt	r3, #32768	; 0x8000
700005c6:	ee09 3f3c 	mcr	15, 0, r3, cr9, cr12, {1}
    __asm__ volatile ("mrc p15, 0, %0, c9, c12, 0" : "=r" (val));
700005ca:	ee19 3f1c 	mrc	15, 0, r3, cr9, cr12, {0}
   /*    bit31 => cycle counter, plus bits [0..(numEventCounters-1)] => event counters */
   pmu_write_cntenset((1 << 31) | ((1 << gPmuConfig.numEventCounters) - 1));

   /* Enable counters in PMCR (bit[0] = E=1) */
   pmcr = pmu_read_pmcr();
   pmcr |= 0x1;
700005ce:	432b      	orrs	r3, r5
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
700005d0:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}

/* PMU User Access Enable Register (PMUSERENR) */
__STATIC_FORCEINLINE void pmu_enable_user_access(void)
{
    uint32_t val;
    __asm__ volatile ("mrc p15, 0, %0, c9, c14, 0" : "=r" (val));
700005d4:	ee19 3f1e 	mrc	15, 0, r3, cr9, cr14, {0}
    val |= 1;  // Enable user mode access
700005d8:	432b      	orrs	r3, r5
    __asm__ volatile ("mcr p15, 0, %0, c9, c14, 0" : : "r" (val));
700005da:	ee09 3f1e 	mcr	15, 0, r3, cr9, cr14, {0}
/* --------------------------------------------------------------------------
 * Init for the Chache Hits/Misses profile structure
 * -------------------------------------------------------------------------- */
void pmu_init_profile(void)
{
   memset(&gProfileObject, 0, sizeof(gProfileObject));
700005de:	f245 732c 	movw	r3, #22316	; 0x572c
700005e2:	4621      	mov	r1, r4
700005e4:	f241 320c 	movw	r2, #4876	; 0x130c
700005e8:	f2c7 0300 	movt	r3, #28672	; 0x7000
700005ec:	4618      	mov	r0, r3
700005ee:	f002 fcbf 	bl	70002f70 <memset>
   gProfileObject.logIndex = 0;
   gProfileObject.numEvents = PMU_MAX_EVENT_COUNTERS;
700005f2:	2203      	movs	r2, #3
700005f4:	f500 5380 	add.w	r3, r0, #4096	; 0x1000
   printk("PMU Initialized.\r\n");
700005f8:	f644 4068 	movw	r0, #19560	; 0x4c68
   gProfileObject.bCycleCounter = 1; /* We use cycle counter */
700005fc:	f883 5308 	strb.w	r5, [r3, #776]	; 0x308
   printk("PMU Initialized.\r\n");
70000600:	f2c7 0000 	movt	r0, #28672	; 0x7000
   gProfileObject.numEvents = PMU_MAX_EVENT_COUNTERS;
70000604:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
   printk("PMU Initialized.\r\n");
70000608:	f000 f9f8 	bl	700009fc <printk>
}
7000060c:	4620      	mov	r0, r4
7000060e:	bd38      	pop	{r3, r4, r5, pc}

70000610 <tm_initialize>:
   test_initialization_function();
70000610:	4700      	bx	r0
70000612:	bf00      	nop

70000614 <tm_thread_create>:
{
70000614:	b5f0      	push	{r4, r5, r6, r7, lr}
   tid = k_thread_create(&test_thread[thread_id], test_stack[thread_id], TM_TEST_STACK_SIZE, entry_function, NULL, NULL,
70000616:	f644 6450 	movw	r4, #20048	; 0x4e50
7000061a:	ebc0 1500 	rsb	r5, r0, r0, lsl #4
7000061e:	f2c7 0400 	movt	r4, #28672	; 0x7000
{
70000622:	4613      	mov	r3, r2
70000624:	b089      	sub	sp, #36	; 0x24
70000626:	f04f 36ff 	mov.w	r6, #4294967295	; 0xffffffff
   tid = k_thread_create(&test_thread[thread_id], test_stack[thread_id], TM_TEST_STACK_SIZE, entry_function, NULL, NULL,
7000062a:	eb04 04c5 	add.w	r4, r4, r5, lsl #3
7000062e:	f04f 37ff 	mov.w	r7, #4294967295	; 0xffffffff
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
70000632:	2500      	movs	r5, #0
70000634:	f44f 6280 	mov.w	r2, #1024	; 0x400
70000638:	9103      	str	r1, [sp, #12]
7000063a:	f646 51e8 	movw	r1, #28136	; 0x6de8
7000063e:	9504      	str	r5, [sp, #16]
70000640:	f2c7 0100 	movt	r1, #28672	; 0x7000
70000644:	e9cd 5501 	strd	r5, r5, [sp, #4]
70000648:	eb01 2180 	add.w	r1, r1, r0, lsl #10
7000064c:	9500      	str	r5, [sp, #0]
7000064e:	4620      	mov	r0, r4
70000650:	e9cd 6706 	strd	r6, r7, [sp, #24]
70000654:	f001 fca6 	bl	70001fa4 <z_impl_k_thread_create>
70000658:	4605      	mov	r5, r0
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_SUSPEND);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_suspend(thread);
7000065a:	4620      	mov	r0, r4
7000065c:	f001 fe4c 	bl	700022f8 <z_impl_k_thread_suspend>
	z_impl_k_wakeup(thread);
70000660:	4620      	mov	r0, r4
70000662:	f002 f82f 	bl	700026c4 <z_impl_k_wakeup>
}
70000666:	1b60      	subs	r0, r4, r5
70000668:	bf18      	it	ne
7000066a:	2001      	movne	r0, #1
7000066c:	b009      	add	sp, #36	; 0x24
7000066e:	bdf0      	pop	{r4, r5, r6, r7, pc}

70000670 <tm_thread_resume>:
{
70000670:	b508      	push	{r3, lr}
   k_thread_resume(&test_thread[thread_id]);
70000672:	f644 6350 	movw	r3, #20048	; 0x4e50
70000676:	ebc0 1000 	rsb	r0, r0, r0, lsl #4
7000067a:	f2c7 0300 	movt	r3, #28672	; 0x7000
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_RESUME);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_resume(thread);
7000067e:	eb03 00c0 	add.w	r0, r3, r0, lsl #3
70000682:	f001 ff0d 	bl	700024a0 <z_impl_k_thread_resume>
}
70000686:	2000      	movs	r0, #0
70000688:	bd08      	pop	{r3, pc}
7000068a:	bf00      	nop

7000068c <tm_thread_sleep>:
   k_sleep(K_SECONDS(seconds));
7000068c:	2100      	movs	r1, #0
7000068e:	ebc0 1340 	rsb	r3, r0, r0, lsl #5
70000692:	eb00 0083 	add.w	r0, r0, r3, lsl #2
70000696:	00c0      	lsls	r0, r0, #3
	return z_impl_k_sleep(timeout);
70000698:	f002 b806 	b.w	700026a8 <z_impl_k_sleep>

7000069c <tm_queue_send_from_isr>:
{
7000069c:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
700006a0:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
   return k_msgq_put(&test_msgq[queue_id], message_ptr, K_FOREVER);
700006a4:	f646 2c88 	movw	ip, #27272	; 0x6a88
700006a8:	eb00 0040 	add.w	r0, r0, r0, lsl #1
700006ac:	f2c7 0c00 	movt	ip, #28672	; 0x7000
		union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm2 = { .val = timeout };
		return (int) arch_syscall_invoke4(parm0.x, parm1.x, parm2.split.lo, parm2.split.hi, K_SYSCALL_K_MSGQ_PUT);
	}
#endif
	compiler_barrier();
	return z_impl_k_msgq_put(msgq, data, timeout);
700006b0:	eb0c 1000 	add.w	r0, ip, r0, lsl #4
700006b4:	f001 bb42 	b.w	70001d3c <z_impl_k_msgq_put>

700006b8 <tm_semaphore_create>:
   return k_sem_init(&test_sem[semaphore_id], 1, 1);
700006b8:	f646 3348 	movw	r3, #27464	; 0x6b48
700006bc:	eb00 0040 	add.w	r0, r0, r0, lsl #1
	return z_impl_k_sem_init(sem, initial_count, limit);
700006c0:	2201      	movs	r2, #1
700006c2:	f2c7 0300 	movt	r3, #28672	; 0x7000
700006c6:	4611      	mov	r1, r2
700006c8:	eb03 00c0 	add.w	r0, r3, r0, lsl #3
700006cc:	f001 bbb4 	b.w	70001e38 <z_impl_k_sem_init>

700006d0 <tm_semaphore_get>:
   return k_sem_take(&test_sem[semaphore_id], K_NO_WAIT);
700006d0:	2200      	movs	r2, #0
700006d2:	2300      	movs	r3, #0
700006d4:	f646 3148 	movw	r1, #27464	; 0x6b48
700006d8:	eb00 0040 	add.w	r0, r0, r0, lsl #1
700006dc:	f2c7 0100 	movt	r1, #28672	; 0x7000
	return z_impl_k_sem_take(sem, timeout);
700006e0:	eb01 00c0 	add.w	r0, r1, r0, lsl #3
700006e4:	f001 bbfa 	b.w	70001edc <z_impl_k_sem_take>

700006e8 <tm_semaphore_wait>:
{
700006e8:	b508      	push	{r3, lr}
700006ea:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
700006ee:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
   int rc = k_sem_take(&test_sem[semaphore_id], K_FOREVER);
700006f2:	f646 3148 	movw	r1, #27464	; 0x6b48
700006f6:	eb00 0040 	add.w	r0, r0, r0, lsl #1
700006fa:	f2c7 0100 	movt	r1, #28672	; 0x7000
700006fe:	eb01 00c0 	add.w	r0, r1, r0, lsl #3
70000702:	f001 fbeb 	bl	70001edc <z_impl_k_sem_take>
}
70000706:	3800      	subs	r0, #0
70000708:	bf18      	it	ne
7000070a:	2001      	movne	r0, #1
7000070c:	bd08      	pop	{r3, pc}
7000070e:	bf00      	nop

70000710 <tm_semaphore_put>:
{
70000710:	b508      	push	{r3, lr}
   k_sem_give(&test_sem[semaphore_id]);
70000712:	f646 3348 	movw	r3, #27464	; 0x6b48
70000716:	eb00 0040 	add.w	r0, r0, r0, lsl #1
7000071a:	f2c7 0300 	movt	r3, #28672	; 0x7000
	z_impl_k_sem_give(sem);
7000071e:	eb03 00c0 	add.w	r0, r3, r0, lsl #3
70000722:	f001 fba5 	bl	70001e70 <z_impl_k_sem_give>
}
70000726:	2000      	movs	r0, #0
70000728:	bd08      	pop	{r3, pc}
7000072a:	bf00      	nop

7000072c <tm_mutex_create>:
   if (mutex_id < 0 || mutex_id >= TM_TEST_NUM_SEMAPHORES)
7000072c:	2803      	cmp	r0, #3
7000072e:	d901      	bls.n	70000734 <tm_mutex_create+0x8>
      return TM_ERROR;
70000730:	2001      	movs	r0, #1
}
70000732:	4770      	bx	lr
{
70000734:	b508      	push	{r3, lr}
   k_mutex_init(&tm_mutex_array[mutex_id]);
70000736:	f646 2338 	movw	r3, #27192	; 0x6a38
7000073a:	eb00 0080 	add.w	r0, r0, r0, lsl #2
7000073e:	f2c7 0300 	movt	r3, #28672	; 0x7000
	return z_impl_k_mutex_init(mutex);
70000742:	eb03 0080 	add.w	r0, r3, r0, lsl #2
70000746:	f001 fb6f 	bl	70001e28 <z_impl_k_mutex_init>
   return TM_SUCCESS;
7000074a:	2000      	movs	r0, #0
}
7000074c:	bd08      	pop	{r3, pc}
7000074e:	bf00      	nop

70000750 <tm_pmu_profile_start>:
 * - Read "start" values
 * - Store them in the next free slot
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_start(const char* name)
{
   uint32_t idx = gProfileObject.logIndex;
70000750:	f245 7c2c 	movw	ip, #22316	; 0x572c
70000754:	f2c7 0c00 	movt	ip, #28672	; 0x7000
{
70000758:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   uint32_t idx = gProfileObject.logIndex;
7000075c:	f8dc 4000 	ldr.w	r4, [ip]
   if (idx >= PMU_MAX_LOG_ENTRIES)
70000760:	2c3f      	cmp	r4, #63	; 0x3f
70000762:	d833      	bhi.n	700007cc <tm_pmu_profile_start+0x7c>
      /* no more space */
      return;
   }

   TM_PMUProfilePoint* p = &gProfileObject.point[idx];
   p->name = name;
70000764:	eb04 02c4 	add.w	r2, r4, r4, lsl #3

   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000768:	f50c 5380 	add.w	r3, ip, #4096	; 0x1000
   p->name = name;
7000076c:	eb04 0242 	add.w	r2, r4, r2, lsl #1
70000770:	ea4f 0ec4 	mov.w	lr, r4, lsl #3
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000774:	f8d3 5304 	ldr.w	r5, [r3, #772]	; 0x304
   p->name = name;
70000778:	eb0c 0182 	add.w	r1, ip, r2, lsl #2
7000077c:	0092      	lsls	r2, r2, #2
7000077e:	6048      	str	r0, [r1, #4]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000780:	b1dd      	cbz	r5, 700007ba <tm_pmu_profile_start+0x6a>
70000782:	f64a 76e8 	movw	r6, #45032	; 0xafe8
70000786:	3234      	adds	r2, #52	; 0x34
70000788:	2300      	movs	r3, #0
7000078a:	f2c7 0600 	movt	r6, #28672	; 0x7000
7000078e:	4462      	add	r2, ip
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
70000790:	461f      	mov	r7, r3
70000792:	f106 0804 	add.w	r8, r6, #4
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
70000796:	ee09 3fbc 	mcr	15, 0, r3, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
7000079a:	ee09 7f5d 	mcr	15, 0, r7, cr9, cr13, {2}
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 2" : "=r" (val));
7000079e:	ee19 0f5d 	mrc	15, 0, r0, cr9, cr13, {2}
   {
      pmu_select_event_counter(i);
      /* Reset the counters to 0 */
      pmu_write_evcounter(0);
      p->eventStart[i] = pmu_read_evcounter();
700007a2:	f842 0f04 	str.w	r0, [r2, #4]!
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700007a6:	310c      	adds	r1, #12

      /* Also store name & type */
      p->events[i].name = gPmuEventCfg[i].name;
700007a8:	f856 0033 	ldr.w	r0, [r6, r3, lsl #3]
700007ac:	6088      	str	r0, [r1, #8]
      p->events[i].type = gPmuEventCfg[i].type;
700007ae:	f858 0033 	ldr.w	r0, [r8, r3, lsl #3]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700007b2:	3301      	adds	r3, #1
      p->events[i].type = gPmuEventCfg[i].type;
700007b4:	60c8      	str	r0, [r1, #12]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700007b6:	42ab      	cmp	r3, r5
700007b8:	d1ed      	bne.n	70000796 <tm_pmu_profile_start+0x46>
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 0" : "=r" (val));
700007ba:	ee19 3f1d 	mrc	15, 0, r3, cr9, cr13, {0}
   }
   /* Immediately read them as "start" values */
   p->cycleCountStart = pmu_read_pmccntr();
700007be:	44a6      	add	lr, r4
700007c0:	eb04 044e 	add.w	r4, r4, lr, lsl #1
700007c4:	eb0c 0c84 	add.w	ip, ip, r4, lsl #2
700007c8:	f8cc 3008 	str.w	r3, [ip, #8]
}
700007cc:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

700007d0 <tm_pmu_profile_end>:
 * - Read PMU Registers for "end" values
 * - Compute delta
 * - Increase log index
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_end(const char* name)
{
700007d0:	b570      	push	{r4, r5, r6, lr}
   uint32_t idx = gProfileObject.logIndex;
700007d2:	f245 7e2c 	movw	lr, #22316	; 0x572c
700007d6:	f2c7 0e00 	movt	lr, #28672	; 0x7000
700007da:	f8de 4000 	ldr.w	r4, [lr]
   if (idx >= PMU_MAX_LOG_ENTRIES)
700007de:	2c3f      	cmp	r4, #63	; 0x3f
700007e0:	d83a      	bhi.n	70000858 <tm_pmu_profile_end+0x88>
700007e2:	ee19 1f1d 	mrc	15, 0, r1, cr9, cr13, {0}
   //    return;
   // }

   /* Read end counters */
   p->cycleCountEnd = pmu_read_pmccntr();
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700007e6:	f50e 5380 	add.w	r3, lr, #4096	; 0x1000
   p->cycleCountEnd = pmu_read_pmccntr();
700007ea:	eb04 0cc4 	add.w	ip, r4, r4, lsl #3
700007ee:	00e5      	lsls	r5, r4, #3
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700007f0:	f8d3 6304 	ldr.w	r6, [r3, #772]	; 0x304
   p->cycleCountEnd = pmu_read_pmccntr();
700007f4:	eb04 0c4c 	add.w	ip, r4, ip, lsl #1
700007f8:	eb0e 038c 	add.w	r3, lr, ip, lsl #2
700007fc:	ea4f 0c8c 	mov.w	ip, ip, lsl #2
70000800:	60d9      	str	r1, [r3, #12]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000802:	b356      	cbz	r6, 7000085a <tm_pmu_profile_end+0x8a>
70000804:	2300      	movs	r3, #0
70000806:	f10c 0240 	add.w	r2, ip, #64	; 0x40
7000080a:	4472      	add	r2, lr
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
7000080c:	ee09 3fbc 	mcr	15, 0, r3, cr9, cr12, {5}
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 2" : "=r" (val));
70000810:	ee19 0f5d 	mrc	15, 0, r0, cr9, cr13, {2}
   {
      pmu_select_event_counter(i);
      p->eventEnd[i] = pmu_read_evcounter();
70000814:	f842 0f04 	str.w	r0, [r2, #4]!
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000818:	3301      	adds	r3, #1
7000081a:	42b3      	cmp	r3, r6
7000081c:	d1f6      	bne.n	7000080c <tm_pmu_profile_end+0x3c>
   }

   /* Compute deltas */
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
7000081e:	4425      	add	r5, r4
70000820:	f10c 0034 	add.w	r0, ip, #52	; 0x34
70000824:	eb04 0545 	add.w	r5, r4, r5, lsl #1
70000828:	f10c 0c1c 	add.w	ip, ip, #28
7000082c:	eb0e 0585 	add.w	r5, lr, r5, lsl #2
70000830:	eb03 0343 	add.w	r3, r3, r3, lsl #1
70000834:	4470      	add	r0, lr
70000836:	68ae      	ldr	r6, [r5, #8]
70000838:	44f4      	add	ip, lr
7000083a:	2200      	movs	r2, #0
7000083c:	1b89      	subs	r1, r1, r6
7000083e:	6129      	str	r1, [r5, #16]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
   {
      uint32_t diff = p->eventEnd[i] - p->eventStart[i];
70000840:	6901      	ldr	r1, [r0, #16]
70000842:	f850 5f04 	ldr.w	r5, [r0, #4]!
70000846:	1b49      	subs	r1, r1, r5
      p->events[i].value = diff;
70000848:	f84c 1022 	str.w	r1, [ip, r2, lsl #2]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
7000084c:	3203      	adds	r2, #3
7000084e:	429a      	cmp	r2, r3
70000850:	d1f6      	bne.n	70000840 <tm_pmu_profile_end+0x70>
   }

   /* Move to next log slot for future profileStart() */
   gProfileObject.logIndex++;
70000852:	3401      	adds	r4, #1
70000854:	f8ce 4000 	str.w	r4, [lr]
}
70000858:	bd70      	pop	{r4, r5, r6, pc}
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
7000085a:	689a      	ldr	r2, [r3, #8]
   gProfileObject.logIndex++;
7000085c:	3401      	adds	r4, #1
7000085e:	f8ce 4000 	str.w	r4, [lr]
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
70000862:	1a8a      	subs	r2, r1, r2
70000864:	611a      	str	r2, [r3, #16]
   gProfileObject.logIndex++;
70000866:	e7f7      	b.n	70000858 <tm_pmu_profile_end+0x88>

70000868 <tm_pmu_profile_print>:
 * tm_pmu_profile_print_entry(name)
 * - Search for an entry with the given name
 * - Print results
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_print(const char* name)
{
70000868:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
7000086c:	f245 792c 	movw	r9, #22316	; 0x572c
{
70000870:	4680      	mov	r8, r0
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
70000872:	f2c7 0900 	movt	r9, #28672	; 0x7000
70000876:	f8d9 a000 	ldr.w	sl, [r9]
7000087a:	f1ba 0f00 	cmp.w	sl, #0
7000087e:	d00d      	beq.n	7000089c <tm_pmu_profile_print+0x34>
70000880:	464e      	mov	r6, r9
70000882:	2500      	movs	r5, #0
   {
      TM_PMUProfilePoint* p = &gProfileObject.point[i];
      if (p->name != NULL && strcmp(p->name, name) == 0)
70000884:	6877      	ldr	r7, [r6, #4]
70000886:	4641      	mov	r1, r8
70000888:	4638      	mov	r0, r7
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
7000088a:	364c      	adds	r6, #76	; 0x4c
      if (p->name != NULL && strcmp(p->name, name) == 0)
7000088c:	b11f      	cbz	r7, 70000896 <tm_pmu_profile_print+0x2e>
7000088e:	f7ff fbd7 	bl	70000040 <strcmp>
70000892:	4604      	mov	r4, r0
70000894:	b158      	cbz	r0, 700008ae <tm_pmu_profile_print+0x46>
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
70000896:	3501      	adds	r5, #1
70000898:	4555      	cmp	r5, sl
7000089a:	d1f3      	bne.n	70000884 <tm_pmu_profile_print+0x1c>
         }
         printk("\r\n");
         return;
      }
   }
   printk("No profile entry found for name: %s\r\n", name);
7000089c:	f644 40b4 	movw	r0, #19636	; 0x4cb4
700008a0:	4641      	mov	r1, r8
700008a2:	f2c7 0000 	movt	r0, #28672	; 0x7000
}
700008a6:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   printk("No profile entry found for name: %s\r\n", name);
700008aa:	f000 b8a7 	b.w	700009fc <printk>
         printk("Profile Entry: %s\r\n", p->name);
700008ae:	f644 407c 	movw	r0, #19580	; 0x4c7c
700008b2:	4639      	mov	r1, r7
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
700008b4:	4e17      	ldr	r6, [pc, #92]	; (70000914 <tm_pmu_profile_print+0xac>)
         printk("Profile Entry: %s\r\n", p->name);
700008b6:	f2c7 0000 	movt	r0, #28672	; 0x7000
700008ba:	f000 f89f 	bl	700009fc <printk>
         printk("Cycle Count: %u\r\n", p->cycleCountValue);
700008be:	f644 4090 	movw	r0, #19600	; 0x4c90
700008c2:	eb05 03c5 	add.w	r3, r5, r5, lsl #3
700008c6:	f2c7 0000 	movt	r0, #28672	; 0x7000
700008ca:	eb05 0543 	add.w	r5, r5, r3, lsl #1
700008ce:	eb09 0985 	add.w	r9, r9, r5, lsl #2
700008d2:	f8d9 1010 	ldr.w	r1, [r9, #16]
700008d6:	f000 f891 	bl	700009fc <printk>
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
700008da:	f8d6 3304 	ldr.w	r3, [r6, #772]	; 0x304
700008de:	b18b      	cbz	r3, 70000904 <tm_pmu_profile_print+0x9c>
            printk("%s Count: %u\r\n", p->events[j].name, p->events[j].value);
700008e0:	f644 45a4 	movw	r5, #19620	; 0x4ca4
700008e4:	f2c7 0500 	movt	r5, #28672	; 0x7000
700008e8:	f8d9 201c 	ldr.w	r2, [r9, #28]
700008ec:	4628      	mov	r0, r5
700008ee:	f8d9 1014 	ldr.w	r1, [r9, #20]
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
700008f2:	3401      	adds	r4, #1
            printk("%s Count: %u\r\n", p->events[j].name, p->events[j].value);
700008f4:	f000 f882 	bl	700009fc <printk>
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
700008f8:	f8d6 3304 	ldr.w	r3, [r6, #772]	; 0x304
700008fc:	f109 090c 	add.w	r9, r9, #12
70000900:	42a3      	cmp	r3, r4
70000902:	d8f1      	bhi.n	700008e8 <tm_pmu_profile_print+0x80>
         printk("\r\n");
70000904:	f644 3050 	movw	r0, #19280	; 0x4b50
}
70000908:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
         printk("\r\n");
7000090c:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000910:	f000 b874 	b.w	700009fc <printk>
70000914:	7000672c 	.word	0x7000672c

70000918 <free_list_add>:
	h->free_bytes += chunksz_to_bytes(h, chunk_size(h, c));
#endif
}

static void free_list_add(struct z_heap *h, chunkid_t c)
{
70000918:	b530      	push	{r4, r5, lr}
	void *cmem = &buf[c];

	if (big_heap(h)) {
		return ((uint32_t *)cmem)[f];
	} else {
		return ((uint16_t *)cmem)[f];
7000091a:	eb00 04c1 	add.w	r4, r0, r1, lsl #3
7000091e:	8863      	ldrh	r3, [r4, #2]
	return chunk_field(h, c, SIZE_AND_USED) & 1U;
}

static inline chunksz_t chunk_size(struct z_heap *h, chunkid_t c)
{
	return chunk_field(h, c, SIZE_AND_USED) >> 1;
70000920:	085b      	lsrs	r3, r3, #1
}

static inline int bucket_idx(struct z_heap *h, chunksz_t sz)
{
	unsigned int usable_sz = sz - min_chunk_size(h) + 1;
	return 31 - __builtin_clz(usable_sz);
70000922:	fab3 f383 	clz	r3, r3
70000926:	f1c3 031f 	rsb	r3, r3, #31
	void *cmem = &buf[c];
7000092a:	ea4f 0cc1 	mov.w	ip, r1, lsl #3
	if (b->next == 0U) {
7000092e:	eb00 0583 	add.w	r5, r0, r3, lsl #2
		((uint16_t *)cmem)[f] = val;
70000932:	f10c 0c04 	add.w	ip, ip, #4
70000936:	fa1f fe81 	uxth.w	lr, r1
7000093a:	692a      	ldr	r2, [r5, #16]
7000093c:	b962      	cbnz	r2, 70000958 <free_list_add+0x40>
		h->avail_buckets |= BIT(bidx);
7000093e:	2401      	movs	r4, #1
70000940:	f36e 020f 	bfi	r2, lr, #0, #16
70000944:	f36e 421f 	bfi	r2, lr, #16, #16
70000948:	409c      	lsls	r4, r3
7000094a:	68c3      	ldr	r3, [r0, #12]
7000094c:	4323      	orrs	r3, r4
7000094e:	60c3      	str	r3, [r0, #12]
		b->next = c;
70000950:	6129      	str	r1, [r5, #16]
70000952:	f840 200c 	str.w	r2, [r0, ip]
	if (!solo_free_header(h, c)) {
		int bidx = bucket_idx(h, chunk_size(h, c));
		free_list_add_bidx(h, c, bidx);
	}
}
70000956:	bd30      	pop	{r4, r5, pc}
	void *cmem = &buf[c];
70000958:	00d3      	lsls	r3, r2, #3
		return ((uint16_t *)cmem)[f];
7000095a:	3304      	adds	r3, #4
7000095c:	5ac1      	ldrh	r1, [r0, r3]
		((uint16_t *)cmem)[f] = val;
7000095e:	f820 100c 	strh.w	r1, [r0, ip]
70000962:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
70000966:	80e2      	strh	r2, [r4, #6]
70000968:	f8a1 e006 	strh.w	lr, [r1, #6]
7000096c:	f820 e003 	strh.w	lr, [r0, r3]
70000970:	bd30      	pop	{r4, r5, pc}
70000972:	bf00      	nop

70000974 <sys_heap_init>:
		__ASSERT(bytes / CHUNK_UNIT <= 0x7fffffffU, "heap size is too big");
	}

	/* Reserve the end marker chunk's header */
	__ASSERT(bytes > heap_footer_bytes(bytes), "heap size is too small");
	bytes -= heap_footer_bytes(bytes);
70000974:	3a04      	subs	r2, #4
{
70000976:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}

	/* Round the start up, the end down */
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
7000097a:	188d      	adds	r5, r1, r2
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
7000097c:	1dcc      	adds	r4, r1, #7
7000097e:	f024 0407 	bic.w	r4, r4, #7
	__ASSERT(heap_sz > chunksz(sizeof(struct z_heap)), "heap size is too small");

	struct z_heap *h = (struct z_heap *)addr;
	heap->heap = h;
	h->end_chunk = heap_sz;
	h->avail_buckets = 0;
70000982:	f04f 0800 	mov.w	r8, #0
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
70000986:	f025 0507 	bic.w	r5, r5, #7
	heap->heap = h;
7000098a:	6004      	str	r4, [r0, #0]
	chunksz_t heap_sz = (end - addr) / CHUNK_UNIT;
7000098c:	1b2d      	subs	r5, r5, r4
				     nb_buckets * sizeof(struct z_heap_bucket));

	__ASSERT(chunk0_size + min_chunk_size(h) <= heap_sz, "heap size is too small");

	for (int i = 0; i < nb_buckets; i++) {
		h->buckets[i].next = 0;
7000098e:	4641      	mov	r1, r8
70000990:	f104 0010 	add.w	r0, r4, #16
	chunksz_t heap_sz = (end - addr) / CHUNK_UNIT;
70000994:	08ef      	lsrs	r7, r5, #3
	return 31 - __builtin_clz(usable_sz);
70000996:	fab7 f287 	clz	r2, r7
	h->avail_buckets = 0;
7000099a:	e9c4 7802 	strd	r7, r8, [r4, #8]
	chunksz_t chunk0_size = chunksz(sizeof(struct z_heap) +
7000099e:	f1c2 0624 	rsb	r6, r2, #36	; 0x24
	int nb_buckets = bucket_idx(h, heap_sz) + 1;
700009a2:	f1c2 0220 	rsb	r2, r2, #32
	chunksz_t chunk0_size = chunksz(sizeof(struct z_heap) +
700009a6:	00b6      	lsls	r6, r6, #2
	return (bytes + CHUNK_UNIT - 1U) / CHUNK_UNIT;
700009a8:	3607      	adds	r6, #7
		h->buckets[i].next = 0;
700009aa:	0092      	lsls	r2, r2, #2
700009ac:	08f6      	lsrs	r6, r6, #3
700009ae:	f002 fadf 	bl	70002f70 <memset>
		((uint16_t *)cmem)[f] = val;
700009b2:	f8a4 8000 	strh.w	r8, [r4]
	set_chunk_size(h, 0, chunk0_size);
	set_left_chunk_size(h, 0, 0);
	set_chunk_used(h, 0, true);

	/* chunk containing the free heap */
	set_chunk_size(h, chunk0_size, heap_sz - chunk0_size);
700009b6:	1bbb      	subs	r3, r7, r6
	/* the end marker chunk */
	set_chunk_size(h, heap_sz, 0);
	set_left_chunk_size(h, heap_sz, heap_sz - chunk0_size);
	set_chunk_used(h, heap_sz, true);

	free_list_add(h, chunk0_size);
700009b8:	4620      	mov	r0, r4
	chunk_set(h, c, SIZE_AND_USED, size << 1);
700009ba:	0072      	lsls	r2, r6, #1
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
700009bc:	f042 0201 	orr.w	r2, r2, #1
	chunk_set(h, c, SIZE_AND_USED, size << 1);
700009c0:	0059      	lsls	r1, r3, #1
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
700009c2:	8062      	strh	r2, [r4, #2]
		((uint16_t *)cmem)[f] = val;
700009c4:	eb04 02c6 	add.w	r2, r4, r6, lsl #3
700009c8:	8051      	strh	r1, [r2, #2]
700009ca:	1962      	adds	r2, r4, r5
700009cc:	f824 6036 	strh.w	r6, [r4, r6, lsl #3]
700009d0:	4631      	mov	r1, r6
700009d2:	5363      	strh	r3, [r4, r5]
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
700009d4:	2301      	movs	r3, #1
700009d6:	8053      	strh	r3, [r2, #2]
}
700009d8:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
	free_list_add(h, chunk0_size);
700009dc:	f7ff bf9c 	b.w	70000918 <free_list_add>

700009e0 <arch_printk_char_out>:
{
	ARG_UNUSED(c);

	/* do nothing */
	return 0;
}
700009e0:	2000      	movs	r0, #0
700009e2:	4770      	bx	lr

700009e4 <char_out>:
}

static int char_out(int c, void *ctx_p)
{
	ARG_UNUSED(ctx_p);
	return _char_out(c);
700009e4:	f24b 0300 	movw	r3, #45056	; 0xb000
700009e8:	f2c7 0300 	movt	r3, #28672	; 0x7000
700009ec:	681b      	ldr	r3, [r3, #0]
700009ee:	4718      	bx	r3

700009f0 <__printk_hook_install>:
	_char_out = fn;
700009f0:	f24b 0300 	movw	r3, #45056	; 0xb000
700009f4:	f2c7 0300 	movt	r3, #28672	; 0x7000
700009f8:	6018      	str	r0, [r3, #0]
}
700009fa:	4770      	bx	lr

700009fc <printk>:
 *
 * @param fmt formatted string to output
 */

void printk(const char *fmt, ...)
{
700009fc:	b40f      	push	{r0, r1, r2, r3}
700009fe:	b500      	push	{lr}
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000a00:	f640 10e5 	movw	r0, #2533	; 0x9e5
{
70000a04:	b087      	sub	sp, #28
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000a06:	2300      	movs	r3, #0
{
70000a08:	aa08      	add	r2, sp, #32
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000a0a:	f04f 0c02 	mov.w	ip, #2
70000a0e:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000a12:	e9cd 3304 	strd	r3, r3, [sp, #16]
70000a16:	e9cd 3002 	strd	r3, r0, [sp, #8]
		(void) vfprintf(&console, fmt, ap);
70000a1a:	a802      	add	r0, sp, #8
{
70000a1c:	f852 1b04 	ldr.w	r1, [r2], #4
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000a20:	f88d c00a 	strb.w	ip, [sp, #10]
	va_list ap;

	va_start(ap, fmt);
70000a24:	9201      	str	r2, [sp, #4]
		(void) vfprintf(&console, fmt, ap);
70000a26:	f002 fc47 	bl	700032b8 <__l_vfprintf>

	vprintk(fmt, ap);

	va_end(ap);
}
70000a2a:	b007      	add	sp, #28
70000a2c:	f85d eb04 	ldr.w	lr, [sp], #4
70000a30:	b004      	add	sp, #16
70000a32:	4770      	bx	lr

70000a34 <z_thread_entry>:
 * This routine does not return, and is marked as such so the compiler won't
 * generate preamble code that is only used by functions that actually return.
 */
FUNC_NORETURN void z_thread_entry(k_thread_entry_t entry,
				 void *p1, void *p2, void *p3)
{
70000a34:	468c      	mov	ip, r1
70000a36:	4604      	mov	r4, r0
70000a38:	4611      	mov	r1, r2

	sys_rand_get((uint8_t *)&stack_guard, sizeof(stack_guard));
	__stack_chk_guard = stack_guard;
	__stack_chk_guard <<= 8;
#endif	/* CONFIG_STACK_CANARIES */
	entry(p1, p2, p3);
70000a3a:	4660      	mov	r0, ip
70000a3c:	461a      	mov	r2, r3
{
70000a3e:	b508      	push	{r3, lr}
	entry(p1, p2, p3);
70000a40:	47a0      	blx	r4
	return z_impl_k_sched_current_thread_query();
70000a42:	f001 fe65 	bl	70002710 <z_impl_k_sched_current_thread_query>
	z_impl_k_thread_abort(thread);
70000a46:	f001 fe69 	bl	7000271c <z_impl_k_thread_abort>
70000a4a:	bf00      	nop

70000a4c <_ConfigAbsSyms>:
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_WARN_DEPRECATED, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_ENFORCE_ZEPHYR_STDINT, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_LEGACY_GENERATED_INCLUDE_PATH, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_BENCHMARK_NUM_ITERATIONS, 1000);

GEN_ABS_SYM_END
70000a4c:	4770      	bx	lr
70000a4e:	bf00      	nop

70000a50 <z_soc_irq_get_active>:

#include "soc.h"

unsigned int z_soc_irq_get_active(void)
{
	return z_vim_irq_get_active();
70000a50:	f000 bb4c 	b.w	700010ec <z_vim_irq_get_active>

70000a54 <z_soc_irq_eoi>:
}

void z_soc_irq_eoi(unsigned int irq)
{
	z_vim_irq_eoi(irq);
70000a54:	f000 bb70 	b.w	70001138 <z_vim_irq_eoi>

70000a58 <z_soc_irq_init>:
}

void z_soc_irq_init(void)
{
	z_vim_irq_init();
70000a58:	f000 bb76 	b.w	70001148 <z_vim_irq_init>

70000a5c <z_soc_irq_priority_set>:
}

void z_soc_irq_priority_set(unsigned int irq, unsigned int prio, uint32_t flags)
{
	/* Configure interrupt type and priority */
	z_vim_irq_priority_set(irq, prio, flags);
70000a5c:	f000 bbac 	b.w	700011b8 <z_vim_irq_priority_set>

70000a60 <z_soc_irq_enable>:
}

void z_soc_irq_enable(unsigned int irq)
{
	/* Enable interrupt */
	z_vim_irq_enable(irq);
70000a60:	f000 bbd6 	b.w	70001210 <z_vim_irq_enable>

70000a64 <soc_reset_hook>:
	/* Check if interrupt is enabled */
	return z_vim_irq_is_enabled(irq);
}

void soc_reset_hook(void)
{
70000a64:	b508      	push	{r3, lr}
 *
 */
static ALWAYS_INLINE void sys_cache_instr_enable(void)
{
#if defined(CONFIG_CACHE_MANAGEMENT) && defined(CONFIG_ICACHE)
	cache_instr_enable();
70000a66:	f000 fa35 	bl	70000ed4 <arch_icache_enable>
	/*
	 * Enable the caches only if configured to do so.
	 */
	sys_cache_instr_enable();
	sys_cache_data_enable();
70000a6a:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	cache_data_enable();
70000a6e:	f000 ba23 	b.w	70000eb8 <arch_dcache_enable>
70000a72:	bf00      	nop

70000a74 <z_arm_fatal_error>:

		LOG_ERR("Unhandled IRQn: %d", irqn);
	}
#endif

	z_fatal_error(reason, esf);
70000a74:	f000 bff8 	b.w	70001a68 <z_fatal_error>

70000a78 <z_do_kernel_oops>:
 * @param esf exception frame
 * @param callee_regs Callee-saved registers (R4-R11)
 * @param exc_return EXC_RETURN value present in LR after exception entry.
 */
void z_do_kernel_oops(const struct arch_esf *esf, _callee_saved_t *callee_regs, uint32_t exc_return)
{
70000a78:	4601      	mov	r1, r0
	z_fatal_error(reason, esf);
70000a7a:	6800      	ldr	r0, [r0, #0]
70000a7c:	f000 bff4 	b.w	70001a68 <z_fatal_error>

70000a80 <z_arm_nmi>:
 * Simply call what is installed in 'static void(*handler)(void)'.
 *
 */

void z_arm_nmi(void)
{
70000a80:	b508      	push	{r3, lr}
	handler();
70000a82:	f24b 0360 	movw	r3, #45152	; 0xb060
70000a86:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000a8a:	681b      	ldr	r3, [r3, #0]
70000a8c:	4798      	blx	r3
	z_arm_int_exit();
}
70000a8e:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_arm_int_exit();
70000a92:	f002 bfa9 	b.w	700039e8 <__z_arm_int_exit_from_thumb>
70000a96:	bf00      	nop

70000a98 <z_SysNmiOnReset>:
_ASM_FILE_PROLOGUE

GTEXT(z_SysNmiOnReset)

SECTION_FUNC(TEXT, z_SysNmiOnReset)
    wfi
70000a98:	e320f003 	wfi
    b z_SysNmiOnReset
70000a9c:	eafffffd 	b	70000a98 <z_SysNmiOnReset>

70000aa0 <z_arm_undef_instruction>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_undef_instruction)
	/*
	 * The undefined instruction address is offset by 2 if the previous
	 * mode is Thumb; otherwise, it is offset by 4.
	 */
	push {r0}
70000aa0:	e52d0004 	push	{r0}		; (str r0, [sp, #-4]!)
	mrs r0, spsr
70000aa4:	e14f0000 	mrs	r0, SPSR
	tst r0, #T_BIT
70000aa8:	e3100020 	tst	r0, #32
	subeq lr, #4	/* ARM   (!T_BIT) */
70000aac:	024ee004 	subeq	lr, lr, #4
	subne lr, #2	/* Thumb (T_BIT) */
70000ab0:	124ee002 	subne	lr, lr, #2
	pop {r0}
70000ab4:	e49d0004 	pop	{r0}		; (ldr r0, [sp], #4)

	/*
	 * Store r0-r3, r12, lr, lr_und and spsr_und into the stack to
	 * construct an exception stack frame.
	 */
	srsdb sp!, #MODE_UND
70000ab8:	f96d051b 	srsdb	sp!, #27
	stmfd sp, {r0-r3, r12, lr}^
70000abc:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
	sub sp, #24
70000ac0:	e24dd018 	sub	sp, sp, #24

	/* Increment exception nesting count */
	get_cpu r2
70000ac4:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000ac8:	e3c22003 	bic	r2, r2, #3
	ldr r1, [r2, #___cpu_t_nested_OFFSET]
70000acc:	e5921000 	ldr	r1, [r2]
	add r1, r1, #1
70000ad0:	e2811001 	add	r1, r1, #1
	str r1, [r2, #___cpu_t_nested_OFFSET]
70000ad4:	e5821000 	str	r1, [r2]
	cps #MODE_UND

	mov r0, sp
	mov sp, r1
#else
	mov r0, sp
70000ad8:	e1a0000d 	mov	r0, sp
#endif

	bl z_arm_fault_undef_instruction
70000adc:	fa00001b 	blx	70000b50 <z_arm_fault_undef_instruction>
	exception_exit

	b z_arm_exc_exit
70000ae0:	ea000153 	b	70001034 <z_arm_exc_exit>

70000ae4 <z_arm_prefetch_abort>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_prefetch_abort)
	/*
	 * The faulting instruction address is always offset by 4 for the
	 * prefetch abort exceptions.
	 */
	sub lr, #4
70000ae4:	e24ee004 	sub	lr, lr, #4

	exception_entry MODE_ABT
70000ae8:	f96d0517 	srsdb	sp!, #23
70000aec:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
70000af0:	e24dd018 	sub	sp, sp, #24
70000af4:	e1a0000d 	mov	r0, sp
70000af8:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000afc:	e3c22003 	bic	r2, r2, #3
70000b00:	e5921000 	ldr	r1, [r2]
70000b04:	e2811001 	add	r1, r1, #1
70000b08:	e5821000 	str	r1, [r2]
	bl z_arm_fault_prefetch
70000b0c:	fa000013 	blx	70000b60 <z_arm_fault_prefetch>
	exception_exit

	b z_arm_exc_exit
70000b10:	ea000147 	b	70001034 <z_arm_exc_exit>

70000b14 <z_arm_data_abort>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_data_abort)
	/*
	 * The faulting instruction address is always offset by 8 for the data
	 * abort exceptions.
	 */
	sub lr, #8
70000b14:	e24ee008 	sub	lr, lr, #8

	exception_entry MODE_ABT
70000b18:	f96d0517 	srsdb	sp!, #23
70000b1c:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
70000b20:	e24dd018 	sub	sp, sp, #24
70000b24:	e1a0000d 	mov	r0, sp
70000b28:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000b2c:	e3c22003 	bic	r2, r2, #3
70000b30:	e5921000 	ldr	r1, [r2]
70000b34:	e2811001 	add	r1, r1, #1
70000b38:	e5821000 	str	r1, [r2]
	bl z_arm_fault_data
70000b3c:	fa00002c 	blx	70000bf4 <z_arm_fault_data>
	/*
	 * If z_arm_fault_data returns false, then we recovered from
	 * the error.  It may have updated $pc, so copy $pc back to
	 * the true esf from the one passed to z_arm_fault_data.
	 */
	cmp r0, #0
70000b40:	e3500000 	cmp	r0, #0
	ldreq r1, [sp, #24 + FPU_SF_SIZE]
70000b44:	059d1018 	ldreq	r1, [sp, #24]

	exception_exit

	streq r1, [sp, #24 + FPU_SF_SIZE]
70000b48:	058d1018 	streq	r1, [sp, #24]

	b z_arm_exc_exit
70000b4c:	ea000138 	b	70001034 <z_arm_exc_exit>

70000b50 <z_arm_fault_undef_instruction>:
 * @brief Undefined instruction fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_undef_instruction(struct arch_esf *esf)
{
70000b50:	4601      	mov	r1, r0
	uint32_t reason = IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) ?
			  K_ERR_CPU_EXCEPTION :
			  K_ERR_ARM_UNDEFINED_INSTRUCTION;

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70000b52:	202d      	movs	r0, #45	; 0x2d
{
70000b54:	b508      	push	{r3, lr}
	z_arm_fatal_error(reason, esf);
70000b56:	f7ff ff8d 	bl	70000a74 <z_arm_fatal_error>

	/* All undefined instructions are treated as fatal for now */
	return true;
}
70000b5a:	2001      	movs	r0, #1
70000b5c:	bd08      	pop	{r3, pc}
70000b5e:	bf00      	nop

70000b60 <z_arm_fault_prefetch>:
 * @brief Prefetch abort fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_prefetch(struct arch_esf *esf)
{
70000b60:	4601      	mov	r1, r0
70000b62:	b508      	push	{r3, lr}
    \return               Instruction Fault Status Register value
 */
__STATIC_FORCEINLINE uint32_t __get_IFSR(void)
{
  uint32_t result;
  __get_CP(15, 0, result, 5, 0, 1);
70000b64:	ee15 2f30 	mrc	15, 0, r2, cr5, cr0, {1}
	__get_CP(15, 0, result, 6, 0, 2);
70000b68:	ee16 3f50 	mrc	15, 0, r3, cr6, cr0, {2}
	/* Read and parse Instruction Fault Status Register (IFSR) */
	uint32_t ifsr = __get_IFSR();
#if defined(CONFIG_AARCH32_ARMV8_R)
	uint32_t fs = ifsr & IFSR_STATUS_Msk;
#else
	uint32_t fs = ((ifsr & IFSR_FS1_Msk) >> 6) | (ifsr & IFSR_FS0_Msk);
70000b6c:	0993      	lsrs	r3, r2, #6
70000b6e:	f003 0310 	and.w	r3, r3, #16
70000b72:	f002 020f 	and.w	r2, r2, #15
70000b76:	4313      	orrs	r3, r2
	switch (status) {
70000b78:	2b19      	cmp	r3, #25
70000b7a:	d80e      	bhi.n	70000b9a <z_arm_fault_prefetch+0x3a>
70000b7c:	e8df f003 	tbb	[pc, r3]
70000b80:	0d1c3717 	.word	0x0d1c3717
70000b84:	0d0d0d0d 	.word	0x0d0d0d0d
70000b88:	0d0d0d23 	.word	0x0d0d0d23
70000b8c:	0d0d280d 	.word	0x0d0d280d
70000b90:	0d0d0d0d 	.word	0x0d0d0d0d
70000b94:	0d2d0d0d 	.word	0x0d2d0d0d
70000b98:	1232      	.short	0x1232
	uint32_t reason = K_ERR_CPU_EXCEPTION;
70000b9a:	2000      	movs	r0, #0
	if (IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) && (reason >= K_ERR_ARCH_START)) {
		reason = K_ERR_CPU_EXCEPTION;
	}

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70000b9c:	f7ff ff6a 	bl	70000a74 <z_arm_fatal_error>

	/* All prefetch aborts are treated as fatal for now */
	return true;
}
70000ba0:	2001      	movs	r0, #1
70000ba2:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_PARITY_ERROR;
70000ba4:	2033      	movs	r0, #51	; 0x33
	z_arm_fatal_error(reason, esf);
70000ba6:	f7ff ff65 	bl	70000a74 <z_arm_fatal_error>
}
70000baa:	2001      	movs	r0, #1
70000bac:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_BACKGROUND_FAULT;
70000bae:	202f      	movs	r0, #47	; 0x2f
	z_arm_fatal_error(reason, esf);
70000bb0:	f7ff ff60 	bl	70000a74 <z_arm_fatal_error>
}
70000bb4:	2001      	movs	r0, #1
70000bb6:	bd08      	pop	{r3, pc}
	__get_CP(14, 0, result, 0, 1, 0);
70000bb8:	ee10 3e11 	mrc	14, 0, r3, cr0, cr1, {0}
		reason = K_ERR_ARM_DEBUG_EVENT;
70000bbc:	2035      	movs	r0, #53	; 0x35
	z_arm_fatal_error(reason, esf);
70000bbe:	f7ff ff59 	bl	70000a74 <z_arm_fatal_error>
}
70000bc2:	2001      	movs	r0, #1
70000bc4:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_EXTERNAL_ABORT;
70000bc6:	2031      	movs	r0, #49	; 0x31
	z_arm_fatal_error(reason, esf);
70000bc8:	f7ff ff54 	bl	70000a74 <z_arm_fatal_error>
}
70000bcc:	2001      	movs	r0, #1
70000bce:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_PERMISSION_FAULT;
70000bd0:	2030      	movs	r0, #48	; 0x30
	z_arm_fatal_error(reason, esf);
70000bd2:	f7ff ff4f 	bl	70000a74 <z_arm_fatal_error>
}
70000bd6:	2001      	movs	r0, #1
70000bd8:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_EXTERNAL_ABORT;
70000bda:	2032      	movs	r0, #50	; 0x32
	z_arm_fatal_error(reason, esf);
70000bdc:	f7ff ff4a 	bl	70000a74 <z_arm_fatal_error>
}
70000be0:	2001      	movs	r0, #1
70000be2:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_PARITY_ERROR;
70000be4:	2034      	movs	r0, #52	; 0x34
	z_arm_fatal_error(reason, esf);
70000be6:	f7ff ff45 	bl	70000a74 <z_arm_fatal_error>
}
70000bea:	2001      	movs	r0, #1
70000bec:	bd08      	pop	{r3, pc}
	switch (status) {
70000bee:	202e      	movs	r0, #46	; 0x2e
70000bf0:	e7d4      	b.n	70000b9c <z_arm_fault_prefetch+0x3c>
70000bf2:	bf00      	nop

70000bf4 <z_arm_fault_data>:
 * @brief Data abort fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_data(struct arch_esf *esf)
{
70000bf4:	4601      	mov	r1, r0
70000bf6:	b508      	push	{r3, lr}
  __get_CP(15, 0, result, 5, 0, 0);
70000bf8:	ee15 2f10 	mrc	15, 0, r2, cr5, cr0, {0}
	__get_CP(15, 0, result, 6, 0, 0);
70000bfc:	ee16 3f10 	mrc	15, 0, r3, cr6, cr0, {0}
	/* Read and parse Data Fault Status Register (DFSR) */
	uint32_t dfsr = __get_DFSR();
#if defined(CONFIG_AARCH32_ARMV8_R)
	uint32_t fs = dfsr & DFSR_STATUS_Msk;
#else
	uint32_t fs = ((dfsr & DFSR_FS1_Msk) >> 6) | (dfsr & DFSR_FS0_Msk);
70000c00:	0993      	lsrs	r3, r2, #6
70000c02:	f003 0310 	and.w	r3, r3, #16
70000c06:	f002 020f 	and.w	r2, r2, #15
70000c0a:	4313      	orrs	r3, r2
	switch (status) {
70000c0c:	2b19      	cmp	r3, #25
70000c0e:	d80e      	bhi.n	70000c2e <z_arm_fault_data+0x3a>
70000c10:	e8df f003 	tbb	[pc, r3]
70000c14:	0d1c3717 	.word	0x0d1c3717
70000c18:	0d0d0d0d 	.word	0x0d0d0d0d
70000c1c:	0d0d0d23 	.word	0x0d0d0d23
70000c20:	0d0d280d 	.word	0x0d0d280d
70000c24:	0d0d0d0d 	.word	0x0d0d0d0d
70000c28:	0d2d0d0d 	.word	0x0d2d0d0d
70000c2c:	1232      	.short	0x1232
	uint32_t reason = K_ERR_CPU_EXCEPTION;
70000c2e:	2000      	movs	r0, #0
	if (IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) && (reason >= K_ERR_ARCH_START)) {
		reason = K_ERR_CPU_EXCEPTION;
	}

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70000c30:	f7ff ff20 	bl	70000a74 <z_arm_fatal_error>

	/* All data aborts are treated as fatal for now */
	return true;
}
70000c34:	2001      	movs	r0, #1
70000c36:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_PARITY_ERROR;
70000c38:	2033      	movs	r0, #51	; 0x33
	z_arm_fatal_error(reason, esf);
70000c3a:	f7ff ff1b 	bl	70000a74 <z_arm_fatal_error>
}
70000c3e:	2001      	movs	r0, #1
70000c40:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_BACKGROUND_FAULT;
70000c42:	202f      	movs	r0, #47	; 0x2f
	z_arm_fatal_error(reason, esf);
70000c44:	f7ff ff16 	bl	70000a74 <z_arm_fatal_error>
}
70000c48:	2001      	movs	r0, #1
70000c4a:	bd08      	pop	{r3, pc}
	__get_CP(14, 0, result, 0, 1, 0);
70000c4c:	ee10 3e11 	mrc	14, 0, r3, cr0, cr1, {0}
		reason = K_ERR_ARM_DEBUG_EVENT;
70000c50:	2035      	movs	r0, #53	; 0x35
	z_arm_fatal_error(reason, esf);
70000c52:	f7ff ff0f 	bl	70000a74 <z_arm_fatal_error>
}
70000c56:	2001      	movs	r0, #1
70000c58:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_EXTERNAL_ABORT;
70000c5a:	2031      	movs	r0, #49	; 0x31
	z_arm_fatal_error(reason, esf);
70000c5c:	f7ff ff0a 	bl	70000a74 <z_arm_fatal_error>
}
70000c60:	2001      	movs	r0, #1
70000c62:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_PERMISSION_FAULT;
70000c64:	2030      	movs	r0, #48	; 0x30
	z_arm_fatal_error(reason, esf);
70000c66:	f7ff ff05 	bl	70000a74 <z_arm_fatal_error>
}
70000c6a:	2001      	movs	r0, #1
70000c6c:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_EXTERNAL_ABORT;
70000c6e:	2032      	movs	r0, #50	; 0x32
	z_arm_fatal_error(reason, esf);
70000c70:	f7ff ff00 	bl	70000a74 <z_arm_fatal_error>
}
70000c74:	2001      	movs	r0, #1
70000c76:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_PARITY_ERROR;
70000c78:	2034      	movs	r0, #52	; 0x34
	z_arm_fatal_error(reason, esf);
70000c7a:	f7ff fefb 	bl	70000a74 <z_arm_fatal_error>
}
70000c7e:	2001      	movs	r0, #1
70000c80:	bd08      	pop	{r3, pc}
	switch (status) {
70000c82:	202e      	movs	r0, #46	; 0x2e
70000c84:	e7d4      	b.n	70000c30 <z_arm_fault_data+0x3c>
70000c86:	bf00      	nop

70000c88 <z_arm_interrupt_init>:
	/*
	 * Initialise interrupt controller.
	 */
#ifdef CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER
	/* Invoke SoC-specific interrupt controller initialisation */
	z_soc_irq_init();
70000c88:	f7ff bee6 	b.w	70000a58 <z_soc_irq_init>

70000c8c <relocate_vector_table>:
		write_sysreg64(val, op1, CRm);				\
	}

MAKE_REG_HELPER(mpuir,	     0, 0, 0, 4);
MAKE_REG_HELPER(mpidr,	     0, 0, 0, 5);
MAKE_REG_HELPER(sctlr,	     0, 1, 0, 0);
70000c8c:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}

void __weak relocate_vector_table(void)
{
#if defined(CONFIG_XIP) && (CONFIG_FLASH_BASE_ADDRESS != 0) ||                                     \
	!defined(CONFIG_XIP) && (CONFIG_SRAM_BASE_ADDRESS != 0)
	write_sctlr(read_sctlr() & ~HIVECS);
70000c90:	f423 5300 	bic.w	r3, r3, #8192	; 0x2000
70000c94:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
	size_t vector_size = (size_t)_vector_end - (size_t)_vector_start;
70000c98:	f240 023c 	movw	r2, #60	; 0x3c
70000c9c:	f240 0100 	movw	r1, #0
70000ca0:	f2c7 0100 	movt	r1, #28672	; 0x7000
	(void)memcpy(VECTOR_ADDRESS, _vector_start, vector_size);
70000ca4:	2000      	movs	r0, #0
	size_t vector_size = (size_t)_vector_end - (size_t)_vector_start;
70000ca6:	f2c7 0200 	movt	r2, #28672	; 0x7000
	(void)memcpy(VECTOR_ADDRESS, _vector_start, vector_size);
70000caa:	1a52      	subs	r2, r2, r1
70000cac:	f002 b8f8 	b.w	70002ea0 <memcpy>

70000cb0 <z_arm_relocate_vector_table>:
#endif

#endif /* !CONFIG_AARCH32_ARMV8_R */

void z_arm_relocate_vector_table(void)
{
70000cb0:	b508      	push	{r3, lr}
	relocate_vector_table();
70000cb2:	f7ff ffeb 	bl	70000c8c <relocate_vector_table>
}
70000cb6:	bd08      	pop	{r3, pc}

70000cb8 <__start>:
    ldr r0, =IMP_CSCTLR(CONFIG_CPU_CORTEX_R52_ICACHE_FLASH_WAY,
                        CONFIG_CPU_CORTEX_R52_DCACHE_FLASH_WAY)
    mcr p15, 1, r0, c9, c1, 0
#endif

    ldr r0, =arm_cpu_boot_params
70000cb8:	e59f0054 	ldr	r0, [pc, #84]	; 70000d14 <__start+0x5c>
    b 2f

_primary_core:
#endif

    ldr r4, =z_prep_c
70000cbc:	e59f4054 	ldr	r4, [pc, #84]	; 70000d18 <__start+0x60>
    ldr r5, =(z_arm_fiq_stack + CONFIG_ARMV7_FIQ_STACK_SIZE)
70000cc0:	e59f5054 	ldr	r5, [pc, #84]	; 70000d1c <__start+0x64>
    ldr r6, =(z_interrupt_stacks + CONFIG_ISR_STACK_SIZE)
70000cc4:	e59f6054 	ldr	r6, [pc, #84]	; 70000d20 <__start+0x68>
    ldr r7, =(z_arm_abort_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000cc8:	e59f7054 	ldr	r7, [pc, #84]	; 70000d24 <__start+0x6c>
    ldr r8, =(z_arm_undef_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000ccc:	e59f8054 	ldr	r8, [pc, #84]	; 70000d28 <__start+0x70>
    ldr r9, =(z_arm_svc_stack + CONFIG_ARMV7_SVC_STACK_SIZE)
70000cd0:	e59f9054 	ldr	r9, [pc, #84]	; 70000d2c <__start+0x74>
    ldr r10, =(z_arm_sys_stack + CONFIG_ARMV7_SYS_STACK_SIZE)
70000cd4:	e59fa054 	ldr	sl, [pc, #84]	; 70000d30 <__start+0x78>
    /*
     * Configure stack.
     */

    /* FIQ mode stack */
    msr CPSR_c, #(MODE_FIQ | I_BIT | F_BIT)
70000cd8:	e321f0d1 	msr	CPSR_c, #209	; 0xd1
    mov sp, r5
70000cdc:	e1a0d005 	mov	sp, r5

    /* IRQ mode stack */
    msr CPSR_c, #(MODE_IRQ | I_BIT | F_BIT)
70000ce0:	e321f0d2 	msr	CPSR_c, #210	; 0xd2
    mov sp, r6
70000ce4:	e1a0d006 	mov	sp, r6

    /* ABT mode stack */
    msr CPSR_c, #(MODE_ABT | I_BIT | F_BIT)
70000ce8:	e321f0d7 	msr	CPSR_c, #215	; 0xd7
    mov sp, r7
70000cec:	e1a0d007 	mov	sp, r7

    /* UND mode stack */
    msr CPSR_c, #(MODE_UND | I_BIT | F_BIT)
70000cf0:	e321f0db 	msr	CPSR_c, #219	; 0xdb
    mov sp, r8
70000cf4:	e1a0d008 	mov	sp, r8

    /* SVC mode stack */
    msr CPSR_c, #(MODE_SVC | I_BIT | F_BIT)
70000cf8:	e321f0d3 	msr	CPSR_c, #211	; 0xd3
    mov sp, r9
70000cfc:	e1a0d009 	mov	sp, r9

    /* SYS mode stack */
    msr CPSR_c, #(MODE_SYS | I_BIT | F_BIT)
70000d00:	e321f0df 	msr	CPSR_c, #223	; 0xdf
    mov sp, r10
70000d04:	e1a0d00a 	mov	sp, sl

#if defined(CONFIG_SOC_RESET_HOOK)
    /* Execute platform-specific initialisation if applicable */
    bl soc_reset_hook
70000d08:	faffff55 	blx	70000a64 <soc_reset_hook>

#if defined(CONFIG_DISABLE_TCM_ECC)
    bl z_arm_tcm_disable_ecc
#endif

    bl z_arm_relocate_vector_table
70000d0c:	faffffe7 	blx	70000cb0 <z_arm_relocate_vector_table>

    bx r4
70000d10:	e12fff14 	bx	r4
    ldr r0, =arm_cpu_boot_params
70000d14:	7000b064 	.word	0x7000b064
    ldr r4, =z_prep_c
70000d18:	70000d3d 	.word	0x70000d3d
    ldr r5, =(z_arm_fiq_stack + CONFIG_ARMV7_FIQ_STACK_SIZE)
70000d1c:	70009ee8 	.word	0x70009ee8
    ldr r6, =(z_interrupt_stacks + CONFIG_ISR_STACK_SIZE)
70000d20:	7000a6e8 	.word	0x7000a6e8
    ldr r7, =(z_arm_abort_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000d24:	70009de8 	.word	0x70009de8
    ldr r8, =(z_arm_undef_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000d28:	70009ce8 	.word	0x70009ce8
    ldr r9, =(z_arm_svc_stack + CONFIG_ARMV7_SVC_STACK_SIZE)
70000d2c:	70009be8 	.word	0x70009be8
    ldr r10, =(z_arm_sys_stack + CONFIG_ARMV7_SYS_STACK_SIZE)
70000d30:	700099e8 	.word	0x700099e8

70000d34 <z_irq_spurious>:
 */
void z_irq_spurious(const void *unused)
{
	ARG_UNUSED(unused);

	z_arm_fatal_error(K_ERR_SPURIOUS_IRQ, NULL);
70000d34:	2100      	movs	r1, #0
70000d36:	2001      	movs	r0, #1
70000d38:	f7ff be9c 	b.w	70000a74 <z_arm_fatal_error>

70000d3c <z_prep_c>:
 *
 * This routine prepares for the execution of and runs C code.
 *
 */
void z_prep_c(void)
{
70000d3c:	b508      	push	{r3, lr}
MAKE_REG_HELPER(prlar,	     0, 6, 3, 1);
MAKE_REG_HELPER(mair0,       0, 10, 2, 0);
MAKE_REG_HELPER(vbar,        0, 12, 0, 0);
MAKE_REG_HELPER(cntv_ctl,    0, 14,  3, 1);
MAKE_REG_HELPER(ctr,         0, 0, 0, 1);
MAKE_REG_HELPER(tpidruro,    0, 13, 0, 3);
70000d3e:	f646 33bc 	movw	r3, #27580	; 0x6bbc
70000d42:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000d46:	ee0d 3f70 	mcr	15, 0, r3, cr13, cr0, {3}
	write_tpidruro((uintptr_t)&_kernel.cpus[0]);

#if defined(CONFIG_CPU_HAS_FPU)
	z_arm_floating_point_init();
#endif
	z_bss_zero();
70000d4a:	f000 ff3f 	bl	70001bcc <z_bss_zero>
	z_data_copy();
#if ((defined(CONFIG_ARMV7_R) || defined(CONFIG_ARMV7_A)) && defined(CONFIG_INIT_STACKS))
	z_arm_init_stacks();
#endif
	z_arm_interrupt_init();
70000d4e:	f7ff ff9b 	bl	70000c88 <z_arm_interrupt_init>
#if CONFIG_ARCH_CACHE
	arch_cache_init();
70000d52:	f000 f8cf 	bl	70000ef4 <arch_cache_init>
	z_arm_mpu_init();
	z_arm_configure_static_mpu_regions();
#elif defined(CONFIG_ARM_AARCH32_MMU)
	z_arm_mmu_init();
#endif
	z_cstart();
70000d56:	f000 ff47 	bl	70001be8 <z_cstart>
70000d5a:	bf00      	nop

70000d5c <arch_new_thread>:
 * of the ESF.
 */
void arch_new_thread(struct k_thread *thread, k_thread_stack_t *stack,
		     char *stack_ptr, k_thread_entry_t entry,
		     void *p1, void *p2, void *p3)
{
70000d5c:	b430      	push	{r4, r5}
	}
#else
	iframe->pc = (uint32_t)z_thread_entry;
#endif

	iframe->a1 = (uint32_t)entry;
70000d5e:	f842 3c20 	str.w	r3, [r2, #-32]
#if defined(CONFIG_BIG_ENDIAN)
	iframe->xpsr |= E_BIT;
#endif /* CONFIG_BIG_ENDIAN */

#if defined(CONFIG_COMPILER_ISA_THUMB2)
	iframe->xpsr |= T_BIT;
70000d62:	f240 153f 	movw	r5, #319	; 0x13f
{
70000d66:	9b02      	ldr	r3, [sp, #8]
	iframe = Z_STACK_PTR_TO_FRAME(struct __basic_sf, stack_ptr);
70000d68:	f1a2 0420 	sub.w	r4, r2, #32
	iframe->a2 = (uint32_t)p1;
70000d6c:	f842 3c1c 	str.w	r3, [r2, #-28]
	iframe->pc = (uint32_t)z_thread_entry;
70000d70:	f640 2335 	movw	r3, #2613	; 0xa35
		((uintptr_t)iframe - sizeof(struct __fpu_sf));
	memset(iframe, 0, sizeof(struct __fpu_sf));
#endif

	thread->callee_saved.psp = (uint32_t)iframe;
	thread->arch.basepri = 0;
70000d74:	2100      	movs	r1, #0
	iframe->pc = (uint32_t)z_thread_entry;
70000d76:	f2c7 0300 	movt	r3, #28672	; 0x7000
	iframe->xpsr |= T_BIT;
70000d7a:	f842 5c04 	str.w	r5, [r2, #-4]
	iframe->pc = (uint32_t)z_thread_entry;
70000d7e:	f842 3c08 	str.w	r3, [r2, #-8]
{
70000d82:	9b03      	ldr	r3, [sp, #12]
	iframe->a3 = (uint32_t)p2;
70000d84:	f842 3c18 	str.w	r3, [r2, #-24]
{
70000d88:	9b04      	ldr	r3, [sp, #16]
	iframe->a4 = (uint32_t)p3;
70000d8a:	f842 3c14 	str.w	r3, [r2, #-20]
	thread->callee_saved.psp = (uint32_t)iframe;
70000d8e:	6504      	str	r4, [r0, #80]	; 0x50
	thread->arch.basepri = 0;
70000d90:	66c1      	str	r1, [r0, #108]	; 0x6c
	thread->switch_handle = thread;
	/* thread birth happens through the exception return path */
	thread->arch.exception_depth = 1;
	thread->callee_saved.lr = (uint32_t)z_arm_cortex_ar_exit_exc;
#endif
}
70000d92:	bc30      	pop	{r4, r5}
70000d94:	4770      	bx	lr
70000d96:	bf00      	nop

70000d98 <arch_cpu_idle>:

	/*
	 * Clear PRIMASK and flush instruction buffer to immediately service
	 * the wake-up interrupt.
	 */
	cpsie	i
70000d98:	f1080080 	cpsie	i
	isb
70000d9c:	f57ff06f 	isb	sy

	bx	lr
70000da0:	e12fff1e 	bx	lr

70000da4 <_isr_wrapper>:
	 * Save away r0-r3, r12 and lr_irq for the previous context to the
	 * process stack since they are clobbered here.  Also, save away lr
	 * and spsr_irq since we may swap processes and return to a different
	 * thread.
	 */
	sub lr, lr, #4
70000da4:	e24ee004 	sub	lr, lr, #4
	srsdb #MODE_SYS!
70000da8:	f96d051f 	srsdb	sp!, #31
	cps #MODE_SYS
70000dac:	f102001f 	cps	#31
	push {r0-r3, r12, lr}
70000db0:	e92d500f 	push	{r0, r1, r2, r3, ip, lr}
	 * threads have high stack usage.
	 *
	 * When userspace is enabled, this also prevents leaking privileged
	 * information to the user mode.
	 */
	cps #MODE_SVC
70000db4:	f1020013 	cps	#19
	/*
	 * Preserve lr_svc which may contain the branch return address of the
	 * interrupted context in case of a nested interrupt. This value will
	 * be restored prior to exiting the interrupt in z_arm_int_exit.
	 */
	push {lr}
70000db8:	e52de004 	push	{lr}		; (str lr, [sp, #-4]!)

	/* Align stack at double-word boundary */
	and r3, sp, #4
70000dbc:	e20d3004 	and	r3, sp, #4
	sub sp, sp, r3
70000dc0:	e04dd003 	sub	sp, sp, r3
	push {r2, r3}
70000dc4:	e92d000c 	push	{r2, r3}

	/* Increment interrupt nesting count */
	get_cpu r2
70000dc8:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000dcc:	e3c22003 	bic	r2, r2, #3
	ldr r0, [r2, #___cpu_t_nested_OFFSET]
70000dd0:	e5920000 	ldr	r0, [r2]
	add r0, r0, #1
70000dd4:	e2800001 	add	r0, r0, #1
	str r0, [r2, #___cpu_t_nested_OFFSET]
70000dd8:	e5820000 	str	r0, [r2]

	/* Get active IRQ number from the interrupt controller */
#if !defined(CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER)
	bl arm_gic_get_active
#else
	bl z_soc_irq_get_active
70000ddc:	faffff1b 	blx	70000a50 <z_soc_irq_get_active>
#endif /* !CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER */
	push {r0, r1}
70000de0:	e92d0003 	push	{r0, r1}
	lsl r0, r0, #3	/* table is 8-byte wide */
70000de4:	e1a00180 	lsl	r0, r0, #3
	 * to note that most interrupt controllers require that the nested
	 * interrupts are handled after the active interrupt is acknowledged;
	 * this is be done through the `get_active` interrupt controller
	 * interface function.
	 */
	cpsie i
70000de8:	f1080080 	cpsie	i

	/*
	 * Skip calling the isr if it is a spurious interrupt.
	 */
	mov r1, #CONFIG_NUM_IRQS
70000dec:	e3a01c02 	mov	r1, #512	; 0x200
	lsl r1, r1, #3
70000df0:	e1a01181 	lsl	r1, r1, #3
	cmp r0, r1
70000df4:	e1500001 	cmp	r0, r1
	bge spurious_continue
70000df8:	aa000003 	bge	70000e0c <spurious_continue>

	ldr r1, =_sw_isr_table
70000dfc:	e59f1018 	ldr	r1, [pc, #24]	; 70000e1c <spurious_continue+0x10>
	add r1, r1, r0	/* table entry: ISRs must have their MSB set to stay
70000e00:	e0811000 	add	r1, r1, r0
			 * in thumb mode */

	ldm r1!,{r0,r3}	/* arg in r0, ISR in r3 */
70000e04:	e8b10009 	ldm	r1!, {r0, r3}
	blx r3		/* call ISR */
70000e08:	e12fff33 	blx	r3

70000e0c <spurious_continue>:

spurious_continue:
	/* Signal end-of-interrupt */
	pop {r0, r1}
70000e0c:	e8bd0003 	pop	{r0, r1}
#if !defined(CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER)
	bl arm_gic_eoi
#else
	bl z_soc_irq_eoi
70000e10:	faffff0f 	blx	70000a54 <z_soc_irq_eoi>
#endif

	/* Use 'bx' instead of 'b' because 'bx' can jump further, and use
	 * 'bx' instead of 'blx' because exception return is done in
	 * z_arm_int_exit() */
	ldr r1, =z_arm_int_exit
70000e14:	e59f1004 	ldr	r1, [pc, #4]	; 70000e20 <spurious_continue+0x14>
	bx r1
70000e18:	e12fff11 	bx	r1
	ldr r1, =_sw_isr_table
70000e1c:	70003a68 	.word	0x70003a68
	ldr r1, =z_arm_int_exit
70000e20:	70000fdc 	.word	0x70000fdc

70000e24 <arch_dcache_invd_all>:

	return 0;
}

int arch_dcache_invd_all(void)
{
70000e24:	b5f0      	push	{r4, r5, r6, r7, lr}
 */
__STATIC_FORCEINLINE uint32_t __get_CLIDR(void)
{
  uint32_t result;
//  __ASM volatile("MRC p15, 1, %0, c0, c0, 1" : "=r"(result) : : "memory");
  __get_CP(15, 1, result, 0, 0, 1);
70000e26:	ee30 6f30 	mrc	15, 1, r6, cr0, cr0, {1}
*/
__STATIC_FORCEINLINE void L1C_CleanInvalidateCache(uint32_t op) {
  uint32_t clidr;
  uint32_t cache_type;
  clidr =  __get_CLIDR();
  for(uint32_t i = 0U; i<7U; i++)
70000e2a:	2400      	movs	r4, #0
  {
    cache_type = (clidr >> i*3U) & 0x7UL;
70000e2c:	eb04 0344 	add.w	r3, r4, r4, lsl #1
70000e30:	fa26 f303 	lsr.w	r3, r6, r3
70000e34:	f003 0307 	and.w	r3, r3, #7
    if ((cache_type >= 2U) && (cache_type <= 4U))
70000e38:	3b02      	subs	r3, #2
70000e3a:	2b02      	cmp	r3, #2
    cache_type = (clidr >> i*3U) & 0x7UL;
70000e3c:	ea4f 0544 	mov.w	r5, r4, lsl #1
    if ((cache_type >= 2U) && (cache_type <= 4U))
70000e40:	d831      	bhi.n	70000ea6 <arch_dcache_invd_all+0x82>
  __set_CP(15, 2, value, 0, 0, 0);
70000e42:	ee40 5f10 	mcr	15, 2, r5, cr0, cr0, {0}
  __get_CP(15, 1, result, 0, 0, 0);
70000e46:	ee30 7f10 	mrc	15, 1, r7, cr0, cr0, {0}
  num_ways = ((ccsidr & 0x00001FF8U) >> 3U) + 1U;
70000e4a:	f3c7 0cc9 	ubfx	ip, r7, #3, #10
70000e4e:	f10c 0e01 	add.w	lr, ip, #1
  if (n < 2U) {
70000e52:	f1bc 0f00 	cmp.w	ip, #0
70000e56:	d02b      	beq.n	70000eb0 <arch_dcache_invd_all+0x8c>
70000e58:	4672      	mov	r2, lr
  uint8_t log = 0U;
70000e5a:	2300      	movs	r3, #0
    t >>= 1U;
70000e5c:	0852      	lsrs	r2, r2, #1
    log++;
70000e5e:	1c59      	adds	r1, r3, #1
70000e60:	4618      	mov	r0, r3
  while(t > 1U)
70000e62:	2a01      	cmp	r2, #1
    log++;
70000e64:	b2cb      	uxtb	r3, r1
  while(t > 1U)
70000e66:	d1f9      	bne.n	70000e5c <arch_dcache_invd_all+0x38>
  if (n & 1U) { log++; }
70000e68:	f01e 0f01 	tst.w	lr, #1
70000e6c:	bf1c      	itt	ne
70000e6e:	3002      	addne	r0, #2
70000e70:	b2c3      	uxtbne	r3, r0
  if ((log2_num_ways < 0) || (log2_num_ways > 32)) {
70000e72:	2b20      	cmp	r3, #32
  shift_way = 32U - (uint32_t)log2_num_ways;
70000e74:	bf98      	it	ls
70000e76:	f1c3 0e20 	rsbls	lr, r3, #32
  if ((log2_num_ways < 0) || (log2_num_ways > 32)) {
70000e7a:	d814      	bhi.n	70000ea6 <arch_dcache_invd_all+0x82>
  log2_linesize = (ccsidr & 0x00000007U) + 2U + 2U;
70000e7c:	f007 0007 	and.w	r0, r7, #7
70000e80:	3004      	adds	r0, #4
  num_sets = ((ccsidr & 0x0FFFE000U) >> 13U) + 1U;
70000e82:	f3c7 374e 	ubfx	r7, r7, #13, #15
    for(int32_t set = num_sets-1; set >= 0; set--)
70000e86:	463b      	mov	r3, r7
      Dummy = (level << 1U) | (((uint32_t)set) << log2_linesize) | (((uint32_t)way) << shift_way);
70000e88:	fa0c f10e 	lsl.w	r1, ip, lr
70000e8c:	4329      	orrs	r1, r5
70000e8e:	fa03 f200 	lsl.w	r2, r3, r0
70000e92:	430a      	orrs	r2, r1
/** \brief  Set DCISW
 */
__STATIC_FORCEINLINE void __set_DCISW(uint32_t value)
{
//  __ASM volatile("MCR p15, 0, %0, c7, c6, 2" : : "r"(value) : "memory")
  __set_CP(15, 0, value, 7, 6, 2);
70000e94:	ee07 2f56 	mcr	15, 0, r2, cr7, cr6, {2}
    for(int32_t set = num_sets-1; set >= 0; set--)
70000e98:	3b01      	subs	r3, #1
70000e9a:	d2f8      	bcs.n	70000e8e <arch_dcache_invd_all+0x6a>
  for(int32_t way = num_ways-1; way >= 0; way--)
70000e9c:	f1bc 0c01 	subs.w	ip, ip, #1
70000ea0:	d2f1      	bcs.n	70000e86 <arch_dcache_invd_all+0x62>
  \details Ensures the apparent order of the explicit memory operations before
           and after the instruction, without ensuring their completion.
 */
__STATIC_FORCEINLINE  void __DMB(void)
{
  __ASM volatile ("dmb 0xF":::"memory");
70000ea2:	f3bf 8f5f 	dmb	sy
  for(uint32_t i = 0U; i<7U; i++)
70000ea6:	3401      	adds	r4, #1
70000ea8:	2c07      	cmp	r4, #7
70000eaa:	d1bf      	bne.n	70000e2c <arch_dcache_invd_all+0x8>
	L1C_InvalidateDCacheAll();

	return 0;
}
70000eac:	2000      	movs	r0, #0
70000eae:	bdf0      	pop	{r4, r5, r6, r7, pc}
70000eb0:	f04f 0e20 	mov.w	lr, #32
70000eb4:	e7e2      	b.n	70000e7c <arch_dcache_invd_all+0x58>
70000eb6:	bf00      	nop

70000eb8 <arch_dcache_enable>:
{
70000eb8:	b508      	push	{r3, lr}
	arch_dcache_invd_all();
70000eba:	f7ff ffb3 	bl	70000e24 <arch_dcache_invd_all>
  __get_CP(15, 0, result, 1, 0, 0);
70000ebe:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}
  __ASM volatile ("dsb 0xF":::"memory");
70000ec2:	f3bf 8f4f 	dsb	sy
	val |= SCTLR_C_Msk;
70000ec6:	f043 0304 	orr.w	r3, r3, #4
  __set_CP(15, 0, sctlr, 1, 0, 0);
70000eca:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
  __ASM volatile ("isb 0xF":::"memory");
70000ece:	f3bf 8f6f 	isb	sy
}
70000ed2:	bd08      	pop	{r3, pc}

70000ed4 <arch_icache_enable>:
  __set_CP(15, 0, value, 7, 5, 0);
70000ed4:	2300      	movs	r3, #0
70000ed6:	ee07 3f15 	mcr	15, 0, r3, cr7, cr5, {0}
  __ASM volatile ("dsb 0xF":::"memory");
70000eda:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
70000ede:	f3bf 8f6f 	isb	sy
  __get_CP(15, 0, result, 1, 0, 0);
70000ee2:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}
#ifdef CONFIG_ICACHE

void arch_icache_enable(void)
{
	arch_icache_invd_all();
	__set_SCTLR(__get_SCTLR() | SCTLR_I_Msk);
70000ee6:	f443 5380 	orr.w	r3, r3, #4096	; 0x1000
  __set_CP(15, 0, sctlr, 1, 0, 0);
70000eea:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
70000eee:	f3bf 8f6f 	isb	sy
	barrier_isync_fence_full();
}
70000ef2:	4770      	bx	lr

70000ef4 <arch_cache_init>:

#endif

void arch_cache_init(void)
{
}
70000ef4:	4770      	bx	lr
70000ef6:	bf00      	nop

70000ef8 <z_arm_do_swap>:
    bl z_thread_mark_switched_out
    pop {r0, lr}
#endif /* CONFIG_INSTRUMENT_THREAD_SWITCHING */

    /* load current _cpu into r1 and current k_thread into r2 */
    get_cpu r1
70000ef8:	ee1d1f70 	mrc	15, 0, r1, cr13, cr0, {3}
70000efc:	e3c11003 	bic	r1, r1, #3
    ldr r2, [r1, #___cpu_t_current_OFFSET]
70000f00:	e5912008 	ldr	r2, [r1, #8]
    /* Store LSB of LR (EXC_RETURN) to the thread's 'mode' word. */
    strb lr, [r2, #_thread_offset_to_mode_exc_return]
#endif

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
70000f04:	e3a00030 	mov	r0, #48	; 0x30
    add r0, r2
70000f08:	e0800002 	add	r0, r0, r2

    /* Store rest of process context */
    cps #MODE_SYS
70000f0c:	f102001f 	cps	#31
    stm r0, {r4-r11, sp}
70000f10:	e8802ff0 	stm	r0, {r4, r5, r6, r7, r8, r9, sl, fp, sp}
    cps #MODE_SVC
70000f14:	f1020013 	cps	#19
    mov r0, #0
    str r0, [r1, #___cpu_t_fp_ctx_OFFSET]
#endif /* CONFIG_FPU_SHARING */

    /* fetch the thread to run from the ready queue cache */
    ldr r3, =_kernel
70000f18:	e59f3028 	ldr	r3, [pc, #40]	; 70000f48 <z_arm_do_swap+0x50>
    ldr r2, [r3, #_kernel_offset_to_ready_q_cache]
70000f1c:	e5932014 	ldr	r2, [r3, #20]

    str r2, [r1, #___cpu_t_current_OFFSET]
70000f20:	e5812008 	str	r2, [r1, #8]
#endif

    /* Restore previous interrupt disable state (irq_lock key)
     * (We clear the arch.basepri field after restoring state)
     */
    ldr r0, [r2, #_thread_offset_to_basepri]
70000f24:	e592006c 	ldr	r0, [r2, #108]	; 0x6c
    movs r3, #0
70000f28:	e3b03000 	movs	r3, #0
    str r3, [r2, #_thread_offset_to_basepri]
70000f2c:	e582306c 	str	r3, [r2, #108]	; 0x6c

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
70000f30:	e3a00030 	mov	r0, #48	; 0x30
    add r0, r2
70000f34:	e0800002 	add	r0, r0, r2

    /* restore r4-r11 and sp for incoming thread */
    cps #MODE_SYS
70000f38:	f102001f 	cps	#31
    ldm r0, {r4-r11, sp}
70000f3c:	e8902ff0 	ldm	r0, {r4, r5, r6, r7, r8, r9, sl, fp, sp}
    cps #MODE_SVC
70000f40:	f1020013 	cps	#19
#endif /* CONFIG_INSTRUMENT_THREAD_SWITCHING */

    /*
     * Cortex-R: return to the caller (z_arm_{exc,int}_exit, or z_arm_svc)
     */
    bx lr
70000f44:	e12fff1e 	bx	lr
    ldr r3, =_kernel
70000f48:	70006bbc 	.word	0x70006bbc

70000f4c <z_arm_svc>:
    /*
     * Switch to system mode to store r0-r3 to the process stack pointer.
     * Save r12 and the lr as we could be swapping in another process and
     * returning to a different location.
     */
    srsdb #MODE_SYS!
70000f4c:	f96d051f 	srsdb	sp!, #31
    cps #MODE_SYS
70000f50:	f102001f 	cps	#31
    push {r0-r3, r12, lr}
70000f54:	e92d500f 	push	{r0, r1, r2, r3, ip, lr}
    ldr r0, [r2, #___cpu_t_fp_ctx_OFFSET]
    cmp r0, #0
    streq sp, [r2, #___cpu_t_fp_ctx_OFFSET]
#endif /* CONFIG_FPU_SHARING */

    mov ip, sp
70000f58:	e1a0c00d 	mov	ip, sp

    cps #MODE_SVC
70000f5c:	f1020013 	cps	#19

    /*
     * Store lr_svc to the SVC mode stack. This value will be restored prior to
     * exiting the SVC call in z_arm_int_exit.
     */
    push {lr}
70000f60:	e52de004 	push	{lr}		; (str lr, [sp, #-4]!)

    /* Align stack at double-word boundary */
    /* TODO: Question, why push {r2, r3} here */
    and r3, sp, #4
70000f64:	e20d3004 	and	r3, sp, #4
    sub sp, sp, r3
70000f68:	e04dd003 	sub	sp, sp, r3
    push {r2, r3}
70000f6c:	e92d000c 	push	{r2, r3}

    /* Increment interrupt nesting count */
    get_cpu r2
70000f70:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000f74:	e3c22003 	bic	r2, r2, #3
    ldr r0, [r2, #___cpu_t_nested_OFFSET]
70000f78:	e5920000 	ldr	r0, [r2]
    add r0, r0, #1
70000f7c:	e2800001 	add	r0, r0, #1
    str r0, [r2, #___cpu_t_nested_OFFSET]
70000f80:	e5820000 	str	r0, [r2]

    /* Get SVC number */
    mrs r0, spsr
70000f84:	e14f0000 	mrs	r0, SPSR
    tst r0, #0x20
70000f88:	e3100020 	tst	r0, #32

    ldreq r1, [lr, #-4]
70000f8c:	051e1004 	ldreq	r1, [lr, #-4]
    biceq r1, #0xff000000
70000f90:	03c114ff 	biceq	r1, r1, #-16777216	; 0xff000000
    beq demux
70000f94:	0a000001 	beq	70000fa0 <demux>

    ldr r1, [lr, #-2]
70000f98:	e51e1002 	ldr	r1, [lr, #-2]
    and r1, #0xff
70000f9c:	e20110ff 	and	r1, r1, #255	; 0xff

70000fa0 <demux>:
#if defined(CONFIG_USERSPACE)
    cmp r1, #_SVC_CALL_SYSTEM_CALL
    beq _do_syscall
#endif

    cmp r1, #_SVC_CALL_CONTEXT_SWITCH
70000fa0:	e3510000 	cmp	r1, #0
    beq _context_switch
70000fa4:	0a000001 	beq	70000fb0 <_context_switch>

    cmp r1, #_SVC_CALL_RUNTIME_EXCEPT
70000fa8:	e3510002 	cmp	r1, #2
    beq _oops
70000fac:	0a000001 	beq	70000fb8 <_oops>

70000fb0 <_context_switch>:
    b z_arm_int_exit
#endif

_context_switch:
    /* handler mode exit, to PendSV */
    bl z_arm_do_swap
70000fb0:	ebffffd0 	bl	70000ef8 <z_arm_do_swap>

    b z_arm_int_exit
70000fb4:	ea000008 	b	70000fdc <z_arm_int_exit>

70000fb8 <_oops>:

_oops:
    /*
     * Pass the exception frame to z_do_kernel_oops.
     */
    cps #MODE_SYS
70000fb8:	f102001f 	cps	#31
    mov r0, sp
70000fbc:	e1a0000d 	mov	r0, sp
    cps #MODE_SVC
70000fc0:	f1020013 	cps	#19
    /* Zero callee_regs and exc_return (only used on Cortex-M) */
    mov r1, #0
70000fc4:	e3a01000 	mov	r1, #0
    mov r2, #0
70000fc8:	e3a02000 	mov	r2, #0
    bl z_do_kernel_oops
70000fcc:	fafffea9 	blx	70000a78 <z_do_kernel_oops>
    b z_arm_int_exit
70000fd0:	ea000001 	b	70000fdc <z_arm_int_exit>

70000fd4 <z_arm_cortex_r_svc>:
    b z_arm_int_exit
#endif

GTEXT(z_arm_cortex_r_svc)
SECTION_FUNC(TEXT, z_arm_cortex_r_svc)
    svc #_SVC_CALL_CONTEXT_SWITCH
70000fd4:	ef000000 	svc	0x00000000
    bx lr
70000fd8:	e12fff1e 	bx	lr

70000fdc <z_arm_int_exit>:
#endif /* CONFIG_STACK_SENTINEL */

	/* Disable nested interrupts while exiting, this should happens
	 * before context switch also, to ensure interrupts are disabled.
	 */
	cpsid i
70000fdc:	f10c0080 	cpsid	i

#ifdef CONFIG_PREEMPT_ENABLED
	/* Do not context switch if exiting a nested interrupt */
	get_cpu r3
70000fe0:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70000fe4:	e3c33003 	bic	r3, r3, #3
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
70000fe8:	e5930000 	ldr	r0, [r3]
	cmp r0, #1
70000fec:	e3500001 	cmp	r0, #1
	bhi __EXIT_INT
70000ff0:	8a000004 	bhi	70001008 <__EXIT_INT>

	ldr r1, [r3, #___cpu_t_current_OFFSET]
70000ff4:	e5931008 	ldr	r1, [r3, #8]
	ldr r2, =_kernel
70000ff8:	e59f2094 	ldr	r2, [pc, #148]	; 70001094 <__EXIT_EXC+0x18>
	ldr r0, [r2, #_kernel_offset_to_ready_q_cache]
70000ffc:	e5920014 	ldr	r0, [r2, #20]
	cmp r0, r1
70001000:	e1500001 	cmp	r0, r1
	blne z_arm_do_swap
70001004:	1bffffbb 	blne	70000ef8 <z_arm_do_swap>

70001008 <__EXIT_INT>:
__EXIT_INT:
#endif /* CONFIG_PREEMPT_ENABLED */

	/* Decrement interrupt nesting count */
	get_cpu r2
70001008:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
7000100c:	e3c22003 	bic	r2, r2, #3
	ldr r0, [r2, #___cpu_t_nested_OFFSET]
70001010:	e5920000 	ldr	r0, [r2]
	sub r0, r0, #1
70001014:	e2400001 	sub	r0, r0, #1
	str r0, [r2, #___cpu_t_nested_OFFSET]
70001018:	e5820000 	str	r0, [r2]

	/* Restore previous stack pointer */
	pop {r2, r3}
7000101c:	e8bd000c 	pop	{r2, r3}
	add sp, sp, r3
70001020:	e08dd003 	add	sp, sp, r3
	/*
	 * Restore lr_svc stored into the SVC mode stack by the mode entry
	 * function. This ensures that the return address of the interrupted
	 * context is preserved in case of interrupt nesting.
	 */
	pop {lr}
70001024:	e49de004 	pop	{lr}		; (ldr lr, [sp], #4)
	 * IRQ mode and z_arm_svc for SVC mode.
	 *
	 * r0-r3 are either the values from the thread before it was switched
	 * out or they are the args to _new_thread for a new thread.
	 */
	cps #MODE_SYS
70001028:	f102001f 	cps	#31

#if defined(CONFIG_FPU_SHARING)
	fpu_exc_exit
#endif

	pop {r0-r3, r12, lr}
7000102c:	e8bd500f 	pop	{r0, r1, r2, r3, ip, lr}
	userspace_exc_exit
	rfeia sp!
70001030:	f8bd0a00 	rfeia	sp!

70001034 <z_arm_exc_exit>:
 *
 * @param fatal True if exiting from a fatal fault; otherwise, false
 */
SECTION_SUBSEC_FUNC(TEXT, _HandlerModeExit, z_arm_exc_exit)
	/* Do not context switch if exiting a nested exception */
	get_cpu r3
70001034:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70001038:	e3c33003 	bic	r3, r3, #3
	ldr r1, [r3, #___cpu_t_nested_OFFSET]
7000103c:	e5931000 	ldr	r1, [r3]
	cmp r1, #1
70001040:	e3510001 	cmp	r1, #1
	bhi __EXIT_EXC
70001044:	8a00000c 	bhi	7000107c <__EXIT_EXC>

	/* If the fault is not fatal, return to the current thread context */
	cmp r0, #0
70001048:	e3500000 	cmp	r0, #0
	beq __EXIT_EXC
7000104c:	0a00000a 	beq	7000107c <__EXIT_EXC>

	/* Clean up exception stack frame */
#if defined(CONFIG_FPU_SHARING)
	add sp, sp, #___fpu_t_SIZEOF
#endif
	add sp, #32
70001050:	e28dd020 	add	sp, sp, #32
	 *
	 * Note that z_arm_do_swap must be called in the SVC mode because it
	 * switches to the SVC mode during context switch and returns to the
	 * caller using lr_svc.
	 */
	cps #MODE_SVC
70001054:	f1020013 	cps	#19
	bl z_arm_do_swap
70001058:	ebffffa6 	bl	70000ef8 <z_arm_do_swap>

	/* Decrement exception nesting count */
	get_cpu r3
7000105c:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70001060:	e3c33003 	bic	r3, r3, #3
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
70001064:	e5930000 	ldr	r0, [r3]
	sub r0, r0, #1
70001068:	e2400001 	sub	r0, r0, #1
	str r0, [r3, #___cpu_t_nested_OFFSET]
7000106c:	e5830000 	str	r0, [r3]

	/* Return to the switched thread */
	cps #MODE_SYS
70001070:	f102001f 	cps	#31
#if defined(CONFIG_FPU_SHARING)
	fpu_exc_exit
#endif
	pop {r0-r3, r12, lr}
70001074:	e8bd500f 	pop	{r0, r1, r2, r3, ip, lr}
	userspace_exc_exit
	rfeia sp!
70001078:	f8bd0a00 	rfeia	sp!

7000107c <__EXIT_EXC>:

__EXIT_EXC:
	/* Decrement exception nesting count */
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
7000107c:	e5930000 	ldr	r0, [r3]
	sub r0, r0, #1
70001080:	e2400001 	sub	r0, r0, #1
	str r0, [r3, #___cpu_t_nested_OFFSET]
70001084:	e5830000 	str	r0, [r3]
#endif
	/*
	 * Restore r0-r3, r12, lr, lr_und and spsr_und from the exception stack
	 * and return to the current thread.
	 */
	ldmia sp, {r0-r3, r12, lr}^
70001088:	e8dd500f 	ldm	sp, {r0, r1, r2, r3, ip, lr}^
	add sp, #24
7000108c:	e28dd018 	add	sp, sp, #24
	rfeia sp!
70001090:	f8bd0a00 	rfeia	sp!
	ldr r2, =_kernel
70001094:	70006bbc 	.word	0x70006bbc

70001098 <picolibc_put>:
}
#include <zephyr/syscalls/zephyr_fputc_mrsh.c>
#endif

static int picolibc_put(char a, FILE *f)
{
70001098:	b508      	push	{r3, lr}
	(*_stdout_hook)(a);
7000109a:	f646 33a8 	movw	r3, #27560	; 0x6ba8
7000109e:	f2c7 0300 	movt	r3, #28672	; 0x7000
700010a2:	681b      	ldr	r3, [r3, #0]
700010a4:	4798      	blx	r3
	zephyr_fputc(a, f);
	return 0;
}
700010a6:	2000      	movs	r0, #0
700010a8:	bd08      	pop	{r3, pc}
700010aa:	bf00      	nop

700010ac <__stdout_hook_install>:
FILE *const stdout = &__stdout;
STDIO_ALIAS(stderr);

void __stdout_hook_install(int (*hook)(int))
{
	_stdout_hook = hook;
700010ac:	f646 31a8 	movw	r1, #27560	; 0x6ba8
	__stdout.flags |= _FDEV_SETUP_WRITE;
700010b0:	f24b 0390 	movw	r3, #45200	; 0xb090
700010b4:	f2c7 0300 	movt	r3, #28672	; 0x7000
700010b8:	789a      	ldrb	r2, [r3, #2]
	_stdout_hook = hook;
700010ba:	f2c7 0100 	movt	r1, #28672	; 0x7000
	__stdout.flags |= _FDEV_SETUP_WRITE;
700010be:	f042 0202 	orr.w	r2, r2, #2
	_stdout_hook = hook;
700010c2:	6008      	str	r0, [r1, #0]
	__stdout.flags |= _FDEV_SETUP_WRITE;
700010c4:	709a      	strb	r2, [r3, #2]
}
700010c6:	4770      	bx	lr

700010c8 <malloc_prepare>:
			break;
		}
		heap_size >>= 1;
	}
#else
	heap_base = UINT_TO_POINTER(HEAP_BASE);
700010c8:	4907      	ldr	r1, [pc, #28]	; (700010e8 <malloc_prepare+0x20>)
	z_malloc_partition.start = POINTER_TO_UINT(heap_base);
	z_malloc_partition.size = heap_size;
	z_malloc_partition.attr = K_MEM_PARTITION_P_RW_U_RW;
#endif

	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
700010ca:	f646 30ac 	movw	r0, #27564	; 0x6bac
700010ce:	f2c7 0000 	movt	r0, #28672	; 0x7000
	heap_base = UINT_TO_POINTER(HEAP_BASE);
700010d2:	f021 0107 	bic.w	r1, r1, #7
	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
700010d6:	f1c1 42e0 	rsb	r2, r1, #1879048192	; 0x70000000
700010da:	f502 3200 	add.w	r2, r2, #131072	; 0x20000
{
700010de:	b508      	push	{r3, lr}
	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
700010e0:	f7ff fc48 	bl	70000974 <sys_heap_init>

	return 0;
}
700010e4:	2000      	movs	r0, #0
700010e6:	bd08      	pop	{r3, pc}
700010e8:	7000b0cb 	.word	0x7000b0cb

700010ec <z_vim_irq_get_active>:

static ALWAYS_INLINE uint32_t sys_read32(mem_addr_t addr)
{
	uint32_t val;

	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700010ec:	2318      	movs	r3, #24
700010ee:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
700010f2:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700010f4:	f3bf 8f5f 	dmb	sy
700010f8:	2320      	movs	r3, #32
700010fa:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
700010fe:	681b      	ldr	r3, [r3, #0]
70001100:	f3bf 8f5f 	dmb	sy
	actirq = sys_read32(VIM_ACTIRQ);

	/* Check if the irq number is valid, else return invalid irq number.
	 * which will be considered as spurious interrupt
	 */
	if ((actirq & (VIM_ACTIRQ_VALID_MASK)) == 0) {
70001104:	2b00      	cmp	r3, #0
70001106:	da14      	bge.n	70001132 <z_vim_irq_get_active+0x46>
		return CONFIG_NUM_IRQS + 1;
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(actirq & VIM_PRIIRQ_NUM_MASK);
70001108:	f3c3 0009 	ubfx	r0, r3, #0, #10
7000110c:	f3bf 8f5f 	dmb	sy
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(actirq & VIM_PRIIRQ_NUM_MASK);

	/* Ack the interrupt in IRQSTS register */
	sys_write32(BIT(irq_bit_num), VIM_IRQSTS(irq_group_num));
70001110:	2101      	movs	r1, #1
70001112:	f44f 6282 	mov.w	r2, #1040	; 0x410
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(actirq & VIM_PRIIRQ_NUM_MASK);
70001116:	f003 0c1f 	and.w	ip, r3, #31
	sys_write32(BIT(irq_bit_num), VIM_IRQSTS(irq_group_num));
7000111a:	f6c2 72ff 	movt	r2, #12287	; 0x2fff
7000111e:	f403 7378 	and.w	r3, r3, #992	; 0x3e0
70001122:	fa01 f10c 	lsl.w	r1, r1, ip
70001126:	441a      	add	r2, r3
}

static ALWAYS_INLINE void sys_write32(uint32_t data, mem_addr_t addr)
{
	barrier_dmem_fence_full();
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001128:	6011      	str	r1, [r2, #0]

	if (irq_group_num > VIM_MAX_GROUP_NUM) {
7000112a:	f5b0 7f08 	cmp.w	r0, #544	; 0x220
7000112e:	d200      	bcs.n	70001132 <z_vim_irq_get_active+0x46>
		return (CONFIG_NUM_IRQS + 1);
	}

	return (actirq & VIM_ACTIRQ_NUM_MASK);
}
70001130:	4770      	bx	lr
		return CONFIG_NUM_IRQS + 1;
70001132:	f240 2001 	movw	r0, #513	; 0x201
70001136:	4770      	bx	lr

70001138 <z_vim_irq_eoi>:
70001138:	f3bf 8f5f 	dmb	sy
7000113c:	2318      	movs	r3, #24
7000113e:	2200      	movs	r2, #0
70001140:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
70001144:	601a      	str	r2, [r3, #0]

void z_vim_irq_eoi(unsigned int irq)
{
	sys_write32(0, VIM_IRQVEC);
}
70001146:	4770      	bx	lr

70001148 <z_vim_irq_init>:
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001148:	2004      	movs	r0, #4
7000114a:	f6c2 70ff 	movt	r0, #12287	; 0x2fff

void z_vim_irq_init(void)
{
7000114e:	b500      	push	{lr}
70001150:	6800      	ldr	r0, [r0, #0]
70001152:	f3bf 8f5f 	dmb	sy
	uint32_t num_of_irqs = sys_read32(VIM_INFO) & VIM_INFO_INTERRUPTS_MASK;
70001156:	f3c0 000a 	ubfx	r0, r0, #0, #11
	unsigned int irq;

	LOG_DBG("VIM: Number of IRQs = %u\n", num_of_irqs);

	/* make sure all IRQs are initially disabled and cleared */
	for (irq = 0; irq < num_of_irqs; irq+=32)
7000115a:	b1b8      	cbz	r0, 7000118c <z_vim_irq_init+0x44>
	{
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
7000115c:	f240 4e0c 	movw	lr, #1036	; 0x40c
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
70001160:	f240 4c04 	movw	ip, #1028	; 0x404
	for (irq = 0; irq < num_of_irqs; irq+=32)
70001164:	2300      	movs	r3, #0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001166:	f06f 4200 	mvn.w	r2, #2147483648	; 0x80000000
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
7000116a:	f6c2 7eff 	movt	lr, #12287	; 0x2fff
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
7000116e:	f6c2 7cff 	movt	ip, #12287	; 0x2fff
70001172:	f3bf 8f5f 	dmb	sy
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
70001176:	eb03 010e 	add.w	r1, r3, lr
7000117a:	600a      	str	r2, [r1, #0]
7000117c:	f3bf 8f5f 	dmb	sy
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
70001180:	eb03 010c 	add.w	r1, r3, ip
70001184:	600a      	str	r2, [r1, #0]
	for (irq = 0; irq < num_of_irqs; irq+=32)
70001186:	3320      	adds	r3, #32
70001188:	4298      	cmp	r0, r3
7000118a:	d8f2      	bhi.n	70001172 <z_vim_irq_init+0x2a>
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000118c:	2318      	movs	r3, #24
7000118e:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
70001192:	681a      	ldr	r2, [r3, #0]
70001194:	f3bf 8f5f 	dmb	sy
70001198:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000119c:	2200      	movs	r2, #0
7000119e:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700011a0:	231c      	movs	r3, #28
700011a2:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
700011a6:	6819      	ldr	r1, [r3, #0]
700011a8:	f3bf 8f5f 	dmb	sy
700011ac:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700011b0:	601a      	str	r2, [r3, #0]
	/* ACK and clear pending IRQs */
	(void) sys_read32(VIM_IRQVEC);
	sys_write32(0, VIM_IRQVEC);
	(void) sys_read32(VIM_FIQVEC);
	sys_write32(0, VIM_FIQVEC);
}
700011b2:	f85d fb04 	ldr.w	pc, [sp], #4
700011b6:	bf00      	nop

700011b8 <z_vim_irq_priority_set>:

void z_vim_irq_priority_set(unsigned int irq, unsigned int prio, uint32_t flags)
{
	uint32_t irq_group_num, irq_bit_num, regval;

	if (irq > CONFIG_NUM_IRQS || prio > VIM_PRI_INT_MAX ||
700011b8:	290f      	cmp	r1, #15
700011ba:	bf98      	it	ls
700011bc:	f5b0 7f00 	cmpls.w	r0, #512	; 0x200
700011c0:	d824      	bhi.n	7000120c <z_vim_irq_priority_set+0x54>
	    (flags != IRQ_TYPE_EDGE && flags != IRQ_TYPE_LEVEL)) {
700011c2:	1e93      	subs	r3, r2, #2
	if (irq > CONFIG_NUM_IRQS || prio > VIM_PRI_INT_MAX ||
700011c4:	f033 0302 	bics.w	r3, r3, #2
700011c8:	d120      	bne.n	7000120c <z_vim_irq_priority_set+0x54>
700011ca:	f3bf 8f5f 	dmb	sy
		LOG_ERR("%s: Invalid argument irq = %u prio = %u flags = %u\n",
			__func__, irq, prio, flags);
		return;
	}

	sys_write8(prio, VIM_PRI_INT(irq));
700011ce:	f100 6340 	add.w	r3, r0, #201326592	; 0xc000000
700011d2:	f5a3 5370 	sub.w	r3, r3, #15360	; 0x3c00
700011d6:	009b      	lsls	r3, r3, #2
	__asm__ volatile("strb %0, [%1]" : : "r" (data), "r" (addr));
700011d8:	7019      	strb	r1, [r3, #0]

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	regval = sys_read32(VIM_INTTYPE(irq_group_num));
700011da:	f240 431c 	movw	r3, #1052	; 0x41c
700011de:	f020 011f 	bic.w	r1, r0, #31
700011e2:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
700011e6:	440b      	add	r3, r1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700011e8:	6819      	ldr	r1, [r3, #0]
700011ea:	f3bf 8f5f 	dmb	sy

	if (flags == IRQ_TYPE_EDGE) {
		regval |= (BIT(irq_bit_num));
700011ee:	f04f 0c01 	mov.w	ip, #1
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
700011f2:	f000 001f 	and.w	r0, r0, #31
	if (flags == IRQ_TYPE_EDGE) {
700011f6:	2a04      	cmp	r2, #4
		regval |= (BIT(irq_bit_num));
700011f8:	fa0c f000 	lsl.w	r0, ip, r0
700011fc:	bf0c      	ite	eq
700011fe:	ea40 0201 	orreq.w	r2, r0, r1
	} else {
		regval &= ~(BIT(irq_bit_num));
70001202:	ea21 0200 	bicne.w	r2, r1, r0
70001206:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000120a:	601a      	str	r2, [r3, #0]
	}

	sys_write32(regval, VIM_INTTYPE(irq_group_num));
}
7000120c:	4770      	bx	lr
7000120e:	bf00      	nop

70001210 <z_vim_irq_enable>:

void z_vim_irq_enable(unsigned int irq)
{
	uint32_t irq_group_num, irq_bit_num;

	if (irq > CONFIG_NUM_IRQS) {
70001210:	f5b0 7f00 	cmp.w	r0, #512	; 0x200
70001214:	d80d      	bhi.n	70001232 <z_vim_irq_enable+0x22>
70001216:	f3bf 8f5f 	dmb	sy
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	sys_write32(BIT(irq_bit_num), VIM_INTR_EN_SET(irq_group_num));
7000121a:	2201      	movs	r2, #1
7000121c:	f44f 6381 	mov.w	r3, #1032	; 0x408
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
70001220:	f000 011f 	and.w	r1, r0, #31
	sys_write32(BIT(irq_bit_num), VIM_INTR_EN_SET(irq_group_num));
70001224:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
70001228:	f020 001f 	bic.w	r0, r0, #31
7000122c:	408a      	lsls	r2, r1
7000122e:	4403      	add	r3, r0
70001230:	601a      	str	r2, [r3, #0]
}
70001232:	4770      	bx	lr

70001234 <console_out>:
		 * function MUST return the byte output.
		 */
		return c;
	}

	if ('\n' == c) {
70001234:	280a      	cmp	r0, #10
{
70001236:	b538      	push	{r3, r4, r5, lr}
70001238:	4604      	mov	r4, r0
	if ('\n' == c) {
7000123a:	d00d      	beq.n	70001258 <console_out+0x24>
7000123c:	f643 2554 	movw	r5, #14932	; 0x3a54
70001240:	f2c7 0500 	movt	r5, #28672	; 0x7000

static inline void z_impl_uart_poll_out(const struct device *dev, unsigned char out_char)
{
	const struct uart_driver_api *api = (const struct uart_driver_api *)dev->api;

	api->poll_out(dev, out_char);
70001244:	68ab      	ldr	r3, [r5, #8]
70001246:	f643 2054 	movw	r0, #14932	; 0x3a54
7000124a:	b2e1      	uxtb	r1, r4
7000124c:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001250:	685b      	ldr	r3, [r3, #4]
70001252:	4798      	blx	r3
	 * As errors cannot be returned, ignore the return value
	 */
	(void)pm_device_runtime_put_async(uart_console_dev, K_MSEC(1));

	return c;
}
70001254:	4620      	mov	r0, r4
70001256:	bd38      	pop	{r3, r4, r5, pc}
70001258:	f643 2554 	movw	r5, #14932	; 0x3a54
7000125c:	210d      	movs	r1, #13
7000125e:	f2c7 0500 	movt	r5, #28672	; 0x7000
70001262:	4628      	mov	r0, r5
70001264:	68ab      	ldr	r3, [r5, #8]
70001266:	685b      	ldr	r3, [r3, #4]
70001268:	4798      	blx	r3
		return;
	}
#endif
	compiler_barrier();
	z_impl_uart_poll_out(dev, out_char);
}
7000126a:	e7eb      	b.n	70001244 <console_out+0x10>

7000126c <uart_console_init>:
 * @brief Initialize one UART as the console/debug port
 *
 * @return 0 if successful, otherwise failed.
 */
static int uart_console_init(void)
{
7000126c:	b508      	push	{r3, lr}
		union { uintptr_t x; const struct device * val; } parm0 = { .val = dev };
		return (bool) arch_syscall_invoke1(parm0.x, K_SYSCALL_DEVICE_IS_READY);
	}
#endif
	compiler_barrier();
	return z_impl_device_is_ready(dev);
7000126e:	f643 2054 	movw	r0, #14932	; 0x3a54
70001272:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001276:	f000 fbe1 	bl	70001a3c <z_impl_device_is_ready>
	if (!device_is_ready(uart_console_dev)) {
7000127a:	b168      	cbz	r0, 70001298 <uart_console_init+0x2c>
	__stdout_hook_install(console_out);
7000127c:	f241 2035 	movw	r0, #4661	; 0x1235
70001280:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001284:	f7ff ff12 	bl	700010ac <__stdout_hook_install>
	__printk_hook_install(console_out);
70001288:	f241 2035 	movw	r0, #4661	; 0x1235
7000128c:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001290:	f7ff fbae 	bl	700009f0 <__printk_hook_install>
		return -ENODEV;
	}

	uart_console_hook_install();

	return 0;
70001294:	2000      	movs	r0, #0
}
70001296:	bd08      	pop	{r3, pc}
		return -ENODEV;
70001298:	f06f 0012 	mvn.w	r0, #18
}
7000129c:	bd08      	pop	{r3, pc}
7000129e:	bf00      	nop

700012a0 <pinctrl_lookup_state>:
#include <zephyr/drivers/pinctrl.h>

int pinctrl_lookup_state(const struct pinctrl_dev_config *config, uint8_t id,
			 const struct pinctrl_state **state)
{
	*state = &config->states[0];
700012a0:	6803      	ldr	r3, [r0, #0]
700012a2:	6013      	str	r3, [r2, #0]
	while (*state < &config->states[config->state_cnt]) {
700012a4:	f890 c004 	ldrb.w	ip, [r0, #4]
700012a8:	eb03 0ccc 	add.w	ip, r3, ip, lsl #3
700012ac:	4563      	cmp	r3, ip
700012ae:	d21f      	bcs.n	700012f0 <pinctrl_lookup_state+0x50>
		if (id == (*state)->id) {
700012b0:	f893 c005 	ldrb.w	ip, [r3, #5]
700012b4:	458c      	cmp	ip, r1
			return 0;
		}

		(*state)++;
700012b6:	f103 0308 	add.w	r3, r3, #8
		if (id == (*state)->id) {
700012ba:	d017      	beq.n	700012ec <pinctrl_lookup_state+0x4c>
{
700012bc:	b500      	push	{lr}
700012be:	e005      	b.n	700012cc <pinctrl_lookup_state+0x2c>
		if (id == (*state)->id) {
700012c0:	f893 c005 	ldrb.w	ip, [r3, #5]
700012c4:	458c      	cmp	ip, r1
		(*state)++;
700012c6:	f103 0308 	add.w	r3, r3, #8
		if (id == (*state)->id) {
700012ca:	d00c      	beq.n	700012e6 <pinctrl_lookup_state+0x46>
		(*state)++;
700012cc:	6013      	str	r3, [r2, #0]
	while (*state < &config->states[config->state_cnt]) {
700012ce:	f890 c004 	ldrb.w	ip, [r0, #4]
700012d2:	f8d0 e000 	ldr.w	lr, [r0]
700012d6:	eb0e 0ccc 	add.w	ip, lr, ip, lsl #3
700012da:	4563      	cmp	r3, ip
700012dc:	d3f0      	bcc.n	700012c0 <pinctrl_lookup_state+0x20>
	}

	return -ENOENT;
700012de:	f06f 0001 	mvn.w	r0, #1
}
700012e2:	f85d fb04 	ldr.w	pc, [sp], #4
			return 0;
700012e6:	2000      	movs	r0, #0
}
700012e8:	f85d fb04 	ldr.w	pc, [sp], #4
			return 0;
700012ec:	2000      	movs	r0, #0
}
700012ee:	4770      	bx	lr
	return -ENOENT;
700012f0:	f06f 0001 	mvn.w	r0, #1
700012f4:	4770      	bx	lr
700012f6:	bf00      	nop

700012f8 <pinctrl_ti_k3_init>:

static int pinctrl_ti_k3_init(const struct device *dev)
{
	DEVICE_MMIO_MAP(dev, K_MEM_CACHE_NONE);
	return 0;
}
700012f8:	2000      	movs	r0, #0
700012fa:	4770      	bx	lr

700012fc <pinctrl_configure_pins>:
	uintptr_t virt_reg_base = DEVICE_MMIO_GET(dev);
700012fc:	f24b 03a0 	movw	r3, #45216	; 0xb0a0
70001300:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
70001304:	b410      	push	{r4}
	uintptr_t virt_reg_base = DEVICE_MMIO_GET(dev);
70001306:	681c      	ldr	r4, [r3, #0]
	for (uint8_t i = 0; i < pin_cnt; i++) {
70001308:	b151      	cbz	r1, 70001320 <pinctrl_configure_pins+0x24>
7000130a:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
		sys_write32(pins[i].value, virt_reg_base + pins[i].offset);
7000130e:	6842      	ldr	r2, [r0, #4]
70001310:	f850 3b08 	ldr.w	r3, [r0], #8
70001314:	4423      	add	r3, r4
70001316:	f3bf 8f5f 	dmb	sy
7000131a:	601a      	str	r2, [r3, #0]
	for (uint8_t i = 0; i < pin_cnt; i++) {
7000131c:	4288      	cmp	r0, r1
7000131e:	d1f6      	bne.n	7000130e <pinctrl_configure_pins+0x12>
}
70001320:	bc10      	pop	{r4}
70001322:	2000      	movs	r0, #0
70001324:	4770      	bx	lr
70001326:	bf00      	nop

70001328 <uart_ns16550_config_get>:
};

#ifdef CONFIG_UART_USE_RUNTIME_CONFIGURE
static int uart_ns16550_config_get(const struct device *dev,
				   struct uart_config *cfg)
{
70001328:	4603      	mov	r3, r0
	cfg->stop_bits = data->uart_config.stop_bits;
	cfg->data_bits = data->uart_config.data_bits;
	cfg->flow_ctrl = data->uart_config.flow_ctrl;

	return 0;
}
7000132a:	2000      	movs	r0, #0
	struct uart_ns16550_dev_data *data = dev->data;
7000132c:	691b      	ldr	r3, [r3, #16]
	cfg->baudrate = data->uart_config.baudrate;
7000132e:	681a      	ldr	r2, [r3, #0]
70001330:	600a      	str	r2, [r1, #0]
	cfg->parity = data->uart_config.parity;
70001332:	791a      	ldrb	r2, [r3, #4]
70001334:	710a      	strb	r2, [r1, #4]
	cfg->stop_bits = data->uart_config.stop_bits;
70001336:	795a      	ldrb	r2, [r3, #5]
70001338:	714a      	strb	r2, [r1, #5]
	cfg->data_bits = data->uart_config.data_bits;
7000133a:	799a      	ldrb	r2, [r3, #6]
7000133c:	718a      	strb	r2, [r1, #6]
	cfg->flow_ctrl = data->uart_config.flow_ctrl;
7000133e:	79db      	ldrb	r3, [r3, #7]
70001340:	71cb      	strb	r3, [r1, #7]
}
70001342:	4770      	bx	lr

70001344 <uart_ns16550_poll_out>:
 * @param dev UART device struct
 * @param c Character to send
 */
static void uart_ns16550_poll_out(const struct device *dev,
					   unsigned char c)
{
70001344:	b410      	push	{r4}
	key = __get_BASEPRI();
	__set_BASEPRI_MAX(_EXC_IRQ_DEFAULT_PRIO);
	__ISB();
#elif defined(CONFIG_ARMV7_R) || defined(CONFIG_AARCH32_ARMV8_R) \
	|| defined(CONFIG_ARMV7_A)
	__asm__ volatile(
70001346:	f3ef 8400 	mrs	r4, CPSR
7000134a:	f004 0480 	and.w	r4, r4, #128	; 0x80
7000134e:	b672      	cpsid	i
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	while ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_THRE) == 0) {
70001350:	f04f 0c05 	mov.w	ip, #5
		port = DEVICE_MMIO_GET(dev);
70001354:	6842      	ldr	r2, [r0, #4]
	while ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_THRE) == 0) {
70001356:	7d13      	ldrb	r3, [r2, #20]
70001358:	6812      	ldr	r2, [r2, #0]
7000135a:	fb1c 2303 	smlabb	r3, ip, r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000135e:	681b      	ldr	r3, [r3, #0]
70001360:	f3bf 8f5f 	dmb	sy
70001364:	069b      	lsls	r3, r3, #26
70001366:	d5f5      	bpl.n	70001354 <uart_ns16550_poll_out+0x10>
		port = DEVICE_MMIO_GET(dev);
70001368:	6843      	ldr	r3, [r0, #4]
7000136a:	681b      	ldr	r3, [r3, #0]
7000136c:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001370:	6019      	str	r1, [r3, #0]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	__set_BASEPRI(key);
	__ISB();
#elif defined(CONFIG_ARMV7_R) || defined(CONFIG_AARCH32_ARMV8_R) \
	|| defined(CONFIG_ARMV7_A)
	if (key != 0U) {
70001372:	b904      	cbnz	r4, 70001376 <uart_ns16550_poll_out+0x32>
  \details Enables IRQ interrupts by clearing the I-bit in the CPSR.
           Can only be executed in Privileged modes.
 */
__STATIC_FORCEINLINE void __enable_irq(void)
{
  __ASM volatile ("cpsie i" : : : "memory");
70001374:	b662      	cpsie	i
	}

	ns16550_outbyte(dev_cfg, THR(dev), c);

	k_spin_unlock(&data->lock, key);
}
70001376:	bc10      	pop	{r4}
70001378:	4770      	bx	lr
7000137a:	bf00      	nop

7000137c <uart_ns16550_err_check>:
	__asm__ volatile(
7000137c:	f3ef 8200 	mrs	r2, CPSR
70001380:	f002 0280 	and.w	r2, r2, #128	; 0x80
70001384:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70001386:	6843      	ldr	r3, [r0, #4]
static int uart_ns16550_err_check(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);
	int check = (ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_EOB_MASK);
70001388:	7d19      	ldrb	r1, [r3, #20]
7000138a:	2005      	movs	r0, #5
7000138c:	681b      	ldr	r3, [r3, #0]
7000138e:	fb10 3001 	smlabb	r0, r0, r1, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001392:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001394:	f3bf 8f5f 	dmb	sy
	if (key != 0U) {
70001398:	b902      	cbnz	r2, 7000139c <uart_ns16550_err_check+0x20>
  __ASM volatile ("cpsie i" : : : "memory");
7000139a:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return check >> 1;
}
7000139c:	f3c0 0043 	ubfx	r0, r0, #1, #4
700013a0:	4770      	bx	lr
700013a2:	bf00      	nop

700013a4 <uart_ns16550_fifo_fill>:
 * @return Number of bytes sent
 */
static int uart_ns16550_fifo_fill(const struct device *dev,
				  const uint8_t *tx_data,
				  int size)
{
700013a4:	b470      	push	{r4, r5, r6}
	struct uart_ns16550_dev_data *data = dev->data;
700013a6:	6905      	ldr	r5, [r0, #16]
	__asm__ volatile(
700013a8:	f3ef 8600 	mrs	r6, CPSR
700013ac:	f006 0680 	and.w	r6, r6, #128	; 0x80
700013b0:	b672      	cpsid	i
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	int i;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
700013b2:	2a00      	cmp	r2, #0
700013b4:	dd15      	ble.n	700013e2 <uart_ns16550_fifo_fill+0x3e>
700013b6:	4684      	mov	ip, r0
700013b8:	3901      	subs	r1, #1
700013ba:	2000      	movs	r0, #0
700013bc:	e00a      	b.n	700013d4 <uart_ns16550_fifo_fill+0x30>
		port = DEVICE_MMIO_GET(dev);
700013be:	f8dc 4004 	ldr.w	r4, [ip, #4]
			sys_write32(val, port);
700013c2:	f811 3f01 	ldrb.w	r3, [r1, #1]!
		port = DEVICE_MMIO_GET(dev);
700013c6:	6824      	ldr	r4, [r4, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700013c8:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700013cc:	6023      	str	r3, [r4, #0]
	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
700013ce:	3001      	adds	r0, #1
700013d0:	4282      	cmp	r2, r0
700013d2:	d002      	beq.n	700013da <uart_ns16550_fifo_fill+0x36>
700013d4:	7a2b      	ldrb	r3, [r5, #8]
700013d6:	4283      	cmp	r3, r0
700013d8:	dcf1      	bgt.n	700013be <uart_ns16550_fifo_fill+0x1a>
	if (key != 0U) {
700013da:	b906      	cbnz	r6, 700013de <uart_ns16550_fifo_fill+0x3a>
  __ASM volatile ("cpsie i" : : : "memory");
700013dc:	b662      	cpsie	i
	}

	k_spin_unlock(&data->lock, key);

	return i;
}
700013de:	bc70      	pop	{r4, r5, r6}
700013e0:	4770      	bx	lr
	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
700013e2:	2000      	movs	r0, #0
700013e4:	e7f9      	b.n	700013da <uart_ns16550_fifo_fill+0x36>
700013e6:	bf00      	nop

700013e8 <uart_ns16550_irq_tx_enable>:
	__asm__ volatile(
700013e8:	f3ef 8100 	mrs	r1, CPSR
700013ec:	f001 0180 	and.w	r1, r1, #128	; 0x80
700013f0:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700013f2:	6843      	ldr	r3, [r0, #4]
		for (uint8_t i = 0U; i < num_cpu_states; i++) {
			pm_policy_state_lock_get(cpu_states[i].state, PM_ALL_SUBSTATES);
		}
	}
#endif
	ns16550_outbyte(dev_cfg, IER(dev), ns16550_inbyte(dev_cfg, IER(dev)) | IER_TBE);
700013f4:	7d1a      	ldrb	r2, [r3, #20]
700013f6:	681b      	ldr	r3, [r3, #0]
700013f8:	441a      	add	r2, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700013fa:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700013fc:	f3bf 8f5f 	dmb	sy
70001400:	f3bf 8f5f 	dmb	sy
70001404:	f043 0302 	orr.w	r3, r3, #2
			sys_write32(val, port);
70001408:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000140a:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
7000140c:	b901      	cbnz	r1, 70001410 <uart_ns16550_irq_tx_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
7000140e:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);
}
70001410:	4770      	bx	lr
70001412:	bf00      	nop

70001414 <uart_ns16550_irq_tx_disable>:
	__asm__ volatile(
70001414:	f3ef 8100 	mrs	r1, CPSR
70001418:	f001 0180 	and.w	r1, r1, #128	; 0x80
7000141c:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000141e:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
70001420:	7d13      	ldrb	r3, [r2, #20]
70001422:	6812      	ldr	r2, [r2, #0]
70001424:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001426:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001428:	f3bf 8f5f 	dmb	sy
7000142c:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
70001430:	f002 02fd 	and.w	r2, r2, #253	; 0xfd
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001434:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
70001436:	b901      	cbnz	r1, 7000143a <uart_ns16550_irq_tx_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
70001438:	b662      	cpsie	i
			pm_policy_state_lock_put(cpu_states[i].state, PM_ALL_SUBSTATES);
		}
	}
#endif
	k_spin_unlock(&data->lock, key);
}
7000143a:	4770      	bx	lr

7000143c <uart_ns16550_irq_tx_ready>:
	__asm__ volatile(
7000143c:	f3ef 8300 	mrs	r3, CPSR
70001440:	f003 0380 	and.w	r3, r3, #128	; 0x80
70001444:	b672      	cpsid	i
static int uart_ns16550_irq_tx_ready(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((IIRC(dev) & IIR_ID) == IIR_THRE) ? 1 : 0;
70001446:	6902      	ldr	r2, [r0, #16]
70001448:	7a50      	ldrb	r0, [r2, #9]
7000144a:	f000 0006 	and.w	r0, r0, #6
7000144e:	f1a0 0002 	sub.w	r0, r0, #2
70001452:	fab0 f080 	clz	r0, r0
70001456:	0940      	lsrs	r0, r0, #5
	if (key != 0U) {
70001458:	b903      	cbnz	r3, 7000145c <uart_ns16550_irq_tx_ready+0x20>
7000145a:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
7000145c:	4770      	bx	lr
7000145e:	bf00      	nop

70001460 <uart_ns16550_irq_tx_complete>:
	__asm__ volatile(
70001460:	f3ef 8200 	mrs	r2, CPSR
70001464:	f002 0280 	and.w	r2, r2, #128	; 0x80
70001468:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000146a:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((ns16550_inbyte(dev_cfg, LSR(dev)) & (LSR_TEMT | LSR_THRE))
7000146c:	7d19      	ldrb	r1, [r3, #20]
7000146e:	2005      	movs	r0, #5
70001470:	681b      	ldr	r3, [r3, #0]
70001472:	fb10 3001 	smlabb	r0, r0, r1, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001476:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001478:	f3bf 8f5f 	dmb	sy
				== (LSR_TEMT | LSR_THRE)) ? 1 : 0;
7000147c:	f000 0060 	and.w	r0, r0, #96	; 0x60
70001480:	f1a0 0060 	sub.w	r0, r0, #96	; 0x60
70001484:	fab0 f080 	clz	r0, r0
70001488:	0940      	lsrs	r0, r0, #5
	if (key != 0U) {
7000148a:	b902      	cbnz	r2, 7000148e <uart_ns16550_irq_tx_complete+0x2e>
  __ASM volatile ("cpsie i" : : : "memory");
7000148c:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
7000148e:	4770      	bx	lr

70001490 <uart_ns16550_irq_rx_enable>:
	__asm__ volatile(
70001490:	f3ef 8100 	mrs	r1, CPSR
70001494:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001498:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000149a:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev), ns16550_inbyte(dev_cfg, IER(dev)) | IER_RXRDY);
7000149c:	7d1a      	ldrb	r2, [r3, #20]
7000149e:	681b      	ldr	r3, [r3, #0]
700014a0:	441a      	add	r2, r3
700014a2:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700014a4:	f3bf 8f5f 	dmb	sy
700014a8:	f3bf 8f5f 	dmb	sy
700014ac:	f043 0301 	orr.w	r3, r3, #1
			sys_write32(val, port);
700014b0:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700014b2:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
700014b4:	b901      	cbnz	r1, 700014b8 <uart_ns16550_irq_rx_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
700014b6:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);
}
700014b8:	4770      	bx	lr
700014ba:	bf00      	nop

700014bc <uart_ns16550_irq_rx_disable>:
	__asm__ volatile(
700014bc:	f3ef 8100 	mrs	r1, CPSR
700014c0:	f001 0180 	and.w	r1, r1, #128	; 0x80
700014c4:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700014c6:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
700014c8:	7d13      	ldrb	r3, [r2, #20]
700014ca:	6812      	ldr	r2, [r2, #0]
700014cc:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700014ce:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700014d0:	f3bf 8f5f 	dmb	sy
700014d4:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
700014d8:	f002 02fe 	and.w	r2, r2, #254	; 0xfe
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700014dc:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
700014de:	b901      	cbnz	r1, 700014e2 <uart_ns16550_irq_rx_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
700014e0:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) & (~IER_RXRDY));

	k_spin_unlock(&data->lock, key);
}
700014e2:	4770      	bx	lr

700014e4 <uart_ns16550_irq_rx_ready>:
	__asm__ volatile(
700014e4:	f3ef 8300 	mrs	r3, CPSR
700014e8:	f003 0380 	and.w	r3, r3, #128	; 0x80
700014ec:	b672      	cpsid	i
static int uart_ns16550_irq_rx_ready(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((IIRC(dev) & IIR_ID) == IIR_RBRF) ? 1 : 0;
700014ee:	6902      	ldr	r2, [r0, #16]
700014f0:	7a50      	ldrb	r0, [r2, #9]
700014f2:	f000 0006 	and.w	r0, r0, #6
700014f6:	f1a0 0004 	sub.w	r0, r0, #4
700014fa:	fab0 f080 	clz	r0, r0
700014fe:	0940      	lsrs	r0, r0, #5
	if (key != 0U) {
70001500:	b903      	cbnz	r3, 70001504 <uart_ns16550_irq_rx_ready+0x20>
70001502:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
70001504:	4770      	bx	lr
70001506:	bf00      	nop

70001508 <uart_ns16550_irq_err_enable>:
	__asm__ volatile(
70001508:	f3ef 8100 	mrs	r1, CPSR
7000150c:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001510:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70001512:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
70001514:	7d1a      	ldrb	r2, [r3, #20]
70001516:	681b      	ldr	r3, [r3, #0]
70001518:	441a      	add	r2, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000151a:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
7000151c:	f3bf 8f5f 	dmb	sy
70001520:	f3bf 8f5f 	dmb	sy
70001524:	f043 0304 	orr.w	r3, r3, #4
			sys_write32(val, port);
70001528:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000152a:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
7000152c:	b901      	cbnz	r1, 70001530 <uart_ns16550_irq_err_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
7000152e:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) | IER_LSR);

	k_spin_unlock(&data->lock, key);
}
70001530:	4770      	bx	lr
70001532:	bf00      	nop

70001534 <uart_ns16550_irq_err_disable>:
	__asm__ volatile(
70001534:	f3ef 8100 	mrs	r1, CPSR
70001538:	f001 0180 	and.w	r1, r1, #128	; 0x80
7000153c:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000153e:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
70001540:	7d13      	ldrb	r3, [r2, #20]
70001542:	6812      	ldr	r2, [r2, #0]
70001544:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001546:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001548:	f3bf 8f5f 	dmb	sy
7000154c:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
70001550:	f002 02fb 	and.w	r2, r2, #251	; 0xfb
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001554:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
70001556:	b901      	cbnz	r1, 7000155a <uart_ns16550_irq_err_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
70001558:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) & (~IER_LSR));

	k_spin_unlock(&data->lock, key);
}
7000155a:	4770      	bx	lr

7000155c <uart_ns16550_irq_is_pending>:
	__asm__ volatile(
7000155c:	f3ef 8300 	mrs	r3, CPSR
70001560:	f003 0380 	and.w	r3, r3, #128	; 0x80
70001564:	b672      	cpsid	i
static int uart_ns16550_irq_is_pending(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = (!(IIRC(dev) & IIR_NIP)) ? 1 : 0;
70001566:	6902      	ldr	r2, [r0, #16]
70001568:	7a50      	ldrb	r0, [r2, #9]
7000156a:	43c0      	mvns	r0, r0
7000156c:	f000 0001 	and.w	r0, r0, #1
	if (key != 0U) {
70001570:	b903      	cbnz	r3, 70001574 <uart_ns16550_irq_is_pending+0x18>
70001572:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
70001574:	4770      	bx	lr
70001576:	bf00      	nop

70001578 <uart_ns16550_irq_update>:
	__asm__ volatile(
70001578:	f3ef 8200 	mrs	r2, CPSR
7000157c:	f002 0280 	and.w	r2, r2, #128	; 0x80
70001580:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70001582:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	IIRC(dev) = ns16550_inbyte(dev_cfg, IIR(dev));
70001584:	6901      	ldr	r1, [r0, #16]
70001586:	7d18      	ldrb	r0, [r3, #20]
70001588:	681b      	ldr	r3, [r3, #0]
7000158a:	eb03 0340 	add.w	r3, r3, r0, lsl #1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000158e:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001590:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
70001594:	724b      	strb	r3, [r1, #9]
	if (key != 0U) {
70001596:	b902      	cbnz	r2, 7000159a <uart_ns16550_irq_update+0x22>
  __ASM volatile ("cpsie i" : : : "memory");
70001598:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return 1;
}
7000159a:	2001      	movs	r0, #1
7000159c:	4770      	bx	lr
7000159e:	bf00      	nop

700015a0 <uart_ns16550_irq_callback_set>:
 */
static void uart_ns16550_irq_callback_set(const struct device *dev,
					  uart_irq_callback_user_data_t cb,
					  void *cb_data)
{
	struct uart_ns16550_dev_data * const dev_data = dev->data;
700015a0:	6903      	ldr	r3, [r0, #16]
	__asm__ volatile(
700015a2:	f3ef 8000 	mrs	r0, CPSR
700015a6:	f000 0080 	and.w	r0, r0, #128	; 0x80
700015aa:	b672      	cpsid	i
	k_spinlock_key_t key = k_spin_lock(&dev_data->lock);

	dev_data->cb = cb;
	dev_data->cb_data = cb_data;
700015ac:	e9c3 1203 	strd	r1, r2, [r3, #12]
	if (key != 0U) {
700015b0:	b900      	cbnz	r0, 700015b4 <uart_ns16550_irq_callback_set+0x14>
700015b2:	b662      	cpsie	i

	k_spin_unlock(&dev_data->lock, key);
}
700015b4:	4770      	bx	lr
700015b6:	bf00      	nop

700015b8 <uart_ns16550_isr>:
 *
 * @param arg Argument to ISR.
 */
static void uart_ns16550_isr(const struct device *dev)
{
	struct uart_ns16550_dev_data * const dev_data = dev->data;
700015b8:	6902      	ldr	r2, [r0, #16]
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;

	if (dev_data->cb) {
700015ba:	68d3      	ldr	r3, [r2, #12]
700015bc:	b10b      	cbz	r3, 700015c2 <uart_ns16550_isr+0xa>
		dev_data->cb(dev, dev_data->cb_data);
700015be:	6911      	ldr	r1, [r2, #16]
700015c0:	4718      	bx	r3
	uint8_t cached_ier = ns16550_inbyte(dev_cfg, IER(dev));

	ns16550_outbyte(dev_cfg, IER(dev), 0U);
	ns16550_outbyte(dev_cfg, IER(dev), cached_ier);
#endif
}
700015c2:	4770      	bx	lr

700015c4 <uart_ns16550_irq_config_func0>:
#define UART_NS16550_DEVICE_INIT(n)                                                  \
	COND_CODE_1(DT_INST_ON_BUS(n, pcie),                                         \
		    (UART_NS16550_DEVICE_PCIE_INIT(n)),                              \
		    (UART_NS16550_DEVICE_IO_MMIO_INIT(n)))

DT_INST_FOREACH_STATUS_OKAY(UART_NS16550_DEVICE_INIT)
700015c4:	20d2      	movs	r0, #210	; 0xd2
700015c6:	2200      	movs	r2, #0
700015c8:	b508      	push	{r3, lr}
700015ca:	210f      	movs	r1, #15
700015cc:	f7ff fa46 	bl	70000a5c <z_soc_irq_priority_set>
700015d0:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
700015d4:	20d2      	movs	r0, #210	; 0xd2
700015d6:	f7ff ba43 	b.w	70000a60 <z_soc_irq_enable>
700015da:	bf00      	nop

700015dc <uart_ns16550_configure>:
{
700015dc:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
	uint32_t pclk = 0U;
700015e0:	f04f 0900 	mov.w	r9, #0
{
700015e4:	b083      	sub	sp, #12
	struct uart_ns16550_dev_data * const dev_data = dev->data;
700015e6:	6906      	ldr	r6, [r0, #16]
{
700015e8:	4604      	mov	r4, r0
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
700015ea:	f8d0 8004 	ldr.w	r8, [r0, #4]
{
700015ee:	460d      	mov	r5, r1
	uint32_t pclk = 0U;
700015f0:	f8cd 9000 	str.w	r9, [sp]
	__asm__ volatile(
700015f4:	f3ef 8700 	mrs	r7, CPSR
700015f8:	f007 0780 	and.w	r7, r7, #128	; 0x80
700015fc:	b672      	cpsid	i
	if (dev_cfg->pincfg != NULL) {
700015fe:	f8d8 0018 	ldr.w	r0, [r8, #24]
70001602:	b158      	cbz	r0, 7000161c <uart_ns16550_configure+0x40>
				      uint8_t id)
{
	int ret;
	const struct pinctrl_state *state;

	ret = pinctrl_lookup_state(config, id, &state);
70001604:	4649      	mov	r1, r9
70001606:	aa01      	add	r2, sp, #4
70001608:	f7ff fe4a 	bl	700012a0 <pinctrl_lookup_state>
	if (ret < 0) {
7000160c:	4548      	cmp	r0, r9
7000160e:	db05      	blt.n	7000161c <uart_ns16550_configure+0x40>
		return ret;
	}

	return pinctrl_apply_state_direct(config, state);
70001610:	9b01      	ldr	r3, [sp, #4]
	return pinctrl_configure_pins(state->pins, state->pin_cnt, reg);
70001612:	464a      	mov	r2, r9
70001614:	7919      	ldrb	r1, [r3, #4]
70001616:	6818      	ldr	r0, [r3, #0]
70001618:	f7ff fe70 	bl	700012fc <pinctrl_configure_pins>
	dev_data->iir_cache = 0U;
7000161c:	2300      	movs	r3, #0
	uint32_t mdr = ns16550_inbyte(dev_cfg, MDR1(dev));
7000161e:	2208      	movs	r2, #8
	dev_data->iir_cache = 0U;
70001620:	7273      	strb	r3, [r6, #9]
		port = DEVICE_MMIO_GET(dev);
70001622:	6861      	ldr	r1, [r4, #4]
	uint32_t mdr = ns16550_inbyte(dev_cfg, MDR1(dev));
70001624:	7d0b      	ldrb	r3, [r1, #20]
70001626:	6809      	ldr	r1, [r1, #0]
70001628:	fb12 1303 	smlabb	r3, r2, r3, r1
7000162c:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
7000162e:	f3bf 8f5f 	dmb	sy
		port = DEVICE_MMIO_GET(dev);
70001632:	6861      	ldr	r1, [r4, #4]
	ns16550_outbyte(dev_cfg, MDR1(dev), mdr);
70001634:	7d08      	ldrb	r0, [r1, #20]
70001636:	6809      	ldr	r1, [r1, #0]
70001638:	fb12 1200 	smlabb	r2, r2, r0, r1
7000163c:	f3bf 8f5f 	dmb	sy
	mdr = ((mdr & ~MDR1_MODE_SELECT_FIELD_MASK) | ((((MDR1_STD_MODE) <<
70001640:	f003 03f8 	and.w	r3, r3, #248	; 0xf8
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001644:	6013      	str	r3, [r2, #0]
	if (dev_cfg->sys_clk_freq != 0U) {
70001646:	f8d8 3004 	ldr.w	r3, [r8, #4]
7000164a:	2b00      	cmp	r3, #0
7000164c:	f000 80ad 	beq.w	700017aa <uart_ns16550_configure+0x1ce>
		pclk = dev_cfg->sys_clk_freq;
70001650:	9300      	str	r3, [sp, #0]
	set_baud_rate(dev, cfg->baudrate, pclk);
70001652:	6829      	ldr	r1, [r5, #0]
	if ((baud_rate != 0U) && (pclk != 0U)) {
70001654:	2900      	cmp	r1, #0
70001656:	bf18      	it	ne
70001658:	2b00      	cmpne	r3, #0
7000165a:	d168      	bne.n	7000172e <uart_ns16550_configure+0x152>
	switch (cfg->data_bits) {
7000165c:	79aa      	ldrb	r2, [r5, #6]
7000165e:	2a03      	cmp	r2, #3
70001660:	d862      	bhi.n	70001728 <uart_ns16550_configure+0x14c>
	switch (cfg->stop_bits) {
70001662:	796b      	ldrb	r3, [r5, #5]
70001664:	2b01      	cmp	r3, #1
70001666:	f000 80af 	beq.w	700017c8 <uart_ns16550_configure+0x1ec>
7000166a:	2b03      	cmp	r3, #3
7000166c:	bf08      	it	eq
7000166e:	f04f 0e04 	moveq.w	lr, #4
70001672:	d159      	bne.n	70001728 <uart_ns16550_configure+0x14c>
	switch (cfg->parity) {
70001674:	792b      	ldrb	r3, [r5, #4]
70001676:	b113      	cbz	r3, 7000167e <uart_ns16550_configure+0xa2>
70001678:	2b02      	cmp	r3, #2
7000167a:	d155      	bne.n	70001728 <uart_ns16550_configure+0x14c>
7000167c:	2310      	movs	r3, #16
	dev_data->uart_config = *cfg;
7000167e:	e895 0003 	ldmia.w	r5, {r0, r1}
	ns16550_outbyte(dev_cfg, LCR(dev),
70001682:	f04f 0c03 	mov.w	ip, #3
	dev_data->uart_config = *cfg;
70001686:	e886 0003 	stmia.w	r6, {r0, r1}
		port = DEVICE_MMIO_GET(dev);
7000168a:	6861      	ldr	r1, [r4, #4]
	ns16550_outbyte(dev_cfg, LCR(dev),
7000168c:	7d08      	ldrb	r0, [r1, #20]
7000168e:	6809      	ldr	r1, [r1, #0]
70001690:	fb1c 1c00 	smlabb	ip, ip, r0, r1
70001694:	f3bf 8f5f 	dmb	sy
70001698:	ea42 020e 	orr.w	r2, r2, lr
			sys_write32(val, port);
7000169c:	4313      	orrs	r3, r2
7000169e:	f8cc 3000 	str.w	r3, [ip]
		port = DEVICE_MMIO_GET(dev);
700016a2:	6862      	ldr	r2, [r4, #4]
	if (cfg->flow_ctrl == UART_CFG_FLOW_CTRL_RTS_CTS) {
700016a4:	79eb      	ldrb	r3, [r5, #7]
700016a6:	2b01      	cmp	r3, #1
700016a8:	bf0c      	ite	eq
700016aa:	212b      	moveq	r1, #43	; 0x2b
700016ac:	210b      	movne	r1, #11
	ns16550_outbyte(dev_cfg, MDC(dev), mdc);
700016ae:	6813      	ldr	r3, [r2, #0]
700016b0:	7d12      	ldrb	r2, [r2, #20]
700016b2:	eb03 0382 	add.w	r3, r3, r2, lsl #2
700016b6:	f3bf 8f5f 	dmb	sy
700016ba:	6019      	str	r1, [r3, #0]
		port = DEVICE_MMIO_GET(dev);
700016bc:	6863      	ldr	r3, [r4, #4]
	ns16550_outbyte(dev_cfg, FCR(dev),
700016be:	7d1a      	ldrb	r2, [r3, #20]
700016c0:	6819      	ldr	r1, [r3, #0]
700016c2:	2302      	movs	r3, #2
700016c4:	fb13 1202 	smlabb	r2, r3, r2, r1
700016c8:	f3bf 8f5f 	dmb	sy
700016cc:	21a7      	movs	r1, #167	; 0xa7
700016ce:	6011      	str	r1, [r2, #0]
		port = DEVICE_MMIO_GET(dev);
700016d0:	6862      	ldr	r2, [r4, #4]
	if ((ns16550_inbyte(dev_cfg, IIR(dev)) & IIR_FE) == IIR_FE) {
700016d2:	7d11      	ldrb	r1, [r2, #20]
700016d4:	6812      	ldr	r2, [r2, #0]
700016d6:	fb13 2301 	smlabb	r3, r3, r1, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700016da:	681b      	ldr	r3, [r3, #0]
700016dc:	f3bf 8f5f 	dmb	sy
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
700016e0:	2205      	movs	r2, #5
	if ((ns16550_inbyte(dev_cfg, IIR(dev)) & IIR_FE) == IIR_FE) {
700016e2:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
		dev_data->fifo_size = 64;
700016e6:	2bc0      	cmp	r3, #192	; 0xc0
700016e8:	bf14      	ite	ne
700016ea:	2301      	movne	r3, #1
700016ec:	2340      	moveq	r3, #64	; 0x40
700016ee:	7233      	strb	r3, [r6, #8]
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
700016f0:	6863      	ldr	r3, [r4, #4]
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
700016f2:	7d19      	ldrb	r1, [r3, #20]
700016f4:	681b      	ldr	r3, [r3, #0]
700016f6:	fb12 3301 	smlabb	r3, r2, r1, r3
700016fa:	681b      	ldr	r3, [r3, #0]
700016fc:	f3bf 8f5f 	dmb	sy
70001700:	07db      	lsls	r3, r3, #31
70001702:	d504      	bpl.n	7000170e <uart_ns16550_configure+0x132>
		port = DEVICE_MMIO_GET(dev);
70001704:	6863      	ldr	r3, [r4, #4]
70001706:	681b      	ldr	r3, [r3, #0]
70001708:	681b      	ldr	r3, [r3, #0]
7000170a:	f3bf 8f5f 	dmb	sy
7000170e:	6862      	ldr	r2, [r4, #4]
	ns16550_outbyte(dev_cfg, IER(dev), 0x00);
70001710:	7d13      	ldrb	r3, [r2, #20]
70001712:	6812      	ldr	r2, [r2, #0]
70001714:	4413      	add	r3, r2
70001716:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000171a:	2000      	movs	r0, #0
7000171c:	6018      	str	r0, [r3, #0]
	if (key != 0U) {
7000171e:	b907      	cbnz	r7, 70001722 <uart_ns16550_configure+0x146>
  __ASM volatile ("cpsie i" : : : "memory");
70001720:	b662      	cpsie	i
};
70001722:	b003      	add	sp, #12
70001724:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	switch (cfg->parity) {
70001728:	f06f 0085 	mvn.w	r0, #133	; 0x85
7000172c:	e7f7      	b.n	7000171e <uart_ns16550_configure+0x142>
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
7000172e:	6860      	ldr	r0, [r4, #4]
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
70001730:	7d02      	ldrb	r2, [r0, #20]
70001732:	f04f 0c03 	mov.w	ip, #3
	return ((pclk + (baud_rate << 3)) / baud_rate) >> 4;
70001736:	eb03 03c1 	add.w	r3, r3, r1, lsl #3
	struct uart_ns16550_dev_data * const dev_data = dev->data;
7000173a:	f8d4 e010 	ldr.w	lr, [r4, #16]
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
7000173e:	6800      	ldr	r0, [r0, #0]
	return ((pclk + (baud_rate << 3)) / baud_rate) >> 4;
70001740:	fbb3 f3f1 	udiv	r3, r3, r1
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
70001744:	fb1c 0202 	smlabb	r2, ip, r2, r0
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001748:	6812      	ldr	r2, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
7000174a:	f3bf 8f5f 	dmb	sy
		port = DEVICE_MMIO_GET(dev);
7000174e:	6860      	ldr	r0, [r4, #4]
		ns16550_outbyte(dev_cfg, LCR(dev), LCR_DLAB | lcr_cache);
70001750:	f890 8014 	ldrb.w	r8, [r0, #20]
70001754:	6800      	ldr	r0, [r0, #0]
70001756:	fb1c 0808 	smlabb	r8, ip, r8, r0
7000175a:	f3bf 8f5f 	dmb	sy
7000175e:	f062 007f 	orn	r0, r2, #127	; 0x7f
			sys_write32(val, port);
70001762:	b2c0      	uxtb	r0, r0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001764:	f8c8 0000 	str.w	r0, [r8]
		port = DEVICE_MMIO_GET(dev);
70001768:	6860      	ldr	r0, [r4, #4]
7000176a:	f8d0 8000 	ldr.w	r8, [r0]
7000176e:	f3bf 8f5f 	dmb	sy
70001772:	f3c3 1007 	ubfx	r0, r3, #4, #8
70001776:	f8c8 0000 	str.w	r0, [r8]
7000177a:	f8d4 8004 	ldr.w	r8, [r4, #4]
		ns16550_outbyte(dev_cfg, BRDH(dev), (unsigned char)((divisor >> 8) & 0xff));
7000177e:	f898 0014 	ldrb.w	r0, [r8, #20]
70001782:	f8d8 8000 	ldr.w	r8, [r8]
70001786:	4440      	add	r0, r8
70001788:	f3bf 8f5f 	dmb	sy
7000178c:	f3c3 3307 	ubfx	r3, r3, #12, #8
70001790:	6003      	str	r3, [r0, #0]
		port = DEVICE_MMIO_GET(dev);
70001792:	6863      	ldr	r3, [r4, #4]
		ns16550_outbyte(dev_cfg, LCR(dev), lcr_cache);
70001794:	7d18      	ldrb	r0, [r3, #20]
70001796:	681b      	ldr	r3, [r3, #0]
70001798:	fb1c 3300 	smlabb	r3, ip, r0, r3
7000179c:	f3bf 8f5f 	dmb	sy
700017a0:	b2d2      	uxtb	r2, r2
700017a2:	601a      	str	r2, [r3, #0]
		dev_data->uart_config.baudrate = baud_rate;
700017a4:	f8ce 1000 	str.w	r1, [lr]
700017a8:	e758      	b.n	7000165c <uart_ns16550_configure+0x80>
		if (!device_is_ready(dev_cfg->clock_dev)) {
700017aa:	f8d8 0008 	ldr.w	r0, [r8, #8]
700017ae:	f000 f945 	bl	70001a3c <z_impl_device_is_ready>
700017b2:	b180      	cbz	r0, 700017d6 <uart_ns16550_configure+0x1fa>
					   dev_cfg->clock_subsys,
700017b4:	e9d8 0102 	ldrd	r0, r1, [r8, #8]
					 uint32_t *rate)
{
	const struct clock_control_driver_api *api =
		(const struct clock_control_driver_api *)dev->api;

	if (api->get_rate == NULL) {
700017b8:	6883      	ldr	r3, [r0, #8]
700017ba:	68db      	ldr	r3, [r3, #12]
700017bc:	b15b      	cbz	r3, 700017d6 <uart_ns16550_configure+0x1fa>
		return -ENOSYS;
	}

	return api->get_rate(dev, sys, rate);
700017be:	466a      	mov	r2, sp
700017c0:	4798      	blx	r3
		if (clock_control_get_rate(dev_cfg->clock_dev,
700017c2:	b940      	cbnz	r0, 700017d6 <uart_ns16550_configure+0x1fa>
	set_baud_rate(dev, cfg->baudrate, pclk);
700017c4:	9b00      	ldr	r3, [sp, #0]
700017c6:	e744      	b.n	70001652 <uart_ns16550_configure+0x76>
		uart_cfg.stop_bits = LCR_1_STB;
700017c8:	f04f 0e00 	mov.w	lr, #0
	switch (cfg->parity) {
700017cc:	792b      	ldrb	r3, [r5, #4]
700017ce:	2b00      	cmp	r3, #0
700017d0:	f47f af52 	bne.w	70001678 <uart_ns16550_configure+0x9c>
700017d4:	e753      	b.n	7000167e <uart_ns16550_configure+0xa2>
			ret = -EINVAL;
700017d6:	f06f 0015 	mvn.w	r0, #21
700017da:	e7a0      	b.n	7000171e <uart_ns16550_configure+0x142>

700017dc <uart_ns16550_init>:
{
700017dc:	b570      	push	{r4, r5, r6, lr}
	ret = uart_ns16550_configure(dev, &data->uart_config);
700017de:	6901      	ldr	r1, [r0, #16]
{
700017e0:	4604      	mov	r4, r0
	const struct uart_ns16550_dev_config *dev_cfg = dev->config;
700017e2:	6846      	ldr	r6, [r0, #4]
	ret = uart_ns16550_configure(dev, &data->uart_config);
700017e4:	f7ff fefa 	bl	700015dc <uart_ns16550_configure>
	if (ret != 0) {
700017e8:	4605      	mov	r5, r0
700017ea:	b910      	cbnz	r0, 700017f2 <uart_ns16550_init+0x16>
	dev_cfg->irq_config_func(dev);
700017ec:	6933      	ldr	r3, [r6, #16]
700017ee:	4620      	mov	r0, r4
700017f0:	4798      	blx	r3
}
700017f2:	4628      	mov	r0, r5
700017f4:	bd70      	pop	{r4, r5, r6, pc}
700017f6:	bf00      	nop

700017f8 <uart_ns16550_fifo_read>:
{
700017f8:	b530      	push	{r4, r5, lr}
	__asm__ volatile(
700017fa:	f3ef 8400 	mrs	r4, CPSR
700017fe:	f004 0480 	and.w	r4, r4, #128	; 0x80
70001802:	b672      	cpsid	i
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
70001804:	2a00      	cmp	r2, #0
70001806:	dd1d      	ble.n	70001844 <uart_ns16550_fifo_read+0x4c>
70001808:	4686      	mov	lr, r0
7000180a:	f101 3cff 	add.w	ip, r1, #4294967295	; 0xffffffff
7000180e:	2000      	movs	r0, #0
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
70001810:	2505      	movs	r5, #5
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
70001812:	f8de 1004 	ldr.w	r1, [lr, #4]
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
70001816:	7d0b      	ldrb	r3, [r1, #20]
70001818:	6809      	ldr	r1, [r1, #0]
7000181a:	fb15 1303 	smlabb	r3, r5, r3, r1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000181e:	681b      	ldr	r3, [r3, #0]
70001820:	f3bf 8f5f 	dmb	sy
70001824:	07db      	lsls	r3, r3, #31
70001826:	d50a      	bpl.n	7000183e <uart_ns16550_fifo_read+0x46>
		port = DEVICE_MMIO_GET(dev);
70001828:	f8de 3004 	ldr.w	r3, [lr, #4]
7000182c:	681b      	ldr	r3, [r3, #0]
7000182e:	681b      	ldr	r3, [r3, #0]
70001830:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
70001834:	f80c 3f01 	strb.w	r3, [ip, #1]!
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
70001838:	3001      	adds	r0, #1
7000183a:	4282      	cmp	r2, r0
7000183c:	d1e9      	bne.n	70001812 <uart_ns16550_fifo_read+0x1a>
	if (key != 0U) {
7000183e:	b904      	cbnz	r4, 70001842 <uart_ns16550_fifo_read+0x4a>
  __ASM volatile ("cpsie i" : : : "memory");
70001840:	b662      	cpsie	i
}
70001842:	bd30      	pop	{r4, r5, pc}
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
70001844:	2000      	movs	r0, #0
70001846:	e7fa      	b.n	7000183e <uart_ns16550_fifo_read+0x46>

70001848 <uart_ns16550_poll_in>:
{
70001848:	b410      	push	{r4}
	__asm__ volatile(
7000184a:	f3ef 8200 	mrs	r2, CPSR
7000184e:	f002 0280 	and.w	r2, r2, #128	; 0x80
70001852:	b672      	cpsid	i
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
70001854:	6843      	ldr	r3, [r0, #4]
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
70001856:	f893 c014 	ldrb.w	ip, [r3, #20]
7000185a:	681c      	ldr	r4, [r3, #0]
7000185c:	2305      	movs	r3, #5
7000185e:	fb13 430c 	smlabb	r3, r3, ip, r4
70001862:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001864:	f3bf 8f5f 	dmb	sy
70001868:	07db      	lsls	r3, r3, #31
7000186a:	d50a      	bpl.n	70001882 <uart_ns16550_poll_in+0x3a>
		port = DEVICE_MMIO_GET(dev);
7000186c:	6843      	ldr	r3, [r0, #4]
7000186e:	681b      	ldr	r3, [r3, #0]
70001870:	681b      	ldr	r3, [r3, #0]
70001872:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
70001876:	700b      	strb	r3, [r1, #0]
		return 0;
70001878:	2000      	movs	r0, #0
	if (key != 0U) {
7000187a:	b902      	cbnz	r2, 7000187e <uart_ns16550_poll_in+0x36>
  __ASM volatile ("cpsie i" : : : "memory");
7000187c:	b662      	cpsie	i
}
7000187e:	bc10      	pop	{r4}
70001880:	4770      	bx	lr
	return -1;
70001882:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
70001886:	e7f8      	b.n	7000187a <uart_ns16550_poll_in+0x32>

70001888 <sys_clock_driver_init>:
	return delta_ticks;
}

static int sys_clock_driver_init(void)
{
	last_cycle = 0;
70001888:	f646 33b8 	movw	r3, #27576	; 0x6bb8

	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
7000188c:	2202      	movs	r2, #2
{
7000188e:	b510      	push	{r4, lr}
	last_cycle = 0;
70001890:	2400      	movs	r4, #0
70001892:	f2c7 0300 	movt	r3, #28672	; 0x7000
	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
70001896:	210f      	movs	r1, #15
70001898:	209f      	movs	r0, #159	; 0x9f
	last_cycle = 0;
7000189a:	601c      	str	r4, [r3, #0]
	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
7000189c:	f7ff f8de 	bl	70000a5c <z_soc_irq_priority_set>
700018a0:	2338      	movs	r3, #56	; 0x38
700018a2:	f2c0 2347 	movt	r3, #583	; 0x247
700018a6:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700018a8:	f3bf 8f5f 	dmb	sy
700018ac:	f3bf 8f5f 	dmb	sy
	reg_val = (reg_val & ~(mask)) | (data << shift);
700018b0:	f022 0220 	bic.w	r2, r2, #32
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700018b4:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700018b6:	681a      	ldr	r2, [r3, #0]
700018b8:	f3bf 8f5f 	dmb	sy
700018bc:	f3bf 8f5f 	dmb	sy
700018c0:	f042 0202 	orr.w	r2, r2, #2
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700018c4:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700018c6:	212c      	movs	r1, #44	; 0x2c
700018c8:	f2c0 2147 	movt	r1, #583	; 0x247
700018cc:	680a      	ldr	r2, [r1, #0]
700018ce:	f3bf 8f5f 	dmb	sy
700018d2:	f3bf 8f5f 	dmb	sy
700018d6:	f042 0201 	orr.w	r2, r2, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700018da:	600a      	str	r2, [r1, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700018dc:	223c      	movs	r2, #60	; 0x3c
700018de:	f2c0 2247 	movt	r2, #583	; 0x247
700018e2:	6811      	ldr	r1, [r2, #0]
700018e4:	f3bf 8f5f 	dmb	sy
700018e8:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700018ec:	6014      	str	r4, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700018ee:	2240      	movs	r2, #64	; 0x40
700018f0:	f2c0 2247 	movt	r2, #583	; 0x247
700018f4:	6811      	ldr	r1, [r2, #0]
700018f6:	f3bf 8f5f 	dmb	sy
700018fa:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700018fe:	6014      	str	r4, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001900:	224c      	movs	r2, #76	; 0x4c
70001902:	f2c0 2247 	movt	r2, #583	; 0x247
70001906:	6811      	ldr	r1, [r2, #0]
70001908:	f3bf 8f5f 	dmb	sy
7000190c:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001910:	f246 11a8 	movw	r1, #25000	; 0x61a8
70001914:	6011      	str	r1, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001916:	681a      	ldr	r2, [r3, #0]
70001918:	f3bf 8f5f 	dmb	sy
7000191c:	f3bf 8f5f 	dmb	sy
70001920:	f042 0240 	orr.w	r2, r2, #64	; 0x40
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001924:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001926:	681a      	ldr	r2, [r3, #0]
70001928:	f3bf 8f5f 	dmb	sy
7000192c:	f3bf 8f5f 	dmb	sy
70001930:	f042 0201 	orr.w	r2, r2, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001934:	601a      	str	r2, [r3, #0]
	TI_DM_TIMER_WRITE(1, TCLR, CE);

	/* Start the timer */
	TI_DM_TIMER_WRITE(1, TCLR, ST);

	irq_enable(TIMER_IRQ_NUM);
70001936:	209f      	movs	r0, #159	; 0x9f
70001938:	f7ff f892 	bl	70000a60 <z_soc_irq_enable>

	return 0;
}
7000193c:	4620      	mov	r0, r4
7000193e:	bd10      	pop	{r4, pc}

70001940 <ti_dmtimer_isr>:
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001940:	2228      	movs	r2, #40	; 0x28
70001942:	f2c0 2247 	movt	r2, #583	; 0x247
70001946:	6813      	ldr	r3, [r2, #0]
70001948:	f3bf 8f5f 	dmb	sy
	if (!TI_DM_TIMER_READ(IRQSTATUS)) {
7000194c:	b33b      	cbz	r3, 7000199e <ti_dmtimer_isr+0x5e>
{
7000194e:	b410      	push	{r4}
	__asm__ volatile(
70001950:	f3ef 8400 	mrs	r4, CPSR
70001954:	f004 0480 	and.w	r4, r4, #128	; 0x80
70001958:	b672      	cpsid	i
7000195a:	233c      	movs	r3, #60	; 0x3c
7000195c:	f2c0 2347 	movt	r3, #583	; 0x247
70001960:	681b      	ldr	r3, [r3, #0]
70001962:	f3bf 8f5f 	dmb	sy
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001966:	f646 31b8 	movw	r1, #27576	; 0x6bb8
7000196a:	f2c7 0100 	movt	r1, #28672	; 0x7000
7000196e:	6808      	ldr	r0, [r1, #0]
	last_cycle = curr_cycle;
70001970:	600b      	str	r3, [r1, #0]
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001972:	1a18      	subs	r0, r3, r0
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70001974:	f24b 5389 	movw	r3, #46473	; 0xb589
70001978:	f2c1 43f8 	movt	r3, #5368	; 0x14f8
7000197c:	08c0      	lsrs	r0, r0, #3
7000197e:	fba3 3000 	umull	r3, r0, r3, r0
70001982:	0a00      	lsrs	r0, r0, #8
70001984:	6813      	ldr	r3, [r2, #0]
70001986:	f3bf 8f5f 	dmb	sy
7000198a:	f3bf 8f5f 	dmb	sy
	reg_val = (reg_val & ~(mask)) | (data << shift);
7000198e:	f043 0301 	orr.w	r3, r3, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001992:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
70001994:	b904      	cbnz	r4, 70001998 <ti_dmtimer_isr+0x58>
  __ASM volatile ("cpsie i" : : : "memory");
70001996:	b662      	cpsie	i
}
70001998:	bc10      	pop	{r4}
	sys_clock_announce(delta_ticks);
7000199a:	f000 bfd7 	b.w	7000294c <sys_clock_announce>
7000199e:	4770      	bx	lr

700019a0 <sys_clock_set_timeout>:
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
700019a0:	1c43      	adds	r3, r0, #1
700019a2:	d028      	beq.n	700019f6 <sys_clock_set_timeout+0x56>
	ticks = CLAMP(ticks, 1, (int32_t)MAX_TICKS);
700019a4:	2801      	cmp	r0, #1
700019a6:	bfd8      	it	le
700019a8:	f246 10a8 	movwle	r0, #25000	; 0x61a8
700019ac:	dd0a      	ble.n	700019c4 <sys_clock_set_timeout+0x24>
700019ae:	f649 7315 	movw	r3, #40725	; 0x9f15
	uint32_t next_cycle = curr_cycle + (ticks * CYC_PER_TICK);
700019b2:	f246 12a8 	movw	r2, #25000	; 0x61a8
	ticks = CLAMP(ticks, 1, (int32_t)MAX_TICKS);
700019b6:	f2c0 0302 	movt	r3, #2
700019ba:	4298      	cmp	r0, r3
700019bc:	bfa8      	it	ge
700019be:	4618      	movge	r0, r3
	uint32_t next_cycle = curr_cycle + (ticks * CYC_PER_TICK);
700019c0:	fb02 f000 	mul.w	r0, r2, r0
	__asm__ volatile(
700019c4:	f3ef 8100 	mrs	r1, CPSR
700019c8:	f001 0180 	and.w	r1, r1, #128	; 0x80
700019cc:	b672      	cpsid	i
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700019ce:	233c      	movs	r3, #60	; 0x3c
700019d0:	f2c0 2347 	movt	r3, #583	; 0x247
700019d4:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700019d6:	f3bf 8f5f 	dmb	sy
700019da:	224c      	movs	r2, #76	; 0x4c
700019dc:	f2c0 2247 	movt	r2, #583	; 0x247
700019e0:	f8d2 c000 	ldr.w	ip, [r2]
700019e4:	f3bf 8f5f 	dmb	sy
700019e8:	f3bf 8f5f 	dmb	sy
700019ec:	4403      	add	r3, r0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700019ee:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
700019f0:	b901      	cbnz	r1, 700019f4 <sys_clock_set_timeout+0x54>
  __ASM volatile ("cpsie i" : : : "memory");
700019f2:	b662      	cpsie	i
}
700019f4:	4770      	bx	lr
700019f6:	f645 20c8 	movw	r0, #23240	; 0x5ac8
700019fa:	f6cf 70ff 	movt	r0, #65535	; 0xffff
700019fe:	e7e1      	b.n	700019c4 <sys_clock_set_timeout+0x24>

70001a00 <sys_clock_elapsed>:
	__asm__ volatile(
70001a00:	f3ef 8100 	mrs	r1, CPSR
70001a04:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001a08:	b672      	cpsid	i
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001a0a:	233c      	movs	r3, #60	; 0x3c
70001a0c:	f2c0 2347 	movt	r3, #583	; 0x247
70001a10:	6818      	ldr	r0, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001a12:	f3bf 8f5f 	dmb	sy
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001a16:	f646 32b8 	movw	r2, #27576	; 0x6bb8
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70001a1a:	f24b 5389 	movw	r3, #46473	; 0xb589
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001a1e:	f2c7 0200 	movt	r2, #28672	; 0x7000
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70001a22:	f2c1 43f8 	movt	r3, #5368	; 0x14f8
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001a26:	6812      	ldr	r2, [r2, #0]
70001a28:	1a80      	subs	r0, r0, r2
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70001a2a:	08c0      	lsrs	r0, r0, #3
70001a2c:	fba3 3000 	umull	r3, r0, r3, r0
70001a30:	0a00      	lsrs	r0, r0, #8
	if (key != 0U) {
70001a32:	b901      	cbnz	r1, 70001a36 <sys_clock_elapsed+0x36>
  __ASM volatile ("cpsie i" : : : "memory");
70001a34:	b662      	cpsie	i
}
70001a36:	4770      	bx	lr

70001a38 <z_device_state_init>:
void z_device_state_init(void)
{
	STRUCT_SECTION_FOREACH(device, dev) {
		k_object_init(dev);
	}
}
70001a38:	4770      	bx	lr
70001a3a:	bf00      	nop

70001a3c <z_impl_device_is_ready>:
{
	/*
	 * if an invalid device pointer is passed as argument, this call
	 * reports the `device` as not ready for usage.
	 */
	if (dev == NULL) {
70001a3c:	b140      	cbz	r0, 70001a50 <z_impl_device_is_ready+0x14>
		return false;
	}

	return dev->state->initialized && (dev->state->init_res == 0U);
70001a3e:	68c3      	ldr	r3, [r0, #12]
70001a40:	7858      	ldrb	r0, [r3, #1]
70001a42:	f010 0001 	ands.w	r0, r0, #1
70001a46:	bf1e      	ittt	ne
70001a48:	7818      	ldrbne	r0, [r3, #0]
70001a4a:	fab0 f080 	clzne	r0, r0
70001a4e:	0940      	lsrne	r0, r0, #5
}
70001a50:	4770      	bx	lr
70001a52:	bf00      	nop

70001a54 <arch_system_halt>:
	__asm__ volatile(
70001a54:	f3ef 8300 	mrs	r3, CPSR
70001a58:	f003 0380 	and.w	r3, r3, #128	; 0x80
70001a5c:	b672      	cpsid	i
	/* TODO: What's the best way to totally halt the system if SMP
	 * is enabled?
	 */

	(void)arch_irq_lock();
	for (;;) {
70001a5e:	e7fe      	b.n	70001a5e <arch_system_halt+0xa>

70001a60 <k_sys_fatal_error_handler>:
/* LCOV_EXCL_STOP */

/* LCOV_EXCL_START */
__weak void k_sys_fatal_error_handler(unsigned int reason,
				      const struct arch_esf *esf)
{
70001a60:	b508      	push	{r3, lr}
	ARG_UNUSED(esf);

	LOG_PANIC();
	LOG_ERR("Halting system");
	arch_system_halt(reason);
70001a62:	f7ff fff7 	bl	70001a54 <arch_system_halt>
70001a66:	bf00      	nop

70001a68 <z_fatal_error>:
	arch_system_halt(reason);
}
/* LCOV_EXCL_STOP */

void z_fatal_error(unsigned int reason, const struct arch_esf *esf)
{
70001a68:	b538      	push	{r3, r4, r5, lr}
70001a6a:	f3ef 8500 	mrs	r5, CPSR
70001a6e:	f005 0580 	and.w	r5, r5, #128	; 0x80
70001a72:	b672      	cpsid	i

	struct k_thread *ret = _current_cpu->current;

	arch_irq_unlock(k);
#else
	struct k_thread *ret = _kernel.cpus[0].current;
70001a74:	f646 32bc 	movw	r2, #27580	; 0x6bbc
70001a78:	f2c7 0200 	movt	r2, #28672	; 0x7000
70001a7c:	6894      	ldr	r4, [r2, #8]
	 * an IRQ or exception was being handled, or thread context.
	 *
	 * See #17656
	 */
#if defined(CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION)
	if ((esf != NULL) && arch_is_in_nested_exception(esf)) {
70001a7e:	b161      	cbz	r1, 70001a9a <z_fatal_error+0x32>
70001a80:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
		LOG_ERR("Current thread: %p (%s)", thread, thread_name_get(thread));
	}

	coredump(reason, esf, thread);

	k_sys_fatal_error_handler(reason, esf);
70001a84:	f7ff ffec 	bl	70001a60 <k_sys_fatal_error_handler>
70001a88:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
	if (key != 0U) {
70001a8c:	b905      	cbnz	r5, 70001a90 <z_fatal_error+0x28>
70001a8e:	b662      	cpsie	i
70001a90:	4620      	mov	r0, r4
	arch_irq_unlock(key);

	if (IS_ENABLED(CONFIG_MULTITHREADING)) {
		k_thread_abort(thread);
	}
}
70001a92:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
70001a96:	f000 be41 	b.w	7000271c <z_impl_k_thread_abort>
	k_sys_fatal_error_handler(reason, esf);
70001a9a:	f7ff ffe1 	bl	70001a60 <k_sys_fatal_error_handler>
		if ((esf != NULL) && arch_is_in_nested_exception(esf)) {
70001a9e:	e7f5      	b.n	70001a8c <z_fatal_error+0x24>

70001aa0 <z_sys_init_run_level>:
		/* End marker */
		__init_end,
	};
	const struct init_entry *entry;

	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001aa0:	f644 5368 	movw	r3, #19816	; 0x4d68
70001aa4:	1c42      	adds	r2, r0, #1
70001aa6:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
70001aaa:	b570      	push	{r4, r5, r6, lr}
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001aac:	f853 4020 	ldr.w	r4, [r3, r0, lsl #2]
70001ab0:	f853 6022 	ldr.w	r6, [r3, r2, lsl #2]
70001ab4:	42b4      	cmp	r4, r6
70001ab6:	d314      	bcc.n	70001ae2 <z_sys_init_run_level+0x42>
70001ab8:	e01b      	b.n	70001af2 <z_sys_init_run_level+0x52>
		rc = entry->init_fn.dev(dev);
70001aba:	4628      	mov	r0, r5
	if (entry->init_fn.dev != NULL) {
70001abc:	b14b      	cbz	r3, 70001ad2 <z_sys_init_run_level+0x32>
		rc = entry->init_fn.dev(dev);
70001abe:	4798      	blx	r3
		if (rc != 0) {
70001ac0:	b138      	cbz	r0, 70001ad2 <z_sys_init_run_level+0x32>
			dev->state->init_res = rc;
70001ac2:	68eb      	ldr	r3, [r5, #12]
			if (rc < 0) {
70001ac4:	2800      	cmp	r0, #0
70001ac6:	bfb8      	it	lt
70001ac8:	4240      	neglt	r0, r0
			if (rc > UINT8_MAX) {
70001aca:	28ff      	cmp	r0, #255	; 0xff
70001acc:	bfa8      	it	ge
70001ace:	20ff      	movge	r0, #255	; 0xff
			dev->state->init_res = rc;
70001ad0:	7018      	strb	r0, [r3, #0]
	dev->state->initialized = true;
70001ad2:	68ea      	ldr	r2, [r5, #12]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001ad4:	3408      	adds	r4, #8
	dev->state->initialized = true;
70001ad6:	7853      	ldrb	r3, [r2, #1]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001ad8:	42a6      	cmp	r6, r4
	dev->state->initialized = true;
70001ada:	f043 0301 	orr.w	r3, r3, #1
70001ade:	7053      	strb	r3, [r2, #1]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001ae0:	d907      	bls.n	70001af2 <z_sys_init_run_level+0x52>

		sys_trace_sys_init_enter(entry, level);
		if (dev != NULL) {
			result = do_device_init(entry);
		} else {
			result = entry->init_fn.sys();
70001ae2:	e9d4 3500 	ldrd	r3, r5, [r4]
		if (dev != NULL) {
70001ae6:	2d00      	cmp	r5, #0
70001ae8:	d1e7      	bne.n	70001aba <z_sys_init_run_level+0x1a>
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001aea:	3408      	adds	r4, #8
			result = entry->init_fn.sys();
70001aec:	4798      	blx	r3
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001aee:	42a6      	cmp	r6, r4
70001af0:	d8f7      	bhi.n	70001ae2 <z_sys_init_run_level+0x42>
		}
		sys_trace_sys_init_exit(entry, level, result);
	}
}
70001af2:	bd70      	pop	{r4, r5, r6, pc}

70001af4 <bg_thread_main>:
	 * may perform memory management tasks (except for
	 * k_mem_map_phys_bare() which is allowed at any time)
	 */
	z_mem_manage_init();
#endif /* CONFIG_MMU */
	z_sys_post_kernel = true;
70001af4:	f646 33e0 	movw	r3, #27616	; 0x6be0
70001af8:	2201      	movs	r2, #1
70001afa:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
70001afe:	b5f0      	push	{r4, r5, r6, r7, lr}

#if CONFIG_IRQ_OFFLOAD
	arch_irq_offload_init();
#endif
	z_sys_init_run_level(INIT_LEVEL_POST_KERNEL);
70001b00:	2003      	movs	r0, #3
{
70001b02:	b087      	sub	sp, #28
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b04:	f644 2668 	movw	r6, #19048	; 0x4a68
70001b08:	f644 2598 	movw	r5, #19096	; 0x4a98
	z_sys_post_kernel = true;
70001b0c:	701a      	strb	r2, [r3, #0]
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b0e:	f2c7 0600 	movt	r6, #28672	; 0x7000
	z_sys_init_run_level(INIT_LEVEL_POST_KERNEL);
70001b12:	f7ff ffc5 	bl	70001aa0 <z_sys_init_run_level>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b16:	f2c7 0500 	movt	r5, #28672	; 0x7000
#endif

#if defined(CONFIG_STACK_POINTER_RANDOM) && (CONFIG_STACK_POINTER_RANDOM != 0)
	z_stack_adjust_initialized = 1;
#endif /* CONFIG_STACK_POINTER_RANDOM */
	boot_banner();
70001b1a:	f001 f82f 	bl	70002b7c <boot_banner>

	void z_init_static(void);
	z_init_static();
70001b1e:	f000 f8d3 	bl	70001cc8 <z_init_static>

	/* Final init level before app starts */
	z_sys_init_run_level(INIT_LEVEL_APPLICATION);
70001b22:	2004      	movs	r0, #4
70001b24:	f7ff ffbc 	bl	70001aa0 <z_sys_init_run_level>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b28:	42ae      	cmp	r6, r5
70001b2a:	d217      	bcs.n	70001b5c <bg_thread_main+0x68>
70001b2c:	4634      	mov	r4, r6
		z_setup_new_thread(
70001b2e:	6a67      	ldr	r7, [r4, #36]	; 0x24
70001b30:	e9d4 2302 	ldrd	r2, r3, [r4, #8]
70001b34:	e9d4 0100 	ldrd	r0, r1, [r4]
70001b38:	9705      	str	r7, [sp, #20]
70001b3a:	6a27      	ldr	r7, [r4, #32]
70001b3c:	9704      	str	r7, [sp, #16]
70001b3e:	69e7      	ldr	r7, [r4, #28]
70001b40:	9703      	str	r7, [sp, #12]
70001b42:	69a7      	ldr	r7, [r4, #24]
70001b44:	9702      	str	r7, [sp, #8]
70001b46:	6967      	ldr	r7, [r4, #20]
70001b48:	9701      	str	r7, [sp, #4]
70001b4a:	6927      	ldr	r7, [r4, #16]
70001b4c:	9700      	str	r7, [sp, #0]
70001b4e:	f000 f9f9 	bl	70001f44 <z_setup_new_thread>
		thread_data->init_thread->init_data = thread_data;
70001b52:	6823      	ldr	r3, [r4, #0]
70001b54:	655c      	str	r4, [r3, #84]	; 0x54
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b56:	3430      	adds	r4, #48	; 0x30
70001b58:	42ac      	cmp	r4, r5
70001b5a:	d3e8      	bcc.n	70001b2e <bg_thread_main+0x3a>
	k_sched_lock();
70001b5c:	f000 fcba 	bl	700024d4 <k_sched_lock>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b60:	42ae      	cmp	r6, r5
70001b62:	d222      	bcs.n	70001baa <bg_thread_main+0xb6>
70001b64:	f644 2468 	movw	r4, #19048	; 0x4a68

extern void z_thread_timeout(struct _timeout *timeout);

static inline void z_add_thread_timeout(struct k_thread *thread, k_timeout_t ticks)
{
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
70001b68:	f242 37f9 	movw	r7, #9209	; 0x23f9
70001b6c:	f2c7 0400 	movt	r4, #28672	; 0x7000
70001b70:	f2c7 0700 	movt	r7, #28672	; 0x7000
70001b74:	e005      	b.n	70001b82 <bg_thread_main+0x8e>
	z_impl_k_wakeup(thread);
70001b76:	4630      	mov	r0, r6
70001b78:	f000 fda4 	bl	700026c4 <z_impl_k_wakeup>
70001b7c:	3430      	adds	r4, #48	; 0x30
70001b7e:	42ac      	cmp	r4, r5
70001b80:	d213      	bcs.n	70001baa <bg_thread_main+0xb6>
		k_timeout_t init_delay = Z_THREAD_INIT_DELAY(thread_data);
70001b82:	e9d4 230a 	ldrd	r2, r3, [r4, #40]	; 0x28
		if (!K_TIMEOUT_EQ(init_delay, K_FOREVER)) {
70001b86:	f1b3 3fff 	cmp.w	r3, #4294967295	; 0xffffffff
70001b8a:	bf08      	it	eq
70001b8c:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
70001b90:	d0f4      	beq.n	70001b7c <bg_thread_main+0x88>
			thread_schedule_new(thread_data->init_thread,
70001b92:	6826      	ldr	r6, [r4, #0]


static inline void thread_schedule_new(struct k_thread *thread, k_timeout_t delay)
{
#ifdef CONFIG_SYS_CLOCK_EXISTS
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
70001b94:	ea52 0003 	orrs.w	r0, r2, r3
70001b98:	4639      	mov	r1, r7
70001b9a:	f106 0018 	add.w	r0, r6, #24
70001b9e:	d0ea      	beq.n	70001b76 <bg_thread_main+0x82>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001ba0:	3430      	adds	r4, #48	; 0x30
70001ba2:	f000 fe19 	bl	700027d8 <z_add_timeout>
70001ba6:	42ac      	cmp	r4, r5
70001ba8:	d3eb      	bcc.n	70001b82 <bg_thread_main+0x8e>
	k_sched_unlock();
70001baa:	f000 fca3 	bl	700024f4 <k_sched_unlock>
	char **argv = prepare_main_args(&argc);
	(void)main(argc, argv);
#else
	extern int main(void);

	(void)main();
70001bae:	f7fe fbb9 	bl	70000324 <main>
 * Exceptions raised by this thread may be recoverable.
 * (This is the default tag for a thread.)
 */
static inline void z_thread_essential_clear(struct k_thread *thread)
{
	thread->base.user_options &= ~K_ESSENTIAL;
70001bb2:	f245 3378 	movw	r3, #21368	; 0x5378
70001bb6:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001bba:	7b1a      	ldrb	r2, [r3, #12]
70001bbc:	f022 0201 	bic.w	r2, r2, #1
70001bc0:	731a      	strb	r2, [r3, #12]

#ifdef CONFIG_COVERAGE_DUMP
	/* Dump coverage data once the main() has exited. */
	gcov_coverage_dump();
#endif /* CONFIG_COVERAGE_DUMP */
} /* LCOV_EXCL_LINE ... because we just dumped final coverage data */
70001bc2:	b007      	add	sp, #28
70001bc4:	bdf0      	pop	{r4, r5, r6, r7, pc}
70001bc6:	bf00      	nop

70001bc8 <z_early_memset>:
	(void) memset(dst, c, n);
70001bc8:	f001 b9d2 	b.w	70002f70 <memset>

70001bcc <z_bss_zero>:
	z_early_memset(__bss_start, 0, __bss_end - __bss_start);
70001bcc:	f646 32e4 	movw	r2, #27620	; 0x6be4
70001bd0:	f644 50d8 	movw	r0, #19928	; 0x4dd8
70001bd4:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001bd8:	2100      	movs	r1, #0
70001bda:	f2c7 0200 	movt	r2, #28672	; 0x7000
70001bde:	1a12      	subs	r2, r2, r0
{
70001be0:	b508      	push	{r3, lr}
	z_early_memset(__bss_start, 0, __bss_end - __bss_start);
70001be2:	f7ff fff1 	bl	70001bc8 <z_early_memset>
}
70001be6:	bd08      	pop	{r3, pc}

70001be8 <z_cstart>:
 * @return Does not return
 */
__boot_func
FUNC_NO_STACK_PROTECTOR
FUNC_NORETURN void z_cstart(void)
{
70001be8:	b580      	push	{r7, lr}
	/* gcov hook needed to get the coverage report.*/
	gcov_static_init();

	/* initialize early init calls */
	z_sys_init_run_level(INIT_LEVEL_EARLY);
70001bea:	2000      	movs	r0, #0
{
70001bec:	b086      	sub	sp, #24
	z_sys_init_run_level(INIT_LEVEL_EARLY);
70001bee:	f7ff ff57 	bl	70001aa0 <z_sys_init_run_level>
	return ret;
}

static ALWAYS_INLINE void arch_current_thread_set(struct k_thread *thread)
{
	_current_cpu->current = thread;
70001bf2:	f646 34bc 	movw	r4, #27580	; 0x6bbc
{
	dummy_thread->base.thread_state = _THREAD_DUMMY;
#ifdef CONFIG_SCHED_CPU_MASK
	dummy_thread->base.cpu_mask = -1;
#endif /* CONFIG_SCHED_CPU_MASK */
	dummy_thread->base.user_options = K_ESSENTIAL;
70001bf6:	f245 33f0 	movw	r3, #21488	; 0x53f0
	dummy_thread->mem_domain_info.mem_domain = &k_mem_domain_default;
#endif /* CONFIG_USERSPACE */
#if (K_HEAP_MEM_POOL_SIZE > 0)
	k_thread_system_pool_assign(dummy_thread);
#else
	dummy_thread->resource_pool = NULL;
70001bfa:	2500      	movs	r5, #0
	dummy_thread->base.user_options = K_ESSENTIAL;
70001bfc:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001c00:	f240 1201 	movw	r2, #257	; 0x101
70001c04:	f2c7 0400 	movt	r4, #28672	; 0x7000
	dummy_thread->resource_pool = NULL;
70001c08:	669d      	str	r5, [r3, #104]	; 0x68
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001c0a:	2701      	movs	r7, #1
	dummy_thread->base.user_options = K_ESSENTIAL;
70001c0c:	819a      	strh	r2, [r3, #12]
	_kernel.ready_q.cache = &z_main_thread;
70001c0e:	f245 3678 	movw	r6, #21368	; 0x5378
70001c12:	60a3      	str	r3, [r4, #8]

#if defined(CONFIG_MULTITHREADING)
	z_dummy_thread_init(&_thread_dummy);
#endif /* CONFIG_MULTITHREADING */
	/* do any necessary initialization of static devices */
	z_device_state_init();
70001c14:	f7ff ff10 	bl	70001a38 <z_device_state_init>
#endif
#if CONFIG_BOARD_EARLY_INIT_HOOK
	board_early_init_hook();
#endif
	/* perform basic hardware initialization */
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_1);
70001c18:	2001      	movs	r0, #1
	_kernel.ready_q.cache = &z_main_thread;
70001c1a:	f2c7 0600 	movt	r6, #28672	; 0x7000
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_1);
70001c1e:	f7ff ff3f 	bl	70001aa0 <z_sys_init_run_level>
#if defined(CONFIG_SMP)
	arch_smp_init();
#endif
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_2);
70001c22:	2002      	movs	r0, #2
70001c24:	f7ff ff3c 	bl	70001aa0 <z_sys_init_run_level>
	z_sched_init();
70001c28:	f000 fc9e 	bl	70002568 <z_sched_init>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001c2c:	f644 5360 	movw	r3, #19808	; 0x4d60
70001c30:	f24a 71e8 	movw	r1, #42984	; 0xa7e8
70001c34:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001c38:	f44f 6280 	mov.w	r2, #1024	; 0x400
70001c3c:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001c40:	9305      	str	r3, [sp, #20]
70001c42:	f641 23f5 	movw	r3, #6901	; 0x1af5
70001c46:	4630      	mov	r0, r6
70001c48:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001c4c:	e9cd 5703 	strd	r5, r7, [sp, #12]
70001c50:	9502      	str	r5, [sp, #8]
70001c52:	e9cd 5500 	strd	r5, r5, [sp]
	_kernel.ready_q.cache = &z_main_thread;
70001c56:	6166      	str	r6, [r4, #20]
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001c58:	f000 f974 	bl	70001f44 <z_setup_new_thread>
	thread->base.thread_state &= ~_THREAD_SLEEPING;
70001c5c:	7b73      	ldrb	r3, [r6, #13]
	z_ready_thread(&z_main_thread);
70001c5e:	4630      	mov	r0, r6
70001c60:	f023 0304 	bic.w	r3, r3, #4
70001c64:	7373      	strb	r3, [r6, #13]
70001c66:	f000 fb3b 	bl	700022e0 <z_ready_thread>
	z_setup_new_thread(thread, stack,
70001c6a:	230f      	movs	r3, #15
70001c6c:	f245 3600 	movw	r6, #21248	; 0x5300
70001c70:	f24a 61e8 	movw	r1, #42728	; 0xa6e8
70001c74:	f2c7 0600 	movt	r6, #28672	; 0x7000
70001c78:	9303      	str	r3, [sp, #12]
70001c7a:	f641 5329 	movw	r3, #7465	; 0x1d29
70001c7e:	f44f 7280 	mov.w	r2, #256	; 0x100
70001c82:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001c86:	4630      	mov	r0, r6
70001c88:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001c8c:	e9cd 7504 	strd	r7, r5, [sp, #16]
70001c90:	e9cd 5501 	strd	r5, r5, [sp, #4]
70001c94:	9400      	str	r4, [sp, #0]
70001c96:	f000 f955 	bl	70001f44 <z_setup_new_thread>
70001c9a:	7b73      	ldrb	r3, [r6, #13]
	_kernel.cpus[id].irq_stack =
70001c9c:	4a09      	ldr	r2, [pc, #36]	; (70001cc4 <z_cstart+0xdc>)
70001c9e:	f023 0304 	bic.w	r3, r3, #4
70001ca2:	6062      	str	r2, [r4, #4]
	_kernel.cpus[id].idle_thread = &z_idle_threads[id];
70001ca4:	60e6      	str	r6, [r4, #12]
70001ca6:	7373      	strb	r3, [r6, #13]
	_kernel.cpus[id].id = id;
70001ca8:	7425      	strb	r5, [r4, #16]
	__asm__ volatile(
70001caa:	f3ef 8100 	mrs	r1, CPSR
70001cae:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001cb2:	b672      	cpsid	i
	struct k_thread *ret = _kernel.cpus[0].current;
70001cb4:	68a3      	ldr	r3, [r4, #8]

static ALWAYS_INLINE int arch_swap(unsigned int key)
{
	/* store off key and return value */
	arch_current_thread()->arch.basepri = key;
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
70001cb6:	f06f 020a 	mvn.w	r2, #10
70001cba:	e9c3 121b 	strd	r1, r2, [r3, #108]	; 0x6c

	z_arm_cortex_r_svc();
70001cbe:	f7ff e98a 	blx	70000fd4 <z_arm_cortex_r_svc>
70001cc2:	b662      	cpsie	i
	CODE_UNREACHABLE; /* LCOV_EXCL_LINE */
70001cc4:	7000a6e8 	.word	0x7000a6e8

70001cc8 <z_init_static>:
	__do_global_ctors_aux();
	__do_init_array_aux();
#elif defined(__CCAC__) /* ARC MWDT */
	__do_global_ctors_aux();
#endif
}
70001cc8:	4770      	bx	lr
70001cca:	bf00      	nop

70001ccc <init_mem_slab_obj_core_list>:
#endif /* CONFIG_OBJ_CORE_STATS_MEM_SLAB */
#endif /* CONFIG_OBJ_CORE_MEM_SLAB */

	/* Initialize statically defined mem_slabs */

	STRUCT_SECTION_FOREACH(k_mem_slab, slab) {
70001ccc:	f24b 01c4 	movw	r1, #45252	; 0xb0c4
70001cd0:	f24b 0cc4 	movw	ip, #45252	; 0xb0c4
70001cd4:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001cd8:	f2c7 0c00 	movt	ip, #28672	; 0x7000
70001cdc:	4561      	cmp	r1, ip
70001cde:	d221      	bcs.n	70001d24 <init_mem_slab_obj_core_list+0x58>
{
70001ce0:	b410      	push	{r4}
	CHECKIF(((slab->info.block_size | (uintptr_t)slab->buffer) &
70001ce2:	694c      	ldr	r4, [r1, #20]
70001ce4:	688b      	ldr	r3, [r1, #8]
70001ce6:	ea43 0004 	orr.w	r0, r3, r4
70001cea:	f010 0003 	ands.w	r0, r0, #3
70001cee:	d116      	bne.n	70001d1e <init_mem_slab_obj_core_list+0x52>
	p = slab->buffer + slab->info.block_size * (slab->info.num_blocks - 1);
70001cf0:	690a      	ldr	r2, [r1, #16]
	slab->free_list = NULL;
70001cf2:	60c8      	str	r0, [r1, #12]
	p = slab->buffer + slab->info.block_size * (slab->info.num_blocks - 1);
70001cf4:	3a01      	subs	r2, #1
70001cf6:	fb04 3202 	mla	r2, r4, r2, r3
	while (p >= slab->buffer) {
70001cfa:	4293      	cmp	r3, r2
70001cfc:	d901      	bls.n	70001d02 <init_mem_slab_obj_core_list+0x36>
70001cfe:	e008      	b.n	70001d12 <init_mem_slab_obj_core_list+0x46>
		p -= slab->info.block_size;
70001d00:	461a      	mov	r2, r3
		*(char **)p = slab->free_list;
70001d02:	6010      	str	r0, [r2, #0]
		p -= slab->info.block_size;
70001d04:	4610      	mov	r0, r2
70001d06:	694b      	ldr	r3, [r1, #20]
	while (p >= slab->buffer) {
70001d08:	688c      	ldr	r4, [r1, #8]
		p -= slab->info.block_size;
70001d0a:	1ad3      	subs	r3, r2, r3
	while (p >= slab->buffer) {
70001d0c:	42a3      	cmp	r3, r4
70001d0e:	d2f7      	bcs.n	70001d00 <init_mem_slab_obj_core_list+0x34>
70001d10:	60ca      	str	r2, [r1, #12]
	STRUCT_SECTION_FOREACH(k_mem_slab, slab) {
70001d12:	311c      	adds	r1, #28
70001d14:	4561      	cmp	r1, ip
70001d16:	d3e4      	bcc.n	70001ce2 <init_mem_slab_obj_core_list+0x16>
70001d18:	2000      	movs	r0, #0
#endif /* CONFIG_OBJ_CORE_MEM_SLAB */
	}

out:
	return rc;
}
70001d1a:	bc10      	pop	{r4}
70001d1c:	4770      	bx	lr
70001d1e:	f06f 0015 	mvn.w	r0, #21
	return rc;
70001d22:	e7fa      	b.n	70001d1a <init_mem_slab_obj_core_list+0x4e>
70001d24:	2000      	movs	r0, #0
}
70001d26:	4770      	bx	lr

70001d28 <idle>:
#include <wait_q.h>

LOG_MODULE_DECLARE(os, CONFIG_KERNEL_LOG_LEVEL);

void idle(void *unused1, void *unused2, void *unused3)
{
70001d28:	b508      	push	{r3, lr}
70001d2a:	f3ef 8300 	mrs	r3, CPSR
70001d2e:	f003 0380 	and.w	r3, r3, #128	; 0x80
70001d32:	b672      	cpsid	i
 * @note In some architectures, before returning, the function unmasks interrupts
 * unconditionally.
 */
static inline void k_cpu_idle(void)
{
	arch_cpu_idle();
70001d34:	f7ff e830 	blx	70000d98 <arch_cpu_idle>
70001d38:	e7f7      	b.n	70001d2a <idle+0x2>
70001d3a:	bf00      	nop

70001d3c <z_impl_k_msgq_put>:
	return 0;
}


int z_impl_k_msgq_put(struct k_msgq *msgq, const void *data, k_timeout_t timeout)
{
70001d3c:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
70001d40:	4604      	mov	r4, r0
70001d42:	b082      	sub	sp, #8
70001d44:	460d      	mov	r5, r1
70001d46:	4616      	mov	r6, r2

	struct k_thread *pending_thread;
	k_spinlock_key_t key;
	int result;

	key = k_spin_lock(&msgq->lock);
70001d48:	f100 0708 	add.w	r7, r0, #8
70001d4c:	f3ef 8800 	mrs	r8, CPSR
70001d50:	f008 0880 	and.w	r8, r8, #128	; 0x80
70001d54:	b672      	cpsid	i

	SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_msgq, put, msgq, timeout);

	if (msgq->used_msgs < msgq->max_msgs) {
70001d56:	6a02      	ldr	r2, [r0, #32]
70001d58:	68c0      	ldr	r0, [r0, #12]
70001d5a:	4282      	cmp	r2, r0
70001d5c:	d224      	bcs.n	70001da8 <z_impl_k_msgq_put+0x6c>
 * @return true if empty, false otherwise
 */

static inline bool sys_dlist_is_empty(sys_dlist_t *list)
{
	return list->head == list;
70001d5e:	f8d4 9000 	ldr.w	r9, [r4]
	__ASSERT_EVAL(, int key = arch_irq_lock(); arch_irq_unlock(key),
		      !arch_irq_unlocked(key), "");

	LOCK_SCHED_SPINLOCK {
		thread = _priq_wait_best(&wait_q->waitq);
		if (unlikely(thread != NULL)) {
70001d62:	f1b9 0f00 	cmp.w	r9, #0
70001d66:	bf18      	it	ne
70001d68:	454c      	cmpne	r4, r9
70001d6a:	d135      	bne.n	70001dd8 <z_impl_k_msgq_put+0x9c>
			return 0;
		} else {
			/* put message in queue */
			__ASSERT_NO_MSG(msgq->write_ptr >= msgq->buffer_start &&
					msgq->write_ptr < msgq->buffer_end);
			(void)memcpy(msgq->write_ptr, (char *)data, msgq->msg_size);
70001d6c:	68a2      	ldr	r2, [r4, #8]
			msgq->used_msgs++;
#ifdef CONFIG_POLL
			handle_poll_events(msgq, K_POLL_STATE_MSGQ_DATA_AVAILABLE);
#endif /* CONFIG_POLL */
		}
		result = 0;
70001d6e:	2600      	movs	r6, #0
			(void)memcpy(msgq->write_ptr, (char *)data, msgq->msg_size);
70001d70:	69e0      	ldr	r0, [r4, #28]
70001d72:	f001 f895 	bl	70002ea0 <memcpy>
			msgq->write_ptr += msgq->msg_size;
70001d76:	69e3      	ldr	r3, [r4, #28]
70001d78:	68a2      	ldr	r2, [r4, #8]
	z_handle_obj_poll_events(&msgq->poll_events, state);
70001d7a:	2110      	movs	r1, #16
70001d7c:	f104 0024 	add.w	r0, r4, #36	; 0x24
			msgq->write_ptr += msgq->msg_size;
70001d80:	4413      	add	r3, r2
			if (msgq->write_ptr == msgq->buffer_end) {
70001d82:	6962      	ldr	r2, [r4, #20]
			msgq->write_ptr += msgq->msg_size;
70001d84:	61e3      	str	r3, [r4, #28]
			if (msgq->write_ptr == msgq->buffer_end) {
70001d86:	4293      	cmp	r3, r2
				msgq->write_ptr = msgq->buffer_start;
70001d88:	bf04      	itt	eq
70001d8a:	6923      	ldreq	r3, [r4, #16]
70001d8c:	61e3      	streq	r3, [r4, #28]
			msgq->used_msgs++;
70001d8e:	6a23      	ldr	r3, [r4, #32]
70001d90:	3301      	adds	r3, #1
70001d92:	6223      	str	r3, [r4, #32]
	z_handle_obj_poll_events(&msgq->poll_events, state);
70001d94:	f000 fedc 	bl	70002b50 <z_handle_obj_poll_events>
		return result;
	}

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_msgq, put, msgq, timeout, result);

	z_reschedule(&msgq->lock, key);
70001d98:	4641      	mov	r1, r8
70001d9a:	4638      	mov	r0, r7
70001d9c:	f000 fb64 	bl	70002468 <z_reschedule>

	return result;
}
70001da0:	4630      	mov	r0, r6
70001da2:	b002      	add	sp, #8
70001da4:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
70001da8:	ea56 0203 	orrs.w	r2, r6, r3
		result = -ENOMSG;
70001dac:	bf08      	it	eq
70001dae:	f06f 0622 	mvneq.w	r6, #34	; 0x22
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
70001db2:	d0f1      	beq.n	70001d98 <z_impl_k_msgq_put+0x5c>
		result = z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
70001db4:	4622      	mov	r2, r4
70001db6:	f646 34bc 	movw	r4, #27580	; 0x6bbc
70001dba:	4641      	mov	r1, r8
70001dbc:	f2c7 0400 	movt	r4, #28672	; 0x7000
70001dc0:	4638      	mov	r0, r7
		arch_current_thread()->base.swap_data = (void *) data;
70001dc2:	68a4      	ldr	r4, [r4, #8]
70001dc4:	6165      	str	r5, [r4, #20]
		result = z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
70001dc6:	e9cd 6300 	strd	r6, r3, [sp]
70001dca:	f000 fb19 	bl	70002400 <z_pend_curr>
70001dce:	4606      	mov	r6, r0
}
70001dd0:	4630      	mov	r0, r6
70001dd2:	b002      	add	sp, #8
70001dd4:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
 */

static inline void sys_dlist_remove(sys_dnode_t *node)
{
	sys_dnode_t *const prev = node->prev;
	sys_dnode_t *const next = node->next;
70001dd8:	e9d9 3200 	ldrd	r3, r2, [r9]
	thread->base.pended_on = NULL;
70001ddc:	f04f 0a00 	mov.w	sl, #0

	prev->next = next;
70001de0:	6013      	str	r3, [r2, #0]
}

static inline int z_abort_thread_timeout(struct k_thread *thread)
{
	return z_abort_timeout(&thread->base.timeout);
70001de2:	f109 0018 	add.w	r0, r9, #24
	next->prev = prev;
70001de6:	605a      	str	r2, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
70001de8:	f899 300d 	ldrb.w	r3, [r9, #13]
	node->next = NULL;
70001dec:	2200      	movs	r2, #0
70001dee:	f023 0302 	bic.w	r3, r3, #2
70001df2:	f8c9 a008 	str.w	sl, [r9, #8]
			return 0;
70001df6:	4656      	mov	r6, sl
70001df8:	f889 300d 	strb.w	r3, [r9, #13]
70001dfc:	2300      	movs	r3, #0
70001dfe:	e9c9 2300 	strd	r2, r3, [r9]
70001e02:	f000 fd7b 	bl	700028fc <z_abort_timeout>
			(void)memcpy(pending_thread->base.swap_data, data,
70001e06:	68a2      	ldr	r2, [r4, #8]
70001e08:	f8d9 0014 	ldr.w	r0, [r9, #20]
70001e0c:	4629      	mov	r1, r5
70001e0e:	f001 f847 	bl	70002ea0 <memcpy>
}

static ALWAYS_INLINE void
arch_thread_return_value_set(struct k_thread *thread, unsigned int value)
{
	thread->arch.swap_return_value = value;
70001e12:	f8c9 a070 	str.w	sl, [r9, #112]	; 0x70
			z_ready_thread(pending_thread);
70001e16:	4648      	mov	r0, r9
70001e18:	f000 fa62 	bl	700022e0 <z_ready_thread>
			z_reschedule(&msgq->lock, key);
70001e1c:	4641      	mov	r1, r8
70001e1e:	4638      	mov	r0, r7
70001e20:	f000 fb22 	bl	70002468 <z_reschedule>
			return 0;
70001e24:	e7bc      	b.n	70001da0 <z_impl_k_msgq_put+0x64>
70001e26:	bf00      	nop

70001e28 <z_impl_k_mutex_init>:
#ifdef CONFIG_OBJ_CORE_MUTEX
static struct k_obj_type obj_type_mutex;
#endif /* CONFIG_OBJ_CORE_MUTEX */

int z_impl_k_mutex_init(struct k_mutex *mutex)
{
70001e28:	4603      	mov	r3, r0
	mutex->owner = NULL;
70001e2a:	2200      	movs	r2, #0
#endif /* CONFIG_OBJ_CORE_MUTEX */

	SYS_PORT_TRACING_OBJ_INIT(k_mutex, mutex, 0);

	return 0;
}
70001e2c:	4610      	mov	r0, r2
	mutex->lock_count = 0U;
70001e2e:	e9c3 2202 	strd	r2, r2, [r3, #8]
	list->head = (sys_dnode_t *)list;
70001e32:	601b      	str	r3, [r3, #0]
70001e34:	605b      	str	r3, [r3, #4]
}
70001e36:	4770      	bx	lr

70001e38 <z_impl_k_sem_init>:
static struct k_obj_type obj_type_sem;
#endif /* CONFIG_OBJ_CORE_SEM */

int z_impl_k_sem_init(struct k_sem *sem, unsigned int initial_count,
		      unsigned int limit)
{
70001e38:	4603      	mov	r3, r0
	/*
	 * Limit cannot be zero and count cannot be greater than limit
	 */
	CHECKIF(limit == 0U || initial_count > limit) {
70001e3a:	428a      	cmp	r2, r1
70001e3c:	bf2c      	ite	cs
70001e3e:	f04f 0c00 	movcs.w	ip, #0
70001e42:	f04f 0c01 	movcc.w	ip, #1
70001e46:	2a00      	cmp	r2, #0
70001e48:	bf14      	ite	ne
70001e4a:	4660      	movne	r0, ip
70001e4c:	f04c 0001 	orreq.w	r0, ip, #1
70001e50:	b950      	cbnz	r0, 70001e68 <z_impl_k_sem_init+0x30>

		return -EINVAL;
	}

	sem->count = initial_count;
	sem->limit = limit;
70001e52:	e9c3 1202 	strd	r1, r2, [r3, #8]

	SYS_PORT_TRACING_OBJ_FUNC(k_sem, init, sem, 0);

	z_waitq_init(&sem->wait_q);
#if defined(CONFIG_POLL)
	sys_dlist_init(&sem->poll_events);
70001e56:	f103 0c10 	add.w	ip, r3, #16
70001e5a:	601b      	str	r3, [r3, #0]
70001e5c:	605b      	str	r3, [r3, #4]
70001e5e:	f8c3 c010 	str.w	ip, [r3, #16]
70001e62:	f8c3 c014 	str.w	ip, [r3, #20]

#ifdef CONFIG_OBJ_CORE_SEM
	k_obj_core_init_and_link(K_OBJ_CORE(sem), &obj_type_sem);
#endif /* CONFIG_OBJ_CORE_SEM */

	return 0;
70001e66:	4770      	bx	lr
		return -EINVAL;
70001e68:	f06f 0015 	mvn.w	r0, #21
}
70001e6c:	4770      	bx	lr
70001e6e:	bf00      	nop

70001e70 <z_impl_k_sem_give>:
	return false;
#endif /* CONFIG_POLL */
}

void z_impl_k_sem_give(struct k_sem *sem)
{
70001e70:	b570      	push	{r4, r5, r6, lr}
70001e72:	f3ef 8500 	mrs	r5, CPSR
70001e76:	f005 0580 	and.w	r5, r5, #128	; 0x80
70001e7a:	b672      	cpsid	i
	return list->head == list;
70001e7c:	6804      	ldr	r4, [r0, #0]
		if (unlikely(thread != NULL)) {
70001e7e:	2c00      	cmp	r4, #0
70001e80:	bf18      	it	ne
70001e82:	42a0      	cmpne	r0, r4
70001e84:	d113      	bne.n	70001eae <z_impl_k_sem_give+0x3e>

	if (unlikely(thread != NULL)) {
		arch_thread_return_value_set(thread, 0);
		z_ready_thread(thread);
	} else {
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
70001e86:	e9d0 3202 	ldrd	r3, r2, [r0, #8]
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
70001e8a:	2102      	movs	r1, #2
70001e8c:	3010      	adds	r0, #16
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
70001e8e:	429a      	cmp	r2, r3
70001e90:	bf18      	it	ne
70001e92:	3301      	addne	r3, #1
70001e94:	f840 3c08 	str.w	r3, [r0, #-8]
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
70001e98:	f000 fe5a 	bl	70002b50 <z_handle_obj_poll_events>
		resched = handle_poll_events(sem);
	}

	if (unlikely(resched)) {
		z_reschedule(&lock, key);
70001e9c:	f646 30dc 	movw	r0, #27612	; 0x6bdc
70001ea0:	4629      	mov	r1, r5
70001ea2:	f2c7 0000 	movt	r0, #28672	; 0x7000
	} else {
		k_spin_unlock(&lock, key);
	}

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_sem, give, sem);
}
70001ea6:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		z_reschedule(&lock, key);
70001eaa:	f000 badd 	b.w	70002468 <z_reschedule>
	sys_dnode_t *const next = node->next;
70001eae:	e9d4 3200 	ldrd	r3, r2, [r4]
	thread->base.pended_on = NULL;
70001eb2:	2600      	movs	r6, #0
	prev->next = next;
70001eb4:	6013      	str	r3, [r2, #0]
	node->next = NULL;
70001eb6:	2100      	movs	r1, #0
	next->prev = prev;
70001eb8:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70001eba:	2000      	movs	r0, #0
70001ebc:	7b63      	ldrb	r3, [r4, #13]
70001ebe:	60a6      	str	r6, [r4, #8]
70001ec0:	e9c4 0100 	strd	r0, r1, [r4]
70001ec4:	f023 0302 	bic.w	r3, r3, #2
70001ec8:	f104 0018 	add.w	r0, r4, #24
70001ecc:	7363      	strb	r3, [r4, #13]
70001ece:	f000 fd15 	bl	700028fc <z_abort_timeout>
70001ed2:	6726      	str	r6, [r4, #112]	; 0x70
		z_ready_thread(thread);
70001ed4:	4620      	mov	r0, r4
70001ed6:	f000 fa03 	bl	700022e0 <z_ready_thread>
70001eda:	e7df      	b.n	70001e9c <z_impl_k_sem_give+0x2c>

70001edc <z_impl_k_sem_take>:
}
#include <zephyr/syscalls/k_sem_give_mrsh.c>
#endif /* CONFIG_USERSPACE */

int z_impl_k_sem_take(struct k_sem *sem, k_timeout_t timeout)
{
70001edc:	4684      	mov	ip, r0
70001ede:	f3ef 8100 	mrs	r1, CPSR
70001ee2:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001ee6:	b672      	cpsid	i

	k_spinlock_key_t key = k_spin_lock(&lock);

	SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_sem, take, sem, timeout);

	if (likely(sem->count > 0U)) {
70001ee8:	6880      	ldr	r0, [r0, #8]
70001eea:	b130      	cbz	r0, 70001efa <z_impl_k_sem_take+0x1e>
		sem->count--;
70001eec:	3801      	subs	r0, #1
70001eee:	f8cc 0008 	str.w	r0, [ip, #8]
	if (key != 0U) {
70001ef2:	b901      	cbnz	r1, 70001ef6 <z_impl_k_sem_take+0x1a>
70001ef4:	b662      	cpsie	i
		k_spin_unlock(&lock, key);
		ret = 0;
70001ef6:	2000      	movs	r0, #0

out:
	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_sem, take, sem, timeout, ret);

	return ret;
}
70001ef8:	4770      	bx	lr
{
70001efa:	b510      	push	{r4, lr}
70001efc:	4614      	mov	r4, r2
70001efe:	b082      	sub	sp, #8
	if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
70001f00:	ea54 0203 	orrs.w	r2, r4, r3
70001f04:	d00a      	beq.n	70001f1c <z_impl_k_sem_take+0x40>
	ret = z_pend_curr(&lock, key, &sem->wait_q, timeout);
70001f06:	f646 30dc 	movw	r0, #27612	; 0x6bdc
70001f0a:	4662      	mov	r2, ip
70001f0c:	e9cd 4300 	strd	r4, r3, [sp]
70001f10:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001f14:	f000 fa74 	bl	70002400 <z_pend_curr>
}
70001f18:	b002      	add	sp, #8
70001f1a:	bd10      	pop	{r4, pc}
70001f1c:	b901      	cbnz	r1, 70001f20 <z_impl_k_sem_take+0x44>
70001f1e:	b662      	cpsie	i
		ret = -EBUSY;
70001f20:	f06f 000f 	mvn.w	r0, #15
70001f24:	e7f8      	b.n	70001f18 <z_impl_k_sem_take+0x3c>
70001f26:	bf00      	nop

70001f28 <k_is_in_isr>:
70001f28:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
#include <zephyr/arch/arm/cortex_a_r/lib_helpers.h>
#include <zephyr/arch/arm/cortex_a_r/tpidruro.h>

static ALWAYS_INLINE _cpu_t *arch_curr_cpu(void)
{
	return (_cpu_t *)(read_tpidruro() & TPIDRURO_CURR_CPU);
70001f2c:	f023 0303 	bic.w	r3, r3, #3
#endif

/* Check the CPSR mode bits to see if we are in IRQ or FIQ mode */
static ALWAYS_INLINE bool arch_is_in_isr(void)
{
	return (arch_curr_cpu()->nested != 0U);
70001f30:	6818      	ldr	r0, [r3, #0]
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data)

bool k_is_in_isr(void)
{
	return arch_is_in_isr();
}
70001f32:	3800      	subs	r0, #0
70001f34:	bf18      	it	ne
70001f36:	2001      	movne	r0, #1
70001f38:	4770      	bx	lr
70001f3a:	bf00      	nop

70001f3c <z_impl_k_thread_name_set>:

	SYS_PORT_TRACING_OBJ_FUNC(k_thread, name_set, thread, -ENOSYS);

	return -ENOSYS;
#endif /* CONFIG_THREAD_NAME */
}
70001f3c:	f06f 0057 	mvn.w	r0, #87	; 0x57
70001f40:	4770      	bx	lr
70001f42:	bf00      	nop

70001f44 <z_setup_new_thread>:
		stack_buf_size = stack_obj_size - K_THREAD_STACK_RESERVED;
	} else
#endif /* CONFIG_USERSPACE */
	{
		/* Object cannot host a user mode thread */
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
70001f44:	3207      	adds	r2, #7
70001f46:	f022 0207 	bic.w	r2, r2, #7
char *z_setup_new_thread(struct k_thread *new_thread,
			 k_thread_stack_t *stack, size_t stack_size,
			 k_thread_entry_t entry,
			 void *p1, void *p2, void *p3,
			 int prio, uint32_t options, const char *name)
{
70001f4a:	e92d 4370 	stmdb	sp!, {r4, r5, r6, r8, r9, lr}
	stack_ptr = (char *)stack + stack_obj_size;
70001f4e:	188d      	adds	r5, r1, r2
	SYS_DLIST_FOR_EACH_CONTAINER(&((wq)->waitq), thread_ptr, \
				     base.qnode_dlist)

static inline void z_waitq_init(_wait_q_t *w)
{
	sys_dlist_init(&w->waitq);
70001f50:	f100 0258 	add.w	r2, r0, #88	; 0x58

void z_init_thread_base(struct _thread_base *thread_base, int priority,
		       uint32_t initial_state, unsigned int options)
{
	/* k_q_node is initialized upon first insertion in a list */
	thread_base->pended_on = NULL;
70001f54:	2600      	movs	r6, #0
{
70001f56:	b084      	sub	sp, #16
	list->head = (sys_dnode_t *)list;
70001f58:	e9c0 2216 	strd	r2, r2, [r0, #88]	; 0x58
	thread_base->user_options = (uint8_t)options;
	thread_base->thread_state = (uint8_t)initial_state;
70001f5c:	2204      	movs	r2, #4
	thread_base->pended_on = NULL;
70001f5e:	6086      	str	r6, [r0, #8]
	node->next = NULL;
70001f60:	f04f 0800 	mov.w	r8, #0
	thread_base->thread_state = (uint8_t)initial_state;
70001f64:	7342      	strb	r2, [r0, #13]
70001f66:	f04f 0900 	mov.w	r9, #0
{
70001f6a:	9a0a      	ldr	r2, [sp, #40]	; 0x28
70001f6c:	4604      	mov	r4, r0

	thread_base->prio = priority;

	thread_base->sched_locked = 0U;
70001f6e:	73c6      	strb	r6, [r0, #15]
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001f70:	9200      	str	r2, [sp, #0]
{
70001f72:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001f74:	9201      	str	r2, [sp, #4]
{
70001f76:	9a0c      	ldr	r2, [sp, #48]	; 0x30
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001f78:	9202      	str	r2, [sp, #8]
{
70001f7a:	9a0d      	ldr	r2, [sp, #52]	; 0x34
	thread_base->prio = priority;
70001f7c:	7382      	strb	r2, [r0, #14]
{
70001f7e:	9a0e      	ldr	r2, [sp, #56]	; 0x38
	thread_base->user_options = (uint8_t)options;
70001f80:	7302      	strb	r2, [r0, #12]
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001f82:	462a      	mov	r2, r5
70001f84:	e9c0 8906 	strd	r8, r9, [r0, #24]
70001f88:	f7fe fee8 	bl	70000d5c <arch_new_thread>
70001f8c:	f646 33bc 	movw	r3, #27580	; 0x6bbc
	new_thread->init_data = NULL;
70001f90:	6566      	str	r6, [r4, #84]	; 0x54
70001f92:	f2c7 0300 	movt	r3, #28672	; 0x7000
}
70001f96:	4628      	mov	r0, r5
	new_thread->resource_pool = arch_current_thread()->resource_pool;
70001f98:	689b      	ldr	r3, [r3, #8]
70001f9a:	6e9b      	ldr	r3, [r3, #104]	; 0x68
70001f9c:	66a3      	str	r3, [r4, #104]	; 0x68
}
70001f9e:	b004      	add	sp, #16
70001fa0:	e8bd 8370 	ldmia.w	sp!, {r4, r5, r6, r8, r9, pc}

70001fa4 <z_impl_k_thread_create>:
{
70001fa4:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
70001fa8:	f100 0658 	add.w	r6, r0, #88	; 0x58
	thread_base->pended_on = NULL;
70001fac:	2500      	movs	r5, #0
{
70001fae:	b085      	sub	sp, #20
	list->head = (sys_dnode_t *)list;
70001fb0:	e9c0 6616 	strd	r6, r6, [r0, #88]	; 0x58
	thread_base->thread_state = (uint8_t)initial_state;
70001fb4:	2604      	movs	r6, #4
	thread_base->pended_on = NULL;
70001fb6:	6085      	str	r5, [r0, #8]
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
70001fb8:	3207      	adds	r2, #7
	thread_base->thread_state = (uint8_t)initial_state;
70001fba:	7346      	strb	r6, [r0, #13]
	node->next = NULL;
70001fbc:	f04f 0800 	mov.w	r8, #0
{
70001fc0:	9e0c      	ldr	r6, [sp, #48]	; 0x30
70001fc2:	f04f 0900 	mov.w	r9, #0
	thread_base->sched_locked = 0U;
70001fc6:	73c5      	strb	r5, [r0, #15]
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
70001fc8:	f022 0207 	bic.w	r2, r2, #7
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001fcc:	9600      	str	r6, [sp, #0]
70001fce:	440a      	add	r2, r1
{
70001fd0:	9e0d      	ldr	r6, [sp, #52]	; 0x34
70001fd2:	4604      	mov	r4, r0
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001fd4:	9601      	str	r6, [sp, #4]
{
70001fd6:	9e0e      	ldr	r6, [sp, #56]	; 0x38
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001fd8:	9602      	str	r6, [sp, #8]
{
70001fda:	9e0f      	ldr	r6, [sp, #60]	; 0x3c
	thread_base->prio = priority;
70001fdc:	7386      	strb	r6, [r0, #14]
{
70001fde:	9e10      	ldr	r6, [sp, #64]	; 0x40
	thread_base->user_options = (uint8_t)options;
70001fe0:	7306      	strb	r6, [r0, #12]
70001fe2:	e9c0 8906 	strd	r8, r9, [r0, #24]
{
70001fe6:	e9dd 7612 	ldrd	r7, r6, [sp, #72]	; 0x48
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001fea:	f7fe feb7 	bl	70000d5c <arch_new_thread>
	new_thread->init_data = NULL;
70001fee:	6565      	str	r5, [r4, #84]	; 0x54
70001ff0:	f646 33bc 	movw	r3, #27580	; 0x6bbc
70001ff4:	f2c7 0300 	movt	r3, #28672	; 0x7000
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
70001ff8:	f1b6 3fff 	cmp.w	r6, #4294967295	; 0xffffffff
70001ffc:	bf08      	it	eq
70001ffe:	f1b7 3fff 	cmpeq.w	r7, #4294967295	; 0xffffffff
	new_thread->resource_pool = arch_current_thread()->resource_pool;
70002002:	689b      	ldr	r3, [r3, #8]
70002004:	6e9b      	ldr	r3, [r3, #104]	; 0x68
70002006:	66a3      	str	r3, [r4, #104]	; 0x68
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
70002008:	d103      	bne.n	70002012 <z_impl_k_thread_create+0x6e>
}
7000200a:	4620      	mov	r0, r4
7000200c:	b005      	add	sp, #20
7000200e:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
70002012:	ea56 0307 	orrs.w	r3, r6, r7
70002016:	d106      	bne.n	70002026 <z_impl_k_thread_create+0x82>
70002018:	4620      	mov	r0, r4
7000201a:	f000 fb53 	bl	700026c4 <z_impl_k_wakeup>
7000201e:	4620      	mov	r0, r4
70002020:	b005      	add	sp, #20
70002022:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
70002026:	f242 31f9 	movw	r1, #9209	; 0x23f9
7000202a:	f104 0018 	add.w	r0, r4, #24
7000202e:	463a      	mov	r2, r7
70002030:	4633      	mov	r3, r6
70002032:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002036:	f000 fbcf 	bl	700027d8 <z_add_timeout>
7000203a:	4620      	mov	r0, r4
7000203c:	b005      	add	sp, #20
7000203e:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
70002042:	bf00      	nop

70002044 <unready_thread>:
}
#include <zephyr/syscalls/k_thread_resume_mrsh.c>
#endif /* CONFIG_USERSPACE */

static void unready_thread(struct k_thread *thread)
{
70002044:	b410      	push	{r4}
	return (thread->base.thread_state & state) != 0U;
70002046:	7b43      	ldrb	r3, [r0, #13]
	if (z_is_thread_queued(thread)) {
70002048:	061c      	lsls	r4, r3, #24
7000204a:	d509      	bpl.n	70002060 <unready_thread+0x1c>
7000204c:	2200      	movs	r2, #0
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000204e:	f003 037f 	and.w	r3, r3, #127	; 0x7f
	sys_dnode_t *const next = node->next;
70002052:	e9d0 1400 	ldrd	r1, r4, [r0]
70002056:	7343      	strb	r3, [r0, #13]
	prev->next = next;
70002058:	6021      	str	r1, [r4, #0]
	next->prev = prev;
7000205a:	604c      	str	r4, [r1, #4]
	node->next = NULL;
7000205c:	6002      	str	r2, [r0, #0]
7000205e:	6042      	str	r2, [r0, #4]
70002060:	f646 33bc 	movw	r3, #27580	; 0x6bbc
70002064:	f2c7 0300 	movt	r3, #28672	; 0x7000
	return list->head == list;
70002068:	4619      	mov	r1, r3
7000206a:	689c      	ldr	r4, [r3, #8]
7000206c:	f851 2f18 	ldr.w	r2, [r1, #24]!
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002070:	428a      	cmp	r2, r1
70002072:	bf18      	it	ne
70002074:	2a00      	cmpne	r2, #0
70002076:	bf08      	it	eq
70002078:	68da      	ldreq	r2, [r3, #12]
					 int preempt_ok)
{
	/* Preemption is OK if it's being explicitly allowed by
	 * software state (e.g. the thread called k_yield())
	 */
	if (preempt_ok != 0) {
7000207a:	42a0      	cmp	r0, r4
7000207c:	d006      	beq.n	7000208c <unready_thread+0x48>
	}

	__ASSERT(arch_current_thread() != NULL, "");

	/* Or if we're pended/suspended/dummy (duh) */
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
7000207e:	7b61      	ldrb	r1, [r4, #13]
70002080:	06c9      	lsls	r1, r1, #27
70002082:	d103      	bne.n	7000208c <unready_thread+0x48>
	}

	/* Otherwise we have to be running a preemptible thread or
	 * switching to a metairq
	 */
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
70002084:	89e1      	ldrh	r1, [r4, #14]
		_kernel.ready_q.cache = arch_current_thread();
70002086:	297f      	cmp	r1, #127	; 0x7f
70002088:	bf88      	it	hi
7000208a:	4622      	movhi	r2, r4
7000208c:	615a      	str	r2, [r3, #20]
		dequeue_thread(thread);
	}
	update_cache(thread == arch_current_thread());
}
7000208e:	bc10      	pop	{r4}
70002090:	4770      	bx	lr
70002092:	bf00      	nop

70002094 <add_to_waitq_locked>:

/* _sched_spinlock must be held */
static void add_to_waitq_locked(struct k_thread *thread, _wait_q_t *wait_q)
{
70002094:	b538      	push	{r3, r4, r5, lr}
70002096:	460d      	mov	r5, r1
	unready_thread(thread);
70002098:	f7ff ffd4 	bl	70002044 <unready_thread>
	thread->base.thread_state |= _THREAD_PENDING;
7000209c:	7b43      	ldrb	r3, [r0, #13]
7000209e:	f043 0302 	orr.w	r3, r3, #2
700020a2:	7343      	strb	r3, [r0, #13]
	z_mark_thread_as_pending(thread);

	SYS_PORT_TRACING_FUNC(k_thread, sched_pend, thread);

	if (wait_q != NULL) {
700020a4:	b1bd      	cbz	r5, 700020d6 <add_to_waitq_locked+0x42>
		thread->base.pended_on = wait_q;
700020a6:	6085      	str	r5, [r0, #8]
700020a8:	4604      	mov	r4, r0
700020aa:	682b      	ldr	r3, [r5, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
700020ac:	429d      	cmp	r5, r3
700020ae:	d00d      	beq.n	700020cc <add_to_waitq_locked+0x38>
static ALWAYS_INLINE void z_priq_dumb_add(sys_dlist_t *pq,
					  struct k_thread *thread)
{
	struct k_thread *t;

	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
700020b0:	b163      	cbz	r3, 700020cc <add_to_waitq_locked+0x38>
	int32_t b2 = thread_2->base.prio;
700020b2:	f993 c00e 	ldrsb.w	ip, [r3, #14]
	int32_t b1 = thread_1->base.prio;
700020b6:	f994 200e 	ldrsb.w	r2, [r4, #14]
	if (b1 != b2) {
700020ba:	4562      	cmp	r2, ip
700020bc:	d001      	beq.n	700020c2 <add_to_waitq_locked+0x2e>
		if (z_sched_prio_cmp(thread, t) > 0) {
700020be:	4594      	cmp	ip, r2
700020c0:	dc0a      	bgt.n	700020d8 <add_to_waitq_locked+0x44>
	return (node == list->tail) ? NULL : node->next;
700020c2:	686a      	ldr	r2, [r5, #4]
700020c4:	4293      	cmp	r3, r2
700020c6:	d002      	beq.n	700020ce <add_to_waitq_locked+0x3a>
700020c8:	681b      	ldr	r3, [r3, #0]
700020ca:	e7f1      	b.n	700020b0 <add_to_waitq_locked+0x1c>
700020cc:	686a      	ldr	r2, [r5, #4]
	node->prev = tail;
700020ce:	e9c4 5200 	strd	r5, r2, [r4]
	tail->next = node;
700020d2:	6014      	str	r4, [r2, #0]
	list->tail = node;
700020d4:	606c      	str	r4, [r5, #4]
		_priq_wait_add(&wait_q->waitq, thread);
	}
}
700020d6:	bd38      	pop	{r3, r4, r5, pc}
	sys_dnode_t *const prev = successor->prev;
700020d8:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
700020da:	e9c4 3200 	strd	r3, r2, [r4]
	prev->next = node;
700020de:	6014      	str	r4, [r2, #0]
	successor->prev = node;
700020e0:	605c      	str	r4, [r3, #4]
700020e2:	bd38      	pop	{r3, r4, r5, pc}

700020e4 <ready_thread>:
	return (thread->base.thread_state & state) != 0U;
700020e4:	7b43      	ldrb	r3, [r0, #13]
	if (!z_is_thread_queued(thread) && z_is_thread_ready(thread)) {
700020e6:	0619      	lsls	r1, r3, #24
700020e8:	d403      	bmi.n	700020f2 <ready_thread+0xe>
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
700020ea:	06da      	lsls	r2, r3, #27
700020ec:	d101      	bne.n	700020f2 <ready_thread+0xe>
	return node->next != NULL;
700020ee:	6982      	ldr	r2, [r0, #24]
700020f0:	b102      	cbz	r2, 700020f4 <ready_thread+0x10>
700020f2:	4770      	bx	lr
	return list->head == list;
700020f4:	f646 3cbc 	movw	ip, #27580	; 0x6bbc
	thread->base.thread_state |= _THREAD_QUEUED;
700020f8:	f063 037f 	orn	r3, r3, #127	; 0x7f
700020fc:	f2c7 0c00 	movt	ip, #28672	; 0x7000
{
70002100:	b430      	push	{r4, r5}
	thread->base.thread_state |= _THREAD_QUEUED;
70002102:	7343      	strb	r3, [r0, #13]
70002104:	4665      	mov	r5, ip
	return (node == list->tail) ? NULL : node->next;
70002106:	f8dc 401c 	ldr.w	r4, [ip, #28]
	return list->head == list;
7000210a:	f855 3f18 	ldr.w	r3, [r5, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
7000210e:	42ab      	cmp	r3, r5
70002110:	bf08      	it	eq
70002112:	2300      	moveq	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
70002114:	b15b      	cbz	r3, 7000212e <ready_thread+0x4a>
	int32_t b2 = thread_2->base.prio;
70002116:	f993 100e 	ldrsb.w	r1, [r3, #14]
	int32_t b1 = thread_1->base.prio;
7000211a:	f990 200e 	ldrsb.w	r2, [r0, #14]
	if (b1 != b2) {
7000211e:	428a      	cmp	r2, r1
70002120:	d001      	beq.n	70002126 <ready_thread+0x42>
		if (z_sched_prio_cmp(thread, t) > 0) {
70002122:	4291      	cmp	r1, r2
70002124:	dc20      	bgt.n	70002168 <ready_thread+0x84>
	return (node == list->tail) ? NULL : node->next;
70002126:	42a3      	cmp	r3, r4
70002128:	d001      	beq.n	7000212e <ready_thread+0x4a>
7000212a:	681b      	ldr	r3, [r3, #0]
7000212c:	e7f2      	b.n	70002114 <ready_thread+0x30>
	node->prev = tail;
7000212e:	e9c0 5400 	strd	r5, r4, [r0]
	tail->next = node;
70002132:	6020      	str	r0, [r4, #0]
	list->tail = node;
70002134:	f8cc 001c 	str.w	r0, [ip, #28]
	return list->head == list;
70002138:	f8dc 3018 	ldr.w	r3, [ip, #24]
7000213c:	f8dc 2008 	ldr.w	r2, [ip, #8]
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
70002140:	7b51      	ldrb	r1, [r2, #13]
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002142:	2b00      	cmp	r3, #0
70002144:	bf18      	it	ne
70002146:	42ab      	cmpne	r3, r5
70002148:	bf08      	it	eq
7000214a:	f8dc 300c 	ldreq.w	r3, [ip, #12]
7000214e:	06c9      	lsls	r1, r1, #27
70002150:	d107      	bne.n	70002162 <ready_thread+0x7e>
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
70002152:	89d1      	ldrh	r1, [r2, #14]
70002154:	297f      	cmp	r1, #127	; 0x7f
		_kernel.ready_q.cache = arch_current_thread();
70002156:	bf88      	it	hi
70002158:	f8cc 2014 	strhi.w	r2, [ip, #20]
7000215c:	d901      	bls.n	70002162 <ready_thread+0x7e>
}
7000215e:	bc30      	pop	{r4, r5}
70002160:	4770      	bx	lr
		_kernel.ready_q.cache = thread;
70002162:	f8cc 3014 	str.w	r3, [ip, #20]
}
70002166:	e7fa      	b.n	7000215e <ready_thread+0x7a>
	sys_dnode_t *const prev = successor->prev;
70002168:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
7000216a:	e9c0 3200 	strd	r3, r2, [r0]
	prev->next = node;
7000216e:	6010      	str	r0, [r2, #0]
	successor->prev = node;
70002170:	6058      	str	r0, [r3, #4]
}
70002172:	e7e1      	b.n	70002138 <ready_thread+0x54>

70002174 <z_thread_halt>:
		halt_thread(thread, terminate ? _THREAD_DEAD : _THREAD_SUSPENDED);
70002174:	2a00      	cmp	r2, #0
70002176:	bf0c      	ite	eq
70002178:	2210      	moveq	r2, #16
7000217a:	2208      	movne	r2, #8
{
7000217c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	bool dummify = false;

	/* We hold the lock, and the thread is known not to be running
	 * anywhere.
	 */
	if ((thread->base.thread_state & new_state) == 0U) {
70002180:	7b43      	ldrb	r3, [r0, #13]
{
70002182:	460f      	mov	r7, r1
	if ((thread->base.thread_state & new_state) == 0U) {
70002184:	ea12 0103 	ands.w	r1, r2, r3
70002188:	bf18      	it	ne
7000218a:	f646 33bc 	movwne	r3, #27580	; 0x6bbc
{
7000218e:	4605      	mov	r5, r0
70002190:	bf18      	it	ne
70002192:	f2c7 0300 	movtne	r3, #28672	; 0x7000
	if ((thread->base.thread_state & new_state) == 0U) {
70002196:	d122      	bne.n	700021de <z_thread_halt+0x6a>
		thread->base.thread_state |= new_state;
70002198:	ea42 0003 	orr.w	r0, r2, r3
		if (z_is_thread_queued(thread)) {
7000219c:	09db      	lsrs	r3, r3, #7
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000219e:	bf17      	itett	ne
700021a0:	f000 007f 	andne.w	r0, r0, #127	; 0x7f
		thread->base.thread_state |= new_state;
700021a4:	7368      	strbeq	r0, [r5, #13]
	thread->base.thread_state &= ~_THREAD_QUEUED;
700021a6:	7368      	strbne	r0, [r5, #13]
	sys_dnode_t *const next = node->next;
700021a8:	e9d5 3000 	ldrdne	r3, r0, [r5]
	prev->next = next;
700021ac:	bf1e      	ittt	ne
700021ae:	6003      	strne	r3, [r0, #0]
	next->prev = prev;
700021b0:	6058      	strne	r0, [r3, #4]
	node->prev = NULL;
700021b2:	e9c5 1100 	strdne	r1, r1, [r5]
			dequeue_thread(thread);
		}

		if (new_state == _THREAD_DEAD) {
700021b6:	2a08      	cmp	r2, #8
700021b8:	d029      	beq.n	7000220e <z_thread_halt+0x9a>
	return list->head == list;
700021ba:	f646 33bc 	movw	r3, #27580	; 0x6bbc
700021be:	f2c7 0300 	movt	r3, #28672	; 0x7000
700021c2:	461a      	mov	r2, r3
700021c4:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
700021c8:	4291      	cmp	r1, r2
700021ca:	d05f      	beq.n	7000228c <z_thread_halt+0x118>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700021cc:	2900      	cmp	r1, #0
700021ce:	d069      	beq.n	700022a4 <z_thread_halt+0x130>
		_kernel.ready_q.cache = thread;
700021d0:	6159      	str	r1, [r3, #20]
  __ASM volatile ("dmb 0xF":::"memory");
700021d2:	f3bf 8f5f 	dmb	sy
	thread->base.thread_state &= ~(_THREAD_ABORTING | _THREAD_SUSPENDING);
700021d6:	7b6a      	ldrb	r2, [r5, #13]
700021d8:	f022 0260 	bic.w	r2, r2, #96	; 0x60
700021dc:	736a      	strb	r2, [r5, #13]
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
700021de:	689a      	ldr	r2, [r3, #8]
700021e0:	4295      	cmp	r5, r2
700021e2:	d003      	beq.n	700021ec <z_thread_halt+0x78>
700021e4:	b907      	cbnz	r7, 700021e8 <z_thread_halt+0x74>
  __ASM volatile ("cpsie i" : : : "memory");
700021e6:	b662      	cpsie	i
}
700021e8:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
700021ec:	ee1d 2f70 	mrc	15, 0, r2, cr13, cr0, {3}
700021f0:	f022 0203 	bic.w	r2, r2, #3
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
700021f4:	6812      	ldr	r2, [r2, #0]
700021f6:	2a00      	cmp	r2, #0
700021f8:	d1f4      	bne.n	700021e4 <z_thread_halt+0x70>
700021fa:	689b      	ldr	r3, [r3, #8]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700021fc:	f06f 020a 	mvn.w	r2, #10
70002200:	e9c3 721b 	strd	r7, r2, [r3, #108]	; 0x6c
	z_arm_cortex_r_svc();
70002204:	f7fe eee6 	blx	70000fd4 <z_arm_cortex_r_svc>
70002208:	2f00      	cmp	r7, #0
7000220a:	d0ec      	beq.n	700021e6 <z_thread_halt+0x72>
7000220c:	e7ec      	b.n	700021e8 <z_thread_halt+0x74>
			if (thread->base.pended_on != NULL) {
7000220e:	68ab      	ldr	r3, [r5, #8]
70002210:	b15b      	cbz	r3, 7000222a <z_thread_halt+0xb6>
	sys_dnode_t *const next = node->next;
70002212:	e9d5 3100 	ldrd	r3, r1, [r5]
	node->next = NULL;
70002216:	2200      	movs	r2, #0
	prev->next = next;
70002218:	600b      	str	r3, [r1, #0]
	next->prev = prev;
7000221a:	6059      	str	r1, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
7000221c:	7b6b      	ldrb	r3, [r5, #13]
	node->prev = NULL;
7000221e:	e9c5 2200 	strd	r2, r2, [r5]
70002222:	f023 0302 	bic.w	r3, r3, #2
70002226:	60aa      	str	r2, [r5, #8]
70002228:	736b      	strb	r3, [r5, #13]
	return z_abort_timeout(&thread->base.timeout);
7000222a:	f105 0018 	add.w	r0, r5, #24
7000222e:	f000 fb65 	bl	700028fc <z_abort_timeout>
	return list->head == list;
70002232:	6dac      	ldr	r4, [r5, #88]	; 0x58
}

static inline struct k_thread *z_waitq_head(_wait_q_t *w)
{
	return (struct k_thread *)sys_dlist_peek_head(&w->waitq);
70002234:	f105 0858 	add.w	r8, r5, #88	; 0x58
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002238:	45a0      	cmp	r8, r4
7000223a:	d019      	beq.n	70002270 <z_thread_halt+0xfc>
	for (thread = z_waitq_head(wait_q); thread != NULL; thread = z_waitq_head(wait_q)) {
7000223c:	b1c4      	cbz	r4, 70002270 <z_thread_halt+0xfc>
	node->next = NULL;
7000223e:	2600      	movs	r6, #0
70002240:	e000      	b.n	70002244 <z_thread_halt+0xd0>
70002242:	b1ac      	cbz	r4, 70002270 <z_thread_halt+0xfc>
	sys_dnode_t *const next = node->next;
70002244:	e9d4 3200 	ldrd	r3, r2, [r4]
70002248:	f104 0018 	add.w	r0, r4, #24
	prev->next = next;
7000224c:	6013      	str	r3, [r2, #0]
	next->prev = prev;
7000224e:	605a      	str	r2, [r3, #4]
70002250:	7b63      	ldrb	r3, [r4, #13]
	node->prev = NULL;
70002252:	e9c4 6600 	strd	r6, r6, [r4]
70002256:	f023 0302 	bic.w	r3, r3, #2
7000225a:	60a6      	str	r6, [r4, #8]
7000225c:	7363      	strb	r3, [r4, #13]
7000225e:	f000 fb4d 	bl	700028fc <z_abort_timeout>
	thread->arch.swap_return_value = value;
70002262:	6726      	str	r6, [r4, #112]	; 0x70
		ready_thread(thread);
70002264:	4620      	mov	r0, r4
70002266:	f7ff ff3d 	bl	700020e4 <ready_thread>
	return list->head == list;
7000226a:	6dac      	ldr	r4, [r5, #88]	; 0x58
	return sys_dlist_is_empty(list) ? NULL : list->head;
7000226c:	45a0      	cmp	r8, r4
7000226e:	d1e8      	bne.n	70002242 <z_thread_halt+0xce>
70002270:	f646 33bc 	movw	r3, #27580	; 0x6bbc
70002274:	f2c7 0300 	movt	r3, #28672	; 0x7000
			 * ISR that preempted it requires clearing the
			 * arch_current_thread() pointer so the upcoming context
			 * switch doesn't clobber the now-freed
			 * memory
			 */
			if (thread == arch_current_thread() && arch_is_in_isr()) {
70002278:	689a      	ldr	r2, [r3, #8]
7000227a:	4295      	cmp	r5, r2
7000227c:	d014      	beq.n	700022a8 <z_thread_halt+0x134>
	return list->head == list;
7000227e:	461a      	mov	r2, r3
70002280:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002284:	4291      	cmp	r1, r2
70002286:	d001      	beq.n	7000228c <z_thread_halt+0x118>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002288:	2900      	cmp	r1, #0
7000228a:	d1a1      	bne.n	700021d0 <z_thread_halt+0x5c>
		_kernel.ready_q.cache = thread;
7000228c:	68da      	ldr	r2, [r3, #12]
7000228e:	615a      	str	r2, [r3, #20]
  __ASM volatile ("dmb 0xF":::"memory");
70002290:	f3bf 8f5f 	dmb	sy
	thread->base.thread_state &= ~(_THREAD_ABORTING | _THREAD_SUSPENDING);
70002294:	7b6a      	ldrb	r2, [r5, #13]
70002296:	f022 0260 	bic.w	r2, r2, #96	; 0x60
7000229a:	736a      	strb	r2, [r5, #13]
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
7000229c:	689a      	ldr	r2, [r3, #8]
7000229e:	4295      	cmp	r5, r2
700022a0:	d1a0      	bne.n	700021e4 <z_thread_halt+0x70>
700022a2:	e7a3      	b.n	700021ec <z_thread_halt+0x78>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700022a4:	68d9      	ldr	r1, [r3, #12]
#ifdef CONFIG_SMP
		unpend_all(&thread->halt_queue);
#endif /* CONFIG_SMP */
		update_cache(1);

		if (new_state == _THREAD_SUSPENDED) {
700022a6:	e793      	b.n	700021d0 <z_thread_halt+0x5c>
700022a8:	ee1d 2f70 	mrc	15, 0, r2, cr13, cr0, {3}
700022ac:	f022 0203 	bic.w	r2, r2, #3
			if (thread == arch_current_thread() && arch_is_in_isr()) {
700022b0:	6812      	ldr	r2, [r2, #0]
700022b2:	2a00      	cmp	r2, #0
700022b4:	d0e3      	beq.n	7000227e <z_thread_halt+0x10a>
	return list->head == list;
700022b6:	461a      	mov	r2, r3
700022b8:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
700022bc:	4291      	cmp	r1, r2
700022be:	d00c      	beq.n	700022da <z_thread_halt+0x166>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700022c0:	b159      	cbz	r1, 700022da <z_thread_halt+0x166>
		_kernel.ready_q.cache = thread;
700022c2:	6159      	str	r1, [r3, #20]
700022c4:	f245 32f0 	movw	r2, #21488	; 0x53f0
700022c8:	f240 1101 	movw	r1, #257	; 0x101
700022cc:	f2c7 0200 	movt	r2, #28672	; 0x7000
700022d0:	8191      	strh	r1, [r2, #12]
	dummy_thread->resource_pool = NULL;
700022d2:	2100      	movs	r1, #0
	_current_cpu->current = thread;
700022d4:	609a      	str	r2, [r3, #8]
700022d6:	6691      	str	r1, [r2, #104]	; 0x68
#ifdef CONFIG_TIMESLICE_PER_THREAD
	dummy_thread->base.slice_ticks = 0;
#endif /* CONFIG_TIMESLICE_PER_THREAD */

	arch_current_thread_set(dummy_thread);
}
700022d8:	e7da      	b.n	70002290 <z_thread_halt+0x11c>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700022da:	68d9      	ldr	r1, [r3, #12]
		 * code.  Note that we must leave a non-null switch
		 * handle for any threads spinning in join() (this can
		 * never be used, as our thread is flagged dead, but
		 * it must not be NULL otherwise join can deadlock).
		 */
		if (dummify && !IS_ENABLED(CONFIG_ARCH_POSIX)) {
700022dc:	e7f1      	b.n	700022c2 <z_thread_halt+0x14e>
700022de:	bf00      	nop

700022e0 <z_ready_thread>:
{
700022e0:	b510      	push	{r4, lr}
	__asm__ volatile(
700022e2:	f3ef 8400 	mrs	r4, CPSR
700022e6:	f004 0480 	and.w	r4, r4, #128	; 0x80
700022ea:	b672      	cpsid	i
			ready_thread(thread);
700022ec:	f7ff fefa 	bl	700020e4 <ready_thread>
	if (key != 0U) {
700022f0:	b904      	cbnz	r4, 700022f4 <z_ready_thread+0x14>
  __ASM volatile ("cpsie i" : : : "memory");
700022f2:	b662      	cpsie	i
}
700022f4:	bd10      	pop	{r4, pc}
700022f6:	bf00      	nop

700022f8 <z_impl_k_thread_suspend>:
	struct k_thread *ret = _kernel.cpus[0].current;
700022f8:	f646 33bc 	movw	r3, #27580	; 0x6bbc
700022fc:	f2c7 0300 	movt	r3, #28672	; 0x7000
	if (thread == arch_current_thread() && !arch_is_in_isr() && !IS_ENABLED(CONFIG_SMP)) {
70002300:	689a      	ldr	r2, [r3, #8]
70002302:	4282      	cmp	r2, r0
70002304:	d00e      	beq.n	70002324 <z_impl_k_thread_suspend+0x2c>
	__asm__ volatile(
70002306:	f3ef 8100 	mrs	r1, CPSR
7000230a:	f001 0180 	and.w	r1, r1, #128	; 0x80
7000230e:	b672      	cpsid	i
	if ((thread->base.thread_state & _THREAD_SUSPENDED) != 0U) {
70002310:	7b42      	ldrb	r2, [r0, #13]
70002312:	f012 0210 	ands.w	r2, r2, #16
70002316:	d002      	beq.n	7000231e <z_impl_k_thread_suspend+0x26>
	if (key != 0U) {
70002318:	b919      	cbnz	r1, 70002322 <z_impl_k_thread_suspend+0x2a>
7000231a:	b662      	cpsie	i
}
7000231c:	4770      	bx	lr
	z_thread_halt(thread, key, false);
7000231e:	f7ff bf29 	b.w	70002174 <z_thread_halt>
70002322:	4770      	bx	lr
70002324:	ee1d 1f70 	mrc	15, 0, r1, cr13, cr0, {3}
70002328:	f021 0103 	bic.w	r1, r1, #3
	if (thread == arch_current_thread() && !arch_is_in_isr() && !IS_ENABLED(CONFIG_SMP)) {
7000232c:	6809      	ldr	r1, [r1, #0]
7000232e:	2900      	cmp	r1, #0
70002330:	d1e9      	bne.n	70002306 <z_impl_k_thread_suspend+0xe>
{
70002332:	b570      	push	{r4, r5, r6, lr}
	__asm__ volatile(
70002334:	f3ef 8400 	mrs	r4, CPSR
70002338:	f004 0480 	and.w	r4, r4, #128	; 0x80
7000233c:	b672      	cpsid	i
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000233e:	7b50      	ldrb	r0, [r2, #13]
	sys_dnode_t *const prev = node->prev;
70002340:	6856      	ldr	r6, [r2, #4]
	sys_dnode_t *const next = node->next;
70002342:	6815      	ldr	r5, [r2, #0]
70002344:	f000 007f 	and.w	r0, r0, #127	; 0x7f
70002348:	f040 0010 	orr.w	r0, r0, #16
7000234c:	7350      	strb	r0, [r2, #13]
	return list->head == list;
7000234e:	4618      	mov	r0, r3
	prev->next = next;
70002350:	6035      	str	r5, [r6, #0]
	next->prev = prev;
70002352:	606e      	str	r6, [r5, #4]
	node->next = NULL;
70002354:	6011      	str	r1, [r2, #0]
70002356:	6051      	str	r1, [r2, #4]
	return list->head == list;
70002358:	f850 2f18 	ldr.w	r2, [r0, #24]!
7000235c:	6899      	ldr	r1, [r3, #8]
	arch_current_thread()->arch.basepri = key;
7000235e:	66cc      	str	r4, [r1, #108]	; 0x6c
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002360:	4282      	cmp	r2, r0
70002362:	bf18      	it	ne
70002364:	2a00      	cmpne	r2, #0
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
70002366:	f06f 000a 	mvn.w	r0, #10
7000236a:	bf08      	it	eq
7000236c:	68da      	ldreq	r2, [r3, #12]
7000236e:	6708      	str	r0, [r1, #112]	; 0x70
		_kernel.ready_q.cache = thread;
70002370:	615a      	str	r2, [r3, #20]
	z_arm_cortex_r_svc();
70002372:	f7fe ee30 	blx	70000fd4 <z_arm_cortex_r_svc>
	if (key != 0U) {
70002376:	b904      	cbnz	r4, 7000237a <z_impl_k_thread_suspend+0x82>
  __ASM volatile ("cpsie i" : : : "memory");
70002378:	b662      	cpsie	i
}
7000237a:	bd70      	pop	{r4, r5, r6, pc}

7000237c <z_unpend_thread_no_timeout>:
	__asm__ volatile(
7000237c:	f3ef 8100 	mrs	r1, CPSR
70002380:	f001 0180 	and.w	r1, r1, #128	; 0x80
70002384:	b672      	cpsid	i
		if (thread->base.pended_on != NULL) {
70002386:	6883      	ldr	r3, [r0, #8]
70002388:	b193      	cbz	r3, 700023b0 <z_unpend_thread_no_timeout+0x34>
	sys_dnode_t *const next = node->next;
7000238a:	e9d0 3200 	ldrd	r3, r2, [r0]
{
7000238e:	b430      	push	{r4, r5}
	prev->next = next;
70002390:	6013      	str	r3, [r2, #0]
	node->next = NULL;
70002392:	2400      	movs	r4, #0
	next->prev = prev;
70002394:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70002396:	2500      	movs	r5, #0
70002398:	7b43      	ldrb	r3, [r0, #13]
7000239a:	2200      	movs	r2, #0
7000239c:	e9c0 4500 	strd	r4, r5, [r0]
700023a0:	f023 0302 	bic.w	r3, r3, #2
700023a4:	6082      	str	r2, [r0, #8]
700023a6:	7343      	strb	r3, [r0, #13]
	if (key != 0U) {
700023a8:	b901      	cbnz	r1, 700023ac <z_unpend_thread_no_timeout+0x30>
700023aa:	b662      	cpsie	i
}
700023ac:	bc30      	pop	{r4, r5}
700023ae:	4770      	bx	lr
700023b0:	b909      	cbnz	r1, 700023b6 <z_unpend_thread_no_timeout+0x3a>
700023b2:	b662      	cpsie	i
	K_SPINLOCK(&_sched_spinlock) {
700023b4:	4770      	bx	lr
700023b6:	4770      	bx	lr

700023b8 <z_sched_wake_thread>:
{
700023b8:	b5d0      	push	{r4, r6, r7, lr}
	__asm__ volatile(
700023ba:	f3ef 8400 	mrs	r4, CPSR
700023be:	f004 0480 	and.w	r4, r4, #128	; 0x80
700023c2:	b672      	cpsid	i
		bool killed = (thread->base.thread_state &
700023c4:	7b43      	ldrb	r3, [r0, #13]
		if (!killed) {
700023c6:	f013 0128 	ands.w	r1, r3, #40	; 0x28
700023ca:	d112      	bne.n	700023f2 <z_sched_wake_thread+0x3a>
			if (thread->base.pended_on != NULL) {
700023cc:	6882      	ldr	r2, [r0, #8]
700023ce:	b15a      	cbz	r2, 700023e8 <z_sched_wake_thread+0x30>
	sys_dnode_t *const next = node->next;
700023d0:	e9d0 3200 	ldrd	r3, r2, [r0]
	node->next = NULL;
700023d4:	2600      	movs	r6, #0
	prev->next = next;
700023d6:	6013      	str	r3, [r2, #0]
	node->next = NULL;
700023d8:	2700      	movs	r7, #0
	next->prev = prev;
700023da:	605a      	str	r2, [r3, #4]
700023dc:	7b43      	ldrb	r3, [r0, #13]
	node->next = NULL;
700023de:	e9c0 6700 	strd	r6, r7, [r0]
700023e2:	f003 03fd 	and.w	r3, r3, #253	; 0xfd
700023e6:	6081      	str	r1, [r0, #8]
	thread->base.thread_state &= ~_THREAD_SLEEPING;
700023e8:	f023 0304 	bic.w	r3, r3, #4
700023ec:	7343      	strb	r3, [r0, #13]
			ready_thread(thread);
700023ee:	f7ff fe79 	bl	700020e4 <ready_thread>
	if (key != 0U) {
700023f2:	b904      	cbnz	r4, 700023f6 <z_sched_wake_thread+0x3e>
700023f4:	b662      	cpsie	i
}
700023f6:	bdd0      	pop	{r4, r6, r7, pc}

700023f8 <z_thread_timeout>:
	z_sched_wake_thread(thread, true);
700023f8:	2101      	movs	r1, #1
700023fa:	3818      	subs	r0, #24
700023fc:	f7ff bfdc 	b.w	700023b8 <z_sched_wake_thread>

70002400 <z_pend_curr>:
{
70002400:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
70002402:	e9dd 7606 	ldrd	r7, r6, [sp, #24]
70002406:	460d      	mov	r5, r1
70002408:	4611      	mov	r1, r2
	__asm__ volatile(
7000240a:	f3ef 8300 	mrs	r3, CPSR
7000240e:	f003 0380 	and.w	r3, r3, #128	; 0x80
70002412:	b672      	cpsid	i
70002414:	f646 34bc 	movw	r4, #27580	; 0x6bbc
70002418:	f2c7 0400 	movt	r4, #28672	; 0x7000
7000241c:	68a0      	ldr	r0, [r4, #8]
	add_to_waitq_locked(thread, wait_q);
7000241e:	f7ff fe39 	bl	70002094 <add_to_waitq_locked>
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
70002422:	f1b6 3fff 	cmp.w	r6, #4294967295	; 0xffffffff
70002426:	bf08      	it	eq
70002428:	f1b7 3fff 	cmpeq.w	r7, #4294967295	; 0xffffffff
7000242c:	d008      	beq.n	70002440 <z_pend_curr+0x40>
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
7000242e:	f242 31f9 	movw	r1, #9209	; 0x23f9
70002432:	463a      	mov	r2, r7
70002434:	4633      	mov	r3, r6
70002436:	3018      	adds	r0, #24
70002438:	f2c7 0100 	movt	r1, #28672	; 0x7000
7000243c:	f000 f9cc 	bl	700027d8 <z_add_timeout>
70002440:	68a3      	ldr	r3, [r4, #8]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
70002442:	f06f 020a 	mvn.w	r2, #10
70002446:	e9c3 521b 	strd	r5, r2, [r3, #108]	; 0x6c
	z_arm_cortex_r_svc();
7000244a:	f7fe edc4 	blx	70000fd4 <z_arm_cortex_r_svc>
	if (key != 0U) {
7000244e:	b905      	cbnz	r5, 70002452 <z_pend_curr+0x52>
70002450:	b662      	cpsie	i
	return arch_current_thread()->arch.swap_return_value;
70002452:	68a3      	ldr	r3, [r4, #8]
}
70002454:	6f18      	ldr	r0, [r3, #112]	; 0x70
70002456:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}

70002458 <z_unpend_thread>:
{
70002458:	b510      	push	{r4, lr}
	z_unpend_thread_no_timeout(thread);
7000245a:	f7ff ff8f 	bl	7000237c <z_unpend_thread_no_timeout>
}
7000245e:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	return z_abort_timeout(&thread->base.timeout);
70002462:	3018      	adds	r0, #24
70002464:	f000 ba4a 	b.w	700028fc <z_abort_timeout>

70002468 <z_reschedule>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
70002468:	b9c1      	cbnz	r1, 7000249c <z_reschedule+0x34>
{
7000246a:	b508      	push	{r3, lr}
7000246c:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70002470:	f023 0303 	bic.w	r3, r3, #3
	return arch_irq_unlocked(key) && !arch_is_in_isr();
70002474:	681a      	ldr	r2, [r3, #0]
70002476:	b97a      	cbnz	r2, 70002498 <z_reschedule+0x30>
70002478:	f646 33bc 	movw	r3, #27580	; 0x6bbc
7000247c:	f2c7 0300 	movt	r3, #28672	; 0x7000
70002480:	6899      	ldr	r1, [r3, #8]
	if (resched(key.key) && need_swap()) {
70002482:	695b      	ldr	r3, [r3, #20]
70002484:	428b      	cmp	r3, r1
70002486:	d007      	beq.n	70002498 <z_reschedule+0x30>
	arch_current_thread()->arch.basepri = key;
70002488:	66ca      	str	r2, [r1, #108]	; 0x6c
7000248a:	f06f 030a 	mvn.w	r3, #10
7000248e:	670b      	str	r3, [r1, #112]	; 0x70
	z_arm_cortex_r_svc();
70002490:	f7fe eda0 	blx	70000fd4 <z_arm_cortex_r_svc>
70002494:	b662      	cpsie	i
}
70002496:	bd08      	pop	{r3, pc}
70002498:	b662      	cpsie	i
7000249a:	bd08      	pop	{r3, pc}
7000249c:	4770      	bx	lr
7000249e:	bf00      	nop

700024a0 <z_impl_k_thread_resume>:
{
700024a0:	b510      	push	{r4, lr}
	__asm__ volatile(
700024a2:	f3ef 8400 	mrs	r4, CPSR
700024a6:	f004 0480 	and.w	r4, r4, #128	; 0x80
700024aa:	b672      	cpsid	i
	return (thread->base.thread_state & _THREAD_SUSPENDED) != 0U;
700024ac:	7b42      	ldrb	r2, [r0, #13]
	if (!z_is_thread_suspended(thread)) {
700024ae:	06d3      	lsls	r3, r2, #27
700024b0:	d402      	bmi.n	700024b8 <z_impl_k_thread_resume+0x18>
	if (key != 0U) {
700024b2:	b904      	cbnz	r4, 700024b6 <z_impl_k_thread_resume+0x16>
700024b4:	b662      	cpsie	i
}
700024b6:	bd10      	pop	{r4, pc}
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
700024b8:	f022 0210 	bic.w	r2, r2, #16
700024bc:	7342      	strb	r2, [r0, #13]
	ready_thread(thread);
700024be:	f7ff fe11 	bl	700020e4 <ready_thread>
	z_reschedule(&_sched_spinlock, key);
700024c2:	f646 30dc 	movw	r0, #27612	; 0x6bdc
700024c6:	4621      	mov	r1, r4
700024c8:	f2c7 0000 	movt	r0, #28672	; 0x7000
}
700024cc:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&_sched_spinlock, key);
700024d0:	f7ff bfca 	b.w	70002468 <z_reschedule>

700024d4 <k_sched_lock>:
	__asm__ volatile(
700024d4:	f3ef 8100 	mrs	r1, CPSR
700024d8:	f001 0180 	and.w	r1, r1, #128	; 0x80
700024dc:	b672      	cpsid	i
700024de:	f646 33bc 	movw	r3, #27580	; 0x6bbc
700024e2:	f2c7 0300 	movt	r3, #28672	; 0x7000
700024e6:	689a      	ldr	r2, [r3, #8]
	--arch_current_thread()->base.sched_locked;
700024e8:	7bd3      	ldrb	r3, [r2, #15]
700024ea:	3b01      	subs	r3, #1
700024ec:	73d3      	strb	r3, [r2, #15]
	if (key != 0U) {
700024ee:	b901      	cbnz	r1, 700024f2 <k_sched_lock+0x1e>
700024f0:	b662      	cpsie	i
}
700024f2:	4770      	bx	lr

700024f4 <k_sched_unlock>:
{
700024f4:	b510      	push	{r4, lr}
	__asm__ volatile(
700024f6:	f3ef 8400 	mrs	r4, CPSR
700024fa:	f004 0480 	and.w	r4, r4, #128	; 0x80
700024fe:	b672      	cpsid	i
70002500:	f646 30bc 	movw	r0, #27580	; 0x6bbc
70002504:	f2c7 0000 	movt	r0, #28672	; 0x7000
	return list->head == list;
70002508:	4601      	mov	r1, r0
7000250a:	6882      	ldr	r2, [r0, #8]
		++arch_current_thread()->base.sched_locked;
7000250c:	7bd3      	ldrb	r3, [r2, #15]
7000250e:	3301      	adds	r3, #1
70002510:	73d3      	strb	r3, [r2, #15]
70002512:	f851 3f18 	ldr.w	r3, [r1, #24]!
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002516:	428b      	cmp	r3, r1
70002518:	bf18      	it	ne
7000251a:	2b00      	cmpne	r3, #0
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
7000251c:	7b51      	ldrb	r1, [r2, #13]
7000251e:	bf08      	it	eq
70002520:	68c3      	ldreq	r3, [r0, #12]
70002522:	06c9      	lsls	r1, r1, #27
70002524:	d103      	bne.n	7000252e <k_sched_unlock+0x3a>
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
70002526:	89d1      	ldrh	r1, [r2, #14]
70002528:	297f      	cmp	r1, #127	; 0x7f
7000252a:	bf88      	it	hi
7000252c:	4613      	movhi	r3, r2
7000252e:	6143      	str	r3, [r0, #20]
	if (key != 0U) {
70002530:	b904      	cbnz	r4, 70002534 <k_sched_unlock+0x40>
70002532:	b662      	cpsie	i
	__asm__ volatile(
70002534:	f3ef 8300 	mrs	r3, CPSR
70002538:	f003 0380 	and.w	r3, r3, #128	; 0x80
7000253c:	b672      	cpsid	i
	return arch_irq_unlocked(key) && !arch_is_in_isr();
7000253e:	b983      	cbnz	r3, 70002562 <k_sched_unlock+0x6e>
70002540:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70002544:	f023 0303 	bic.w	r3, r3, #3
70002548:	681b      	ldr	r3, [r3, #0]
7000254a:	b95b      	cbnz	r3, 70002564 <k_sched_unlock+0x70>
7000254c:	6882      	ldr	r2, [r0, #8]
	if (resched(key) && need_swap()) {
7000254e:	6941      	ldr	r1, [r0, #20]
70002550:	4291      	cmp	r1, r2
70002552:	d007      	beq.n	70002564 <k_sched_unlock+0x70>
	arch_current_thread()->arch.basepri = key;
70002554:	66d3      	str	r3, [r2, #108]	; 0x6c
70002556:	f06f 010a 	mvn.w	r1, #10
7000255a:	6711      	str	r1, [r2, #112]	; 0x70
	z_arm_cortex_r_svc();
7000255c:	f7fe ed3a 	blx	70000fd4 <z_arm_cortex_r_svc>
70002560:	b662      	cpsie	i
}
70002562:	bd10      	pop	{r4, pc}
70002564:	b662      	cpsie	i
70002566:	bd10      	pop	{r4, pc}

70002568 <z_sched_init>:
{
70002568:	4a02      	ldr	r2, [pc, #8]	; (70002574 <z_sched_init+0xc>)
	list->head = (sys_dnode_t *)list;
7000256a:	4613      	mov	r3, r2
7000256c:	f843 2918 	str.w	r2, [r3], #-24
70002570:	61da      	str	r2, [r3, #28]
}
70002572:	4770      	bx	lr
70002574:	70006bd4 	.word	0x70006bd4

70002578 <z_impl_k_yield>:
{
70002578:	b570      	push	{r4, r5, r6, lr}
7000257a:	f3ef 8600 	mrs	r6, CPSR
7000257e:	f006 0680 	and.w	r6, r6, #128	; 0x80
70002582:	b672      	cpsid	i
70002584:	f646 3cbc 	movw	ip, #27580	; 0x6bbc
70002588:	f2c7 0c00 	movt	ip, #28672	; 0x7000
	return list->head == list;
7000258c:	4665      	mov	r5, ip
7000258e:	f8dc 3008 	ldr.w	r3, [ip, #8]
	thread->base.thread_state &= ~_THREAD_QUEUED;
70002592:	7b5a      	ldrb	r2, [r3, #13]
70002594:	f002 027f 	and.w	r2, r2, #127	; 0x7f
70002598:	735a      	strb	r2, [r3, #13]
	node->next = NULL;
7000259a:	2200      	movs	r2, #0
	sys_dnode_t *const prev = node->prev;
7000259c:	6858      	ldr	r0, [r3, #4]
	sys_dnode_t *const next = node->next;
7000259e:	6819      	ldr	r1, [r3, #0]
	prev->next = next;
700025a0:	6001      	str	r1, [r0, #0]
	next->prev = prev;
700025a2:	6048      	str	r0, [r1, #4]
	node->next = NULL;
700025a4:	601a      	str	r2, [r3, #0]
700025a6:	605a      	str	r2, [r3, #4]
700025a8:	f8dc 0008 	ldr.w	r0, [ip, #8]
	thread->base.thread_state |= _THREAD_QUEUED;
700025ac:	7b43      	ldrb	r3, [r0, #13]
700025ae:	f063 037f 	orn	r3, r3, #127	; 0x7f
700025b2:	7343      	strb	r3, [r0, #13]
	return list->head == list;
700025b4:	f855 3f18 	ldr.w	r3, [r5, #24]!
	return (node == list->tail) ? NULL : node->next;
700025b8:	f8dc 401c 	ldr.w	r4, [ip, #28]
	return sys_dlist_is_empty(list) ? NULL : list->head;
700025bc:	42ab      	cmp	r3, r5
700025be:	bf08      	it	eq
700025c0:	4613      	moveq	r3, r2
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
700025c2:	b163      	cbz	r3, 700025de <z_impl_k_yield+0x66>
	int32_t b2 = thread_2->base.prio;
700025c4:	f993 100e 	ldrsb.w	r1, [r3, #14]
	int32_t b1 = thread_1->base.prio;
700025c8:	f990 200e 	ldrsb.w	r2, [r0, #14]
	if (b1 != b2) {
700025cc:	428a      	cmp	r2, r1
700025ce:	d001      	beq.n	700025d4 <z_impl_k_yield+0x5c>
		if (z_sched_prio_cmp(thread, t) > 0) {
700025d0:	4291      	cmp	r1, r2
700025d2:	dc1e      	bgt.n	70002612 <z_impl_k_yield+0x9a>
	return (node == list->tail) ? NULL : node->next;
700025d4:	42a3      	cmp	r3, r4
700025d6:	d002      	beq.n	700025de <z_impl_k_yield+0x66>
700025d8:	681b      	ldr	r3, [r3, #0]
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
700025da:	2b00      	cmp	r3, #0
700025dc:	d1f2      	bne.n	700025c4 <z_impl_k_yield+0x4c>
	node->prev = tail;
700025de:	e9c0 5400 	strd	r5, r4, [r0]
	tail->next = node;
700025e2:	6020      	str	r0, [r4, #0]
	list->tail = node;
700025e4:	f8cc 001c 	str.w	r0, [ip, #28]
	return list->head == list;
700025e8:	f8dc 3018 	ldr.w	r3, [ip, #24]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700025ec:	f06f 010a 	mvn.w	r1, #10
700025f0:	f8dc 2008 	ldr.w	r2, [ip, #8]
	arch_current_thread()->arch.basepri = key;
700025f4:	66d6      	str	r6, [r2, #108]	; 0x6c
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700025f6:	42ab      	cmp	r3, r5
700025f8:	bf18      	it	ne
700025fa:	2b00      	cmpne	r3, #0
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700025fc:	6711      	str	r1, [r2, #112]	; 0x70
700025fe:	bf08      	it	eq
70002600:	f8dc 300c 	ldreq.w	r3, [ip, #12]
		_kernel.ready_q.cache = thread;
70002604:	f8cc 3014 	str.w	r3, [ip, #20]
	z_arm_cortex_r_svc();
70002608:	f7fe ece4 	blx	70000fd4 <z_arm_cortex_r_svc>
	if (key != 0U) {
7000260c:	b906      	cbnz	r6, 70002610 <z_impl_k_yield+0x98>
7000260e:	b662      	cpsie	i
}
70002610:	bd70      	pop	{r4, r5, r6, pc}
	sys_dnode_t *const prev = successor->prev;
70002612:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
70002614:	e9c0 3200 	strd	r3, r2, [r0]
	prev->next = node;
70002618:	6010      	str	r0, [r2, #0]
	successor->prev = node;
7000261a:	6058      	str	r0, [r3, #4]
}
7000261c:	e7e4      	b.n	700025e8 <z_impl_k_yield+0x70>
7000261e:	bf00      	nop

70002620 <z_tick_sleep>:
	if (ticks == 0) {
70002620:	ea50 0301 	orrs.w	r3, r0, r1
{
70002624:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	if (ticks == 0) {
70002628:	d039      	beq.n	7000269e <z_tick_sleep+0x7e>
7000262a:	4604      	mov	r4, r0
	if (Z_TICK_ABS(ticks) <= 0) {
7000262c:	1c83      	adds	r3, r0, #2
7000262e:	460d      	mov	r5, r1
70002630:	f171 33ff 	sbcs.w	r3, r1, #4294967295	; 0xffffffff
		expected_wakeup_ticks = Z_TICK_ABS(ticks);
70002634:	bfbc      	itt	lt
70002636:	f06f 0001 	mvnlt.w	r0, #1
7000263a:	1b06      	sublt	r6, r0, r4
	if (Z_TICK_ABS(ticks) <= 0) {
7000263c:	da2b      	bge.n	70002696 <z_tick_sleep+0x76>
	__asm__ volatile(
7000263e:	f3ef 8800 	mrs	r8, CPSR
70002642:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002646:	b672      	cpsid	i
70002648:	f646 37bc 	movw	r7, #27580	; 0x6bbc
7000264c:	f2c7 0700 	movt	r7, #28672	; 0x7000
	unready_thread(arch_current_thread());
70002650:	68b8      	ldr	r0, [r7, #8]
70002652:	f7ff fcf7 	bl	70002044 <unready_thread>
70002656:	68b8      	ldr	r0, [r7, #8]
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
70002658:	f242 31f9 	movw	r1, #9209	; 0x23f9
7000265c:	4622      	mov	r2, r4
7000265e:	462b      	mov	r3, r5
70002660:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002664:	3018      	adds	r0, #24
70002666:	f000 f8b7 	bl	700027d8 <z_add_timeout>
7000266a:	68bb      	ldr	r3, [r7, #8]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
7000266c:	f06f 010a 	mvn.w	r1, #10
	thread->base.thread_state |= _THREAD_SLEEPING;
70002670:	7b5a      	ldrb	r2, [r3, #13]
70002672:	f042 0204 	orr.w	r2, r2, #4
70002676:	e9c3 811b 	strd	r8, r1, [r3, #108]	; 0x6c
7000267a:	735a      	strb	r2, [r3, #13]
	z_arm_cortex_r_svc();
7000267c:	f7fe ecaa 	blx	70000fd4 <z_arm_cortex_r_svc>
	if (key != 0U) {
70002680:	f1b8 0f00 	cmp.w	r8, #0
70002684:	d100      	bne.n	70002688 <z_tick_sleep+0x68>
70002686:	b662      	cpsie	i
	uint32_t left_ticks = expected_wakeup_ticks - sys_clock_tick_get_32();
70002688:	f000 fa02 	bl	70002a90 <sys_clock_tick_get_32>
7000268c:	1a30      	subs	r0, r6, r0
	if (ticks > 0) {
7000268e:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
}
70002692:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		expected_wakeup_ticks = ticks + sys_clock_tick_get_32();
70002696:	f000 f9fb 	bl	70002a90 <sys_clock_tick_get_32>
7000269a:	1906      	adds	r6, r0, r4
7000269c:	e7cf      	b.n	7000263e <z_tick_sleep+0x1e>
	z_impl_k_yield();
7000269e:	f7ff ff6b 	bl	70002578 <z_impl_k_yield>
		return 0;
700026a2:	2000      	movs	r0, #0
}
700026a4:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

700026a8 <z_impl_k_sleep>:
{
700026a8:	b538      	push	{r3, r4, r5, lr}
700026aa:	4605      	mov	r5, r0
700026ac:	460c      	mov	r4, r1
	ticks = z_tick_sleep(ticks);
700026ae:	f7ff ffb7 	bl	70002620 <z_tick_sleep>
	int32_t ret = K_TIMEOUT_EQ(timeout, K_FOREVER) ? K_TICKS_FOREVER :
700026b2:	f1b4 3fff 	cmp.w	r4, #4294967295	; 0xffffffff
700026b6:	bf08      	it	eq
700026b8:	f1b5 3fff 	cmpeq.w	r5, #4294967295	; 0xffffffff
700026bc:	bf08      	it	eq
700026be:	f04f 30ff 	moveq.w	r0, #4294967295	; 0xffffffff
}
700026c2:	bd38      	pop	{r3, r4, r5, pc}

700026c4 <z_impl_k_wakeup>:
{
700026c4:	b538      	push	{r3, r4, r5, lr}
700026c6:	4604      	mov	r4, r0
	return z_abort_timeout(&thread->base.timeout);
700026c8:	3018      	adds	r0, #24
700026ca:	f000 f917 	bl	700028fc <z_abort_timeout>
	__asm__ volatile(
700026ce:	f3ef 8500 	mrs	r5, CPSR
700026d2:	f005 0580 	and.w	r5, r5, #128	; 0x80
700026d6:	b672      	cpsid	i
	return (thread->base.thread_state & _THREAD_SLEEPING) != 0U;
700026d8:	7b63      	ldrb	r3, [r4, #13]
	if (!z_is_thread_sleeping(thread)) {
700026da:	075a      	lsls	r2, r3, #29
700026dc:	d402      	bmi.n	700026e4 <z_impl_k_wakeup+0x20>
	if (key != 0U) {
700026de:	b905      	cbnz	r5, 700026e2 <z_impl_k_wakeup+0x1e>
700026e0:	b662      	cpsie	i
}
700026e2:	bd38      	pop	{r3, r4, r5, pc}
	ready_thread(thread);
700026e4:	4620      	mov	r0, r4
	thread->base.thread_state &= ~_THREAD_SLEEPING;
700026e6:	f023 0304 	bic.w	r3, r3, #4
700026ea:	7363      	strb	r3, [r4, #13]
700026ec:	f7ff fcfa 	bl	700020e4 <ready_thread>
700026f0:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
700026f4:	f023 0303 	bic.w	r3, r3, #3
	if (arch_is_in_isr()) {
700026f8:	681b      	ldr	r3, [r3, #0]
700026fa:	2b00      	cmp	r3, #0
700026fc:	d1ef      	bne.n	700026de <z_impl_k_wakeup+0x1a>
		z_reschedule(&_sched_spinlock, key);
700026fe:	f646 30dc 	movw	r0, #27612	; 0x6bdc
70002702:	4629      	mov	r1, r5
70002704:	f2c7 0000 	movt	r0, #28672	; 0x7000
}
70002708:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		z_reschedule(&_sched_spinlock, key);
7000270c:	f7ff beac 	b.w	70002468 <z_reschedule>

70002710 <z_impl_k_sched_current_thread_query>:
70002710:	f646 33bc 	movw	r3, #27580	; 0x6bbc
70002714:	f2c7 0300 	movt	r3, #28672	; 0x7000
}
70002718:	6898      	ldr	r0, [r3, #8]
7000271a:	4770      	bx	lr

7000271c <z_impl_k_thread_abort>:
	__asm__ volatile(
7000271c:	f3ef 8100 	mrs	r1, CPSR
70002720:	f001 0180 	and.w	r1, r1, #128	; 0x80
70002724:	b672      	cpsid	i
	return (thread->base.user_options & K_ESSENTIAL) == K_ESSENTIAL;
70002726:	7b02      	ldrb	r2, [r0, #12]

void z_thread_abort(struct k_thread *thread)
{
	k_spinlock_key_t key = k_spin_lock(&_sched_spinlock);

	if (z_is_thread_essential(thread)) {
70002728:	07d2      	lsls	r2, r2, #31
7000272a:	d409      	bmi.n	70002740 <z_impl_k_thread_abort+0x24>
		__ASSERT(false, "aborting essential thread %p", thread);
		k_panic();
		return;
	}

	if ((thread->base.thread_state & _THREAD_DEAD) != 0U) {
7000272c:	7b43      	ldrb	r3, [r0, #13]
7000272e:	071b      	lsls	r3, r3, #28
70002730:	d502      	bpl.n	70002738 <z_impl_k_thread_abort+0x1c>
	if (key != 0U) {
70002732:	b921      	cbnz	r1, 7000273e <z_impl_k_thread_abort+0x22>
70002734:	b662      	cpsie	i
}
70002736:	4770      	bx	lr
		k_spin_unlock(&_sched_spinlock, key);
		return;
	}

	z_thread_halt(thread, key, true);
70002738:	2201      	movs	r2, #1
7000273a:	f7ff bd1b 	b.w	70002174 <z_thread_halt>
	z_thread_abort(thread);

	__ASSERT_NO_MSG((thread->base.thread_state & _THREAD_DEAD) != 0);

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_thread, abort, thread);
}
7000273e:	4770      	bx	lr
70002740:	b901      	cbnz	r1, 70002744 <z_impl_k_thread_abort+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
70002742:	b662      	cpsie	i
		k_panic();
70002744:	2004      	movs	r0, #4
70002746:	b500      	push	{lr}
70002748:	b662      	cpsie	i
7000274a:	df02      	svc	2
7000274c:	f85d eb04 	ldr.w	lr, [sp], #4
		return;
70002750:	4770      	bx	lr
70002752:	bf00      	nop

70002754 <z_sched_wake>:

/*
 * future scheduler.h API implementations
 */
bool z_sched_wake(_wait_q_t *wait_q, int swap_retval, void *swap_data)
{
70002754:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	__asm__ volatile(
70002758:	f3ef 8800 	mrs	r8, CPSR
7000275c:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002760:	b672      	cpsid	i
	return list->head == list;
70002762:	6804      	ldr	r4, [r0, #0]
	bool ret = false;

	K_SPINLOCK(&_sched_spinlock) {
		thread = _priq_wait_best(&wait_q->waitq);

		if (thread != NULL) {
70002764:	42a0      	cmp	r0, r4
70002766:	bf18      	it	ne
70002768:	2c00      	cmpne	r4, #0
7000276a:	bf14      	ite	ne
7000276c:	2501      	movne	r5, #1
7000276e:	2500      	moveq	r5, #0
70002770:	d106      	bne.n	70002780 <z_sched_wake+0x2c>
	if (key != 0U) {
70002772:	f1b8 0f00 	cmp.w	r8, #0
70002776:	d100      	bne.n	7000277a <z_sched_wake+0x26>
70002778:	b662      	cpsie	i
			ret = true;
		}
	}

	return ret;
}
7000277a:	4628      	mov	r0, r5
7000277c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	sys_dnode_t *const next = node->next;
70002780:	e9d4 3000 	ldrd	r3, r0, [r4]
	node->next = NULL;
70002784:	2600      	movs	r6, #0
z_thread_return_value_set_with_data(struct k_thread *thread,
				   unsigned int value,
				   void *data)
{
	arch_thread_return_value_set(thread, value);
	thread->base.swap_data = data;
70002786:	6162      	str	r2, [r4, #20]
70002788:	2700      	movs	r7, #0
	thread->arch.swap_return_value = value;
7000278a:	6721      	str	r1, [r4, #112]	; 0x70
	thread->base.pended_on = NULL;
7000278c:	2200      	movs	r2, #0
	prev->next = next;
7000278e:	6003      	str	r3, [r0, #0]
	next->prev = prev;
70002790:	6058      	str	r0, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
70002792:	7b63      	ldrb	r3, [r4, #13]
70002794:	f023 0302 	bic.w	r3, r3, #2
	node->next = NULL;
70002798:	e9c4 6700 	strd	r6, r7, [r4]
7000279c:	f104 0018 	add.w	r0, r4, #24
700027a0:	7363      	strb	r3, [r4, #13]
700027a2:	60a2      	str	r2, [r4, #8]
700027a4:	f000 f8aa 	bl	700028fc <z_abort_timeout>
			ready_thread(thread);
700027a8:	4620      	mov	r0, r4
700027aa:	f7ff fc9b 	bl	700020e4 <ready_thread>
			ret = true;
700027ae:	e7e0      	b.n	70002772 <z_sched_wake+0x1e>

700027b0 <z_sched_wait>:

int z_sched_wait(struct k_spinlock *lock, k_spinlock_key_t key,
		 _wait_q_t *wait_q, k_timeout_t timeout, void **data)
{
700027b0:	b510      	push	{r4, lr}
700027b2:	b082      	sub	sp, #8
	int ret = z_pend_curr(lock, key, wait_q, timeout);
700027b4:	e9dd 3404 	ldrd	r3, r4, [sp, #16]
700027b8:	e9cd 3400 	strd	r3, r4, [sp]
{
700027bc:	9c06      	ldr	r4, [sp, #24]
	int ret = z_pend_curr(lock, key, wait_q, timeout);
700027be:	f7ff fe1f 	bl	70002400 <z_pend_curr>

	if (data != NULL) {
700027c2:	b134      	cbz	r4, 700027d2 <z_sched_wait+0x22>
700027c4:	f646 33bc 	movw	r3, #27580	; 0x6bbc
700027c8:	f2c7 0300 	movt	r3, #28672	; 0x7000
		*data = arch_current_thread()->base.swap_data;
700027cc:	689b      	ldr	r3, [r3, #8]
700027ce:	695b      	ldr	r3, [r3, #20]
700027d0:	6023      	str	r3, [r4, #0]
	}
	return ret;
}
700027d2:	b002      	add	sp, #8
700027d4:	bd10      	pop	{r4, pc}
700027d6:	bf00      	nop

700027d8 <z_add_timeout>:
}

void z_add_timeout(struct _timeout *to, _timeout_func_t fn,
		   k_timeout_t timeout)
{
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
700027d8:	f1b3 3fff 	cmp.w	r3, #4294967295	; 0xffffffff
700027dc:	bf08      	it	eq
700027de:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
700027e2:	f000 808a 	beq.w	700028fa <z_add_timeout+0x122>
{
700027e6:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
700027e8:	4606      	mov	r6, r0
700027ea:	461d      	mov	r5, r3
700027ec:	4614      	mov	r4, r2
700027ee:	4618      	mov	r0, r3
#ifdef CONFIG_KERNEL_COHERENCE
	__ASSERT_NO_MSG(arch_mem_coherent(to));
#endif /* CONFIG_KERNEL_COHERENCE */

	__ASSERT(!sys_dnode_is_linked(&to->node), "");
	to->fn = fn;
700027f0:	60b1      	str	r1, [r6, #8]
	__asm__ volatile(
700027f2:	f3ef 8700 	mrs	r7, CPSR
700027f6:	f007 0780 	and.w	r7, r7, #128	; 0x80
700027fa:	b672      	cpsid	i

	K_SPINLOCK(&timeout_lock) {
		struct _timeout *t;

		if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) &&
700027fc:	3201      	adds	r2, #1
700027fe:	f175 33ff 	sbcs.w	r3, r5, #4294967295	; 0xffffffff
70002802:	da5f      	bge.n	700028c4 <z_add_timeout+0xec>
		    (Z_TICK_ABS(timeout.ticks) >= 0)) {
			k_ticks_t ticks = Z_TICK_ABS(timeout.ticks) - curr_tick;
70002804:	f245 4268 	movw	r2, #21608	; 0x5468
70002808:	f06f 0301 	mvn.w	r3, #1
7000280c:	f2c7 0200 	movt	r2, #28672	; 0x7000
70002810:	e9d2 1500 	ldrd	r1, r5, [r2]
70002814:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
70002818:	1a5b      	subs	r3, r3, r1
7000281a:	eb62 0505 	sbc.w	r5, r2, r5
7000281e:	1b1c      	subs	r4, r3, r4
70002820:	eb65 0500 	sbc.w	r5, r5, r0

			to->dticks = MAX(1, ticks);
70002824:	2c01      	cmp	r4, #1
70002826:	f175 0300 	sbcs.w	r3, r5, #0
7000282a:	bfbc      	itt	lt
7000282c:	2401      	movlt	r4, #1
7000282e:	2500      	movlt	r5, #0
70002830:	6134      	str	r4, [r6, #16]
	return list->head == list;
70002832:	f24b 00b8 	movw	r0, #45240	; 0xb0b8
70002836:	6175      	str	r5, [r6, #20]
70002838:	f2c7 0000 	movt	r0, #28672	; 0x7000
	return (node == list->tail) ? NULL : node->next;
7000283c:	e9d0 2c00 	ldrd	r2, ip, [r0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002840:	4282      	cmp	r2, r0
70002842:	d011      	beq.n	70002868 <z_add_timeout+0x90>
		} else {
			to->dticks = timeout.ticks + 1 + elapsed();
		}

		for (t = first(); t != NULL; t = next(t)) {
70002844:	b182      	cbz	r2, 70002868 <z_add_timeout+0x90>
			if (t->dticks > to->dticks) {
70002846:	e9d2 3104 	ldrd	r3, r1, [r2, #16]
7000284a:	429c      	cmp	r4, r3
7000284c:	eb75 0e01 	sbcs.w	lr, r5, r1
70002850:	db48      	blt.n	700028e4 <z_add_timeout+0x10c>
				t->dticks -= to->dticks;
				sys_dlist_insert(&t->node, &to->node);
				break;
			}
			to->dticks -= t->dticks;
70002852:	1ae3      	subs	r3, r4, r3
70002854:	461c      	mov	r4, r3
70002856:	eb65 0501 	sbc.w	r5, r5, r1
	return (node == list->tail) ? NULL : node->next;
7000285a:	4562      	cmp	r2, ip
7000285c:	e9c6 3504 	strd	r3, r5, [r6, #16]
70002860:	d002      	beq.n	70002868 <z_add_timeout+0x90>
70002862:	6812      	ldr	r2, [r2, #0]
		for (t = first(); t != NULL; t = next(t)) {
70002864:	2a00      	cmp	r2, #0
70002866:	d1ee      	bne.n	70002846 <z_add_timeout+0x6e>
	node->prev = tail;
70002868:	e9c6 0c00 	strd	r0, ip, [r6]
	tail->next = node;
7000286c:	f8cc 6000 	str.w	r6, [ip]
	list->tail = node;
70002870:	6046      	str	r6, [r0, #4]
	return list->head == list;
70002872:	6804      	ldr	r4, [r0, #0]

		if (t == NULL) {
			sys_dlist_append(&timeout_list, &to->node);
		}

		if (to == first() && announce_remaining == 0) {
70002874:	1a20      	subs	r0, r4, r0
70002876:	bf18      	it	ne
70002878:	2001      	movne	r0, #1
7000287a:	42a6      	cmp	r6, r4
7000287c:	bf18      	it	ne
7000287e:	2000      	movne	r0, #0
70002880:	b910      	cbnz	r0, 70002888 <z_add_timeout+0xb0>
	if (key != 0U) {
70002882:	b907      	cbnz	r7, 70002886 <z_add_timeout+0xae>
70002884:	b662      	cpsie	i
			sys_clock_set_timeout(next_timeout(), false);
		}
	}
}
70002886:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		if (to == first() && announce_remaining == 0) {
70002888:	f646 33dc 	movw	r3, #27612	; 0x6bdc
7000288c:	f2c7 0300 	movt	r3, #28672	; 0x7000
70002890:	681b      	ldr	r3, [r3, #0]
70002892:	2b00      	cmp	r3, #0
70002894:	d1f5      	bne.n	70002882 <z_add_timeout+0xaa>
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002896:	f7ff f8b3 	bl	70001a00 <sys_clock_elapsed>
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
7000289a:	6923      	ldr	r3, [r4, #16]
7000289c:	6962      	ldr	r2, [r4, #20]
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
7000289e:	4601      	mov	r1, r0
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
700028a0:	1a18      	subs	r0, r3, r0
700028a2:	eb62 73e1 	sbc.w	r3, r2, r1, asr #31
			sys_clock_set_timeout(next_timeout(), false);
700028a6:	2100      	movs	r1, #0
		ret = MAX(0, to->dticks - ticks_elapsed);
700028a8:	2b00      	cmp	r3, #0
700028aa:	bfbc      	itt	lt
700028ac:	2000      	movlt	r0, #0
700028ae:	2300      	movlt	r3, #0
			sys_clock_set_timeout(next_timeout(), false);
700028b0:	f1b0 4f00 	cmp.w	r0, #2147483648	; 0x80000000
700028b4:	f173 0300 	sbcs.w	r3, r3, #0
700028b8:	bfa8      	it	ge
700028ba:	f06f 4000 	mvnge.w	r0, #2147483648	; 0x80000000
700028be:	f7ff f86f 	bl	700019a0 <sys_clock_set_timeout>
700028c2:	e7de      	b.n	70002882 <z_add_timeout+0xaa>
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
700028c4:	f646 32dc 	movw	r2, #27612	; 0x6bdc
			to->dticks = timeout.ticks + 1 + elapsed();
700028c8:	3401      	adds	r4, #1
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
700028ca:	f2c7 0200 	movt	r2, #28672	; 0x7000
			to->dticks = timeout.ticks + 1 + elapsed();
700028ce:	f145 0500 	adc.w	r5, r5, #0
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
700028d2:	6813      	ldr	r3, [r2, #0]
700028d4:	2b00      	cmp	r3, #0
700028d6:	d1ab      	bne.n	70002830 <z_add_timeout+0x58>
700028d8:	f7ff f892 	bl	70001a00 <sys_clock_elapsed>
			to->dticks = timeout.ticks + 1 + elapsed();
700028dc:	1904      	adds	r4, r0, r4
700028de:	eb45 75e0 	adc.w	r5, r5, r0, asr #31
700028e2:	e7a5      	b.n	70002830 <z_add_timeout+0x58>
				t->dticks -= to->dticks;
700028e4:	1b1b      	subs	r3, r3, r4
	sys_dnode_t *const prev = successor->prev;
700028e6:	6854      	ldr	r4, [r2, #4]
700028e8:	eb61 0105 	sbc.w	r1, r1, r5
700028ec:	e9c2 3104 	strd	r3, r1, [r2, #16]
	node->next = successor;
700028f0:	e9c6 2400 	strd	r2, r4, [r6]
	prev->next = node;
700028f4:	6026      	str	r6, [r4, #0]
	successor->prev = node;
700028f6:	6056      	str	r6, [r2, #4]
		if (t == NULL) {
700028f8:	e7bb      	b.n	70002872 <z_add_timeout+0x9a>
700028fa:	4770      	bx	lr

700028fc <z_abort_timeout>:

int z_abort_timeout(struct _timeout *to)
{
700028fc:	b430      	push	{r4, r5}
	__asm__ volatile(
700028fe:	f3ef 8500 	mrs	r5, CPSR
70002902:	f005 0580 	and.w	r5, r5, #128	; 0x80
70002906:	b672      	cpsid	i
	return node->next != NULL;
70002908:	6802      	ldr	r2, [r0, #0]
	int ret = -EINVAL;

	K_SPINLOCK(&timeout_lock) {
		if (sys_dnode_is_linked(&to->node)) {
7000290a:	b1e2      	cbz	r2, 70002946 <z_abort_timeout+0x4a>
	return (node == list->tail) ? NULL : node->next;
7000290c:	f24b 01b8 	movw	r1, #45240	; 0xb0b8
70002910:	4603      	mov	r3, r0
70002912:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002916:	6849      	ldr	r1, [r1, #4]
70002918:	4288      	cmp	r0, r1
7000291a:	d009      	beq.n	70002930 <z_abort_timeout+0x34>
		next(t)->dticks += t->dticks;
7000291c:	6904      	ldr	r4, [r0, #16]
7000291e:	6911      	ldr	r1, [r2, #16]
70002920:	6950      	ldr	r0, [r2, #20]
70002922:	1909      	adds	r1, r1, r4
70002924:	695c      	ldr	r4, [r3, #20]
70002926:	eb40 0004 	adc.w	r0, r0, r4
7000292a:	e9c2 1004 	strd	r1, r0, [r2, #16]
	sys_dnode_t *const next = node->next;
7000292e:	681a      	ldr	r2, [r3, #0]
	sys_dnode_t *const prev = node->prev;
70002930:	685c      	ldr	r4, [r3, #4]
	node->next = NULL;
70002932:	2100      	movs	r1, #0
	prev->next = next;
70002934:	6022      	str	r2, [r4, #0]
			remove_timeout(to);
			ret = 0;
70002936:	4608      	mov	r0, r1
	next->prev = prev;
70002938:	6054      	str	r4, [r2, #4]
	node->next = NULL;
7000293a:	6019      	str	r1, [r3, #0]
7000293c:	6059      	str	r1, [r3, #4]
	if (key != 0U) {
7000293e:	b905      	cbnz	r5, 70002942 <z_abort_timeout+0x46>
70002940:	b662      	cpsie	i
		}
	}

	return ret;
}
70002942:	bc30      	pop	{r4, r5}
70002944:	4770      	bx	lr
	int ret = -EINVAL;
70002946:	f06f 0015 	mvn.w	r0, #21
7000294a:	e7f8      	b.n	7000293e <z_abort_timeout+0x42>

7000294c <sys_clock_announce>:
	}
	return ret;
}

void sys_clock_announce(int32_t ticks)
{
7000294c:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
70002950:	4603      	mov	r3, r0
	__asm__ volatile(
70002952:	f3ef 8800 	mrs	r8, CPSR
70002956:	f008 0880 	and.w	r8, r8, #128	; 0x80
7000295a:	b672      	cpsid	i
	return list->head == list;
7000295c:	f24b 09b8 	movw	r9, #45240	; 0xb0b8
		announce_remaining += ticks;
		k_spin_unlock(&timeout_lock, key);
		return;
	}

	announce_remaining = ticks;
70002960:	f646 3adc 	movw	sl, #27612	; 0x6bdc
70002964:	f2c7 0900 	movt	r9, #28672	; 0x7000
70002968:	f2c7 0a00 	movt	sl, #28672	; 0x7000
7000296c:	f8ca 0000 	str.w	r0, [sl]
70002970:	f8d9 0000 	ldr.w	r0, [r9]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002974:	4548      	cmp	r0, r9
70002976:	bf04      	itt	eq
70002978:	f245 4568 	movweq	r5, #21608	; 0x5468
7000297c:	f2c7 0500 	movteq	r5, #28672	; 0x7000
70002980:	d068      	beq.n	70002a54 <sys_clock_announce+0x108>

	struct _timeout *t;

	for (t = first();
	     (t != NULL) && (t->dticks <= announce_remaining);
70002982:	2800      	cmp	r0, #0
70002984:	d076      	beq.n	70002a74 <sys_clock_announce+0x128>
70002986:	f245 4568 	movw	r5, #21608	; 0x5468
	node->next = NULL;
7000298a:	f04f 0b00 	mov.w	fp, #0
	     t = first()) {
		int dt = t->dticks;

		curr_tick += dt;
		t->dticks = 0;
7000298e:	2600      	movs	r6, #0
70002990:	f2c7 0500 	movt	r5, #28672	; 0x7000
70002994:	2700      	movs	r7, #0
	     (t != NULL) && (t->dticks <= announce_remaining);
70002996:	e9d0 4204 	ldrd	r4, r2, [r0, #16]
7000299a:	17d9      	asrs	r1, r3, #31
7000299c:	42a3      	cmp	r3, r4
7000299e:	eb71 0c02 	sbcs.w	ip, r1, r2
700029a2:	db29      	blt.n	700029f8 <sys_clock_announce+0xac>
		curr_tick += dt;
700029a4:	e9d5 3200 	ldrd	r3, r2, [r5]
	sys_dnode_t *const prev = node->prev;
700029a8:	6841      	ldr	r1, [r0, #4]
		t->dticks = 0;
700029aa:	e9c0 6704 	strd	r6, r7, [r0, #16]
		curr_tick += dt;
700029ae:	191b      	adds	r3, r3, r4
700029b0:	eb42 72e4 	adc.w	r2, r2, r4, asr #31
700029b4:	602b      	str	r3, [r5, #0]
	sys_dnode_t *const next = node->next;
700029b6:	6803      	ldr	r3, [r0, #0]
	prev->next = next;
700029b8:	600b      	str	r3, [r1, #0]
700029ba:	606a      	str	r2, [r5, #4]
	next->prev = prev;
700029bc:	6059      	str	r1, [r3, #4]
	node->next = NULL;
700029be:	f8c0 b000 	str.w	fp, [r0]
700029c2:	f8c0 b004 	str.w	fp, [r0, #4]
	if (key != 0U) {
700029c6:	f1b8 0f00 	cmp.w	r8, #0
700029ca:	d100      	bne.n	700029ce <sys_clock_announce+0x82>
700029cc:	b662      	cpsie	i
		remove_timeout(t);

		k_spin_unlock(&timeout_lock, key);
		t->fn(t);
700029ce:	6883      	ldr	r3, [r0, #8]
700029d0:	4798      	blx	r3
	__asm__ volatile(
700029d2:	f3ef 8800 	mrs	r8, CPSR
700029d6:	f008 0880 	and.w	r8, r8, #128	; 0x80
700029da:	b672      	cpsid	i
		key = k_spin_lock(&timeout_lock);
		announce_remaining -= dt;
700029dc:	f8da 3000 	ldr.w	r3, [sl]
	return list->head == list;
700029e0:	f8d9 0000 	ldr.w	r0, [r9]
700029e4:	1b1b      	subs	r3, r3, r4
	return sys_dlist_is_empty(list) ? NULL : list->head;
700029e6:	4548      	cmp	r0, r9
700029e8:	f8ca 3000 	str.w	r3, [sl]
700029ec:	d032      	beq.n	70002a54 <sys_clock_announce+0x108>
	     (t != NULL) && (t->dticks <= announce_remaining);
700029ee:	2800      	cmp	r0, #0
700029f0:	d1d1      	bne.n	70002996 <sys_clock_announce+0x4a>
	return list->head == list;
700029f2:	4604      	mov	r4, r0
700029f4:	17d9      	asrs	r1, r3, #31
700029f6:	e006      	b.n	70002a06 <sys_clock_announce+0xba>
	}

	if (t != NULL) {
		t->dticks -= announce_remaining;
700029f8:	1ae4      	subs	r4, r4, r3
700029fa:	eb62 0201 	sbc.w	r2, r2, r1
700029fe:	6104      	str	r4, [r0, #16]
70002a00:	f8d9 4000 	ldr.w	r4, [r9]
70002a04:	6142      	str	r2, [r0, #20]
	}

	curr_tick += announce_remaining;
70002a06:	682a      	ldr	r2, [r5, #0]
70002a08:	18d2      	adds	r2, r2, r3
70002a0a:	686b      	ldr	r3, [r5, #4]
70002a0c:	602a      	str	r2, [r5, #0]
70002a0e:	eb43 0301 	adc.w	r3, r3, r1
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002a12:	454c      	cmp	r4, r9
70002a14:	606b      	str	r3, [r5, #4]
	announce_remaining = 0;
70002a16:	f04f 0300 	mov.w	r3, #0
70002a1a:	f8ca 3000 	str.w	r3, [sl]
70002a1e:	d024      	beq.n	70002a6a <sys_clock_announce+0x11e>
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002a20:	f7fe ffee 	bl	70001a00 <sys_clock_elapsed>
	if ((to == NULL) ||
70002a24:	b31c      	cbz	r4, 70002a6e <sys_clock_announce+0x122>
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
70002a26:	e9d4 3204 	ldrd	r3, r2, [r4, #16]
70002a2a:	1a1b      	subs	r3, r3, r0
70002a2c:	eb62 72e0 	sbc.w	r2, r2, r0, asr #31
	if ((to == NULL) ||
70002a30:	f1b3 4f00 	cmp.w	r3, #2147483648	; 0x80000000
70002a34:	f172 0100 	sbcs.w	r1, r2, #0
70002a38:	da19      	bge.n	70002a6e <sys_clock_announce+0x122>
		ret = MAX(0, to->dticks - ticks_elapsed);
70002a3a:	2a00      	cmp	r2, #0
70002a3c:	bfac      	ite	ge
70002a3e:	4618      	movge	r0, r3
70002a40:	2000      	movlt	r0, #0

	sys_clock_set_timeout(next_timeout(), false);
70002a42:	2100      	movs	r1, #0
70002a44:	f7fe ffac 	bl	700019a0 <sys_clock_set_timeout>
	if (key != 0U) {
70002a48:	f1b8 0f00 	cmp.w	r8, #0
70002a4c:	d100      	bne.n	70002a50 <sys_clock_announce+0x104>
70002a4e:	b662      	cpsie	i
	k_spin_unlock(&timeout_lock, key);

#ifdef CONFIG_TIMESLICING
	z_time_slice();
#endif /* CONFIG_TIMESLICING */
}
70002a50:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
	curr_tick += announce_remaining;
70002a54:	682a      	ldr	r2, [r5, #0]
70002a56:	18d2      	adds	r2, r2, r3
70002a58:	602a      	str	r2, [r5, #0]
	announce_remaining = 0;
70002a5a:	f04f 0200 	mov.w	r2, #0
70002a5e:	f8ca 2000 	str.w	r2, [sl]
	curr_tick += announce_remaining;
70002a62:	686a      	ldr	r2, [r5, #4]
70002a64:	eb42 72e3 	adc.w	r2, r2, r3, asr #31
70002a68:	606a      	str	r2, [r5, #4]
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002a6a:	f7fe ffc9 	bl	70001a00 <sys_clock_elapsed>
		ret = MAX_WAIT;
70002a6e:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
70002a72:	e7e6      	b.n	70002a42 <sys_clock_announce+0xf6>
	announce_remaining = 0;
70002a74:	f8ca 0000 	str.w	r0, [sl]
	curr_tick += announce_remaining;
70002a78:	f245 4268 	movw	r2, #21608	; 0x5468
70002a7c:	f2c7 0200 	movt	r2, #28672	; 0x7000
70002a80:	e9d2 1000 	ldrd	r1, r0, [r2]
70002a84:	18c9      	adds	r1, r1, r3
70002a86:	eb40 70e3 	adc.w	r0, r0, r3, asr #31
70002a8a:	e9c2 1000 	strd	r1, r0, [r2]
70002a8e:	e7ec      	b.n	70002a6a <sys_clock_announce+0x11e>

70002a90 <sys_clock_tick_get_32>:
	}
	return t;
}

uint32_t sys_clock_tick_get_32(void)
{
70002a90:	b510      	push	{r4, lr}
	__asm__ volatile(
70002a92:	f3ef 8400 	mrs	r4, CPSR
70002a96:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002a9a:	b672      	cpsid	i
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002a9c:	f646 33dc 	movw	r3, #27612	; 0x6bdc
70002aa0:	2000      	movs	r0, #0
70002aa2:	f2c7 0300 	movt	r3, #28672	; 0x7000
70002aa6:	681b      	ldr	r3, [r3, #0]
70002aa8:	b90b      	cbnz	r3, 70002aae <sys_clock_tick_get_32+0x1e>
70002aaa:	f7fe ffa9 	bl	70001a00 <sys_clock_elapsed>
		t = curr_tick + elapsed();
70002aae:	f245 4368 	movw	r3, #21608	; 0x5468
70002ab2:	f2c7 0300 	movt	r3, #28672	; 0x7000
70002ab6:	681b      	ldr	r3, [r3, #0]
70002ab8:	18c0      	adds	r0, r0, r3
	if (key != 0U) {
70002aba:	b904      	cbnz	r4, 70002abe <sys_clock_tick_get_32+0x2e>
70002abc:	b662      	cpsie	i
#ifdef CONFIG_TICKLESS_KERNEL
	return (uint32_t)sys_clock_tick_get();
#else
	return (uint32_t)curr_tick;
#endif /* CONFIG_TICKLESS_KERNEL */
}
70002abe:	bd10      	pop	{r4, pc}

70002ac0 <signal_poll_event.constprop.0>:
}
#include <zephyr/syscalls/k_poll_mrsh.c>
#endif /* CONFIG_USERSPACE */

/* must be called with interrupts locked */
static int signal_poll_event(struct k_poll_event *event, uint32_t state)
70002ac0:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
{
	struct z_poller *poller = event->poller;
70002ac4:	6886      	ldr	r6, [r0, #8]
static int signal_poll_event(struct k_poll_event *event, uint32_t state)
70002ac6:	4604      	mov	r4, r0
70002ac8:	460d      	mov	r5, r1
	int retcode = 0;

	if (poller != NULL) {
70002aca:	b136      	cbz	r6, 70002ada <signal_poll_event.constprop.0+0x1a>
		if (poller->mode == MODE_POLL) {
70002acc:	7873      	ldrb	r3, [r6, #1]
70002ace:	2b01      	cmp	r3, #1
70002ad0:	d022      	beq.n	70002b18 <signal_poll_event.constprop.0+0x58>
			retcode = signal_poller(event, state);
		} else if (poller->mode == MODE_TRIGGERED) {
70002ad2:	2b02      	cmp	r3, #2
70002ad4:	d00c      	beq.n	70002af0 <signal_poll_event.constprop.0+0x30>
		} else {
			/* Poller is not poll or triggered mode. No action needed.*/
			;
		}

		poller->is_polling = false;
70002ad6:	2300      	movs	r3, #0
70002ad8:	7033      	strb	r3, [r6, #0]
	event->state |= state;
70002ada:	68e3      	ldr	r3, [r4, #12]
	event->poller = NULL;
70002adc:	2000      	movs	r0, #0
70002ade:	60a0      	str	r0, [r4, #8]
	event->state |= state;
70002ae0:	f3c3 3286 	ubfx	r2, r3, #14, #7
70002ae4:	4315      	orrs	r5, r2
70002ae6:	f365 3394 	bfi	r3, r5, #14, #7
70002aea:	60e3      	str	r3, [r4, #12]
		}
	}

	set_event_ready(event, state);
	return retcode;
}
70002aec:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
{
	struct z_poller *poller = event->poller;
	struct k_work_poll *twork =
		CONTAINER_OF(poller, struct k_work_poll, poller);

	if (poller->is_polling && twork->workq != NULL) {
70002af0:	7833      	ldrb	r3, [r6, #0]
70002af2:	2b00      	cmp	r3, #0
70002af4:	d0ef      	beq.n	70002ad6 <signal_poll_event.constprop.0+0x16>
70002af6:	f856 7c04 	ldr.w	r7, [r6, #-4]
70002afa:	2f00      	cmp	r7, #0
70002afc:	d0eb      	beq.n	70002ad6 <signal_poll_event.constprop.0+0x16>
		struct k_work_q *work_q = twork->workq;

		z_abort_timeout(&twork->timeout);
70002afe:	f106 0014 	add.w	r0, r6, #20
70002b02:	f7ff fefb 	bl	700028fc <z_abort_timeout>
		twork->poll_result = 0;
70002b06:	2300      	movs	r3, #0
		z_work_submit_to_queue(work_q, &twork->work);
70002b08:	4638      	mov	r0, r7
		z_abort_timeout(&twork->timeout);
70002b0a:	f1a6 0814 	sub.w	r8, r6, #20
		twork->poll_result = 0;
70002b0e:	62f3      	str	r3, [r6, #44]	; 0x2c
		z_work_submit_to_queue(work_q, &twork->work);
70002b10:	4641      	mov	r1, r8
70002b12:	f000 f977 	bl	70002e04 <z_work_submit_to_queue>
70002b16:	e7de      	b.n	70002ad6 <signal_poll_event.constprop.0+0x16>
	if (!z_is_thread_pending(thread)) {
70002b18:	f816 3c53 	ldrb.w	r3, [r6, #-83]
70002b1c:	079a      	lsls	r2, r3, #30
70002b1e:	d5da      	bpl.n	70002ad6 <signal_poll_event.constprop.0+0x16>
	return p ? CONTAINER_OF(p, struct k_thread, poller) : NULL;
70002b20:	f1a6 0760 	sub.w	r7, r6, #96	; 0x60
	z_unpend_thread(thread);
70002b24:	4638      	mov	r0, r7
70002b26:	f7ff fc97 	bl	70002458 <z_unpend_thread>
	arch_thread_return_value_set(thread,
70002b2a:	2d08      	cmp	r5, #8
70002b2c:	bf14      	ite	ne
70002b2e:	2300      	movne	r3, #0
70002b30:	f06f 0303 	mvneq.w	r3, #3
70002b34:	6133      	str	r3, [r6, #16]
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
70002b36:	f816 3c53 	ldrb.w	r3, [r6, #-83]
70002b3a:	06db      	lsls	r3, r3, #27
70002b3c:	d1cb      	bne.n	70002ad6 <signal_poll_event.constprop.0+0x16>
70002b3e:	f856 3c48 	ldr.w	r3, [r6, #-72]
70002b42:	2b00      	cmp	r3, #0
70002b44:	d1c7      	bne.n	70002ad6 <signal_poll_event.constprop.0+0x16>
	z_ready_thread(thread);
70002b46:	4638      	mov	r0, r7
70002b48:	f7ff fbca 	bl	700022e0 <z_ready_thread>
	return 0;
70002b4c:	e7c3      	b.n	70002ad6 <signal_poll_event.constprop.0+0x16>
70002b4e:	bf00      	nop

70002b50 <z_handle_obj_poll_events>:
{
70002b50:	4603      	mov	r3, r0
70002b52:	b510      	push	{r4, lr}
	__asm__ volatile(
70002b54:	f3ef 8400 	mrs	r4, CPSR
70002b58:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002b5c:	b672      	cpsid	i
	return list->head == list;
70002b5e:	6800      	ldr	r0, [r0, #0]

static inline sys_dnode_t *sys_dlist_get(sys_dlist_t *list)
{
	sys_dnode_t *node = NULL;

	if (!sys_dlist_is_empty(list)) {
70002b60:	4283      	cmp	r3, r0
70002b62:	d008      	beq.n	70002b76 <z_handle_obj_poll_events+0x26>
	sys_dnode_t *const next = node->next;
70002b64:	e9d0 3200 	ldrd	r3, r2, [r0]
	prev->next = next;
70002b68:	6013      	str	r3, [r2, #0]
	next->prev = prev;
70002b6a:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70002b6c:	2300      	movs	r3, #0
70002b6e:	6003      	str	r3, [r0, #0]
70002b70:	6043      	str	r3, [r0, #4]
		(void) signal_poll_event(poll_event, state);
70002b72:	f7ff ffa5 	bl	70002ac0 <signal_poll_event.constprop.0>
	if (key != 0U) {
70002b76:	b904      	cbnz	r4, 70002b7a <z_handle_obj_poll_events+0x2a>
70002b78:	b662      	cpsie	i
}
70002b7a:	bd10      	pop	{r4, pc}

70002b7c <boot_banner>:
	  */
	printk("\x1b[3J\x1b[2J\x1b[H");
#endif /* CONFIG_BOOT_CLEAR_SCREEN */

#ifdef CONFIG_BOOT_BANNER
	printk("*** " CONFIG_BOOT_BANNER_STRING " " BANNER_VERSION BANNER_POSTFIX " ***\n");
70002b7c:	f644 5080 	movw	r0, #19840	; 0x4d80
70002b80:	f2c7 0000 	movt	r0, #28672	; 0x7000
70002b84:	f7fd bf3a 	b.w	700009fc <printk>

70002b88 <statics_init>:

	SYS_PORT_TRACING_OBJ_INIT(k_heap, heap);
}

static int statics_init(void)
{
70002b88:	b538      	push	{r3, r4, r5, lr}
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70002b8a:	f24b 04c4 	movw	r4, #45252	; 0xb0c4
70002b8e:	f24b 05c4 	movw	r5, #45252	; 0xb0c4
70002b92:	f2c7 0400 	movt	r4, #28672	; 0x7000
70002b96:	f2c7 0500 	movt	r5, #28672	; 0x7000
70002b9a:	42ac      	cmp	r4, r5
70002b9c:	d20b      	bcs.n	70002bb6 <statics_init+0x2e>
	sys_heap_init(&heap->heap, mem, bytes);
70002b9e:	e9d4 1201 	ldrd	r1, r2, [r4, #4]
70002ba2:	f104 030c 	add.w	r3, r4, #12
70002ba6:	4620      	mov	r0, r4
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70002ba8:	3414      	adds	r4, #20
	list->head = (sys_dnode_t *)list;
70002baa:	601b      	str	r3, [r3, #0]
70002bac:	605b      	str	r3, [r3, #4]
	sys_heap_init(&heap->heap, mem, bytes);
70002bae:	f7fd fee1 	bl	70000974 <sys_heap_init>
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70002bb2:	42ac      	cmp	r4, r5
70002bb4:	d3f3      	bcc.n	70002b9e <statics_init+0x16>
		{
			k_heap_init(heap, heap->heap.init_mem, heap->heap.init_bytes);
		}
	}
	return 0;
}
70002bb6:	2000      	movs	r0, #0
70002bb8:	bd38      	pop	{r3, r4, r5, pc}
70002bba:	bf00      	nop

70002bbc <k_sys_work_q_init>:

struct k_work_q k_sys_work_q;

static int k_sys_work_q_init(void)
{
	struct k_work_queue_config cfg = {
70002bbc:	f644 21e4 	movw	r1, #19172	; 0x4ae4
		.name = "sysworkq",
		.no_yield = IS_ENABLED(CONFIG_SYSTEM_WORKQUEUE_NO_YIELD),
		.essential = true,
	};

	k_work_queue_start(&k_sys_work_q,
70002bc0:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
	struct k_work_queue_config cfg = {
70002bc4:	f2c7 0100 	movt	r1, #28672	; 0x7000
{
70002bc8:	b510      	push	{r4, lr}
	struct k_work_queue_config cfg = {
70002bca:	c903      	ldmia	r1, {r0, r1}
{
70002bcc:	b084      	sub	sp, #16
	k_work_queue_start(&k_sys_work_q,
70002bce:	f44f 6280 	mov.w	r2, #1024	; 0x400
	struct k_work_queue_config cfg = {
70002bd2:	ac02      	add	r4, sp, #8
	k_work_queue_start(&k_sys_work_q,
70002bd4:	9400      	str	r4, [sp, #0]
	struct k_work_queue_config cfg = {
70002bd6:	e884 0003 	stmia.w	r4, {r0, r1}
	k_work_queue_start(&k_sys_work_q,
70002bda:	f64a 31e8 	movw	r1, #44008	; 0xabe8
70002bde:	f245 4070 	movw	r0, #21616	; 0x5470
70002be2:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002be6:	f2c7 0000 	movt	r0, #28672	; 0x7000
70002bea:	f000 f91b 	bl	70002e24 <k_work_queue_start>
			    sys_work_q_stack,
			    K_KERNEL_STACK_SIZEOF(sys_work_q_stack),
			    CONFIG_SYSTEM_WORKQUEUE_PRIORITY, &cfg);
	return 0;
}
70002bee:	2000      	movs	r0, #0
70002bf0:	b004      	add	sp, #16
70002bf2:	bd10      	pop	{r4, pc}

70002bf4 <work_queue_main>:
/* Loop executed by a work queue thread.
 *
 * @param workq_ptr pointer to the work queue structure
 */
static void work_queue_main(void *workq_ptr, void *p2, void *p3)
{
70002bf4:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
 *
 * @return A pointer on the first node of the list (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_head(sys_slist_t *list)
{
	return list->head;
70002bf8:	f245 5608 	movw	r6, #21768	; 0x5508
70002bfc:	b084      	sub	sp, #16
70002bfe:	4605      	mov	r5, r0
70002c00:	f2c7 0600 	movt	r6, #28672	; 0x7000
	return node->next;
70002c04:	2700      	movs	r7, #0
	__asm__ volatile(
70002c06:	f3ef 8800 	mrs	r8, CPSR
70002c0a:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002c0e:	b672      	cpsid	i
	return list->head;
70002c10:	6fac      	ldr	r4, [r5, #120]	; 0x78
 *
 * @return A pointer to the first node of the list (or NULL if empty)
 */
static inline sys_snode_t *sys_slist_get(sys_slist_t *list);

Z_GENLIST_GET(slist, snode)
70002c12:	2c00      	cmp	r4, #0
70002c14:	d060      	beq.n	70002cd8 <work_queue_main+0xe4>
Z_GENLIST_GET_NOT_EMPTY(slist, snode)
70002c16:	6fea      	ldr	r2, [r5, #124]	; 0x7c
	return node->next;
70002c18:	6823      	ldr	r3, [r4, #0]
	list->head = node;
70002c1a:	67ab      	str	r3, [r5, #120]	; 0x78
Z_GENLIST_GET_NOT_EMPTY(slist, snode)
70002c1c:	4294      	cmp	r4, r2
	list->tail = node;
70002c1e:	bf08      	it	eq
70002c20:	67eb      	streq	r3, [r5, #124]	; 0x7c
	*flagp |= BIT(bit);
70002c22:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
70002c26:	f043 0302 	orr.w	r3, r3, #2
70002c2a:	f8c5 3090 	str.w	r3, [r5, #144]	; 0x90
	*flagp &= ~BIT(bit);
70002c2e:	68e3      	ldr	r3, [r4, #12]
			 * of struct k_work object that has been placed at address NULL,
			 * which should never happen, even line 'if (work != NULL)'
			 * ensures that.
			 * This means that if node is not NULL, then work will not be NULL.
			 */
			handler = work->handler;
70002c30:	6862      	ldr	r2, [r4, #4]
	*flagp &= ~BIT(bit);
70002c32:	f023 0304 	bic.w	r3, r3, #4
70002c36:	f043 0301 	orr.w	r3, r3, #1
70002c3a:	60e3      	str	r3, [r4, #12]
	if (key != 0U) {
70002c3c:	f1b8 0f00 	cmp.w	r8, #0
70002c40:	d100      	bne.n	70002c44 <work_queue_main+0x50>
70002c42:	b662      	cpsie	i
		}

		k_spin_unlock(&lock, key);

		__ASSERT_NO_MSG(handler != NULL);
		handler(work);
70002c44:	4620      	mov	r0, r4
70002c46:	4790      	blx	r2
	__asm__ volatile(
70002c48:	f3ef 8800 	mrs	r8, CPSR
70002c4c:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002c50:	b672      	cpsid	i
	*flagp &= ~BIT(bit);
70002c52:	68e2      	ldr	r2, [r4, #12]
70002c54:	f022 0301 	bic.w	r3, r2, #1
		 * yield to prevent starving other threads.
		 */
		key = k_spin_lock(&lock);

		flag_clear(&work->flags, K_WORK_RUNNING_BIT);
		if (flag_test(&work->flags, K_WORK_FLUSHING_BIT)) {
70002c58:	06d1      	lsls	r1, r2, #27
	*flagp &= ~BIT(bit);
70002c5a:	bf58      	it	pl
70002c5c:	60e3      	strpl	r3, [r4, #12]
		if (flag_test(&work->flags, K_WORK_FLUSHING_BIT)) {
70002c5e:	d432      	bmi.n	70002cc6 <work_queue_main+0xd2>
			finalize_flush_locked(work);
		}
		if (flag_test(&work->flags, K_WORK_CANCELING_BIT)) {
70002c60:	079a      	lsls	r2, r3, #30
70002c62:	d410      	bmi.n	70002c86 <work_queue_main+0x92>
	*flagp &= ~BIT(bit);
70002c64:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
70002c68:	f023 0302 	bic.w	r3, r3, #2
	return (*flagp & BIT(bit)) != 0U;
70002c6c:	f3c3 2200 	ubfx	r2, r3, #8, #1
	*flagp &= ~BIT(bit);
70002c70:	f8c5 3090 	str.w	r3, [r5, #144]	; 0x90
	if (key != 0U) {
70002c74:	f1b8 0f00 	cmp.w	r8, #0
70002c78:	d100      	bne.n	70002c7c <work_queue_main+0x88>
70002c7a:	b662      	cpsie	i
		k_spin_unlock(&lock, key);

		/* Optionally yield to prevent the work queue from
		 * starving other threads.
		 */
		if (yield) {
70002c7c:	2a00      	cmp	r2, #0
70002c7e:	d1c2      	bne.n	70002c06 <work_queue_main+0x12>
70002c80:	f7ff fc7a 	bl	70002578 <z_impl_k_yield>
}
70002c84:	e7bf      	b.n	70002c06 <work_queue_main+0x12>
	return list->head;
70002c86:	6830      	ldr	r0, [r6, #0]
	*flagp &= ~BIT(bit);
70002c88:	f023 0302 	bic.w	r3, r3, #2
70002c8c:	60e3      	str	r3, [r4, #12]
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(&pending_cancels, wc, tmp, node) {
70002c8e:	2800      	cmp	r0, #0
70002c90:	d0e8      	beq.n	70002c64 <work_queue_main+0x70>
		if (wc->work == work) {
70002c92:	6842      	ldr	r2, [r0, #4]
	return node->next;
70002c94:	2100      	movs	r1, #0
70002c96:	6803      	ldr	r3, [r0, #0]
70002c98:	4294      	cmp	r4, r2
70002c9a:	d007      	beq.n	70002cac <work_queue_main+0xb8>
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(&pending_cancels, wc, tmp, node) {
70002c9c:	2b00      	cmp	r3, #0
70002c9e:	d0e1      	beq.n	70002c64 <work_queue_main+0x70>
			sys_slist_remove(&pending_cancels, prev, &wc->node);
70002ca0:	4601      	mov	r1, r0
70002ca2:	4618      	mov	r0, r3
Z_GENLIST_PEEK_NEXT(slist, snode)
70002ca4:	681b      	ldr	r3, [r3, #0]
		if (wc->work == work) {
70002ca6:	6842      	ldr	r2, [r0, #4]
70002ca8:	4294      	cmp	r4, r2
70002caa:	d1f7      	bne.n	70002c9c <work_queue_main+0xa8>
	return node->next;
70002cac:	6803      	ldr	r3, [r0, #0]
 */
static inline void sys_slist_remove(sys_slist_t *list,
				    sys_snode_t *prev_node,
				    sys_snode_t *node);

Z_GENLIST_REMOVE(slist, snode)
70002cae:	2900      	cmp	r1, #0
70002cb0:	d042      	beq.n	70002d38 <work_queue_main+0x144>
	parent->next = child;
70002cb2:	600b      	str	r3, [r1, #0]
Z_GENLIST_REMOVE(slist, snode)
70002cb4:	6873      	ldr	r3, [r6, #4]
70002cb6:	4283      	cmp	r3, r0
	list->tail = node;
70002cb8:	bf08      	it	eq
70002cba:	6071      	streq	r1, [r6, #4]
	parent->next = child;
70002cbc:	f840 7b08 	str.w	r7, [r0], #8
	z_impl_k_sem_give(sem);
70002cc0:	f7ff f8d6 	bl	70001e70 <z_impl_k_sem_give>
}
70002cc4:	e7ce      	b.n	70002c64 <work_queue_main+0x70>
	*flagp &= ~BIT(bit);
70002cc6:	f022 0211 	bic.w	r2, r2, #17
70002cca:	60e2      	str	r2, [r4, #12]
	z_impl_k_sem_give(sem);
70002ccc:	f104 0010 	add.w	r0, r4, #16
70002cd0:	f7ff f8ce 	bl	70001e70 <z_impl_k_sem_give>
	return (*flagp & BIT(bit)) != 0U;
70002cd4:	68e3      	ldr	r3, [r4, #12]
};
70002cd6:	e7c3      	b.n	70002c60 <work_queue_main+0x6c>
	return (*flagp & BIT(bit)) != 0U;
70002cd8:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
	*flagp &= ~BIT(bit);
70002cdc:	f023 0204 	bic.w	r2, r3, #4
		} else if (flag_test_and_clear(&queue->flags,
70002ce0:	075c      	lsls	r4, r3, #29
	*flagp &= ~BIT(bit);
70002ce2:	f8c5 2090 	str.w	r2, [r5, #144]	; 0x90
		} else if (flag_test_and_clear(&queue->flags,
70002ce6:	f3c3 0180 	ubfx	r1, r3, #2, #1
70002cea:	d40a      	bmi.n	70002d02 <work_queue_main+0x10e>
		} else if (flag_test(&queue->flags, K_WORK_QUEUE_STOP_BIT)) {
70002cec:	06d0      	lsls	r0, r2, #27
70002cee:	d511      	bpl.n	70002d14 <work_queue_main+0x120>
	*flagp = flags;
70002cf0:	f8c5 1090 	str.w	r1, [r5, #144]	; 0x90
70002cf4:	f1b8 0f00 	cmp.w	r8, #0
70002cf8:	d100      	bne.n	70002cfc <work_queue_main+0x108>
70002cfa:	b662      	cpsie	i
			k_yield();
		}
	}
}
70002cfc:	b004      	add	sp, #16
70002cfe:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
			(void)z_sched_wake_all(&queue->drainq, 1, NULL);
70002d02:	f105 0488 	add.w	r4, r5, #136	; 0x88
static inline bool z_sched_wake_all(_wait_q_t *wait_q, int swap_retval,
				    void *swap_data)
{
	bool woken = false;

	while (z_sched_wake(wait_q, swap_retval, swap_data)) {
70002d06:	2200      	movs	r2, #0
70002d08:	2101      	movs	r1, #1
70002d0a:	4620      	mov	r0, r4
70002d0c:	f7ff fd22 	bl	70002754 <z_sched_wake>
70002d10:	2800      	cmp	r0, #0
70002d12:	d1f8      	bne.n	70002d06 <work_queue_main+0x112>
					   K_FOREVER, NULL);
70002d14:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
70002d18:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
			(void)z_sched_wait(&lock, key, &queue->notifyq,
70002d1c:	f646 30e0 	movw	r0, #27616	; 0x6be0
70002d20:	4641      	mov	r1, r8
70002d22:	e9cd 2300 	strd	r2, r3, [sp]
70002d26:	2300      	movs	r3, #0
70002d28:	f105 0280 	add.w	r2, r5, #128	; 0x80
70002d2c:	9302      	str	r3, [sp, #8]
70002d2e:	f2c7 0000 	movt	r0, #28672	; 0x7000
70002d32:	f7ff fd3d 	bl	700027b0 <z_sched_wait>
			continue;
70002d36:	e766      	b.n	70002c06 <work_queue_main+0x12>
Z_GENLIST_REMOVE(slist, snode)
70002d38:	6872      	ldr	r2, [r6, #4]
	list->head = node;
70002d3a:	6033      	str	r3, [r6, #0]
Z_GENLIST_REMOVE(slist, snode)
70002d3c:	4282      	cmp	r2, r0
	list->tail = node;
70002d3e:	bf08      	it	eq
70002d40:	6073      	streq	r3, [r6, #4]
70002d42:	e7bb      	b.n	70002cbc <work_queue_main+0xc8>

70002d44 <submit_to_queue_locked>:
{
70002d44:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	return (*flagp & BIT(bit)) != 0U;
70002d46:	68c3      	ldr	r3, [r0, #12]
{
70002d48:	460d      	mov	r5, r1
	if (flag_test(&work->flags, K_WORK_CANCELING_BIT)) {
70002d4a:	079a      	lsls	r2, r3, #30
70002d4c:	f3c3 0640 	ubfx	r6, r3, #1, #1
70002d50:	d407      	bmi.n	70002d62 <submit_to_queue_locked+0x1e>
	} else if (!flag_test(&work->flags, K_WORK_QUEUED_BIT)) {
70002d52:	075f      	lsls	r7, r3, #29
	return (*flagp & BIT(bit)) != 0U;
70002d54:	f3c3 0280 	ubfx	r2, r3, #2, #1
	} else if (!flag_test(&work->flags, K_WORK_QUEUED_BIT)) {
70002d58:	d506      	bpl.n	70002d68 <submit_to_queue_locked+0x24>
		*queuep = NULL;
70002d5a:	2300      	movs	r3, #0
}
70002d5c:	4630      	mov	r0, r6
		*queuep = NULL;
70002d5e:	602b      	str	r3, [r5, #0]
}
70002d60:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		ret = -EBUSY;
70002d62:	f06f 060f 	mvn.w	r6, #15
70002d66:	e7f8      	b.n	70002d5a <submit_to_queue_locked+0x16>
		if (*queuep == NULL) {
70002d68:	680f      	ldr	r7, [r1, #0]
70002d6a:	4604      	mov	r4, r0
70002d6c:	2f00      	cmp	r7, #0
70002d6e:	d032      	beq.n	70002dd6 <submit_to_queue_locked+0x92>
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002d70:	07db      	lsls	r3, r3, #31
		ret = 1;
70002d72:	bf58      	it	pl
70002d74:	2601      	movpl	r6, #1
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002d76:	d504      	bpl.n	70002d82 <submit_to_queue_locked+0x3e>
			*queuep = work->queue;
70002d78:	68a7      	ldr	r7, [r4, #8]
			ret = 2;
70002d7a:	2602      	movs	r6, #2
			*queuep = work->queue;
70002d7c:	602f      	str	r7, [r5, #0]
	if (queue == NULL) {
70002d7e:	2f00      	cmp	r7, #0
70002d80:	d03d      	beq.n	70002dfe <submit_to_queue_locked+0xba>
70002d82:	f646 33bc 	movw	r3, #27580	; 0x6bbc
70002d86:	f2c7 0300 	movt	r3, #28672	; 0x7000
	bool chained = (arch_current_thread() == &queue->thread) && !k_is_in_isr();
70002d8a:	689b      	ldr	r3, [r3, #8]
70002d8c:	42bb      	cmp	r3, r7
70002d8e:	d02d      	beq.n	70002dec <submit_to_queue_locked+0xa8>
	return (*flagp & BIT(bit)) != 0U;
70002d90:	f8d7 0090 	ldr.w	r0, [r7, #144]	; 0x90
70002d94:	f3c0 0380 	ubfx	r3, r0, #2, #1
70002d98:	f3c0 01c0 	ubfx	r1, r0, #3, #1
	if (!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT)) {
70002d9c:	07c0      	lsls	r0, r0, #31
70002d9e:	d52b      	bpl.n	70002df8 <submit_to_queue_locked+0xb4>
	} else if (draining && !chained) {
70002da0:	f082 0201 	eor.w	r2, r2, #1
70002da4:	4213      	tst	r3, r2
70002da6:	d1dc      	bne.n	70002d62 <submit_to_queue_locked+0x1e>
	} else if (plugged && !draining) {
70002da8:	f083 0301 	eor.w	r3, r3, #1
70002dac:	4019      	ands	r1, r3
70002dae:	d1d8      	bne.n	70002d62 <submit_to_queue_locked+0x1e>
	parent->next = child;
70002db0:	6021      	str	r1, [r4, #0]
	return list->tail;
70002db2:	6ffb      	ldr	r3, [r7, #124]	; 0x7c
Z_GENLIST_APPEND(slist, snode)
70002db4:	b1bb      	cbz	r3, 70002de6 <submit_to_queue_locked+0xa2>
	parent->next = child;
70002db6:	601c      	str	r4, [r3, #0]
	list->tail = node;
70002db8:	67fc      	str	r4, [r7, #124]	; 0x7c
		rv = z_sched_wake(&queue->notifyq, 0, NULL);
70002dba:	2200      	movs	r2, #0
70002dbc:	f107 0080 	add.w	r0, r7, #128	; 0x80
70002dc0:	4611      	mov	r1, r2
70002dc2:	f7ff fcc7 	bl	70002754 <z_sched_wake>
	*flagp |= BIT(bit);
70002dc6:	68e3      	ldr	r3, [r4, #12]
}
70002dc8:	4630      	mov	r0, r6
	*flagp |= BIT(bit);
70002dca:	f043 0304 	orr.w	r3, r3, #4
70002dce:	60e3      	str	r3, [r4, #12]
			work->queue = *queuep;
70002dd0:	682b      	ldr	r3, [r5, #0]
70002dd2:	60a3      	str	r3, [r4, #8]
}
70002dd4:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
			*queuep = work->queue;
70002dd6:	6887      	ldr	r7, [r0, #8]
70002dd8:	600f      	str	r7, [r1, #0]
	return (*flagp & BIT(bit)) != 0U;
70002dda:	68c3      	ldr	r3, [r0, #12]
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002ddc:	07de      	lsls	r6, r3, #31
		ret = 1;
70002dde:	bf58      	it	pl
70002de0:	2601      	movpl	r6, #1
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002de2:	d5cc      	bpl.n	70002d7e <submit_to_queue_locked+0x3a>
70002de4:	e7c8      	b.n	70002d78 <submit_to_queue_locked+0x34>
	list->head = node;
70002de6:	67bc      	str	r4, [r7, #120]	; 0x78
70002de8:	67fc      	str	r4, [r7, #124]	; 0x7c
	if (queue != NULL) {
70002dea:	e7e6      	b.n	70002dba <submit_to_queue_locked+0x76>
	bool chained = (arch_current_thread() == &queue->thread) && !k_is_in_isr();
70002dec:	f7ff f89c 	bl	70001f28 <k_is_in_isr>
70002df0:	f080 0201 	eor.w	r2, r0, #1
70002df4:	b2d2      	uxtb	r2, r2
70002df6:	e7cb      	b.n	70002d90 <submit_to_queue_locked+0x4c>
		ret = -ENODEV;
70002df8:	f06f 0612 	mvn.w	r6, #18
70002dfc:	e7ad      	b.n	70002d5a <submit_to_queue_locked+0x16>
		return -EINVAL;
70002dfe:	f06f 0615 	mvn.w	r6, #21
70002e02:	e7aa      	b.n	70002d5a <submit_to_queue_locked+0x16>

70002e04 <z_work_submit_to_queue>:
{
70002e04:	b510      	push	{r4, lr}
70002e06:	b082      	sub	sp, #8
70002e08:	9001      	str	r0, [sp, #4]
70002e0a:	4608      	mov	r0, r1
	__asm__ volatile(
70002e0c:	f3ef 8400 	mrs	r4, CPSR
70002e10:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002e14:	b672      	cpsid	i
	int ret = submit_to_queue_locked(work, &queue);
70002e16:	a901      	add	r1, sp, #4
70002e18:	f7ff ff94 	bl	70002d44 <submit_to_queue_locked>
	if (key != 0U) {
70002e1c:	b904      	cbnz	r4, 70002e20 <z_work_submit_to_queue+0x1c>
70002e1e:	b662      	cpsie	i
}
70002e20:	b002      	add	sp, #8
70002e22:	bd10      	pop	{r4, pc}

70002e24 <k_work_queue_start>:
void k_work_queue_start(struct k_work_q *queue,
			k_thread_stack_t *stack,
			size_t stack_size,
			int prio,
			const struct k_work_queue_config *cfg)
{
70002e24:	b5f0      	push	{r4, r5, r6, r7, lr}
70002e26:	4604      	mov	r4, r0
70002e28:	b089      	sub	sp, #36	; 0x24
	list->head = NULL;
70002e2a:	2000      	movs	r0, #0
70002e2c:	67a0      	str	r0, [r4, #120]	; 0x78
70002e2e:	67e0      	str	r0, [r4, #124]	; 0x7c
	sys_dlist_init(&w->waitq);
70002e30:	f104 0080 	add.w	r0, r4, #128	; 0x80
70002e34:	9d0e      	ldr	r5, [sp, #56]	; 0x38
	list->tail = (sys_dnode_t *)list;
70002e36:	e9c4 0020 	strd	r0, r0, [r4, #128]	; 0x80
70002e3a:	f104 0088 	add.w	r0, r4, #136	; 0x88
70002e3e:	e9c4 0022 	strd	r0, r0, [r4, #136]	; 0x88
	__ASSERT_NO_MSG(queue);
	__ASSERT_NO_MSG(stack);
	__ASSERT_NO_MSG(!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT));
	uint32_t flags = K_WORK_QUEUE_STARTED;
70002e42:	2001      	movs	r0, #1

	sys_slist_init(&queue->pending);
	z_waitq_init(&queue->notifyq);
	z_waitq_init(&queue->drainq);

	if ((cfg != NULL) && cfg->no_yield) {
70002e44:	b12d      	cbz	r5, 70002e52 <k_work_queue_start+0x2e>
70002e46:	792e      	ldrb	r6, [r5, #4]
		flags |= K_WORK_QUEUE_NO_YIELD;
70002e48:	f240 1001 	movw	r0, #257	; 0x101
70002e4c:	2e00      	cmp	r6, #0
70002e4e:	bf08      	it	eq
70002e50:	2001      	moveq	r0, #1
	*flagp = flags;
70002e52:	f04f 36ff 	mov.w	r6, #4294967295	; 0xffffffff
70002e56:	f04f 37ff 	mov.w	r7, #4294967295	; 0xffffffff
70002e5a:	f8c4 0090 	str.w	r0, [r4, #144]	; 0x90
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
70002e5e:	9303      	str	r3, [sp, #12]
70002e60:	2000      	movs	r0, #0
70002e62:	e9cd 6706 	strd	r6, r7, [sp, #24]
70002e66:	f642 33f5 	movw	r3, #11253	; 0x2bf5
70002e6a:	9004      	str	r0, [sp, #16]
70002e6c:	f2c7 0300 	movt	r3, #28672	; 0x7000
70002e70:	e9cd 0001 	strd	r0, r0, [sp, #4]
70002e74:	4620      	mov	r0, r4
70002e76:	9400      	str	r4, [sp, #0]
70002e78:	f7ff f894 	bl	70001fa4 <z_impl_k_thread_create>

	(void)k_thread_create(&queue->thread, stack, stack_size,
			      work_queue_main, queue, NULL, NULL,
			      prio, 0, K_FOREVER);

	if ((cfg != NULL) && (cfg->name != NULL)) {
70002e7c:	b155      	cbz	r5, 70002e94 <k_work_queue_start+0x70>
70002e7e:	6829      	ldr	r1, [r5, #0]
70002e80:	b111      	cbz	r1, 70002e88 <k_work_queue_start+0x64>
	return z_impl_k_thread_name_set(thread, str);
70002e82:	4620      	mov	r0, r4
70002e84:	f7ff f85a 	bl	70001f3c <z_impl_k_thread_name_set>
		k_thread_name_set(&queue->thread, cfg->name);
	}

	if ((cfg != NULL) && (cfg->essential)) {
70002e88:	796b      	ldrb	r3, [r5, #5]
70002e8a:	b11b      	cbz	r3, 70002e94 <k_work_queue_start+0x70>
		queue->thread.base.user_options |= K_ESSENTIAL;
70002e8c:	7b23      	ldrb	r3, [r4, #12]
70002e8e:	f043 0301 	orr.w	r3, r3, #1
70002e92:	7323      	strb	r3, [r4, #12]
	z_impl_k_wakeup(thread);
70002e94:	4620      	mov	r0, r4
	}

	k_thread_start(&queue->thread);

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_work_queue, start, queue);
}
70002e96:	b009      	add	sp, #36	; 0x24
70002e98:	e8bd 40f0 	ldmia.w	sp!, {r4, r5, r6, r7, lr}
70002e9c:	f7ff bc12 	b.w	700026c4 <z_impl_k_wakeup>

70002ea0 <memcpy>:
  long *aligned_dst;
  const long *aligned_src;

  /* If the size is small, or either SRC or DST is unaligned,
     then punt into the byte copy loop.  This should be rare.  */
  if (!TOO_SMALL(len0) && !UNALIGNED (src, dst))
70002ea0:	2a0f      	cmp	r2, #15
70002ea2:	d913      	bls.n	70002ecc <memcpy+0x2c>
70002ea4:	ea40 0301 	orr.w	r3, r0, r1
70002ea8:	f013 0303 	ands.w	r3, r3, #3
  char *dst = dst0;
70002eac:	bf1c      	itt	ne
70002eae:	4603      	movne	r3, r0
       /* Pick up any residual with a byte copier.  */
      dst = (char*)aligned_dst;
      src = (char*)aligned_src;
    }

  while (len0--)
70002eb0:	f102 3cff 	addne.w	ip, r2, #4294967295	; 0xffffffff
  if (!TOO_SMALL(len0) && !UNALIGNED (src, dst))
70002eb4:	d010      	beq.n	70002ed8 <memcpy+0x38>
70002eb6:	f10c 0c01 	add.w	ip, ip, #1
70002eba:	3b01      	subs	r3, #1
70002ebc:	448c      	add	ip, r1
    *dst++ = *src++;
70002ebe:	f811 2b01 	ldrb.w	r2, [r1], #1
70002ec2:	f803 2f01 	strb.w	r2, [r3, #1]!
  while (len0--)
70002ec6:	458c      	cmp	ip, r1
70002ec8:	d1f9      	bne.n	70002ebe <memcpy+0x1e>
70002eca:	4770      	bx	lr
  char *dst = dst0;
70002ecc:	4603      	mov	r3, r0
  while (len0--)
70002ece:	f102 3cff 	add.w	ip, r2, #4294967295	; 0xffffffff
70002ed2:	2a00      	cmp	r2, #0
70002ed4:	d1ef      	bne.n	70002eb6 <memcpy+0x16>

  return dst0;
#endif /* not PREFER_SIZE_OVER_SPEED */
}
70002ed6:	4770      	bx	lr
{
70002ed8:	b5f0      	push	{r4, r5, r6, r7, lr}
70002eda:	4684      	mov	ip, r0
70002edc:	f1a2 0710 	sub.w	r7, r2, #16
70002ee0:	468e      	mov	lr, r1
70002ee2:	093f      	lsrs	r7, r7, #4
70002ee4:	3701      	adds	r7, #1
          *aligned_dst++ = *aligned_src++;
70002ee6:	f8de 4008 	ldr.w	r4, [lr, #8]
70002eea:	3301      	adds	r3, #1
70002eec:	f8de 6000 	ldr.w	r6, [lr]
70002ef0:	429f      	cmp	r7, r3
70002ef2:	f8de 5004 	ldr.w	r5, [lr, #4]
70002ef6:	f10c 0c10 	add.w	ip, ip, #16
70002efa:	f84c 4c08 	str.w	r4, [ip, #-8]
70002efe:	f10e 0e10 	add.w	lr, lr, #16
70002f02:	f85e 4c04 	ldr.w	r4, [lr, #-4]
70002f06:	f84c 6c10 	str.w	r6, [ip, #-16]
70002f0a:	f84c 5c0c 	str.w	r5, [ip, #-12]
70002f0e:	f84c 4c04 	str.w	r4, [ip, #-4]
      while (len0 >= BIGBLOCKSIZE)
70002f12:	d8e8      	bhi.n	70002ee6 <memcpy+0x46>
      while (len0 >= LITTLEBLOCKSIZE)
70002f14:	f012 0f0c 	tst.w	r2, #12
          len0 -= BIGBLOCKSIZE;
70002f18:	f002 050f 	and.w	r5, r2, #15
          *aligned_dst++ = *aligned_src++;
70002f1c:	eb01 1107 	add.w	r1, r1, r7, lsl #4
          len0 -= BIGBLOCKSIZE;
70002f20:	bf08      	it	eq
70002f22:	462a      	moveq	r2, r5
          *aligned_dst++ = *aligned_src++;
70002f24:	eb00 1307 	add.w	r3, r0, r7, lsl #4
      while (len0 >= LITTLEBLOCKSIZE)
70002f28:	d013      	beq.n	70002f52 <memcpy+0xb2>
70002f2a:	3d04      	subs	r5, #4
70002f2c:	f025 0c03 	bic.w	ip, r5, #3
70002f30:	1f1c      	subs	r4, r3, #4
70002f32:	08ad      	lsrs	r5, r5, #2
          *aligned_dst++ = *aligned_src++;
70002f34:	460e      	mov	r6, r1
70002f36:	449c      	add	ip, r3
          *aligned_dst++ = *aligned_src++;
70002f38:	f856 7b04 	ldr.w	r7, [r6], #4
70002f3c:	f844 7f04 	str.w	r7, [r4, #4]!
      while (len0 >= LITTLEBLOCKSIZE)
70002f40:	4564      	cmp	r4, ip
70002f42:	d1f9      	bne.n	70002f38 <memcpy+0x98>
70002f44:	1c6c      	adds	r4, r5, #1
          len0 -= LITTLEBLOCKSIZE;
70002f46:	f002 0203 	and.w	r2, r2, #3
          *aligned_dst++ = *aligned_src++;
70002f4a:	eb03 0384 	add.w	r3, r3, r4, lsl #2
70002f4e:	eb01 0184 	add.w	r1, r1, r4, lsl #2
  while (len0--)
70002f52:	f102 3cff 	add.w	ip, r2, #4294967295	; 0xffffffff
70002f56:	f10c 0c01 	add.w	ip, ip, #1
70002f5a:	3b01      	subs	r3, #1
70002f5c:	448c      	add	ip, r1
70002f5e:	b12a      	cbz	r2, 70002f6c <memcpy+0xcc>
    *dst++ = *src++;
70002f60:	f811 2b01 	ldrb.w	r2, [r1], #1
70002f64:	f803 2f01 	strb.w	r2, [r3, #1]!
  while (len0--)
70002f68:	458c      	cmp	ip, r1
70002f6a:	d1f9      	bne.n	70002f60 <memcpy+0xc0>
}
70002f6c:	bdf0      	pop	{r4, r5, r6, r7, pc}
70002f6e:	bf00      	nop

70002f70 <memset>:
  unsigned long buffer;
  unsigned long *aligned_addr;
  unsigned int d = c & 0xff;	/* To avoid sign extension, copy C to an
				   unsigned variable.  */

  while (UNALIGNED (s))
70002f70:	0783      	lsls	r3, r0, #30
{
70002f72:	b530      	push	{r4, r5, lr}
  while (UNALIGNED (s))
70002f74:	d04a      	beq.n	7000300c <memset+0x9c>
    {
      if (n--)
70002f76:	1e54      	subs	r4, r2, #1
70002f78:	2a00      	cmp	r2, #0
70002f7a:	d041      	beq.n	70003000 <memset+0x90>
  char *s = (char *) m;
70002f7c:	4603      	mov	r3, r0
        *s++ = (char) c;
70002f7e:	b2ca      	uxtb	r2, r1
70002f80:	e001      	b.n	70002f86 <memset+0x16>
      if (n--)
70002f82:	3c01      	subs	r4, #1
70002f84:	d33c      	bcc.n	70003000 <memset+0x90>
        *s++ = (char) c;
70002f86:	f803 2b01 	strb.w	r2, [r3], #1
  while (UNALIGNED (s))
70002f8a:	079d      	lsls	r5, r3, #30
70002f8c:	d1f9      	bne.n	70002f82 <memset+0x12>
      else
        return m;
    }

  if (!TOO_SMALL (n))
70002f8e:	2c03      	cmp	r4, #3
70002f90:	d92f      	bls.n	70002ff2 <memset+0x82>
  unsigned int d = c & 0xff;	/* To avoid sign extension, copy C to an
70002f92:	b2cd      	uxtb	r5, r1
      buffer |= (buffer << 16);
      for (i = 32; i < LBLOCKSIZE * 8; i <<= 1)
        buffer = (buffer << i) | buffer;

      /* Unroll the loop.  */
      while (n >= LBLOCKSIZE*4)
70002f94:	2c0f      	cmp	r4, #15
70002f96:	eb05 2505 	add.w	r5, r5, r5, lsl #8
70002f9a:	eb05 4505 	add.w	r5, r5, r5, lsl #16
70002f9e:	d938      	bls.n	70003012 <memset+0xa2>
70002fa0:	f1a4 0210 	sub.w	r2, r4, #16
70002fa4:	f022 0c0f 	bic.w	ip, r2, #15
70002fa8:	f103 0e10 	add.w	lr, r3, #16
70002fac:	44e6      	add	lr, ip
70002fae:	ea4f 1c12 	mov.w	ip, r2, lsr #4
70002fb2:	461a      	mov	r2, r3
        {
          *aligned_addr++ = buffer;
70002fb4:	6015      	str	r5, [r2, #0]
      while (n >= LBLOCKSIZE*4)
70002fb6:	3210      	adds	r2, #16
          *aligned_addr++ = buffer;
70002fb8:	f842 5c0c 	str.w	r5, [r2, #-12]
70002fbc:	f842 5c08 	str.w	r5, [r2, #-8]
70002fc0:	f842 5c04 	str.w	r5, [r2, #-4]
      while (n >= LBLOCKSIZE*4)
70002fc4:	4572      	cmp	r2, lr
70002fc6:	d1f5      	bne.n	70002fb4 <memset+0x44>
          *aligned_addr++ = buffer;
          *aligned_addr++ = buffer;
          *aligned_addr++ = buffer;
70002fc8:	f10c 0201 	add.w	r2, ip, #1
          n -= 4*LBLOCKSIZE;
        }

      while (n >= LBLOCKSIZE)
70002fcc:	f014 0f0c 	tst.w	r4, #12
          *aligned_addr++ = buffer;
70002fd0:	eb03 1202 	add.w	r2, r3, r2, lsl #4
          n -= 4*LBLOCKSIZE;
70002fd4:	f004 0c0f 	and.w	ip, r4, #15
      while (n >= LBLOCKSIZE)
70002fd8:	d013      	beq.n	70003002 <memset+0x92>
70002fda:	f1ac 0304 	sub.w	r3, ip, #4
70002fde:	f023 0303 	bic.w	r3, r3, #3
70002fe2:	3304      	adds	r3, #4
70002fe4:	4413      	add	r3, r2
        {
          *aligned_addr++ = buffer;
70002fe6:	f842 5b04 	str.w	r5, [r2], #4
      while (n >= LBLOCKSIZE)
70002fea:	429a      	cmp	r2, r3
70002fec:	d1fb      	bne.n	70002fe6 <memset+0x76>
          n -= LBLOCKSIZE;
70002fee:	f00c 0403 	and.w	r4, ip, #3
      s = (char*)aligned_addr;
    }

#endif /* not PREFER_SIZE_OVER_SPEED */

  while (n--)
70002ff2:	b12c      	cbz	r4, 70003000 <memset+0x90>
        *s++ = (char) c;
70002ff4:	b2c9      	uxtb	r1, r1
70002ff6:	441c      	add	r4, r3
    *s++ = (char) c;
70002ff8:	f803 1b01 	strb.w	r1, [r3], #1
  while (n--)
70002ffc:	429c      	cmp	r4, r3
70002ffe:	d1fb      	bne.n	70002ff8 <memset+0x88>

  return m;
}
70003000:	bd30      	pop	{r4, r5, pc}
          n -= 4*LBLOCKSIZE;
70003002:	4664      	mov	r4, ip
          *aligned_addr++ = buffer;
70003004:	4613      	mov	r3, r2
  while (n--)
70003006:	2c00      	cmp	r4, #0
70003008:	d1f4      	bne.n	70002ff4 <memset+0x84>
7000300a:	e7f9      	b.n	70003000 <memset+0x90>
  char *s = (char *) m;
7000300c:	4603      	mov	r3, r0
  while (UNALIGNED (s))
7000300e:	4614      	mov	r4, r2
70003010:	e7bd      	b.n	70002f8e <memset+0x1e>
      while (n >= LBLOCKSIZE*4)
70003012:	461a      	mov	r2, r3
70003014:	46a4      	mov	ip, r4
70003016:	e7e0      	b.n	70002fda <memset+0x6a>

70003018 <strnlen>:
strnlen (const char *str,
	size_t n)
{
  const char *start = str;

  while (n-- > 0 && *str)
70003018:	4603      	mov	r3, r0
7000301a:	eb00 0c01 	add.w	ip, r0, r1
7000301e:	b911      	cbnz	r1, 70003026 <strnlen+0xe>
70003020:	e00a      	b.n	70003038 <strnlen+0x20>
70003022:	4563      	cmp	r3, ip
70003024:	d006      	beq.n	70003034 <strnlen+0x1c>
    str++;
70003026:	461a      	mov	r2, r3
70003028:	3301      	adds	r3, #1
  while (n-- > 0 && *str)
7000302a:	7811      	ldrb	r1, [r2, #0]
7000302c:	2900      	cmp	r1, #0
7000302e:	d1f8      	bne.n	70003022 <strnlen+0xa>

  return str - start;
70003030:	1a10      	subs	r0, r2, r0
}
70003032:	4770      	bx	lr
  return str - start;
70003034:	1a18      	subs	r0, r3, r0
70003036:	4770      	bx	lr
  while (n-- > 0 && *str)
70003038:	4608      	mov	r0, r1
7000303a:	4770      	bx	lr

7000303c <__ultoa_invert>:
#endif
#endif

static __noinline char *
__ultoa_invert(ultoa_unsigned_t val, char *str, int base)
{
7000303c:	b570      	push	{r4, r5, r6, lr}
7000303e:	4684      	mov	ip, r0
	char hex = ('a' - '0' - 10 + 16) - base;
70003040:	f1c3 0437 	rsb	r4, r3, #55	; 0x37
{
70003044:	4610      	mov	r0, r2
	char hex = ('a' - '0' - 10 + 16) - base;
70003046:	b2e2      	uxtb	r2, r4

        base &= 31;
70003048:	f003 041f 	and.w	r4, r3, #31
    switch(base) {
7000304c:	2c08      	cmp	r4, #8
        *dig = val & 1;
7000304e:	fa5f fe8c 	uxtb.w	lr, ip
    switch(base) {
70003052:	d042      	beq.n	700030da <__ultoa_invert+0x9e>
70003054:	2c10      	cmp	r4, #16
	q = (n >> 1) + (n >> 2);
70003056:	ea4f 035c 	mov.w	r3, ip, lsr #1
7000305a:	ea4f 069c 	mov.w	r6, ip, lsr #2
7000305e:	ea43 73c1 	orr.w	r3, r3, r1, lsl #31
70003062:	ea46 7681 	orr.w	r6, r6, r1, lsl #30
70003066:	ea4f 0591 	mov.w	r5, r1, lsr #2
    switch(base) {
7000306a:	d04c      	beq.n	70003106 <__ultoa_invert+0xca>
7000306c:	2c02      	cmp	r4, #2
7000306e:	d042      	beq.n	700030f6 <__ultoa_invert+0xba>
	q = (n >> 1) + (n >> 2);
70003070:	199b      	adds	r3, r3, r6
70003072:	eb45 0551 	adc.w	r5, r5, r1, lsr #1
	q = q + (q >> 4);
70003076:	0919      	lsrs	r1, r3, #4
70003078:	ea41 7105 	orr.w	r1, r1, r5, lsl #28
7000307c:	185b      	adds	r3, r3, r1
7000307e:	eb45 1515 	adc.w	r5, r5, r5, lsr #4
	q = q + (q >> 8);
70003082:	0a19      	lsrs	r1, r3, #8
70003084:	ea41 6105 	orr.w	r1, r1, r5, lsl #24
70003088:	185b      	adds	r3, r3, r1
7000308a:	eb45 2515 	adc.w	r5, r5, r5, lsr #8
	q = q + (q >> 16);
7000308e:	0c19      	lsrs	r1, r3, #16
70003090:	ea41 4105 	orr.w	r1, r1, r5, lsl #16
70003094:	185b      	adds	r3, r3, r1
70003096:	eb45 4515 	adc.w	r5, r5, r5, lsr #16
        q = q + (q >> 32);
7000309a:	195b      	adds	r3, r3, r5
7000309c:	f145 0500 	adc.w	r5, r5, #0
	q = q >> 3;
700030a0:	ea4f 0cd3 	mov.w	ip, r3, lsr #3
700030a4:	ea4c 7c45 	orr.w	ip, ip, r5, lsl #29
700030a8:	08e9      	lsrs	r1, r5, #3
	r = (char) (n - (((q << 2) + q) << 1));
700030aa:	eb0c 038c 	add.w	r3, ip, ip, lsl #2
700030ae:	ebae 0343 	sub.w	r3, lr, r3, lsl #1
700030b2:	b2db      	uxtb	r3, r3
            r -= 10;
700030b4:	f1a3 050a 	sub.w	r5, r3, #10
        if (r > 9) {
700030b8:	2b09      	cmp	r3, #9
            r -= 10;
700030ba:	b2ed      	uxtb	r5, r5
        if (r > 9) {
700030bc:	d914      	bls.n	700030e8 <__ultoa_invert+0xac>
            q++;
700030be:	f11c 0c01 	adds.w	ip, ip, #1
700030c2:	f141 0100 	adc.w	r1, r1, #0
                val = udivmod(val, base, &v);
#else
                v = val % base;
                val /= base;
#endif
		if (v > 9)
700030c6:	2d09      	cmp	r5, #9
700030c8:	d92a      	bls.n	70003120 <__ultoa_invert+0xe4>
                        v += hex;
700030ca:	4415      	add	r5, r2
                v += '0';
700030cc:	3530      	adds	r5, #48	; 0x30
    switch(base) {
700030ce:	2c08      	cmp	r4, #8
		*str++ = v;
700030d0:	f800 5b01 	strb.w	r5, [r0], #1
        *dig = val & 1;
700030d4:	fa5f fe8c 	uxtb.w	lr, ip
    switch(base) {
700030d8:	d1bc      	bne.n	70003054 <__ultoa_invert+0x18>
        return val >> 3;
700030da:	ea4f 0cdc 	mov.w	ip, ip, lsr #3
700030de:	ea4c 7c41 	orr.w	ip, ip, r1, lsl #29
        *dig = val & 7;
700030e2:	f00e 0307 	and.w	r3, lr, #7
        return val >> 3;
700030e6:	08c9      	lsrs	r1, r1, #3
                v += '0';
700030e8:	3330      	adds	r3, #48	; 0x30
		*str++ = v;
700030ea:	f800 3b01 	strb.w	r3, [r0], #1
	} while (val);
700030ee:	ea5c 0301 	orrs.w	r3, ip, r1
700030f2:	d1ab      	bne.n	7000304c <__ultoa_invert+0x10>
	return str;
}
700030f4:	bd70      	pop	{r4, r5, r6, pc}
        return val >> 1;
700030f6:	ea4f 0c5c 	mov.w	ip, ip, lsr #1
700030fa:	ea4c 7cc1 	orr.w	ip, ip, r1, lsl #31
        *dig = val & 1;
700030fe:	f00e 0301 	and.w	r3, lr, #1
        return val >> 1;
70003102:	0849      	lsrs	r1, r1, #1
		if (v > 9)
70003104:	e7f0      	b.n	700030e8 <__ultoa_invert+0xac>
        *dig = val & 15;
70003106:	f00e 030f 	and.w	r3, lr, #15
		if (v > 9)
7000310a:	2b09      	cmp	r3, #9
                        v += hex;
7000310c:	bf88      	it	hi
7000310e:	189b      	addhi	r3, r3, r2
        return val >> 4;
70003110:	ea4f 1c1c 	mov.w	ip, ip, lsr #4
70003114:	ea4c 7c01 	orr.w	ip, ip, r1, lsl #28
                        v += hex;
70003118:	bf88      	it	hi
7000311a:	b2db      	uxtbhi	r3, r3
        return val >> 4;
7000311c:	0909      	lsrs	r1, r1, #4
		if (v > 9)
7000311e:	e7e3      	b.n	700030e8 <__ultoa_invert+0xac>
                v += '0';
70003120:	3326      	adds	r3, #38	; 0x26
        *dig = val & 1;
70003122:	fa5f fe8c 	uxtb.w	lr, ip
		*str++ = v;
70003126:	f800 3b01 	strb.w	r3, [r0], #1
    switch(base) {
7000312a:	e793      	b.n	70003054 <__ultoa_invert+0x18>

7000312c <skip_to_arg>:
 * and types to slowly walk the argument vector until it points at the
 * target_argno so that the outer printf code can then extract it.
 */
static void
skip_to_arg(const CHAR *fmt_orig, my_va_list *ap, int target_argno)
{
7000312c:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
    unsigned c;		/* holds a char from the format string */
    uint16_t flags;
    int current_argno = 1;
70003130:	f04f 0e01 	mov.w	lr, #1
70003134:	4603      	mov	r3, r0
    int argno;
    int width;
    const CHAR *fmt = fmt_orig;

    while (current_argno < target_argno) {
70003136:	4572      	cmp	r2, lr
70003138:	dc02      	bgt.n	70003140 <skip_to_arg+0x14>
7000313a:	e006      	b.n	7000314a <skip_to_arg+0x1e>
        for (;;) {
            c = *fmt++;
            if (!c) return;
            if (c == '%') {
7000313c:	2c25      	cmp	r4, #37	; 0x25
7000313e:	d006      	beq.n	7000314e <skip_to_arg+0x22>
70003140:	469c      	mov	ip, r3
            c = *fmt++;
70003142:	f813 4b01 	ldrb.w	r4, [r3], #1
            if (!c) return;
70003146:	2c00      	cmp	r4, #0
70003148:	d1f8      	bne.n	7000313c <skip_to_arg+0x10>
            }
            ++current_argno;
            fmt = fmt_orig;
        }
    }
}
7000314a:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
                c = *fmt++;
7000314e:	781c      	ldrb	r4, [r3, #0]
                if (c != '%') break;
70003150:	2c25      	cmp	r4, #37	; 0x25
                c = *fmt++;
70003152:	f10c 0c02 	add.w	ip, ip, #2
70003156:	4663      	mov	r3, ip
                if (c != '%') break;
70003158:	d0f2      	beq.n	70003140 <skip_to_arg+0x14>
        width = 0;
7000315a:	2600      	movs	r6, #0
		switch (c) {
7000315c:	f642 0789 	movw	r7, #10377	; 0x2889
        argno = 0;
70003160:	46b0      	mov	r8, r6
		switch (c) {
70003162:	f2c0 0701 	movt	r7, #1
        flags = 0;
70003166:	4633      	mov	r3, r6
	    if (flags < FL_WIDTH) {
70003168:	2b1f      	cmp	r3, #31
7000316a:	d847      	bhi.n	700031fc <skip_to_arg+0xd0>
		switch (c) {
7000316c:	f1a4 0520 	sub.w	r5, r4, #32
70003170:	2d10      	cmp	r5, #16
70003172:	d856      	bhi.n	70003222 <skip_to_arg+0xf6>
70003174:	fa27 f505 	lsr.w	r5, r7, r5
70003178:	07ed      	lsls	r5, r5, #31
7000317a:	d434      	bmi.n	700031e6 <skip_to_arg+0xba>
		if (c >= '0' && c <= '9') {
7000317c:	f1a4 0530 	sub.w	r5, r4, #48	; 0x30
70003180:	2d09      	cmp	r5, #9
70003182:	d952      	bls.n	7000322a <skip_to_arg+0xfe>
                if (c == '$') {
70003184:	2c24      	cmp	r4, #36	; 0x24
70003186:	d10a      	bne.n	7000319e <skip_to_arg+0x72>
                    if (argno) {
70003188:	f1b8 0f00 	cmp.w	r8, #0
7000318c:	d053      	beq.n	70003236 <skip_to_arg+0x10a>
                        if (width == current_argno) {
7000318e:	4576      	cmp	r6, lr
70003190:	d137      	bne.n	70003202 <skip_to_arg+0xd6>
                SKIP_FLOAT_ARG(flags, ap->ap);
70003192:	680d      	ldr	r5, [r1, #0]
                arg_to_unsigned(ap->ap, flags, x);
70003194:	3504      	adds	r5, #4
                SKIP_FLOAT_ARG(flags, ap->ap);
70003196:	600d      	str	r5, [r1, #0]
            ++current_argno;
70003198:	f10e 0e01 	add.w	lr, lr, #1
            fmt = fmt_orig;
7000319c:	e7ca      	b.n	70003134 <skip_to_arg+0x8>
		if (c == '*') {
7000319e:	f024 0504 	bic.w	r5, r4, #4
		if (c == '.') {
700031a2:	2d2a      	cmp	r5, #42	; 0x2a
700031a4:	d02d      	beq.n	70003202 <skip_to_arg+0xd6>
            CHECK_INT_SIZES(c, flags);
700031a6:	f1a4 054c 	sub.w	r5, r4, #76	; 0x4c
700031aa:	2d2e      	cmp	r5, #46	; 0x2e
700031ac:	d81f      	bhi.n	700031ee <skip_to_arg+0xc2>
700031ae:	e8df f005 	tbb	[pc, r5]
700031b2:	1e18      	.short	0x1e18
700031b4:	1e1e1e1e 	.word	0x1e1e1e1e
700031b8:	1e1e1e1e 	.word	0x1e1e1e1e
700031bc:	1e1e1e1e 	.word	0x1e1e1e1e
700031c0:	1e1e1e1e 	.word	0x1e1e1e1e
700031c4:	1e1e1e1e 	.word	0x1e1e1e1e
700031c8:	1e1e1e1e 	.word	0x1e1e1e1e
700031cc:	1e2a1e1e 	.word	0x1e2a1e1e
700031d0:	1e311e18 	.word	0x1e311e18
700031d4:	1e1e1e1e 	.word	0x1e1e1e1e
700031d8:	1e1a1e1e 	.word	0x1e1a1e1e
700031dc:	1e1e1e1e 	.word	0x1e1e1e1e
700031e0:	1a          	.byte	0x1a
700031e1:	00          	.byte	0x00
700031e2:	f443 7320 	orr.w	r3, r3, #640	; 0x280
	} while ( (c = *fmt++) != 0);
700031e6:	f81c 4b01 	ldrb.w	r4, [ip], #1
700031ea:	2c00      	cmp	r4, #0
700031ec:	d1bc      	bne.n	70003168 <skip_to_arg+0x3c>
        if (argno == 0)
700031ee:	f1b8 0f00 	cmp.w	r8, #0
700031f2:	d0aa      	beq.n	7000314a <skip_to_arg+0x1e>
        if (argno == current_argno) {
700031f4:	45f0      	cmp	r8, lr
700031f6:	d021      	beq.n	7000323c <skip_to_arg+0x110>
700031f8:	4663      	mov	r3, ip
700031fa:	e79c      	b.n	70003136 <skip_to_arg+0xa>
	    if (flags < FL_LONG) {
700031fc:	2b7f      	cmp	r3, #127	; 0x7f
700031fe:	d8d2      	bhi.n	700031a6 <skip_to_arg+0x7a>
70003200:	e7bc      	b.n	7000317c <skip_to_arg+0x50>
                    width = 0;
70003202:	2600      	movs	r6, #0
70003204:	e7ef      	b.n	700031e6 <skip_to_arg+0xba>
            CHECK_INT_SIZES(c, flags);
70003206:	05dd      	lsls	r5, r3, #23
70003208:	bf48      	it	mi
7000320a:	f443 7300 	orrmi.w	r3, r3, #512	; 0x200
7000320e:	f443 7380 	orr.w	r3, r3, #256	; 0x100
70003212:	e7e8      	b.n	700031e6 <skip_to_arg+0xba>
70003214:	061c      	lsls	r4, r3, #24
70003216:	bf48      	it	mi
70003218:	f443 7300 	orrmi.w	r3, r3, #512	; 0x200
7000321c:	f043 0380 	orr.w	r3, r3, #128	; 0x80
70003220:	e7e1      	b.n	700031e6 <skip_to_arg+0xba>
		if (c >= '0' && c <= '9') {
70003222:	f1a4 0530 	sub.w	r5, r4, #48	; 0x30
70003226:	2d09      	cmp	r5, #9
70003228:	d8b9      	bhi.n	7000319e <skip_to_arg+0x72>
                    flags |= FL_WIDTH;
7000322a:	2320      	movs	r3, #32
                    width = 10 * width + c;
7000322c:	eb06 0686 	add.w	r6, r6, r6, lsl #2
70003230:	eb05 0646 	add.w	r6, r5, r6, lsl #1
		    continue;
70003234:	e7d7      	b.n	700031e6 <skip_to_arg+0xba>
70003236:	46b0      	mov	r8, r6
                    width = 0;
70003238:	2600      	movs	r6, #0
7000323a:	e7d4      	b.n	700031e6 <skip_to_arg+0xba>
                SKIP_FLOAT_ARG(flags, ap->ap);
7000323c:	680d      	ldr	r5, [r1, #0]
            if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
7000323e:	f044 0620 	orr.w	r6, r4, #32
                || TOLOWER(c) == 'a'
70003242:	f1a6 0765 	sub.w	r7, r6, #101	; 0x65
            if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
70003246:	2e61      	cmp	r6, #97	; 0x61
70003248:	bf18      	it	ne
7000324a:	2f02      	cmpne	r7, #2
7000324c:	d92e      	bls.n	700032ac <skip_to_arg+0x180>
            } else if (c == 'c') {
7000324e:	3c63      	subs	r4, #99	; 0x63
70003250:	2c10      	cmp	r4, #16
70003252:	d825      	bhi.n	700032a0 <skip_to_arg+0x174>
70003254:	a601      	add	r6, pc, #4	; (adr r6, 7000325c <skip_to_arg+0x130>)
70003256:	f856 f024 	ldr.w	pc, [r6, r4, lsl #2]
7000325a:	bf00      	nop
7000325c:	70003195 	.word	0x70003195
70003260:	700032a1 	.word	0x700032a1
70003264:	700032a1 	.word	0x700032a1
70003268:	700032a1 	.word	0x700032a1
7000326c:	700032a1 	.word	0x700032a1
70003270:	700032a1 	.word	0x700032a1
70003274:	700032a1 	.word	0x700032a1
70003278:	700032a1 	.word	0x700032a1
7000327c:	700032a1 	.word	0x700032a1
70003280:	700032a1 	.word	0x700032a1
70003284:	700032a1 	.word	0x700032a1
70003288:	700032a1 	.word	0x700032a1
7000328c:	700032a1 	.word	0x700032a1
70003290:	700032a1 	.word	0x700032a1
70003294:	700032a1 	.word	0x700032a1
70003298:	700032a1 	.word	0x700032a1
7000329c:	70003195 	.word	0x70003195
                arg_to_unsigned(ap->ap, flags, x);
700032a0:	061c      	lsls	r4, r3, #24
700032a2:	f57f af77 	bpl.w	70003194 <skip_to_arg+0x68>
700032a6:	059b      	lsls	r3, r3, #22
700032a8:	f57f af74 	bpl.w	70003194 <skip_to_arg+0x68>
700032ac:	3507      	adds	r5, #7
700032ae:	f025 0507 	bic.w	r5, r5, #7
700032b2:	3508      	adds	r5, #8
700032b4:	e76f      	b.n	70003196 <skip_to_arg+0x6a>
700032b6:	bf00      	nop

700032b8 <__l_vfprintf>:
    return len;
}
#endif

int vfprintf (FILE * stream, const CHAR *fmt, va_list ap_orig)
{
700032b8:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    int (*put)(char, FILE *) = stream->put;
#define my_putc(c, stream) do { ++stream_len; if (put(c, stream) < 0) goto fail; } while(0)
#endif
#endif

    if ((stream->flags & __SWR) == 0)
700032bc:	7883      	ldrb	r3, [r0, #2]
    int (*put)(char, FILE *) = stream->put;
700032be:	f8d0 b004 	ldr.w	fp, [r0, #4]
    if ((stream->flags & __SWR) == 0)
700032c2:	079e      	lsls	r6, r3, #30
{
700032c4:	b09b      	sub	sp, #108	; 0x6c
    if ((stream->flags & __SWR) == 0)
700032c6:	f140 836c 	bpl.w	700039a2 <__l_vfprintf+0x6ea>
700032ca:	4607      	mov	r7, r0
#endif

    for (;;) {

	for (;;) {
	    c = *fmt++;
700032cc:	460b      	mov	r3, r1
    va_copy(ap, ap_orig);
700032ce:	9209      	str	r2, [sp, #36]	; 0x24
	    c = *fmt++;
700032d0:	4696      	mov	lr, r2
700032d2:	f813 0b01 	ldrb.w	r0, [r3], #1
	    if (!c) goto ret;
700032d6:	2800      	cmp	r0, #0
700032d8:	f000 835a 	beq.w	70003990 <__l_vfprintf+0x6d8>
700032dc:	460d      	mov	r5, r1
    int stream_len = 0;
700032de:	2400      	movs	r4, #0
700032e0:	e9cd 1203 	strd	r1, r2, [sp, #12]
700032e4:	e00a      	b.n	700032fc <__l_vfprintf+0x44>
	    if (c == '%') {
		c = *fmt++;
		if (c != '%') break;
	    }
	    my_putc (c, stream);
700032e6:	4639      	mov	r1, r7
700032e8:	b2c0      	uxtb	r0, r0
700032ea:	461d      	mov	r5, r3
700032ec:	47d8      	blx	fp
700032ee:	3401      	adds	r4, #1
700032f0:	2800      	cmp	r0, #0
700032f2:	db10      	blt.n	70003316 <__l_vfprintf+0x5e>
	    c = *fmt++;
700032f4:	462b      	mov	r3, r5
700032f6:	f813 0b01 	ldrb.w	r0, [r3], #1
	    if (!c) goto ret;
700032fa:	b190      	cbz	r0, 70003322 <__l_vfprintf+0x6a>
	    if (c == '%') {
700032fc:	2825      	cmp	r0, #37	; 0x25
700032fe:	d1f2      	bne.n	700032e6 <__l_vfprintf+0x2e>
		c = *fmt++;
70003300:	f105 0802 	add.w	r8, r5, #2
70003304:	786d      	ldrb	r5, [r5, #1]
		if (c != '%') break;
70003306:	2d25      	cmp	r5, #37	; 0x25
70003308:	d10f      	bne.n	7000332a <__l_vfprintf+0x72>
	    my_putc (c, stream);
7000330a:	4639      	mov	r1, r7
		c = *fmt++;
7000330c:	4645      	mov	r5, r8
	    my_putc (c, stream);
7000330e:	47d8      	blx	fp
70003310:	3401      	adds	r4, #1
70003312:	2800      	cmp	r0, #0
70003314:	daee      	bge.n	700032f4 <__l_vfprintf+0x3c>
#endif
    return stream_len;
#undef my_putc
#undef ap
  fail:
    stream->flags |= __SERR;
70003316:	78bb      	ldrb	r3, [r7, #2]
    stream_len = -1;
70003318:	f04f 34ff 	mov.w	r4, #4294967295	; 0xffffffff
    stream->flags |= __SERR;
7000331c:	f043 0304 	orr.w	r3, r3, #4
70003320:	70bb      	strb	r3, [r7, #2]
    goto ret;
}
70003322:	4620      	mov	r0, r4
70003324:	b01b      	add	sp, #108	; 0x6c
70003326:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
        argno = 0;
7000332a:	f04f 0a00 	mov.w	sl, #0
	width = 0;
7000332e:	46d1      	mov	r9, sl
	flags = 0;
70003330:	4656      	mov	r6, sl
	prec = 0;
70003332:	f8cd a004 	str.w	sl, [sp, #4]
	    if (flags < FL_WIDTH) {
70003336:	2e1f      	cmp	r6, #31
70003338:	d857      	bhi.n	700033ea <__l_vfprintf+0x132>
		switch (c) {
7000333a:	f1a5 0320 	sub.w	r3, r5, #32
7000333e:	2b10      	cmp	r3, #16
70003340:	d80a      	bhi.n	70003358 <__l_vfprintf+0xa0>
70003342:	e8df f003 	tbb	[pc, r3]
70003346:	0946      	.short	0x0946
70003348:	09094909 	.word	0x09094909
7000334c:	09091409 	.word	0x09091409
70003350:	4f094409 	.word	0x4f094409
70003354:	0909      	.short	0x0909
70003356:	4c          	.byte	0x4c
70003357:	00          	.byte	0x00
		if (c >= '0' && c <= '9') {
70003358:	f1a5 0330 	sub.w	r3, r5, #48	; 0x30
7000335c:	2b09      	cmp	r3, #9
7000335e:	f200 80b0 	bhi.w	700034c2 <__l_vfprintf+0x20a>
		    width = 10*width + c;
70003362:	eb09 0989 	add.w	r9, r9, r9, lsl #2
		    flags |= FL_WIDTH;
70003366:	f046 0620 	orr.w	r6, r6, #32
		    width = 10*width + c;
7000336a:	eb03 0949 	add.w	r9, r3, r9, lsl #1
	} while ( (c = *fmt++) != 0);
7000336e:	f818 5b01 	ldrb.w	r5, [r8], #1
70003372:	2d00      	cmp	r5, #0
70003374:	d1df      	bne.n	70003336 <__l_vfprintf+0x7e>
        if (argno) {
70003376:	9502      	str	r5, [sp, #8]
70003378:	2320      	movs	r3, #32
7000337a:	f1ba 0f00 	cmp.w	sl, #0
7000337e:	f040 80c9 	bne.w	70003514 <__l_vfprintf+0x25c>
	if (prec < 0) {
70003382:	9a01      	ldr	r2, [sp, #4]
70003384:	2a00      	cmp	r2, #0
	    prec = 0;
70003386:	bfbf      	itttt	lt
70003388:	2200      	movlt	r2, #0
	    flags &= ~FL_PREC;
7000338a:	f026 0640 	biclt.w	r6, r6, #64	; 0x40
	    prec = 0;
7000338e:	9201      	strlt	r2, [sp, #4]
	    flags &= ~FL_PREC;
70003390:	b2b6      	uxthlt	r6, r6
	if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
70003392:	9a02      	ldr	r2, [sp, #8]
70003394:	2a00      	cmp	r2, #0
70003396:	f040 80f1 	bne.w	7000357c <__l_vfprintf+0x2c4>
            if (c == 'c') {
7000339a:	f1a5 0263 	sub.w	r2, r5, #99	; 0x63
7000339e:	2a12      	cmp	r2, #18
700033a0:	f200 8141 	bhi.w	70003626 <__l_vfprintf+0x36e>
700033a4:	e8df f012 	tbh	[pc, r2, lsl #1]
700033a8:	0158018e 	.word	0x0158018e
700033ac:	013f013f 	.word	0x013f013f
700033b0:	013f013f 	.word	0x013f013f
700033b4:	013f0158 	.word	0x013f0158
700033b8:	013f013f 	.word	0x013f013f
700033bc:	013f013f 	.word	0x013f013f
700033c0:	019802cb 	.word	0x019802cb
700033c4:	013f013f 	.word	0x013f013f
700033c8:	013f01e5 	.word	0x013f01e5
700033cc:	01e0      	.short	0x01e0
		    flags |= FL_PLUS;
700033ce:	f046 0602 	orr.w	r6, r6, #2
		    flags |= FL_SPACE;
700033d2:	f046 0604 	orr.w	r6, r6, #4
		    continue;
700033d6:	e7ca      	b.n	7000336e <__l_vfprintf+0xb6>
		    flags |= FL_ALT;
700033d8:	f046 0610 	orr.w	r6, r6, #16
		    continue;
700033dc:	e7c7      	b.n	7000336e <__l_vfprintf+0xb6>
		    flags |= FL_ZFILL;
700033de:	f046 0601 	orr.w	r6, r6, #1
		    continue;
700033e2:	e7c4      	b.n	7000336e <__l_vfprintf+0xb6>
		    flags |= FL_LPAD;
700033e4:	f046 0608 	orr.w	r6, r6, #8
		    continue;
700033e8:	e7c1      	b.n	7000336e <__l_vfprintf+0xb6>
	    if (flags < FL_LONG) {
700033ea:	2e7f      	cmp	r6, #127	; 0x7f
700033ec:	f240 82eb 	bls.w	700039c6 <__l_vfprintf+0x70e>
            CHECK_INT_SIZES(c, flags);
700033f0:	f1a5 034c 	sub.w	r3, r5, #76	; 0x4c
700033f4:	2b2e      	cmp	r3, #46	; 0x2e
700033f6:	d87e      	bhi.n	700034f6 <__l_vfprintf+0x23e>
700033f8:	a201      	add	r2, pc, #4	; (adr r2, 70003400 <__l_vfprintf+0x148>)
700033fa:	f852 f023 	ldr.w	pc, [r2, r3, lsl #2]
700033fe:	bf00      	nop
70003400:	700034bd 	.word	0x700034bd
70003404:	700034f7 	.word	0x700034f7
70003408:	700034f7 	.word	0x700034f7
7000340c:	700034f7 	.word	0x700034f7
70003410:	700034f7 	.word	0x700034f7
70003414:	700034f7 	.word	0x700034f7
70003418:	700034f7 	.word	0x700034f7
7000341c:	700034f7 	.word	0x700034f7
70003420:	700034f7 	.word	0x700034f7
70003424:	700034f7 	.word	0x700034f7
70003428:	700034f7 	.word	0x700034f7
7000342c:	700034f7 	.word	0x700034f7
70003430:	700034f7 	.word	0x700034f7
70003434:	700034f7 	.word	0x700034f7
70003438:	700034f7 	.word	0x700034f7
7000343c:	700034f7 	.word	0x700034f7
70003440:	700034f7 	.word	0x700034f7
70003444:	700034f7 	.word	0x700034f7
70003448:	700034f7 	.word	0x700034f7
7000344c:	700034f7 	.word	0x700034f7
70003450:	700034f7 	.word	0x700034f7
70003454:	700034f7 	.word	0x700034f7
70003458:	700034f7 	.word	0x700034f7
7000345c:	700034f7 	.word	0x700034f7
70003460:	700034f7 	.word	0x700034f7
70003464:	700034f7 	.word	0x700034f7
70003468:	700034f7 	.word	0x700034f7
7000346c:	700034f7 	.word	0x700034f7
70003470:	70003537 	.word	0x70003537
70003474:	700034f7 	.word	0x700034f7
70003478:	700034bd 	.word	0x700034bd
7000347c:	700034f7 	.word	0x700034f7
70003480:	70003529 	.word	0x70003529
70003484:	700034f7 	.word	0x700034f7
70003488:	700034f7 	.word	0x700034f7
7000348c:	700034f7 	.word	0x700034f7
70003490:	700034f7 	.word	0x700034f7
70003494:	700034f7 	.word	0x700034f7
70003498:	700034f7 	.word	0x700034f7
7000349c:	700034f7 	.word	0x700034f7
700034a0:	7000336f 	.word	0x7000336f
700034a4:	700034f7 	.word	0x700034f7
700034a8:	700034f7 	.word	0x700034f7
700034ac:	700034f7 	.word	0x700034f7
700034b0:	700034f7 	.word	0x700034f7
700034b4:	700034f7 	.word	0x700034f7
700034b8:	7000336f 	.word	0x7000336f
700034bc:	f446 7620 	orr.w	r6, r6, #640	; 0x280
700034c0:	e755      	b.n	7000336e <__l_vfprintf+0xb6>
		if (c == '*') {
700034c2:	2d2a      	cmp	r5, #42	; 0x2a
700034c4:	d03e      	beq.n	70003544 <__l_vfprintf+0x28c>
		if (c == '.') {
700034c6:	2d2e      	cmp	r5, #46	; 0x2e
700034c8:	d052      	beq.n	70003570 <__l_vfprintf+0x2b8>
                if (c == '$') {
700034ca:	2d24      	cmp	r5, #36	; 0x24
700034cc:	d190      	bne.n	700033f0 <__l_vfprintf+0x138>
                    if (argno) {
700034ce:	f1ba 0f00 	cmp.w	sl, #0
700034d2:	f000 821c 	beq.w	7000390e <__l_vfprintf+0x656>
                        va_copy(ap, ap_orig);
700034d6:	9b04      	ldr	r3, [sp, #16]
                        skip_to_arg(fmt_orig, &my_ap, (flags & FL_PREC) ? prec : width);
700034d8:	0672      	lsls	r2, r6, #25
                        va_copy(ap, ap_orig);
700034da:	9309      	str	r3, [sp, #36]	; 0x24
                        skip_to_arg(fmt_orig, &my_ap, (flags & FL_PREC) ? prec : width);
700034dc:	f140 823d 	bpl.w	7000395a <__l_vfprintf+0x6a2>
700034e0:	9a01      	ldr	r2, [sp, #4]
700034e2:	a909      	add	r1, sp, #36	; 0x24
700034e4:	9803      	ldr	r0, [sp, #12]
700034e6:	f7ff fe21 	bl	7000312c <skip_to_arg>
                            prec = va_arg(ap, int);
700034ea:	9b09      	ldr	r3, [sp, #36]	; 0x24
700034ec:	1d1a      	adds	r2, r3, #4
700034ee:	9209      	str	r2, [sp, #36]	; 0x24
700034f0:	681b      	ldr	r3, [r3, #0]
700034f2:	9301      	str	r3, [sp, #4]
700034f4:	e73b      	b.n	7000336e <__l_vfprintf+0xb6>
	if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
700034f6:	f045 0320 	orr.w	r3, r5, #32
            || TOLOWER(c) == 'a'
700034fa:	f1a3 0265 	sub.w	r2, r3, #101	; 0x65
700034fe:	2b61      	cmp	r3, #97	; 0x61
70003500:	bf18      	it	ne
70003502:	2a02      	cmpne	r2, #2
70003504:	bf94      	ite	ls
70003506:	2201      	movls	r2, #1
70003508:	2200      	movhi	r2, #0
7000350a:	9202      	str	r2, [sp, #8]
        if (argno) {
7000350c:	f1ba 0f00 	cmp.w	sl, #0
70003510:	f43f af37 	beq.w	70003382 <__l_vfprintf+0xca>
            va_copy(ap, ap_orig);
70003514:	9305      	str	r3, [sp, #20]
            skip_to_arg(fmt_orig, &my_ap, argno);
70003516:	4652      	mov	r2, sl
            va_copy(ap, ap_orig);
70003518:	9b04      	ldr	r3, [sp, #16]
            skip_to_arg(fmt_orig, &my_ap, argno);
7000351a:	a909      	add	r1, sp, #36	; 0x24
7000351c:	9803      	ldr	r0, [sp, #12]
            va_copy(ap, ap_orig);
7000351e:	9309      	str	r3, [sp, #36]	; 0x24
            skip_to_arg(fmt_orig, &my_ap, argno);
70003520:	f7ff fe04 	bl	7000312c <skip_to_arg>
70003524:	9b05      	ldr	r3, [sp, #20]
70003526:	e72c      	b.n	70003382 <__l_vfprintf+0xca>
            CHECK_INT_SIZES(c, flags);
70003528:	0633      	lsls	r3, r6, #24
7000352a:	bf48      	it	mi
7000352c:	f446 7600 	orrmi.w	r6, r6, #512	; 0x200
70003530:	f046 0680 	orr.w	r6, r6, #128	; 0x80
70003534:	e71b      	b.n	7000336e <__l_vfprintf+0xb6>
70003536:	05f5      	lsls	r5, r6, #23
70003538:	bf48      	it	mi
7000353a:	f446 7600 	orrmi.w	r6, r6, #512	; 0x200
7000353e:	f446 7680 	orr.w	r6, r6, #256	; 0x100
70003542:	e714      	b.n	7000336e <__l_vfprintf+0xb6>
                    if (argno)
70003544:	f1ba 0f00 	cmp.w	sl, #0
70003548:	f47f af11 	bne.w	7000336e <__l_vfprintf+0xb6>
			prec = va_arg(ap, int);
7000354c:	9b09      	ldr	r3, [sp, #36]	; 0x24
		    if (flags & FL_PREC) {
7000354e:	0670      	lsls	r0, r6, #25
			prec = va_arg(ap, int);
70003550:	f103 0204 	add.w	r2, r3, #4
70003554:	9209      	str	r2, [sp, #36]	; 0x24
		    if (flags & FL_PREC) {
70003556:	d4cb      	bmi.n	700034f0 <__l_vfprintf+0x238>
			width = va_arg(ap, int);
70003558:	f8d3 9000 	ldr.w	r9, [r3]
			if (width < 0) {
7000355c:	f1b9 0f00 	cmp.w	r9, #0
			flags |= FL_WIDTH;
70003560:	bfae      	itee	ge
70003562:	f046 0620 	orrge.w	r6, r6, #32
			    width = -width;
70003566:	f1c9 0900 	rsblt	r9, r9, #0
			    flags |= FL_LPAD;
7000356a:	f046 0628 	orrlt.w	r6, r6, #40	; 0x28
7000356e:	e6fe      	b.n	7000336e <__l_vfprintf+0xb6>
		    if (flags & FL_PREC)
70003570:	0671      	lsls	r1, r6, #25
70003572:	f53f aed6 	bmi.w	70003322 <__l_vfprintf+0x6a>
		    flags |= FL_PREC;
70003576:	f046 0640 	orr.w	r6, r6, #64	; 0x40
		    continue;
7000357a:	e6f8      	b.n	7000336e <__l_vfprintf+0xb6>
            SKIP_FLOAT_ARG(flags, ap);
7000357c:	9b09      	ldr	r3, [sp, #36]	; 0x24
	    pnt = "*float*";
7000357e:	f644 52d0 	movw	r2, #19920	; 0x4dd0
	    size = sizeof ("*float*") - 1;
70003582:	f04f 0a07 	mov.w	sl, #7
	    pnt = "*float*";
70003586:	f2c7 0200 	movt	r2, #28672	; 0x7000
            SKIP_FLOAT_ARG(flags, ap);
7000358a:	3307      	adds	r3, #7
7000358c:	f023 0307 	bic.w	r3, r3, #7
70003590:	3308      	adds	r3, #8
70003592:	9309      	str	r3, [sp, #36]	; 0x24
                    while ((size_t) width > size) {
70003594:	4649      	mov	r1, r9
                if (!(flags & FL_LPAD)) {
70003596:	0730      	lsls	r0, r6, #28
70003598:	d419      	bmi.n	700035ce <__l_vfprintf+0x316>
                    while ((size_t) width > size) {
7000359a:	45ca      	cmp	sl, r9
7000359c:	bf3e      	ittt	cc
7000359e:	465d      	movcc	r5, fp
700035a0:	4616      	movcc	r6, r2
700035a2:	46cb      	movcc	fp, r9
700035a4:	d303      	bcc.n	700035ae <__l_vfprintf+0x2f6>
700035a6:	e012      	b.n	700035ce <__l_vfprintf+0x316>
700035a8:	459a      	cmp	sl, r3
700035aa:	d208      	bcs.n	700035be <__l_vfprintf+0x306>
                        width--;
700035ac:	4699      	mov	r9, r3
                        my_putc (' ', stream);
700035ae:	4639      	mov	r1, r7
700035b0:	2020      	movs	r0, #32
700035b2:	47a8      	blx	r5
                        width--;
700035b4:	f109 33ff 	add.w	r3, r9, #4294967295	; 0xffffffff
                        my_putc (' ', stream);
700035b8:	2800      	cmp	r0, #0
700035ba:	daf5      	bge.n	700035a8 <__l_vfprintf+0x2f0>
700035bc:	e6ab      	b.n	70003316 <__l_vfprintf+0x5e>
700035be:	4659      	mov	r1, fp
700035c0:	3401      	adds	r4, #1
700035c2:	4632      	mov	r2, r6
700035c4:	440c      	add	r4, r1
700035c6:	46ab      	mov	fp, r5
700035c8:	eba4 0409 	sub.w	r4, r4, r9
                    while ((size_t) width > size) {
700035cc:	4619      	mov	r1, r3
                    while (size--)
700035ce:	4623      	mov	r3, r4
700035d0:	465e      	mov	r6, fp
700035d2:	4614      	mov	r4, r2
700035d4:	eb02 050a 	add.w	r5, r2, sl
700035d8:	4693      	mov	fp, r2
700035da:	4699      	mov	r9, r3
700035dc:	9101      	str	r1, [sp, #4]
700035de:	e005      	b.n	700035ec <__l_vfprintf+0x334>
                        my_putc (*pnt++, stream);
700035e0:	f814 0b01 	ldrb.w	r0, [r4], #1
700035e4:	47b0      	blx	r6
700035e6:	2800      	cmp	r0, #0
700035e8:	f6ff ae95 	blt.w	70003316 <__l_vfprintf+0x5e>
700035ec:	4639      	mov	r1, r7
                    while (size--)
700035ee:	42ac      	cmp	r4, r5
700035f0:	d1f6      	bne.n	700035e0 <__l_vfprintf+0x328>
700035f2:	465a      	mov	r2, fp
700035f4:	464b      	mov	r3, r9
700035f6:	9901      	ldr	r1, [sp, #4]
700035f8:	46a1      	mov	r9, r4
700035fa:	46b3      	mov	fp, r6
700035fc:	1a9b      	subs	r3, r3, r2
                width -= size;
700035fe:	eba1 060a 	sub.w	r6, r1, sl
70003602:	4499      	add	r9, r3
                while (prec > buf_len) {
70003604:	464c      	mov	r4, r9
70003606:	444e      	add	r6, r9
70003608:	465d      	mov	r5, fp
7000360a:	e004      	b.n	70003616 <__l_vfprintf+0x35e>
	    my_putc (' ', stream);
7000360c:	47a8      	blx	r5
7000360e:	3401      	adds	r4, #1
70003610:	2800      	cmp	r0, #0
70003612:	f6ff ae80 	blt.w	70003316 <__l_vfprintf+0x5e>
70003616:	4639      	mov	r1, r7
70003618:	1b33      	subs	r3, r6, r4
7000361a:	2020      	movs	r0, #32
	while (width-- > 0) {
7000361c:	2b00      	cmp	r3, #0
7000361e:	dcf5      	bgt.n	7000360c <__l_vfprintf+0x354>
70003620:	46ab      	mov	fp, r5
70003622:	4645      	mov	r5, r8
70003624:	e666      	b.n	700032f4 <__l_vfprintf+0x3c>
                    } else if (TOLOWER(c) == 'x') {
70003626:	2b78      	cmp	r3, #120	; 0x78
                        base = ('x' - c) | 16;
70003628:	bf04      	itt	eq
7000362a:	f1c5 0378 	rsbeq	r3, r5, #120	; 0x78
7000362e:	f043 0310 	orreq.w	r3, r3, #16
                    } else if (TOLOWER(c) == 'x') {
70003632:	d055      	beq.n	700036e0 <__l_vfprintf+0x428>
                    } else if (TOLOWER(c) == 'b') {
70003634:	2b62      	cmp	r3, #98	; 0x62
70003636:	f000 81b2 	beq.w	7000399e <__l_vfprintf+0x6e6>
                        my_putc('%', stream);
7000363a:	4639      	mov	r1, r7
7000363c:	2025      	movs	r0, #37	; 0x25
7000363e:	47d8      	blx	fp
70003640:	2800      	cmp	r0, #0
70003642:	f6ff ae68 	blt.w	70003316 <__l_vfprintf+0x5e>
                        my_putc(c, stream);
70003646:	4628      	mov	r0, r5
70003648:	4639      	mov	r1, r7
7000364a:	47d8      	blx	fp
7000364c:	2800      	cmp	r0, #0
7000364e:	f6ff ae62 	blt.w	70003316 <__l_vfprintf+0x5e>
70003652:	4645      	mov	r5, r8
70003654:	3402      	adds	r4, #2
70003656:	e64d      	b.n	700032f4 <__l_vfprintf+0x3c>
            SKIP_FLOAT_ARG(flags, ap);
70003658:	9b09      	ldr	r3, [sp, #36]	; 0x24
                    arg_to_signed(ap, flags, x_s);
7000365a:	0632      	lsls	r2, r6, #24
7000365c:	f100 8172 	bmi.w	70003944 <__l_vfprintf+0x68c>
70003660:	1d1a      	adds	r2, r3, #4
70003662:	05f1      	lsls	r1, r6, #23
70003664:	9209      	str	r2, [sp, #36]	; 0x24
70003666:	681a      	ldr	r2, [r3, #0]
70003668:	bf5c      	itt	pl
7000366a:	4610      	movpl	r0, r2
7000366c:	17c2      	asrpl	r2, r0, #31
7000366e:	d507      	bpl.n	70003680 <__l_vfprintf+0x3c8>
70003670:	05b3      	lsls	r3, r6, #22
70003672:	bf4b      	itete	mi
70003674:	b250      	sxtbmi	r0, r2
70003676:	b210      	sxthpl	r0, r2
70003678:	f342 12c0 	sbfxmi	r2, r2, #7, #1
7000367c:	f342 32c0 	sbfxpl	r2, r2, #15, #1
                    if (x_s < 0) {
70003680:	f026 0110 	bic.w	r1, r6, #16
70003684:	2a00      	cmp	r2, #0
70003686:	fa1f fa81 	uxth.w	sl, r1
7000368a:	f2c0 8171 	blt.w	70003970 <__l_vfprintf+0x6b8>
                    if (x_s == 0 && (flags & FL_PREC) && prec == 0)
7000368e:	ea50 0102 	orrs.w	r1, r0, r2
70003692:	f040 8190 	bne.w	700039b6 <__l_vfprintf+0x6fe>
70003696:	9a01      	ldr	r2, [sp, #4]
70003698:	f3c6 1380 	ubfx	r3, r6, #6, #1
7000369c:	2a00      	cmp	r2, #0
7000369e:	bf14      	ite	ne
700036a0:	2300      	movne	r3, #0
700036a2:	f003 0301 	andeq.w	r3, r3, #1
700036a6:	f006 0240 	and.w	r2, r6, #64	; 0x40
700036aa:	9202      	str	r2, [sp, #8]
700036ac:	2b00      	cmp	r3, #0
700036ae:	f040 817b 	bne.w	700039a8 <__l_vfprintf+0x6f0>
700036b2:	4618      	mov	r0, r3
700036b4:	4619      	mov	r1, r3
                        buf_len = __ultoa_invert (x_s, buf, 10) - buf;
700036b6:	230a      	movs	r3, #10
700036b8:	ae0a      	add	r6, sp, #40	; 0x28
700036ba:	4632      	mov	r2, r6
700036bc:	f7ff fcbe 	bl	7000303c <__ultoa_invert>
700036c0:	1b83      	subs	r3, r0, r6
700036c2:	e03a      	b.n	7000373a <__l_vfprintf+0x482>
                buf[0] = va_arg (ap, int);
700036c4:	9b09      	ldr	r3, [sp, #36]	; 0x24
                size = 1;
700036c6:	f04f 0a01 	mov.w	sl, #1
                pnt = buf;
700036ca:	aa0a      	add	r2, sp, #40	; 0x28
                buf[0] = va_arg (ap, int);
700036cc:	1d19      	adds	r1, r3, #4
700036ce:	9109      	str	r1, [sp, #36]	; 0x24
700036d0:	681b      	ldr	r3, [r3, #0]
700036d2:	f88d 3028 	strb.w	r3, [sp, #40]	; 0x28
                goto str_lpad;
700036d6:	e75d      	b.n	70003594 <__l_vfprintf+0x2dc>
                        base = 16;
700036d8:	2310      	movs	r3, #16
                        flags |= FL_ALT;
700036da:	f046 0610 	orr.w	r6, r6, #16
                        c = 'x';
700036de:	2578      	movs	r5, #120	; 0x78
            SKIP_FLOAT_ARG(flags, ap);
700036e0:	9a09      	ldr	r2, [sp, #36]	; 0x24
                    arg_to_unsigned(ap, flags, x);
700036e2:	f016 0c80 	ands.w	ip, r6, #128	; 0x80
700036e6:	f000 80a2 	beq.w	7000382e <__l_vfprintf+0x576>
700036ea:	f416 7100 	ands.w	r1, r6, #512	; 0x200
700036ee:	bf1d      	ittte	ne
700036f0:	3207      	addne	r2, #7
700036f2:	f022 0207 	bicne.w	r2, r2, #7
700036f6:	f102 0108 	addne.w	r1, r2, #8
700036fa:	1d10      	addeq	r0, r2, #4
700036fc:	bf15      	itete	ne
700036fe:	9109      	strne	r1, [sp, #36]	; 0x24
70003700:	9009      	streq	r0, [sp, #36]	; 0x24
70003702:	e9d2 0100 	ldrdne	r0, r1, [r2]
70003706:	6810      	ldreq	r0, [r2, #0]
                    if (x == 0)
70003708:	ea50 0201 	orrs.w	r2, r0, r1
7000370c:	f040 80c5 	bne.w	7000389a <__l_vfprintf+0x5e2>
                    if (x == 0 && (flags & FL_PREC) && prec == 0)
70003710:	9a01      	ldr	r2, [sp, #4]
                        flags &= ~FL_ALT;
70003712:	f026 0c16 	bic.w	ip, r6, #22
                    if (x == 0 && (flags & FL_PREC) && prec == 0)
70003716:	fab2 f282 	clz	r2, r2
                        flags &= ~FL_ALT;
7000371a:	fa1f fa8c 	uxth.w	sl, ip
                    if (x == 0 && (flags & FL_PREC) && prec == 0)
7000371e:	0952      	lsrs	r2, r2, #5
70003720:	f006 0c40 	and.w	ip, r6, #64	; 0x40
70003724:	ea12 1296 	ands.w	r2, r2, r6, lsr #6
70003728:	f8cd c008 	str.w	ip, [sp, #8]
7000372c:	f040 8129 	bne.w	70003982 <__l_vfprintf+0x6ca>
                        buf_len = __ultoa_invert (x, buf, base) - buf;
70003730:	ae0a      	add	r6, sp, #40	; 0x28
70003732:	4632      	mov	r2, r6
70003734:	f7ff fc82 	bl	7000303c <__ultoa_invert>
70003738:	1b83      	subs	r3, r0, r6
                if (flags & FL_PREC) {
7000373a:	9a02      	ldr	r2, [sp, #8]
7000373c:	f00a 0c10 	and.w	ip, sl, #16
70003740:	b37a      	cbz	r2, 700037a2 <__l_vfprintf+0x4ea>
                    if (len < prec) {
70003742:	9901      	ldr	r1, [sp, #4]
                    flags &= ~FL_ZFILL;
70003744:	f02a 0201 	bic.w	r2, sl, #1
                    if (len < prec) {
70003748:	4299      	cmp	r1, r3
                    flags &= ~FL_ZFILL;
7000374a:	b292      	uxth	r2, r2
                    if (len < prec) {
7000374c:	bfdc      	itt	le
7000374e:	f00a 0c10 	andle.w	ip, sl, #16
                    flags &= ~FL_ZFILL;
70003752:	4692      	movle	sl, r2
                    if (len < prec) {
70003754:	dd25      	ble.n	700037a2 <__l_vfprintf+0x4ea>
                        if (c == '\0')
70003756:	2d00      	cmp	r5, #0
70003758:	f040 80ea 	bne.w	70003930 <__l_vfprintf+0x678>
                            flags &= ~FL_ALT;
7000375c:	f02a 0211 	bic.w	r2, sl, #17
70003760:	fa1f fa82 	uxth.w	sl, r2
70003764:	9a01      	ldr	r2, [sp, #4]
70003766:	e071      	b.n	7000384c <__l_vfprintf+0x594>
                        base = 10;
70003768:	230a      	movs	r3, #10
                        flags &= ~FL_ALT;
7000376a:	f026 0610 	bic.w	r6, r6, #16
7000376e:	b2b6      	uxth	r6, r6
                        base = 10;
70003770:	e7b6      	b.n	700036e0 <__l_vfprintf+0x428>
                    pnt = va_arg (ap, char *);
70003772:	9a09      	ldr	r2, [sp, #36]	; 0x24
                    pnt = "(null)";
70003774:	f644 53c8 	movw	r3, #19912	; 0x4dc8
70003778:	f2c7 0300 	movt	r3, #28672	; 0x7000
                    pnt = va_arg (ap, char *);
7000377c:	1d11      	adds	r1, r2, #4
7000377e:	9109      	str	r1, [sp, #36]	; 0x24
70003780:	6812      	ldr	r2, [r2, #0]
                size = strnlen (pnt, size);
70003782:	9901      	ldr	r1, [sp, #4]
                    pnt = "(null)";
70003784:	2a00      	cmp	r2, #0
70003786:	bf08      	it	eq
70003788:	461a      	moveq	r2, r3
                size = strnlen (pnt, size);
7000378a:	4610      	mov	r0, r2
                size = (flags & FL_PREC) ? (size_t) prec : SIZE_MAX;
7000378c:	f016 0f40 	tst.w	r6, #64	; 0x40
                size = strnlen (pnt, size);
70003790:	9201      	str	r2, [sp, #4]
70003792:	bf08      	it	eq
70003794:	f04f 31ff 	moveq.w	r1, #4294967295	; 0xffffffff
70003798:	f7ff fc3e 	bl	70003018 <strnlen>
7000379c:	9a01      	ldr	r2, [sp, #4]
7000379e:	4682      	mov	sl, r0
700037a0:	e6f8      	b.n	70003594 <__l_vfprintf+0x2dc>
                if (flags & FL_ALT) {
700037a2:	f1bc 0f00 	cmp.w	ip, #0
700037a6:	d050      	beq.n	7000384a <__l_vfprintf+0x592>
                    len += 1;
700037a8:	1c5a      	adds	r2, r3, #1
                    if (c != '\0')
700037aa:	b10d      	cbz	r5, 700037b0 <__l_vfprintf+0x4f8>
700037ac:	461a      	mov	r2, r3
                        len += 1;
700037ae:	3202      	adds	r2, #2
                if (!(flags & FL_LPAD)) {
700037b0:	f01a 0f08 	tst.w	sl, #8
                width -= len;
700037b4:	bf18      	it	ne
700037b6:	eba9 0602 	subne.w	r6, r9, r2
                if (!(flags & FL_LPAD)) {
700037ba:	d053      	beq.n	70003864 <__l_vfprintf+0x5ac>
                    my_putc ('0', stream);
700037bc:	4639      	mov	r1, r7
700037be:	2030      	movs	r0, #48	; 0x30
700037c0:	9302      	str	r3, [sp, #8]
700037c2:	47d8      	blx	fp
700037c4:	2800      	cmp	r0, #0
700037c6:	f6ff ada6 	blt.w	70003316 <__l_vfprintf+0x5e>
                    if (c != '\0')
700037ca:	9b02      	ldr	r3, [sp, #8]
700037cc:	2d00      	cmp	r5, #0
700037ce:	f040 8094 	bne.w	700038fa <__l_vfprintf+0x642>
                    my_putc ('0', stream);
700037d2:	3401      	adds	r4, #1
                while (prec > buf_len) {
700037d4:	9a01      	ldr	r2, [sp, #4]
700037d6:	4293      	cmp	r3, r2
700037d8:	bfa8      	it	ge
700037da:	4625      	movge	r5, r4
700037dc:	da12      	bge.n	70003804 <__l_vfprintf+0x54c>
700037de:	9d01      	ldr	r5, [sp, #4]
700037e0:	469a      	mov	sl, r3
700037e2:	4425      	add	r5, r4
700037e4:	1aed      	subs	r5, r5, r3
700037e6:	46a9      	mov	r9, r5
700037e8:	465d      	mov	r5, fp
700037ea:	e001      	b.n	700037f0 <__l_vfprintf+0x538>
700037ec:	45a1      	cmp	r9, r4
700037ee:	d006      	beq.n	700037fe <__l_vfprintf+0x546>
                    my_putc ('0', stream);
700037f0:	4639      	mov	r1, r7
700037f2:	2030      	movs	r0, #48	; 0x30
700037f4:	47a8      	blx	r5
700037f6:	3401      	adds	r4, #1
700037f8:	2800      	cmp	r0, #0
700037fa:	daf7      	bge.n	700037ec <__l_vfprintf+0x534>
700037fc:	e58b      	b.n	70003316 <__l_vfprintf+0x5e>
700037fe:	46ab      	mov	fp, r5
70003800:	4653      	mov	r3, sl
70003802:	464d      	mov	r5, r9
70003804:	46aa      	mov	sl, r5
70003806:	ac0a      	add	r4, sp, #40	; 0x28
70003808:	465d      	mov	r5, fp
7000380a:	eb04 0903 	add.w	r9, r4, r3
7000380e:	469b      	mov	fp, r3
70003810:	e005      	b.n	7000381e <__l_vfprintf+0x566>
                    my_putc (buf[--buf_len], stream);
70003812:	f819 0d01 	ldrb.w	r0, [r9, #-1]!
70003816:	47a8      	blx	r5
70003818:	2800      	cmp	r0, #0
7000381a:	f6ff ad7c 	blt.w	70003316 <__l_vfprintf+0x5e>
7000381e:	4639      	mov	r1, r7
                while (buf_len)
70003820:	45a1      	cmp	r9, r4
70003822:	d1f6      	bne.n	70003812 <__l_vfprintf+0x55a>
70003824:	465b      	mov	r3, fp
70003826:	46ab      	mov	fp, r5
70003828:	eb0a 0903 	add.w	r9, sl, r3
7000382c:	e6ea      	b.n	70003604 <__l_vfprintf+0x34c>
                    arg_to_unsigned(ap, flags, x);
7000382e:	1d11      	adds	r1, r2, #4
70003830:	9109      	str	r1, [sp, #36]	; 0x24
70003832:	f416 7180 	ands.w	r1, r6, #256	; 0x100
70003836:	6810      	ldr	r0, [r2, #0]
70003838:	f43f af66 	beq.w	70003708 <__l_vfprintf+0x450>
7000383c:	f416 7100 	ands.w	r1, r6, #512	; 0x200
70003840:	bf1a      	itte	ne
70003842:	4661      	movne	r1, ip
70003844:	b2c0      	uxtbne	r0, r0
70003846:	b280      	uxtheq	r0, r0
70003848:	e75e      	b.n	70003708 <__l_vfprintf+0x450>
7000384a:	461a      	mov	r2, r3
                if (!(flags & FL_LPAD)) {
7000384c:	f240 4106 	movw	r1, #1030	; 0x406
                } else if (flags & (FL_NEGATIVE | FL_PLUS | FL_SPACE)) {
70003850:	ea1a 0101 	ands.w	r1, sl, r1
                    len += 1;
70003854:	bf18      	it	ne
70003856:	3201      	addne	r2, #1
                if (!(flags & FL_LPAD)) {
70003858:	f01a 0c08 	ands.w	ip, sl, #8
                width -= len;
7000385c:	bf18      	it	ne
7000385e:	eba9 0602 	subne.w	r6, r9, r2
                if (!(flags & FL_LPAD)) {
70003862:	d135      	bne.n	700038d0 <__l_vfprintf+0x618>
                    if (flags & FL_ZFILL) {
70003864:	f01a 0f01 	tst.w	sl, #1
70003868:	d158      	bne.n	7000391c <__l_vfprintf+0x664>
                    while (len < width) {
7000386a:	4591      	cmp	r9, r2
7000386c:	f340 80a8 	ble.w	700039c0 <__l_vfprintf+0x708>
70003870:	f8cd 8008 	str.w	r8, [sp, #8]
70003874:	eb09 0604 	add.w	r6, r9, r4
70003878:	e9cd 3205 	strd	r3, r2, [sp, #20]
7000387c:	1ab6      	subs	r6, r6, r2
7000387e:	9407      	str	r4, [sp, #28]
70003880:	46b0      	mov	r8, r6
70003882:	465e      	mov	r6, fp
70003884:	46e3      	mov	fp, ip
70003886:	e001      	b.n	7000388c <__l_vfprintf+0x5d4>
70003888:	45a0      	cmp	r8, r4
7000388a:	d00e      	beq.n	700038aa <__l_vfprintf+0x5f2>
                        my_putc (' ', stream);
7000388c:	4639      	mov	r1, r7
7000388e:	2020      	movs	r0, #32
70003890:	47b0      	blx	r6
70003892:	3401      	adds	r4, #1
70003894:	2800      	cmp	r0, #0
70003896:	daf7      	bge.n	70003888 <__l_vfprintf+0x5d0>
70003898:	e53d      	b.n	70003316 <__l_vfprintf+0x5e>
                    flags &= ~(FL_PLUS | FL_SPACE);
7000389a:	f026 0206 	bic.w	r2, r6, #6
7000389e:	f006 0640 	and.w	r6, r6, #64	; 0x40
700038a2:	fa1f fa82 	uxth.w	sl, r2
700038a6:	9602      	str	r6, [sp, #8]
700038a8:	e742      	b.n	70003730 <__l_vfprintf+0x478>
                        len++;
700038aa:	e9dd 3205 	ldrd	r3, r2, [sp, #20]
700038ae:	46dc      	mov	ip, fp
700038b0:	9907      	ldr	r1, [sp, #28]
700038b2:	46b3      	mov	fp, r6
700038b4:	f8dd 8008 	ldr.w	r8, [sp, #8]
700038b8:	1a56      	subs	r6, r2, r1
700038ba:	4426      	add	r6, r4
                width -= len;
700038bc:	eba9 0606 	sub.w	r6, r9, r6
                if (flags & FL_ALT) {
700038c0:	f1bc 0f00 	cmp.w	ip, #0
700038c4:	f47f af7a 	bne.w	700037bc <__l_vfprintf+0x504>
700038c8:	f240 4106 	movw	r1, #1030	; 0x406
700038cc:	ea0a 0101 	and.w	r1, sl, r1
                } else if (flags & (FL_NEGATIVE | FL_PLUS | FL_SPACE)) {
700038d0:	2900      	cmp	r1, #0
700038d2:	f43f af7f 	beq.w	700037d4 <__l_vfprintf+0x51c>
                    my_putc (z, stream);
700038d6:	4639      	mov	r1, r7
                    if (flags & FL_PLUS) z = '+';
700038d8:	f01a 0f02 	tst.w	sl, #2
700038dc:	bf14      	ite	ne
700038de:	202b      	movne	r0, #43	; 0x2b
700038e0:	2020      	moveq	r0, #32
                    if (flags & FL_NEGATIVE) z = '-';
700038e2:	9302      	str	r3, [sp, #8]
700038e4:	f41a 6f80 	tst.w	sl, #1024	; 0x400
                    my_putc (z, stream);
700038e8:	bf18      	it	ne
700038ea:	202d      	movne	r0, #45	; 0x2d
700038ec:	3401      	adds	r4, #1
700038ee:	47d8      	blx	fp
700038f0:	9b02      	ldr	r3, [sp, #8]
700038f2:	2800      	cmp	r0, #0
700038f4:	f6bf af6e 	bge.w	700037d4 <__l_vfprintf+0x51c>
700038f8:	e50d      	b.n	70003316 <__l_vfprintf+0x5e>
                        my_putc (c, stream);
700038fa:	4628      	mov	r0, r5
700038fc:	4639      	mov	r1, r7
700038fe:	9302      	str	r3, [sp, #8]
70003900:	47d8      	blx	fp
70003902:	9b02      	ldr	r3, [sp, #8]
70003904:	3402      	adds	r4, #2
70003906:	2800      	cmp	r0, #0
70003908:	f6bf af64 	bge.w	700037d4 <__l_vfprintf+0x51c>
7000390c:	e503      	b.n	70003316 <__l_vfprintf+0x5e>
7000390e:	464b      	mov	r3, r9
                        prec = 0;
70003910:	4656      	mov	r6, sl
70003912:	f8cd a004 	str.w	sl, [sp, #4]
                        width = 0;
70003916:	46d1      	mov	r9, sl
70003918:	469a      	mov	sl, r3
7000391a:	e528      	b.n	7000336e <__l_vfprintf+0xb6>
                        if (len < width) {
7000391c:	4591      	cmp	r9, r2
                            prec += width - len;
7000391e:	eba9 0602 	sub.w	r6, r9, r2
70003922:	bfd8      	it	le
70003924:	9301      	strle	r3, [sp, #4]
                        if (len < width) {
70003926:	ddcb      	ble.n	700038c0 <__l_vfprintf+0x608>
                            prec += width - len;
70003928:	199a      	adds	r2, r3, r6
7000392a:	2600      	movs	r6, #0
7000392c:	9201      	str	r2, [sp, #4]
                            len = width;
7000392e:	e7c7      	b.n	700038c0 <__l_vfprintf+0x608>
                if (flags & FL_ALT) {
70003930:	f01a 0c10 	ands.w	ip, sl, #16
70003934:	4692      	mov	sl, r2
                        len = prec;
70003936:	9a01      	ldr	r2, [sp, #4]
                if (flags & FL_ALT) {
70003938:	f47f af39 	bne.w	700037ae <__l_vfprintf+0x4f6>
7000393c:	e786      	b.n	7000384c <__l_vfprintf+0x594>
	if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
7000393e:	2308      	movs	r3, #8
70003940:	2500      	movs	r5, #0
70003942:	e6cd      	b.n	700036e0 <__l_vfprintf+0x428>
                    arg_to_signed(ap, flags, x_s);
70003944:	05b0      	lsls	r0, r6, #22
70003946:	d525      	bpl.n	70003994 <__l_vfprintf+0x6dc>
70003948:	3307      	adds	r3, #7
7000394a:	f023 0307 	bic.w	r3, r3, #7
7000394e:	f103 0208 	add.w	r2, r3, #8
70003952:	9209      	str	r2, [sp, #36]	; 0x24
70003954:	e9d3 0200 	ldrd	r0, r2, [r3]
70003958:	e692      	b.n	70003680 <__l_vfprintf+0x3c8>
                        skip_to_arg(fmt_orig, &my_ap, (flags & FL_PREC) ? prec : width);
7000395a:	464a      	mov	r2, r9
7000395c:	a909      	add	r1, sp, #36	; 0x24
7000395e:	9803      	ldr	r0, [sp, #12]
70003960:	f7ff fbe4 	bl	7000312c <skip_to_arg>
                            width = va_arg(ap, int);
70003964:	9b09      	ldr	r3, [sp, #36]	; 0x24
70003966:	1d1a      	adds	r2, r3, #4
70003968:	9209      	str	r2, [sp, #36]	; 0x24
7000396a:	f8d3 9000 	ldr.w	r9, [r3]
7000396e:	e4fe      	b.n	7000336e <__l_vfprintf+0xb6>
                    flags &= ~FL_ALT;
70003970:	f006 0340 	and.w	r3, r6, #64	; 0x40
                        x_s = -x_s;
70003974:	4240      	negs	r0, r0
                    flags &= ~FL_ALT;
70003976:	f44a 6a80 	orr.w	sl, sl, #1024	; 0x400
                    if (x_s == 0 && (flags & FL_PREC) && prec == 0)
7000397a:	9302      	str	r3, [sp, #8]
                        x_s = -x_s;
7000397c:	eb62 0142 	sbc.w	r1, r2, r2, lsl #1
70003980:	e699      	b.n	700036b6 <__l_vfprintf+0x3fe>
                        buf_len = 0;
70003982:	2200      	movs	r2, #0
                    flags &= ~FL_ZFILL;
70003984:	f026 0617 	bic.w	r6, r6, #23
                        buf_len = 0;
70003988:	4613      	mov	r3, r2
                    flags &= ~FL_ZFILL;
7000398a:	fa1f fa86 	uxth.w	sl, r6
                if (flags & FL_ALT) {
7000398e:	e75d      	b.n	7000384c <__l_vfprintf+0x594>
    int stream_len = 0;
70003990:	4604      	mov	r4, r0
    return stream_len;
70003992:	e4c6      	b.n	70003322 <__l_vfprintf+0x6a>
                    arg_to_signed(ap, flags, x_s);
70003994:	1d1a      	adds	r2, r3, #4
70003996:	9209      	str	r2, [sp, #36]	; 0x24
70003998:	6818      	ldr	r0, [r3, #0]
7000399a:	17c2      	asrs	r2, r0, #31
7000399c:	e670      	b.n	70003680 <__l_vfprintf+0x3c8>
                        base = 2;
7000399e:	2302      	movs	r3, #2
700039a0:	e69e      	b.n	700036e0 <__l_vfprintf+0x428>
	return EOF;
700039a2:	f04f 34ff 	mov.w	r4, #4294967295	; 0xffffffff
700039a6:	e4bc      	b.n	70003322 <__l_vfprintf+0x6a>
                        buf_len = 0;
700039a8:	2200      	movs	r2, #0
                    flags &= ~FL_ZFILL;
700039aa:	f026 0611 	bic.w	r6, r6, #17
                        buf_len = 0;
700039ae:	4613      	mov	r3, r2
                    flags &= ~FL_ZFILL;
700039b0:	fa1f fa86 	uxth.w	sl, r6
                if (flags & FL_ALT) {
700039b4:	e74a      	b.n	7000384c <__l_vfprintf+0x594>
                        buf_len = __ultoa_invert (x_s, buf, 10) - buf;
700039b6:	4611      	mov	r1, r2
700039b8:	f006 0340 	and.w	r3, r6, #64	; 0x40
700039bc:	9302      	str	r3, [sp, #8]
700039be:	e67a      	b.n	700036b6 <__l_vfprintf+0x3fe>
                            prec += width - len;
700039c0:	eba9 0602 	sub.w	r6, r9, r2
700039c4:	e77c      	b.n	700038c0 <__l_vfprintf+0x608>
		if (c >= '0' && c <= '9') {
700039c6:	f1a5 0330 	sub.w	r3, r5, #48	; 0x30
700039ca:	2b09      	cmp	r3, #9
700039cc:	f63f ad79 	bhi.w	700034c2 <__l_vfprintf+0x20a>
		    if (flags & FL_PREC) {
700039d0:	0675      	lsls	r5, r6, #25
700039d2:	f57f acc6 	bpl.w	70003362 <__l_vfprintf+0xaa>
			prec = 10*prec + c;
700039d6:	9a01      	ldr	r2, [sp, #4]
700039d8:	eb02 0282 	add.w	r2, r2, r2, lsl #2
700039dc:	eb03 0342 	add.w	r3, r3, r2, lsl #1
700039e0:	9301      	str	r3, [sp, #4]
			continue;
700039e2:	e4c4      	b.n	7000336e <__l_vfprintf+0xb6>
700039e4:	0000      	movs	r0, r0
	...

700039e8 <__z_arm_int_exit_from_thumb>:
700039e8:	4778      	bx	pc
700039ea:	e7fd      	b.n	700039e8 <__z_arm_int_exit_from_thumb>
700039ec:	eafff57a 	b	70000fdc <z_arm_int_exit>

Disassembly of section .boot_section:

00000000 <__boot_spring>:
 * @brief Initialisation of fault handling
 */
void z_arm_fault_init(void)
{
	/* Nothing to do for now */
}
   0:	e59fd004 	ldr	sp, [pc, #4]	; c <___thread_base_t_user_options_OFFSET>
	arch_system_halt(reason);
   4:	fa000024 	blx	9c <MpuP_init>
	handler = pHandler;
   8:	ea000054 	b	160 <____start_veneer>
};

void rsc_table_get(struct fw_resource_table **table_ptr, int *length)
{
	*table_ptr = &resource_table;
	*length = sizeof(resource_table);
   c:	700099e8 	.word	0x700099e8

00000010 <MpuP_setRegion>:
	cmp	r0, #0
	bne	_irq_disabled
	cpsie	i
_irq_disabled:

	bx	lr
  10:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
  12:	f893 c004 	ldrb.w	ip, [r3, #4]
{
	uint32_t *ssf_contents = ssf_ptr;
	struct arch_esf oops_esf = { 0 };

	/* TODO: Copy the rest of the register set out of ssf_ptr */
	oops_esf.basic.pc = ssf_contents[3];
  16:	f893 e000 	ldrb.w	lr, [r3]
	z_fatal_error(reason, esf);
  1a:	79de      	ldrb	r6, [r3, #7]
}
  1c:	4604      	mov	r4, r0
  1e:	ea4f 3c0c 	mov.w	ip, ip, lsl #12
   z_vim_irq_enable(irq);
  22:	7998      	ldrb	r0, [r3, #6]
  24:	0200      	lsls	r0, r0, #8
		(void) vfprintf(&console, fmt, ap);
  26:	f400 60e0 	and.w	r0, r0, #1792	; 0x700
}
  2a:	f40c 5c80 	and.w	ip, ip, #4096	; 0x1000
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	sys_write32(BIT(irq_bit_num), VIM_RAW(irq_group_num));
  2e:	ea4c 0c00 	orr.w	ip, ip, r0
  32:	7898      	ldrb	r0, [r3, #2]
  34:	f000 0001 	and.w	r0, r0, #1
  38:	ea4c 0c00 	orr.w	ip, ip, r0
}
  3c:	7958      	ldrb	r0, [r3, #5]
	return dev->state->initialized && (dev->state->init_res == 0U);
  3e:	00c0      	lsls	r0, r0, #3
		return NULL;
  40:	f000 0038 	and.w	r0, r0, #56	; 0x38
  44:	ea4c 0c00 	orr.w	ip, ip, r0
}
  48:	78d8      	ldrb	r0, [r3, #3]
		return NULL;
  4a:	0080      	lsls	r0, r0, #2
}
  4c:	f000 0004 	and.w	r0, r0, #4
	void *ret = sys_heap_aligned_realloc(&z_malloc_heap, ptr,
					     __alignof__(z_max_align_t),
					     requested_size);

	if (ret == NULL && requested_size != 0) {
		errno = ENOMEM;
  50:	f002 021f 	and.w	r2, r2, #31
  54:	ea4c 0c00 	orr.w	ip, ip, r0
	return z_impl_k_mutex_unlock(mutex);
  58:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
  5c:	1c55      	adds	r5, r2, #1
  5e:	f00e 0e01 	and.w	lr, lr, #1
	}

	malloc_unlock();

	return ret;
}
  62:	40a8      	lsls	r0, r5
  64:	ea01 0500 	and.w	r5, r1, r0
	slab->info.num_used--;

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_mem_slab, free, slab);

	k_spin_unlock(&slab->lock, key);
}
  68:	7858      	ldrb	r0, [r3, #1]
  6a:	0040      	lsls	r0, r0, #1
			z_reschedule(&slab->lock, key);
  6c:	ea4e 2e06 	orr.w	lr, lr, r6, lsl #8
	return list->head == list;
  70:	f000 0002 	and.w	r0, r0, #2
		if (unlikely(thread != NULL)) {
  74:	ea4c 0600 	orr.w	r6, ip, r0
  78:	ea4e 0742 	orr.w	r7, lr, r2, lsl #1

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_heap, realloc, heap, ptr, bytes, timeout, ret);

	k_spin_unlock(&heap->lock, key);
	return ret;
}
  7c:	f000 e85c 	blx	138 <MpuP_isEnableAsm>
  80:	4633      	mov	r3, r6
  82:	463a      	mov	r2, r7
}
  84:	4629      	mov	r1, r5
      {
         printk("Event %s Count: %u\r\n", p->events[j].name, p->events[j].value);
      }
      printk("\r\n");
   }
}
  86:	4606      	mov	r6, r0
  88:	4620      	mov	r0, r4
		wfe();
	}

	cpu_map[cpu_num] = cpu_mpid;

	printk("Secondary CPU core %d (MPID:%#x) is up\n", cpu_num, cpu_mpid);
  8a:	f000 e860 	blx	14c <MpuP_setRegionAsm>
  8e:	b906      	cbnz	r6, 92 <CONFIG_CONSOLE_INPUT_MAX_LINE_LEN+0x12>
}
  90:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		_kernel.ready_q.cache = thread;
  92:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
  96:	f000 b867 	b.w	168 <__MpuP_enableAsm_from_thumb>
	node->prev = prev;
  9a:	bf00      	nop

0000009c <MpuP_init>:
  9c:	b570      	push	{r4, r5, r6, lr}
	prev->next = node;
  9e:	f000 e830 	blx	100 <MpuP_disableBRAsm>
}
  a2:	f24b 0654 	movw	r6, #45140	; 0xb054
   for (i = 0; i < ITERATION_COUNT; i++)
   {
      // printf("Receive Latency: ");
      // tm_pmu_profile_print(pmu_recv_names[i]);
      printf("Send Latency: ");
      tm_pmu_profile_print(pmu_send_names[i]);
  a6:	f2c7 0600 	movt	r6, #28672	; 0x7000
   for (i = 0; i < ITERATION_COUNT; i++)
  aa:	6833      	ldr	r3, [r6, #0]
   }

   tm_thread_suspend(0);
}
  ac:	b163      	cbz	r3, c8 <MpuP_init+0x2c>
  ae:	4c0d      	ldr	r4, [pc, #52]	; (e4 <__data_size+0xc>)
   tm_thread_suspend(0);
  b0:	2500      	movs	r5, #0
  b2:	4623      	mov	r3, r4
  b4:	4628      	mov	r0, r5
    /*
     * Initialize MPU regions
     */
    for (i = 0; i < gMpuConfig.numRegions; i++)
    {
        MpuP_setRegion(i,
  b6:	e954 1202 	ldrd	r1, r2, [r4, #-8]
    for (i = 0; i < gMpuConfig.numRegions; i++)
  ba:	3501      	adds	r5, #1
        MpuP_setRegion(i,
  bc:	f7ff ffa8 	bl	10 <MpuP_setRegion>
    for (i = 0; i < gMpuConfig.numRegions; i++)
  c0:	6833      	ldr	r3, [r6, #0]
  c2:	3410      	adds	r4, #16
  c4:	42ab      	cmp	r3, r5
  c6:	d8f4      	bhi.n	b2 <MpuP_init+0x16>
                gMpuRegionConfig[i].size,
                &gMpuRegionConfig[i].attrs
        );
    }

    if (gMpuConfig.enableBackgroundRegion) {
  c8:	6873      	ldr	r3, [r6, #4]
  ca:	b913      	cbnz	r3, d2 <MpuP_init+0x36>
        MpuP_enableBRAsm();
    }

    if (gMpuConfig.enableMpu) {
  cc:	68b3      	ldr	r3, [r6, #8]
  ce:	b92b      	cbnz	r3, dc <__data_size+0x4>
	    MpuP_enableAsm();
    }
}
  d0:	bd70      	pop	{r4, r5, r6, pc}
        MpuP_enableBRAsm();
  d2:	f000 e82a 	blx	128 <MpuP_enableBRAsm>
    if (gMpuConfig.enableMpu) {
  d6:	68b3      	ldr	r3, [r6, #8]
  d8:	2b00      	cmp	r3, #0
  da:	d0f9      	beq.n	d0 <MpuP_init+0x34>
}
  dc:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	    MpuP_enableAsm();
  e0:	f000 b842 	b.w	168 <__MpuP_enableAsm_from_thumb>
  e4:	7000b00c 	.word	0x7000b00c

000000e8 <MpuP_disableAsm>:
_ASM_FILE_PROLOGUE

/* FUNCTION DEF: void MpuP_disableAsm(void) */
GTEXT(MpuP_disableAsm)
SECTION_FUNC(boot_section, MpuP_disableAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
  e8:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        bic     r0, r0, #0x1             // clear bit 0 in r0
  ec:	e3c00001 	bic	r0, r0, #1
        dsb
  f0:	f57ff04f 	dsb	sy
        mcr     p15, #0, r0, c1, c0, #0  // MPU disabled (bit 0 = 0)
  f4:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        isb                              // flush instruction pipeline
  f8:	f57ff06f 	isb	sy
        bx      LR
  fc:	e12fff1e 	bx	lr

00000100 <MpuP_disableBRAsm>:

/* FUNCTION DEF: void MpuP_disableBRAsm(void) */
GTEXT(MpuP_disableBRAsm)
SECTION_FUNC(boot_section, MpuP_disableBRAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 100:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        bic     r0, r0, #0x20000         // clear bit 17 in r0
 104:	e3c00802 	bic	r0, r0, #131072	; 0x20000
        mcr     p15, #0, r0, c1, c0, #0  // disable background region
 108:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        bx      LR
 10c:	e12fff1e 	bx	lr

00000110 <MpuP_enableAsm>:

/* FUNCTION DEF: void MpuP_enableAsm(void) */
GTEXT(MpuP_enableAsm)
SECTION_FUNC(boot_section, MpuP_enableAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 110:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        orr     r0, r0, #0x1             // set bit 0 in r0
 114:	e3800001 	orr	r0, r0, #1
        dsb
 118:	f57ff04f 	dsb	sy
        mcr     p15, #0, r0, c1, c0, #0  // MPU enabled (bit 0 = 1)
 11c:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        isb                              // flush instruction pipeline
 120:	f57ff06f 	isb	sy
        bx      LR
 124:	e12fff1e 	bx	lr

00000128 <MpuP_enableBRAsm>:

/* FUNCTION DEF: void MpuP_enableBRAsm(void) */
GTEXT(MpuP_enableBRAsm)
SECTION_FUNC(boot_section, MpuP_enableBRAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 128:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        orr     r0, r0, #0x20000         // set bit 17 in r0
 12c:	e3800802 	orr	r0, r0, #131072	; 0x20000
        mcr     p15, #0, r0, c1, c0, #0  // background region enabled
 130:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        bx      LR
 134:	e12fff1e 	bx	lr

00000138 <MpuP_isEnableAsm>:

/* FUNCTION DEF: uint32_t MpuP_isEnableAsm(void) */
GTEXT(MpuP_isEnableAsm)
SECTION_FUNC(boot_section, MpuP_isEnableAsm)
        mov     r0, #0
 138:	e3a00000 	mov	r0, #0
        mrc     p15, #0, r1, c1, c0, #0  // read SCTLR register to r1
 13c:	ee111f10 	mrc	15, 0, r1, cr1, cr0, {0}
        tst     r1, #0x1                 // test bit 0
 140:	e3110001 	tst	r1, #1
        movne   r0, #1                   // if not 0, MPU is enabled
 144:	13a00001 	movne	r0, #1
        bx      LR
 148:	e12fff1e 	bx	lr

0000014c <MpuP_setRegionAsm>:
 * r2 = sizeAndEnable
 * r3 = regionAttrs
 */
GTEXT(MpuP_setRegionAsm)
SECTION_FUNC(boot_section, MpuP_setRegionAsm)
        mcr     p15, #0, r0, c6, c2, #0  // select MPU region
 14c:	ee060f12 	mcr	15, 0, r0, cr6, cr2, {0}
        mcr     p15, #0, r1, c6, c1, #0  // set region base address
 150:	ee061f11 	mcr	15, 0, r1, cr6, cr1, {0}
        mcr     p15, #0, r2, c6, c1, #2  // set region size and enable it
 154:	ee062f51 	mcr	15, 0, r2, cr6, cr1, {2}
        mcr     p15, #0, r3, c6, c1, #4  // set protection attributes
 158:	ee063f91 	mcr	15, 0, r3, cr6, cr1, {4}
        bx      LR
 15c:	e12fff1e 	bx	lr

00000160 <____start_veneer>:
		split_chunks(h, c, c + chunks_need);
 160:	e51ff004 	ldr	pc, [pc, #-4]	; 164 <____start_veneer+0x4>
 164:	70000cb8 	.word	0x70000cb8

00000168 <__MpuP_enableAsm_from_thumb>:
		free_chunk(h, c + chunks_need);
 168:	4778      	bx	pc
 16a:	e7fd      	b.n	168 <__MpuP_enableAsm_from_thumb>
 16c:	eaffffe7 	b	110 <MpuP_enableAsm>
