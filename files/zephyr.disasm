
files/zephyr.elf:     file format elf32-littlearm


Disassembly of section rom_start:

70000000 <_vector_table>:
#include "macro_priv.inc"

_ASM_FILE_PROLOGUE

SECTION_SUBSEC_FUNC(exc_vector_table,_vector_table_section,_vector_table)
	ldr pc, =z_arm_reset             /*                   offset 0 */
70000000:	18 f0 9f e5 18 f0 9f e5 18 f0 9f e5 18 f0 9f e5     ................
	ldr pc, =z_arm_undef_instruction /* undef instruction offset 4 */
	ldr pc, =z_arm_svc               /* svc               offset 8 */
	ldr pc, =z_arm_prefetch_abort    /* prefetch abort offset  0xc */
	ldr pc, =z_arm_data_abort        /* data abort     offset 0x10 */
70000010:	18 f0 9f e5 00 f0 20 e3 14 f0 9f e5 14 f0 9f e5     ...... .........
	ldr pc, =z_arm_reset             /*                   offset 0 */
70000020:	5c 0d 00 70 44 0b 00 70 f0 0f 00 70 88 0b 00 70     \..pD..p...p...p
	ldr pc, =z_arm_data_abort        /* data abort     offset 0x10 */
70000030:	b8 0b 00 70 48 0e 00 70 25 0b 00 70                 ...pH..p%..p

Disassembly of section text:

70000040 <strcmp>:
	.fnstart
	.cfi_sections .debug_frame
	.cfi_startproc
	prologue push_ip=HAVE_PAC_LEAF
#ifndef STRCMP_NO_PRECHECK
	ldrb	r2, [src1]
70000040:	7802      	ldrb	r2, [r0, #0]
	ldrb	r3, [src2]
70000042:	780b      	ldrb	r3, [r1, #0]
	cmp	r2, #1
70000044:	2a01      	cmp	r2, #1
	it	cs
70000046:	bf28      	it	cs
	cmpcs	r2, r3
70000048:	429a      	cmpcs	r2, r3
	bne	.Lfastpath_exit
7000004a:	f040 80d8 	bne.w	700001fe <strcmp+0x1be>
#endif
	strd	r4, r5, [sp, #-16]!
7000004e:	e96d 4504 	strd	r4, r5, [sp, #-16]!
	.cfi_adjust_cfa_offset 16
	.cfi_rel_offset 4, 0
	.cfi_rel_offset 5, 4
	orr	tmp1, src1, src2
70000052:	ea40 0401 	orr.w	r4, r0, r1
	strd	r6, r7, [sp, #8]
70000056:	e9cd 6702 	strd	r6, r7, [sp, #8]
	.cfi_rel_offset 6, 8
	.cfi_rel_offset 7, 12
	mvn	const_m1, #0
7000005a:	f06f 0c00 	mvn.w	ip, #0
	lsl	r2, tmp1, #29
7000005e:	ea4f 7244 	mov.w	r2, r4, lsl #29
	cbz	r2, .Lloop_aligned8
70000062:	b31a      	cbz	r2, 700000ac <strcmp+0x6c>

.Lnot_aligned:
	eor	tmp1, src1, src2
70000064:	ea80 0401 	eor.w	r4, r0, r1
	tst	tmp1, #7
70000068:	f014 0f07 	tst.w	r4, #7
	bne	.Lmisaligned8
7000006c:	d16b      	bne.n	70000146 <strcmp+0x106>

	/* Deal with mutual misalignment by aligning downwards and then
	   masking off the unwanted loaded data to prevent a difference.  */
	and	tmp1, src1, #7
7000006e:	f000 0407 	and.w	r4, r0, #7
	bic	src1, src1, #7
70000072:	f020 0007 	bic.w	r0, r0, #7
	and	tmp2, tmp1, #3
70000076:	f004 0503 	and.w	r5, r4, #3
	bic	src2, src2, #7
7000007a:	f021 0107 	bic.w	r1, r1, #7
	lsl	tmp2, tmp2, #3	/* Bytes -> bits.  */
7000007e:	ea4f 05c5 	mov.w	r5, r5, lsl #3
	ldrd	data1a, data1b, [src1], #16
70000082:	e8f0 2304 	ldrd	r2, r3, [r0], #16
	tst	tmp1, #4
70000086:	f014 0f04 	tst.w	r4, #4
	ldrd	data2a, data2b, [src2], #16
7000008a:	e8f1 6704 	ldrd	r6, r7, [r1], #16
	/* In thumb code we can't use MVN with a register shift, but
	   we do have ORN.  */
	S2HI	tmp1, const_m1, tmp2
7000008e:	fa0c f405 	lsl.w	r4, ip, r5
	orn	data1a, data1a, tmp1
70000092:	ea62 0204 	orn	r2, r2, r4
	orn	data2a, data2a, tmp1
70000096:	ea66 0604 	orn	r6, r6, r4
	beq	.Lstart_realigned8
7000009a:	d00b      	beq.n	700000b4 <strcmp+0x74>
	orn	data1b, data1b, tmp1
7000009c:	ea63 0304 	orn	r3, r3, r4
	mov	data1a, const_m1
700000a0:	4662      	mov	r2, ip
	orn	data2b, data2b, tmp1
700000a2:	ea67 0704 	orn	r7, r7, r4
	mov	data2a, const_m1
700000a6:	4666      	mov	r6, ip
	b	.Lstart_realigned8
700000a8:	e004      	b.n	700000b4 <strcmp+0x74>
700000aa:	bf00      	nop
	/* Unwind the inner loop by a factor of 2, giving 16 bytes per
	   pass.  */
	.p2align 5,,12  /* Don't start in the tail bytes of a cache line.  */
	.p2align 2	/* Always word aligned.  */
.Lloop_aligned8:
	ldrd	data1a, data1b, [src1], #16
700000ac:	e8f0 2304 	ldrd	r2, r3, [r0], #16
	ldrd	data2a, data2b, [src2], #16
700000b0:	e8f1 6704 	ldrd	r6, r7, [r1], #16
.Lstart_realigned8:
	uadd8	syndrome_b, data1a, const_m1	/* Only want GE bits,  */
700000b4:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome_a, data1a, data2a
700000b8:	ea82 0406 	eor.w	r4, r2, r6
	sel	syndrome_a, syndrome_a, const_m1
700000bc:	faa4 f48c 	sel	r4, r4, ip
	cbnz	syndrome_a, .Ldiff_in_a
700000c0:	bb6c      	cbnz	r4, 7000011e <strcmp+0xde>
	uadd8	syndrome_b, data1b, const_m1	/* Only want GE bits.  */
700000c2:	fa83 f54c 	uadd8	r5, r3, ip
	eor	syndrome_b, data1b, data2b
700000c6:	ea83 0507 	eor.w	r5, r3, r7
	sel	syndrome_b, syndrome_b, const_m1
700000ca:	faa5 f58c 	sel	r5, r5, ip
	cbnz	syndrome_b, .Ldiff_in_b
700000ce:	b995      	cbnz	r5, 700000f6 <strcmp+0xb6>

	ldrd	data1a, data1b, [src1, #-8]
700000d0:	e950 2302 	ldrd	r2, r3, [r0, #-8]
	ldrd	data2a, data2b, [src2, #-8]
700000d4:	e951 6702 	ldrd	r6, r7, [r1, #-8]
	uadd8	syndrome_b, data1a, const_m1	/* Only want GE bits,  */
700000d8:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome_a, data1a, data2a
700000dc:	ea82 0406 	eor.w	r4, r2, r6
	sel	syndrome_a, syndrome_a, const_m1
700000e0:	faa4 f48c 	sel	r4, r4, ip
	uadd8	syndrome_b, data1b, const_m1	/* Only want GE bits.  */
700000e4:	fa83 f54c 	uadd8	r5, r3, ip
	eor	syndrome_b, data1b, data2b
700000e8:	ea83 0507 	eor.w	r5, r3, r7
	sel	syndrome_b, syndrome_b, const_m1
700000ec:	faa5 f58c 	sel	r5, r5, ip
	/* Can't use CBZ for backwards branch.  */
	orrs	syndrome_b, syndrome_b, syndrome_a /* Only need if s_a == 0 */
700000f0:	4325      	orrs	r5, r4
	beq	.Lloop_aligned8
700000f2:	d0db      	beq.n	700000ac <strcmp+0x6c>

.Ldiff_found:
	cbnz	syndrome_a, .Ldiff_in_a
700000f4:	b99c      	cbnz	r4, 7000011e <strcmp+0xde>

.Ldiff_in_b:
	strcmp_epilogue_aligned syndrome_b, data1b, data2b 1
700000f6:	ba2d      	rev	r5, r5
700000f8:	fab5 f485 	clz	r4, r5
700000fc:	f024 0407 	bic.w	r4, r4, #7
70000100:	fa27 f104 	lsr.w	r1, r7, r4
70000104:	e9dd 6702 	ldrd	r6, r7, [sp, #8]
70000108:	fa23 f304 	lsr.w	r3, r3, r4
7000010c:	f003 00ff 	and.w	r0, r3, #255	; 0xff
70000110:	f001 01ff 	and.w	r1, r1, #255	; 0xff
70000114:	e8fd 4504 	ldrd	r4, r5, [sp], #16
70000118:	eba0 0001 	sub.w	r0, r0, r1
7000011c:	4770      	bx	lr

.Ldiff_in_a:
	.cfi_restore_state
	strcmp_epilogue_aligned syndrome_a, data1a, data2a 1
7000011e:	ba24      	rev	r4, r4
70000120:	fab4 f484 	clz	r4, r4
70000124:	f024 0407 	bic.w	r4, r4, #7
70000128:	fa26 f104 	lsr.w	r1, r6, r4
7000012c:	e9dd 6702 	ldrd	r6, r7, [sp, #8]
70000130:	fa22 f204 	lsr.w	r2, r2, r4
70000134:	f002 00ff 	and.w	r0, r2, #255	; 0xff
70000138:	f001 01ff 	and.w	r1, r1, #255	; 0xff
7000013c:	e8fd 4504 	ldrd	r4, r5, [sp], #16
70000140:	eba0 0001 	sub.w	r0, r0, r1
70000144:	4770      	bx	lr

	.cfi_restore_state
.Lmisaligned8:
	tst	tmp1, #3
70000146:	f014 0f03 	tst.w	r4, #3
	bne	.Lmisaligned4
7000014a:	d13c      	bne.n	700001c6 <strcmp+0x186>
	ands	tmp1, src1, #3
7000014c:	f010 0403 	ands.w	r4, r0, #3
	bne	.Lmutual_align4
70000150:	d128      	bne.n	700001a4 <strcmp+0x164>

	/* Unrolled by a factor of 2, to reduce the number of post-increment
	   operations.  */
.Lloop_aligned4:
	ldr	data1, [src1], #8
70000152:	f850 2b08 	ldr.w	r2, [r0], #8
	ldr	data2, [src2], #8
70000156:	f851 3b08 	ldr.w	r3, [r1], #8
.Lstart_realigned4:
	uadd8	syndrome, data1, const_m1	/* Only need GE bits.  */
7000015a:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome, data1, data2
7000015e:	ea82 0503 	eor.w	r5, r2, r3
	sel	syndrome, syndrome, const_m1
70000162:	faa5 f58c 	sel	r5, r5, ip
	cbnz	syndrome, .Laligned4_done
70000166:	b95d      	cbnz	r5, 70000180 <strcmp+0x140>
	ldr	data1, [src1, #-4]
70000168:	f850 2c04 	ldr.w	r2, [r0, #-4]
	ldr	data2, [src2, #-4]
7000016c:	f851 3c04 	ldr.w	r3, [r1, #-4]
	uadd8	syndrome, data1, const_m1
70000170:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome, data1, data2
70000174:	ea82 0503 	eor.w	r5, r2, r3
	sel	syndrome, syndrome, const_m1
70000178:	faa5 f58c 	sel	r5, r5, ip
	cmp	syndrome, #0
7000017c:	2d00      	cmp	r5, #0
	beq	.Lloop_aligned4
7000017e:	d0e8      	beq.n	70000152 <strcmp+0x112>

.Laligned4_done:
	strcmp_epilogue_aligned syndrome, data1, data2, 0
70000180:	ba2d      	rev	r5, r5
70000182:	fab5 f485 	clz	r4, r5
70000186:	f024 0407 	bic.w	r4, r4, #7
7000018a:	fa23 f104 	lsr.w	r1, r3, r4
7000018e:	fa22 f204 	lsr.w	r2, r2, r4
70000192:	f002 00ff 	and.w	r0, r2, #255	; 0xff
70000196:	f001 01ff 	and.w	r1, r1, #255	; 0xff
7000019a:	e8fd 4504 	ldrd	r4, r5, [sp], #16
7000019e:	eba0 0001 	sub.w	r0, r0, r1
700001a2:	4770      	bx	lr

.Lmutual_align4:
	.cfi_restore_state
	/* Deal with mutual misalignment by aligning downwards and then
	   masking off the unwanted loaded data to prevent a difference.  */
	lsl	tmp1, tmp1, #3	/* Bytes -> bits.  */
700001a4:	ea4f 04c4 	mov.w	r4, r4, lsl #3
	bic	src1, src1, #3
700001a8:	f020 0003 	bic.w	r0, r0, #3
	ldr	data1, [src1], #8
700001ac:	f850 2b08 	ldr.w	r2, [r0], #8
	bic	src2, src2, #3
700001b0:	f021 0103 	bic.w	r1, r1, #3
	ldr	data2, [src2], #8
700001b4:	f851 3b08 	ldr.w	r3, [r1], #8

	/* In thumb code we can't use MVN with a register shift, but
	   we do have ORN.  */
	S2HI	tmp1, const_m1, tmp1
700001b8:	fa0c f404 	lsl.w	r4, ip, r4
	orn	data1, data1, tmp1
700001bc:	ea62 0204 	orn	r2, r2, r4
	orn	data2, data2, tmp1
700001c0:	ea63 0304 	orn	r3, r3, r4
	b	.Lstart_realigned4
700001c4:	e7c9      	b.n	7000015a <strcmp+0x11a>

.Lmisaligned4:
	ands	tmp1, src1, #3
700001c6:	f010 0403 	ands.w	r4, r0, #3
	beq	.Lsrc1_aligned
700001ca:	d01d      	beq.n	70000208 <strcmp+0x1c8>
	sub	src2, src2, tmp1
700001cc:	eba1 0104 	sub.w	r1, r1, r4
	bic	src1, src1, #3
700001d0:	f020 0003 	bic.w	r0, r0, #3
	lsls	tmp1, tmp1, #31
700001d4:	07e4      	lsls	r4, r4, #31
	ldr	data1, [src1], #4
700001d6:	f850 2b04 	ldr.w	r2, [r0], #4
	beq	.Laligned_m2
700001da:	d006      	beq.n	700001ea <strcmp+0x1aa>
	bcs	.Laligned_m1
700001dc:	d212      	bcs.n	70000204 <strcmp+0x1c4>
	add	src2, src2, #4
	cbnz	data2, .Lsrc1_aligned
#else  /* STRCMP_NO_PRECHECK */
	/* If we've done the pre-check, then we don't need to check the
	   first byte again here.  */
	ldrb	data2, [src2, #2]
700001de:	788b      	ldrb	r3, [r1, #2]
	uxtb	tmp1, data1, ror #BYTE2_OFFSET
700001e0:	fa5f f4a2 	uxtb.w	r4, r2, ror #16
	subs	tmp1, tmp1, data2
700001e4:	1ae4      	subs	r4, r4, r3
	bne	.Lmisaligned_exit
700001e6:	d106      	bne.n	700001f6 <strcmp+0x1b6>
	cbz	data2, .Lmisaligned_exit
700001e8:	b12b      	cbz	r3, 700001f6 <strcmp+0x1b6>

.Laligned_m2:
	ldrb	data2, [src2, #3]
700001ea:	78cb      	ldrb	r3, [r1, #3]
	uxtb	tmp1, data1, ror #BYTE3_OFFSET
700001ec:	fa5f f4b2 	uxtb.w	r4, r2, ror #24
	subs	tmp1, tmp1, data2
700001f0:	1ae4      	subs	r4, r4, r3
	bne	.Lmisaligned_exit
700001f2:	d100      	bne.n	700001f6 <strcmp+0x1b6>
	cbnz	data2, .Laligned_m1
700001f4:	b933      	cbnz	r3, 70000204 <strcmp+0x1c4>
#endif

.Lmisaligned_exit:
	.cfi_remember_state
	mov	result, tmp1
700001f6:	4620      	mov	r0, r4
	ldr	r4, [sp], #16
700001f8:	f85d 4b10 	ldr.w	r4, [sp], #16
	.cfi_restore 4
	.cfi_adjust_cfa_offset -16
	epilogue push_ip=HAVE_PAC_LEAF
700001fc:	4770      	bx	lr

#ifndef STRCMP_NO_PRECHECK
.Lfastpath_exit:
	.cfi_restore_state
	.cfi_remember_state
	sub	r0, r2, r3
700001fe:	eba2 0003 	sub.w	r0, r2, r3
	epilogue push_ip=HAVE_PAC_LEAF
70000202:	4770      	bx	lr

.Laligned_m1:
	.cfi_restore_state
	.cfi_remember_state
	add	src2, src2, #4
70000204:	f101 0104 	add.w	r1, r1, #4
#endif
.Lsrc1_aligned:
	.cfi_restore_state
	/* src1 is word aligned, but src2 has no common alignment
	   with it.  */
	ldr	data1, [src1], #4
70000208:	f850 2b04 	ldr.w	r2, [r0], #4
	lsls	tmp1, src2, #31		/* C=src2[1], Z=src2[0].  */
7000020c:	07cc      	lsls	r4, r1, #31

	bic	src2, src2, #3
7000020e:	f021 0103 	bic.w	r1, r1, #3
	ldr	data2, [src2], #4
70000212:	f851 3b04 	ldr.w	r3, [r1], #4
	bhi	.Loverlap1		/* C=1, Z=0 => src2[1:0] = 0b11.  */
70000216:	d848      	bhi.n	700002aa <strcmp+0x26a>
	bcs	.Loverlap2		/* C=1, Z=1 => src2[1:0] = 0b10.  */
70000218:	d224      	bcs.n	70000264 <strcmp+0x224>

	/* (overlap3) C=0, Z=0 => src2[1:0] = 0b01.  */
.Loverlap3:
	bic	tmp1, data1, #MSB
7000021a:	f022 447f 	bic.w	r4, r2, #4278190080	; 0xff000000
	uadd8	syndrome, data1, const_m1
7000021e:	fa82 f54c 	uadd8	r5, r2, ip
	eors	syndrome, tmp1, data2, S2LO #8
70000222:	ea94 2513 	eors.w	r5, r4, r3, lsr #8
	sel	syndrome, syndrome, const_m1
70000226:	faa5 f58c 	sel	r5, r5, ip
	bne	4f
7000022a:	d10a      	bne.n	70000242 <strcmp+0x202>
	cbnz	syndrome, 5f
7000022c:	b965      	cbnz	r5, 70000248 <strcmp+0x208>
	ldr	data2, [src2], #4
7000022e:	f851 3b04 	ldr.w	r3, [r1], #4
	eor	tmp1, tmp1, data1
70000232:	ea84 0402 	eor.w	r4, r4, r2
	cmp	tmp1, data2, S2HI #24
70000236:	ebb4 6f03 	cmp.w	r4, r3, lsl #24
	bne	6f
7000023a:	d10e      	bne.n	7000025a <strcmp+0x21a>
	ldr	data1, [src1], #4
7000023c:	f850 2b04 	ldr.w	r2, [r0], #4
	b	.Loverlap3
70000240:	e7eb      	b.n	7000021a <strcmp+0x1da>
4:
	S2LO	data2, data2, #8
70000242:	ea4f 2313 	mov.w	r3, r3, lsr #8
	b	.Lstrcmp_tail
70000246:	e055      	b.n	700002f4 <strcmp+0x2b4>

5:
	bics	syndrome, syndrome, #MSB
70000248:	f035 457f 	bics.w	r5, r5, #4278190080	; 0xff000000
	bne	.Lstrcmp_done_equal
7000024c:	d14d      	bne.n	700002ea <strcmp+0x2aa>

	/* We can only get here if the MSB of data1 contains 0, so
	   fast-path the exit.  */
	ldrb	result, [src2]
7000024e:	7808      	ldrb	r0, [r1, #0]
	.cfi_remember_state
	ldrd	r4, r5, [sp], #16
70000250:	e8fd 4504 	ldrd	r4, r5, [sp], #16
	.cfi_restore 5
	/* R6/7 Not used in this sequence.  */
	.cfi_restore 6
	.cfi_restore 7
	.cfi_adjust_cfa_offset -16
	neg	result, result
70000254:	f1c0 0000 	rsb	r0, r0, #0
	epilogue push_ip=HAVE_PAC_LEAF
70000258:	4770      	bx	lr

6:
	.cfi_restore_state
	S2LO	data1, data1, #24
7000025a:	ea4f 6212 	mov.w	r2, r2, lsr #24
	and	data2, data2, #LSB
7000025e:	f003 03ff 	and.w	r3, r3, #255	; 0xff
	b	.Lstrcmp_tail
70000262:	e047      	b.n	700002f4 <strcmp+0x2b4>

	.p2align 5,,12	/* Ensure at least 3 instructions in cache line.  */
.Loverlap2:
	and	tmp1, data1, const_m1, S2LO #16
70000264:	ea02 441c 	and.w	r4, r2, ip, lsr #16
	uadd8	syndrome, data1, const_m1
70000268:	fa82 f54c 	uadd8	r5, r2, ip
	eors	syndrome, tmp1, data2, S2LO #16
7000026c:	ea94 4513 	eors.w	r5, r4, r3, lsr #16
	sel	syndrome, syndrome, const_m1
70000270:	faa5 f58c 	sel	r5, r5, ip
	bne	4f
70000274:	d10a      	bne.n	7000028c <strcmp+0x24c>
	cbnz	syndrome, 5f
70000276:	b965      	cbnz	r5, 70000292 <strcmp+0x252>
	ldr	data2, [src2], #4
70000278:	f851 3b04 	ldr.w	r3, [r1], #4
	eor	tmp1, tmp1, data1
7000027c:	ea84 0402 	eor.w	r4, r4, r2
	cmp	tmp1, data2, S2HI #16
70000280:	ebb4 4f03 	cmp.w	r4, r3, lsl #16
	bne	6f
70000284:	d10c      	bne.n	700002a0 <strcmp+0x260>
	ldr	data1, [src1], #4
70000286:	f850 2b04 	ldr.w	r2, [r0], #4
	b	.Loverlap2
7000028a:	e7eb      	b.n	70000264 <strcmp+0x224>
4:
	S2LO	data2, data2, #16
7000028c:	ea4f 4313 	mov.w	r3, r3, lsr #16
	b	.Lstrcmp_tail
70000290:	e030      	b.n	700002f4 <strcmp+0x2b4>
5:
	ands	syndrome, syndrome, const_m1, S2LO #16
70000292:	ea15 451c 	ands.w	r5, r5, ip, lsr #16
	bne	.Lstrcmp_done_equal
70000296:	d128      	bne.n	700002ea <strcmp+0x2aa>

	ldrh	data2, [src2]
70000298:	880b      	ldrh	r3, [r1, #0]
	S2LO	data1, data1, #16
7000029a:	ea4f 4212 	mov.w	r2, r2, lsr #16
#ifdef __ARM_BIG_ENDIAN
	lsl	data2, data2, #16
#endif
	b	.Lstrcmp_tail
7000029e:	e029      	b.n	700002f4 <strcmp+0x2b4>

6:
	S2LO	data1, data1, #16
700002a0:	ea4f 4212 	mov.w	r2, r2, lsr #16
	and	data2, data2, const_m1, S2LO #16
700002a4:	ea03 431c 	and.w	r3, r3, ip, lsr #16
	b	.Lstrcmp_tail
700002a8:	e024      	b.n	700002f4 <strcmp+0x2b4>

	.p2align 5,,12	/* Ensure at least 3 instructions in cache line.  */
.Loverlap1:
	and	tmp1, data1, #LSB
700002aa:	f002 04ff 	and.w	r4, r2, #255	; 0xff
	uadd8	syndrome, data1, const_m1
700002ae:	fa82 f54c 	uadd8	r5, r2, ip
	eors	syndrome, tmp1, data2, S2LO #24
700002b2:	ea94 6513 	eors.w	r5, r4, r3, lsr #24
	sel	syndrome, syndrome, const_m1
700002b6:	faa5 f58c 	sel	r5, r5, ip
	bne	4f
700002ba:	d10a      	bne.n	700002d2 <strcmp+0x292>
	cbnz	syndrome, 5f
700002bc:	b965      	cbnz	r5, 700002d8 <strcmp+0x298>
	ldr	data2, [src2], #4
700002be:	f851 3b04 	ldr.w	r3, [r1], #4
	eor	tmp1, tmp1, data1
700002c2:	ea84 0402 	eor.w	r4, r4, r2
	cmp	tmp1, data2, S2HI #8
700002c6:	ebb4 2f03 	cmp.w	r4, r3, lsl #8
	bne	6f
700002ca:	d109      	bne.n	700002e0 <strcmp+0x2a0>
	ldr	data1, [src1], #4
700002cc:	f850 2b04 	ldr.w	r2, [r0], #4
	b	.Loverlap1
700002d0:	e7eb      	b.n	700002aa <strcmp+0x26a>
4:
	S2LO	data2, data2, #24
700002d2:	ea4f 6313 	mov.w	r3, r3, lsr #24
	b	.Lstrcmp_tail
700002d6:	e00d      	b.n	700002f4 <strcmp+0x2b4>
5:
	tst	syndrome, #LSB
700002d8:	f015 0fff 	tst.w	r5, #255	; 0xff
	bne	.Lstrcmp_done_equal
700002dc:	d105      	bne.n	700002ea <strcmp+0x2aa>
	ldr	data2, [src2]
700002de:	680b      	ldr	r3, [r1, #0]
6:
	S2LO	data1, data1, #8
700002e0:	ea4f 2212 	mov.w	r2, r2, lsr #8
	bic	data2, data2, #MSB
700002e4:	f023 437f 	bic.w	r3, r3, #4278190080	; 0xff000000
	b	.Lstrcmp_tail
700002e8:	e004      	b.n	700002f4 <strcmp+0x2b4>

.Lstrcmp_done_equal:
	mov	result, #0
700002ea:	f04f 0000 	mov.w	r0, #0
	.cfi_remember_state
	ldrd	r4, r5, [sp], #16
700002ee:	e8fd 4504 	ldrd	r4, r5, [sp], #16
	.cfi_restore 5
	/* R6/7 not used in this sequence.  */
	.cfi_restore 6
	.cfi_restore 7
	.cfi_adjust_cfa_offset -16
	epilogue push_ip=HAVE_PAC_LEAF
700002f2:	4770      	bx	lr

.Lstrcmp_tail:
	.cfi_restore_state
#ifndef __ARM_BIG_ENDIAN
	rev	data1, data1
700002f4:	ba12      	rev	r2, r2
	rev	data2, data2
700002f6:	ba1b      	rev	r3, r3
	/* Now everything looks big-endian...  */
#endif
	uadd8	tmp1, data1, const_m1
700002f8:	fa82 f44c 	uadd8	r4, r2, ip
	eor	tmp1, data1, data2
700002fc:	ea82 0403 	eor.w	r4, r2, r3
	sel	syndrome, tmp1, const_m1
70000300:	faa4 f58c 	sel	r5, r4, ip
	clz	tmp1, syndrome
70000304:	fab5 f485 	clz	r4, r5
	lsl	data1, data1, tmp1
70000308:	fa02 f204 	lsl.w	r2, r2, r4
	lsl	data2, data2, tmp1
7000030c:	fa03 f304 	lsl.w	r3, r3, r4
	lsr	result, data1, #24
70000310:	ea4f 6012 	mov.w	r0, r2, lsr #24
	ldrd	r4, r5, [sp], #16
70000314:	e8fd 4504 	ldrd	r4, r5, [sp], #16
	.cfi_restore 5
	/* R6/7 not used in this sequence.  */
	.cfi_restore 6
	.cfi_restore 7
	.cfi_adjust_cfa_offset -16
	sub	result, result, data2, lsr #24
70000318:	eba0 6013 	sub.w	r0, r0, r3, lsr #24
	epilogue push_ip=HAVE_PAC_LEAF
7000031c:	4770      	bx	lr
7000031e:	bf00      	nop

70000320 <_OffsetAbsSyms>:

#include <gen_offset.h>

#include "offsets_aarch32.c"

GEN_ABS_SYM_END
70000320:	4770      	bx	lr
70000322:	bf00      	nop

70000324 <main>:

int main(void)
{
#ifdef USING_ZEPHYR
   extern int rtos_main_zephyr(void);
   return rtos_main_zephyr();
70000324:	f000 b830 	b.w	70000388 <rtos_main_zephyr>

70000328 <tm_interrupt_handler>:
void* test_interrupt_handler = NULL;

/* Define the interrupt handler */
void tm_interrupt_handler(void* args)
{
   if (test_interrupt_handler != NULL)
70000328:	f245 7398 	movw	r3, #22424	; 0x5798
7000032c:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000330:	681b      	ldr	r3, [r3, #0]
70000332:	b103      	cbz	r3, 70000336 <tm_interrupt_handler+0xe>
   {
      /* Call the assigned handler function */
      ((void (*)(void)) test_interrupt_handler)();
70000334:	4718      	bx	r3
   }
}
70000336:	4770      	bx	lr

70000338 <main_task>:
}

void main_task(void* pvParameters)
{
   /* Start Thread-Metric tests */
   printk("Starting Thread-Metric tests...\r\n");
70000338:	f644 50d4 	movw	r0, #19924	; 0x4dd4
{
7000033c:	b510      	push	{r4, lr}

   /* Initialize custom interrupts*/
   test_interrupt_handler = tm_isr_message_handler;
7000033e:	f240 34b5 	movw	r4, #949	; 0x3b5
   printk("Starting Thread-Metric tests...\r\n");
70000342:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000346:	f000 fbab 	bl	70000aa0 <printk>
   test_interrupt_handler = tm_isr_message_handler;
7000034a:	f245 7398 	movw	r3, #22424	; 0x5798
7000034e:	f2c7 0300 	movt	r3, #28672	; 0x7000
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
70000352:	2204      	movs	r2, #4
   test_interrupt_handler = tm_isr_message_handler;
70000354:	f2c7 0400 	movt	r4, #28672	; 0x7000
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
70000358:	2101      	movs	r1, #1
7000035a:	200a      	movs	r0, #10
   test_interrupt_handler = tm_isr_message_handler;
7000035c:	601c      	str	r4, [r3, #0]
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
7000035e:	f000 ff7d 	bl	7000125c <z_vim_irq_priority_set>
   IRQ_CONNECT(SOFTWARE_INTERRUPT_ID, 1, tm_interrupt_handler, NULL, 0);
70000362:	2200      	movs	r2, #0
70000364:	2101      	movs	r1, #1
70000366:	200a      	movs	r0, #10
70000368:	f000 fbca 	bl	70000b00 <z_soc_irq_priority_set>
   irq_enable(SOFTWARE_INTERRUPT_ID);
7000036c:	200a      	movs	r0, #10
7000036e:	f000 fbc9 	bl	70000b04 <z_soc_irq_enable>
   z_vim_irq_enable(irq);
70000372:	200a      	movs	r0, #10
70000374:	f000 ff9e 	bl	700012b4 <z_vim_irq_enable>
   setup_interrupt();

   /* Call the main Thread-Metric function */
   main_inheritance();
70000378:	f000 f92a 	bl	700005d0 <main_inheritance>
	if (z_syscall_trap()) {
		return (k_tid_t) arch_syscall_invoke0(K_SYSCALL_K_SCHED_CURRENT_THREAD_QUERY);
	}
#endif
	compiler_barrier();
	return z_impl_k_sched_current_thread_query();
7000037c:	f002 fb00 	bl	70002980 <z_impl_k_sched_current_thread_query>

   /* Delete thread after completion */
   k_thread_abort(k_current_get());
}
70000380:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_ABORT);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_abort(thread);
70000384:	f002 bb02 	b.w	7000298c <z_impl_k_thread_abort>

70000388 <rtos_main_zephyr>:
/* Thread definition */
K_THREAD_DEFINE(main_thread, 512 /* STACKSIZE */, main_task, NULL, NULL, NULL, MAIN_TASK_PRI, K_USER, -1);

int rtos_main_zephyr(void)
{
   printk("Initializing Zephyr system...\r\n");
70000388:	f644 50f8 	movw	r0, #19960	; 0x4df8
{
7000038c:	b508      	push	{r3, lr}
   printk("Initializing Zephyr system...\r\n");
7000038e:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000392:	f000 fb85 	bl	70000aa0 <printk>
	z_impl_k_wakeup(thread);
70000396:	f245 0060 	movw	r0, #20576	; 0x5060
7000039a:	f2c7 0000 	movt	r0, #28672	; 0x7000
7000039e:	f002 fac9 	bl	70002934 <z_impl_k_wakeup>

   /* Create main task */
   k_thread_start(main_thread);

   printk("Main task created and running...\r\n");
700003a2:	f644 6018 	movw	r0, #19992	; 0x4e18
700003a6:	f2c7 0000 	movt	r0, #28672	; 0x7000
700003aa:	f000 fb79 	bl	70000aa0 <printk>

   return 0;
}
700003ae:	2000      	movs	r0, #0
700003b0:	bd08      	pop	{r3, pc}
700003b2:	bf00      	nop

700003b4 <tm_isr_message_handler>:

/* Minimal ISR: No prints, no dynamic formatting */
void tm_isr_message_handler(void)
{
   int i;
   tm_isr_counter++;
700003b4:	f645 2320 	movw	r3, #23072	; 0x5a20
   /* Generate message:
      [0] : Producer ID (1)
      [1] : Message counter (isr_message_counter)
      [2..MESSAGE_SIZE-2] : Pattern = 1000 + (isr_message_counter * 10) + index
      [MESSAGE_SIZE-1] : Checksum over first (MESSAGE_SIZE-1) words */
   message[0] = 1;
700003b8:	2001      	movs	r0, #1
   tm_isr_counter++;
700003ba:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
700003be:	b510      	push	{r4, lr}
   tm_isr_counter++;
700003c0:	681a      	ldr	r2, [r3, #0]
   message[1] = isr_message_counter;
700003c2:	f645 241c 	movw	r4, #23068	; 0x5a1c
   message[0] = 1;
700003c6:	f645 1c9c 	movw	ip, #22940	; 0x599c
   message[1] = isr_message_counter;
700003ca:	f2c7 0400 	movt	r4, #28672	; 0x7000
   tm_isr_counter++;
700003ce:	4402      	add	r2, r0
   message[0] = 1;
700003d0:	f2c7 0c00 	movt	ip, #28672	; 0x7000
   tm_isr_counter++;
700003d4:	601a      	str	r2, [r3, #0]
   message[1] = isr_message_counter;
700003d6:	4661      	mov	r1, ip
700003d8:	6823      	ldr	r3, [r4, #0]
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
700003da:	2202      	movs	r2, #2
   message[0] = 1;
700003dc:	f8cc 0000 	str.w	r0, [ip]
   message[1] = isr_message_counter;
700003e0:	f841 3f04 	str.w	r3, [r1, #4]!
   {
      message[i] = 1000 + (isr_message_counter * 10) + i;
700003e4:	6823      	ldr	r3, [r4, #0]
700003e6:	eb03 0383 	add.w	r3, r3, r3, lsl #2
700003ea:	eb02 0343 	add.w	r3, r2, r3, lsl #1
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
700003ee:	3201      	adds	r2, #1
      message[i] = 1000 + (isr_message_counter * 10) + i;
700003f0:	f503 737a 	add.w	r3, r3, #1000	; 0x3e8
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
700003f4:	2a1f      	cmp	r2, #31
      message[i] = 1000 + (isr_message_counter * 10) + i;
700003f6:	f841 3f04 	str.w	r3, [r1, #4]!
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
700003fa:	d1f3      	bne.n	700003e4 <tm_isr_message_handler+0x30>
700003fc:	4b0f      	ldr	r3, [pc, #60]	; (7000043c <tm_isr_message_handler+0x88>)
   unsigned long checksum = 0;
700003fe:	2200      	movs	r2, #0
70000400:	f103 007c 	add.w	r0, r3, #124	; 0x7c
      checksum += msg[i];
70000404:	f853 1f04 	ldr.w	r1, [r3, #4]!
   for (int i = 0; i < size; i++)
70000408:	4283      	cmp	r3, r0
      checksum += msg[i];
7000040a:	440a      	add	r2, r1
   for (int i = 0; i < size; i++)
7000040c:	d1fa      	bne.n	70000404 <tm_isr_message_handler+0x50>
   }
   message[MESSAGE_SIZE - 1] = compute_checksum(message, MESSAGE_SIZE - 1);

   /* Measure send latency using a precomputed PMU name */
   tm_pmu_profile_start(pmu_send_names[isr_message_counter]);
7000040e:	6820      	ldr	r0, [r4, #0]
70000410:	f245 739c 	movw	r3, #22428	; 0x579c
   message[MESSAGE_SIZE - 1] = compute_checksum(message, MESSAGE_SIZE - 1);
70000414:	f8cc 207c 	str.w	r2, [ip, #124]	; 0x7c
   tm_pmu_profile_start(pmu_send_names[isr_message_counter]);
70000418:	f2c7 0300 	movt	r3, #28672	; 0x7000
7000041c:	eb03 1000 	add.w	r0, r3, r0, lsl #4
70000420:	f000 f9e8 	bl	700007f4 <tm_pmu_profile_start>
   tm_queue_send_from_isr(0, message);
70000424:	f645 119c 	movw	r1, #22940	; 0x599c
70000428:	2000      	movs	r0, #0
7000042a:	f2c7 0100 	movt	r1, #28672	; 0x7000
7000042e:	f000 f98d 	bl	7000074c <tm_queue_send_from_isr>
   // tm_pmu_profile_end(pmu_send_names[isr_message_counter]);

   isr_message_counter++; /* Prepare for next iteration */
70000432:	6823      	ldr	r3, [r4, #0]
70000434:	3301      	adds	r3, #1
70000436:	6023      	str	r3, [r4, #0]
}
70000438:	bd10      	pop	{r4, pc}
7000043a:	bf00      	nop
7000043c:	70005998 	.word	0x70005998

70000440 <tm_priority_inheritance_initialize>:
 * Test Initialization
 *
 * Precomputes PMU keys, creates the mutex and tasks, and starts the test.
 ******************************************************************************/
static void tm_priority_inheritance_initialize(void)
{
70000440:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
   int i;
   tm_setup_pmu();
70000442:	f000 f8cf 	bl	700005e4 <tm_setup_pmu>
   tm_mutex_create(SHARED_MUTEX_ID);
70000446:	2001      	movs	r0, #1
70000448:	f645 2428 	movw	r4, #23080	; 0x5a28
7000044c:	f000 f98c 	bl	70000768 <tm_mutex_create>

   /* Precompute PMU keys (e.g. "INV00", "INV01", ... "INV29") */
   for (i = 0; i < ITERATION_COUNT; i++)
   {
      snprintf(pmu_names[i], PMU_KEY_LEN, "INV%02d", i);
70000450:	f644 6648 	movw	r6, #20040	; 0x4e48
   for (i = 0; i < ITERATION_COUNT; i++)
70000454:	2500      	movs	r5, #0
70000456:	f2c7 0400 	movt	r4, #28672	; 0x7000
7000045a:	f504 7780 	add.w	r7, r4, #256	; 0x100
      snprintf(pmu_names[i], PMU_KEY_LEN, "INV%02d", i);
7000045e:	f2c7 0600 	movt	r6, #28672	; 0x7000
70000462:	2108      	movs	r1, #8
70000464:	462b      	mov	r3, r5
70000466:	4620      	mov	r0, r4
70000468:	4632      	mov	r2, r6
   for (i = 0; i < ITERATION_COUNT; i++)
7000046a:	440c      	add	r4, r1
      snprintf(pmu_names[i], PMU_KEY_LEN, "INV%02d", i);
7000046c:	f002 ff1e 	bl	700032ac <snprintf>
   for (i = 0; i < ITERATION_COUNT; i++)
70000470:	42bc      	cmp	r4, r7
70000472:	f105 0501 	add.w	r5, r5, #1
70000476:	d1f4      	bne.n	70000462 <tm_priority_inheritance_initialize+0x22>
   }

   tm_thread_create(LOW_TASK_ID, LOW_TASK_PRIO, LowPrioTask);
70000478:	f240 5285 	movw	r2, #1413	; 0x585
7000047c:	2114      	movs	r1, #20
7000047e:	2002      	movs	r0, #2
70000480:	f2c7 0200 	movt	r2, #28672	; 0x7000
70000484:	f000 f90a 	bl	7000069c <tm_thread_create>
   tm_thread_create(MED_TASK_ID, MED_TASK_PRIO, MedPrioTask);
70000488:	f240 5221 	movw	r2, #1313	; 0x521
7000048c:	210a      	movs	r1, #10
7000048e:	f2c7 0200 	movt	r2, #28672	; 0x7000
70000492:	2001      	movs	r0, #1
70000494:	f000 f902 	bl	7000069c <tm_thread_create>
   tm_thread_create(HIGH_TASK_ID, HIGH_TASK_PRIO, HighPrioTask);
70000498:	f240 42cd 	movw	r2, #1229	; 0x4cd
7000049c:	2105      	movs	r1, #5
7000049e:	f2c7 0200 	movt	r2, #28672	; 0x7000
700004a2:	2000      	movs	r0, #0
700004a4:	f000 f8fa 	bl	7000069c <tm_thread_create>

   tm_thread_resume(LOW_TASK_ID);
700004a8:	2002      	movs	r0, #2
700004aa:	f000 f925 	bl	700006f8 <tm_thread_resume>
   tm_thread_resume(MED_TASK_ID);
700004ae:	2001      	movs	r0, #1
700004b0:	f000 f922 	bl	700006f8 <tm_thread_resume>
   tm_thread_resume(HIGH_TASK_ID);
700004b4:	2000      	movs	r0, #0
700004b6:	f000 f91f 	bl	700006f8 <tm_thread_resume>

   printf("[Init] Priority Inheritance detection test started for %d cycles.\r\n", ITERATION_COUNT);
700004ba:	f644 6050 	movw	r0, #20048	; 0x4e50
}
700004be:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
   printf("[Init] Priority Inheritance detection test started for %d cycles.\r\n", ITERATION_COUNT);
700004c2:	2120      	movs	r1, #32
700004c4:	f2c7 0000 	movt	r0, #28672	; 0x7000
700004c8:	f000 baea 	b.w	70000aa0 <printk>

700004cc <HighPrioTask>:
{
700004cc:	b538      	push	{r3, r4, r5, lr}
700004ce:	f645 2428 	movw	r4, #23080	; 0x5a28
700004d2:	f2c7 0400 	movt	r4, #28672	; 0x7000
700004d6:	f504 7580 	add.w	r5, r4, #256	; 0x100
700004da:	e005      	b.n	700004e8 <HighPrioTask+0x1c>
      tm_thread_sleep_ticks(5);
700004dc:	2005      	movs	r0, #5
   for (int i = 0; i < ITERATION_COUNT; i++)
700004de:	3408      	adds	r4, #8
      tm_thread_sleep_ticks(5);
700004e0:	f000 f930 	bl	70000744 <tm_thread_sleep_ticks>
   for (int i = 0; i < ITERATION_COUNT; i++)
700004e4:	42ac      	cmp	r4, r5
700004e6:	d016      	beq.n	70000516 <HighPrioTask+0x4a>
      tm_thread_sleep_ticks(15);
700004e8:	200f      	movs	r0, #15
700004ea:	f000 f92b 	bl	70000744 <tm_thread_sleep_ticks>
      tm_pmu_profile_start(pmu_names[i]);
700004ee:	4620      	mov	r0, r4
700004f0:	f000 f980 	bl	700007f4 <tm_pmu_profile_start>
      if (tm_mutex_get(SHARED_MUTEX_ID) == TM_SUCCESS)
700004f4:	2001      	movs	r0, #1
700004f6:	f000 f949 	bl	7000078c <tm_mutex_get>
700004fa:	2800      	cmp	r0, #0
700004fc:	d1ee      	bne.n	700004dc <HighPrioTask+0x10>
         tm_pmu_profile_end(pmu_names[i]);
700004fe:	4620      	mov	r0, r4
   for (int i = 0; i < ITERATION_COUNT; i++)
70000500:	3408      	adds	r4, #8
         tm_pmu_profile_end(pmu_names[i]);
70000502:	f000 f9b7 	bl	70000874 <tm_pmu_profile_end>
         tm_mutex_put(SHARED_MUTEX_ID);
70000506:	2001      	movs	r0, #1
70000508:	f000 f958 	bl	700007bc <tm_mutex_put>
      tm_thread_sleep_ticks(5);
7000050c:	2005      	movs	r0, #5
7000050e:	f000 f919 	bl	70000744 <tm_thread_sleep_ticks>
   for (int i = 0; i < ITERATION_COUNT; i++)
70000512:	42ac      	cmp	r4, r5
70000514:	d1e8      	bne.n	700004e8 <HighPrioTask+0x1c>
}
70000516:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
   tm_thread_suspend(HIGH_TASK_ID);
7000051a:	2000      	movs	r0, #0
7000051c:	f000 b8fa 	b.w	70000714 <tm_thread_suspend>

70000520 <MedPrioTask>:
{
70000520:	b538      	push	{r3, r4, r5, lr}
70000522:	f645 2524 	movw	r5, #23076	; 0x5a24
70000526:	f2c7 0500 	movt	r5, #28672	; 0x7000
7000052a:	f44f 737a 	mov.w	r3, #1000	; 0x3e8
         __asm__ volatile("nop");
7000052e:	bf00      	nop
      for (int i = 0; i < 1000; i++)
70000530:	3b01      	subs	r3, #1
70000532:	d1fc      	bne.n	7000052e <MedPrioTask+0xe>
      tm_thread_sleep_ticks(2);
70000534:	2002      	movs	r0, #2
70000536:	f000 f905 	bl	70000744 <tm_thread_sleep_ticks>
      if (inversion_count >= ITERATION_COUNT)
7000053a:	682b      	ldr	r3, [r5, #0]
7000053c:	2b1f      	cmp	r3, #31
7000053e:	d9f4      	bls.n	7000052a <MedPrioTask+0xa>
         tm_thread_sleep_ticks(10);
70000540:	200a      	movs	r0, #10
70000542:	f645 2428 	movw	r4, #23080	; 0x5a28
70000546:	f000 f8fd 	bl	70000744 <tm_thread_sleep_ticks>
         printf("\r\n*** Test Complete ***\r\n");
7000054a:	f644 6094 	movw	r0, #20116	; 0x4e94
7000054e:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000552:	f000 faa5 	bl	70000aa0 <printk>
         printf("Total inversion cycles completed: %lu\r\n", inversion_count);
70000556:	f644 60b0 	movw	r0, #20144	; 0x4eb0
7000055a:	6829      	ldr	r1, [r5, #0]
7000055c:	f2c7 0400 	movt	r4, #28672	; 0x7000
70000560:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000564:	f504 7580 	add.w	r5, r4, #256	; 0x100
70000568:	f000 fa9a 	bl	70000aa0 <printk>
            tm_pmu_profile_print(pmu_names[i]);
7000056c:	4620      	mov	r0, r4
         for (int i = 0; i < ITERATION_COUNT; i++)
7000056e:	3408      	adds	r4, #8
            tm_pmu_profile_print(pmu_names[i]);
70000570:	f000 f9cc 	bl	7000090c <tm_pmu_profile_print>
         for (int i = 0; i < ITERATION_COUNT; i++)
70000574:	42ac      	cmp	r4, r5
70000576:	d1f9      	bne.n	7000056c <MedPrioTask+0x4c>
}
70000578:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
         tm_thread_exit(MED_TASK_ID);
7000057c:	2001      	movs	r0, #1
7000057e:	f000 b8d7 	b.w	70000730 <tm_thread_exit>
70000582:	bf00      	nop

70000584 <LowPrioTask>:
{
70000584:	b538      	push	{r3, r4, r5, lr}
         inversion_count++; /* Completed inversion cycle */
70000586:	f645 2524 	movw	r5, #23076	; 0x5a24
{
7000058a:	2420      	movs	r4, #32
         inversion_count++; /* Completed inversion cycle */
7000058c:	f2c7 0500 	movt	r5, #28672	; 0x7000
      if (tm_mutex_get(SHARED_MUTEX_ID) == TM_SUCCESS)
70000590:	2001      	movs	r0, #1
70000592:	f000 f8fb 	bl	7000078c <tm_mutex_get>
70000596:	b150      	cbz	r0, 700005ae <LowPrioTask+0x2a>
      tm_thread_sleep_ticks(1);
70000598:	2001      	movs	r0, #1
7000059a:	f000 f8d3 	bl	70000744 <tm_thread_sleep_ticks>
   for (int i = 0; i < ITERATION_COUNT; i++)
7000059e:	3c01      	subs	r4, #1
700005a0:	d1f6      	bne.n	70000590 <LowPrioTask+0xc>
}
700005a2:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
   tm_thread_suspend(LOW_TASK_ID);
700005a6:	2002      	movs	r0, #2
700005a8:	f000 b8b4 	b.w	70000714 <tm_thread_suspend>
            __asm__ volatile("nop");
700005ac:	bf00      	nop
         while (tm_task_priority_get(LOW_TASK_ID) == LOW_TASK_PRIO)
700005ae:	2002      	movs	r0, #2
700005b0:	f000 f916 	bl	700007e0 <tm_task_priority_get>
700005b4:	2814      	cmp	r0, #20
700005b6:	d0f9      	beq.n	700005ac <LowPrioTask+0x28>
         tm_mutex_put(SHARED_MUTEX_ID);
700005b8:	2001      	movs	r0, #1
700005ba:	f000 f8ff 	bl	700007bc <tm_mutex_put>
         inversion_count++; /* Completed inversion cycle */
700005be:	682b      	ldr	r3, [r5, #0]
      tm_thread_sleep_ticks(1);
700005c0:	2001      	movs	r0, #1
         inversion_count++; /* Completed inversion cycle */
700005c2:	3301      	adds	r3, #1
700005c4:	602b      	str	r3, [r5, #0]
      tm_thread_sleep_ticks(1);
700005c6:	f000 f8bd 	bl	70000744 <tm_thread_sleep_ticks>
   for (int i = 0; i < ITERATION_COUNT; i++)
700005ca:	3c01      	subs	r4, #1
700005cc:	d1e0      	bne.n	70000590 <LowPrioTask+0xc>
700005ce:	e7e8      	b.n	700005a2 <LowPrioTask+0x1e>

700005d0 <main_inheritance>:
 *
 * Initializes the RTOS and starts the test.
 ******************************************************************************/
int main_inheritance(void)
{
   tm_initialize(tm_priority_inheritance_initialize);
700005d0:	f240 4041 	movw	r0, #1089	; 0x441
700005d4:	f2c7 0000 	movt	r0, #28672	; 0x7000
{
700005d8:	b508      	push	{r3, lr}
   tm_initialize(tm_priority_inheritance_initialize);
700005da:	f000 f85d 	bl	70000698 <tm_initialize>
   return 0;
}
700005de:	2000      	movs	r0, #0
700005e0:	bd08      	pop	{r3, pc}
700005e2:	bf00      	nop

700005e4 <tm_setup_pmu>:
/* --------------------------------------------------------------------------
 * PMU Initialization (called at system boot)
 * -------------------------------------------------------------------------- */
int tm_setup_pmu(void)
{
   printk("Initializing PMU...\r\n");
700005e4:	f644 60d8 	movw	r0, #20184	; 0x4ed8
{
700005e8:	b538      	push	{r3, r4, r5, lr}
   printk("Initializing PMU...\r\n");
700005ea:	f2c7 0000 	movt	r0, #28672	; 0x7000
700005ee:	f000 fa57 	bl	70000aa0 <printk>

/* Performance Monitor Control Register (PMCR) */
__STATIC_FORCEINLINE uint32_t pmu_read_pmcr(void)
{
    uint32_t val;
    __asm__ volatile ("mrc p15, 0, %0, c9, c12, 0" : "=r" (val));
700005f2:	ee19 3f1c 	mrc	15, 0, r3, cr9, cr12, {0}

   /* Disable all counters (PMCR.E=0) */
   uint32_t pmcr = pmu_read_pmcr();
   pmcr &= ~0x1;
700005f6:	f023 0301 	bic.w	r3, r3, #1
    return val;
}

__STATIC_FORCEINLINE void pmu_write_pmcr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
700005fa:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}
}

/* Performance Monitor Count Enable Clear Register (PMCNTENCLR) */
__STATIC_FORCEINLINE void pmu_write_cntenclr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 2" : : "r" (val));
700005fe:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
70000602:	ee09 3f5c 	mcr	15, 0, r3, cr9, cr12, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
70000606:	2306      	movs	r3, #6
70000608:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}
    return val;
}

__STATIC_FORCEINLINE void pmu_write_pmccntr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 0" : : "r" (val));
7000060c:	2400      	movs	r4, #0
7000060e:	ee09 4f1d 	mcr	15, 0, r4, cr9, cr13, {0}
}

/* Event Counter Selection Register (PMSELR) */
__STATIC_FORCEINLINE void pmu_select_event_counter(uint32_t counter_idx)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
70000612:	ee09 4fbc 	mcr	15, 0, r4, cr9, cr12, {5}

   /* Configure event counters */
   for (uint32_t i = 0; i < gPmuConfig.numEventCounters; i++)
   {
      pmu_select_event_counter(i);
      pmu_write_evtyper(gPmuConfig.eventCounters[i].type);
70000616:	f24b 3380 	movw	r3, #45952	; 0xb380
7000061a:	f2c7 0300 	movt	r3, #28672	; 0x7000
}

/* Event Type Register (PMXEVTYPER) */
__STATIC_FORCEINLINE void pmu_write_evtyper(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
7000061e:	685a      	ldr	r2, [r3, #4]
70000620:	ee09 2f3d 	mcr	15, 0, r2, cr9, cr13, {1}
    return val;
}

__STATIC_FORCEINLINE void pmu_write_evcounter(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
70000624:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
70000628:	2501      	movs	r5, #1
7000062a:	ee09 5fbc 	mcr	15, 0, r5, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
7000062e:	68da      	ldr	r2, [r3, #12]
70000630:	ee09 2f3d 	mcr	15, 0, r2, cr9, cr13, {1}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
70000634:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
70000638:	2202      	movs	r2, #2
7000063a:	ee09 2fbc 	mcr	15, 0, r2, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
7000063e:	695b      	ldr	r3, [r3, #20]
70000640:	ee09 3f3d 	mcr	15, 0, r3, cr9, cr13, {1}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
70000644:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 1" : : "r" (val));
70000648:	2307      	movs	r3, #7
7000064a:	f2c8 0300 	movt	r3, #32768	; 0x8000
7000064e:	ee09 3f3c 	mcr	15, 0, r3, cr9, cr12, {1}
    __asm__ volatile ("mrc p15, 0, %0, c9, c12, 0" : "=r" (val));
70000652:	ee19 3f1c 	mrc	15, 0, r3, cr9, cr12, {0}
   /*    bit31 => cycle counter, plus bits [0..(numEventCounters-1)] => event counters */
   pmu_write_cntenset((1 << 31) | ((1 << gPmuConfig.numEventCounters) - 1));

   /* Enable counters in PMCR (bit[0] = E=1) */
   pmcr = pmu_read_pmcr();
   pmcr |= 0x1;
70000656:	432b      	orrs	r3, r5
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
70000658:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}

/* PMU User Access Enable Register (PMUSERENR) */
__STATIC_FORCEINLINE void pmu_enable_user_access(void)
{
    uint32_t val;
    __asm__ volatile ("mrc p15, 0, %0, c9, c14, 0" : "=r" (val));
7000065c:	ee19 3f1e 	mrc	15, 0, r3, cr9, cr14, {0}
    val |= 1;  // Enable user mode access
70000660:	432b      	orrs	r3, r5
    __asm__ volatile ("mcr p15, 0, %0, c9, c14, 0" : : "r" (val));
70000662:	ee09 3f1e 	mcr	15, 0, r3, cr9, cr14, {0}
/* --------------------------------------------------------------------------
 * Init for the Chache Hits/Misses profile structure
 * -------------------------------------------------------------------------- */
void pmu_init_profile(void)
{
   memset(&gProfileObject, 0, sizeof(gProfileObject));
70000666:	f645 3328 	movw	r3, #23336	; 0x5b28
7000066a:	4621      	mov	r1, r4
7000066c:	f241 320c 	movw	r2, #4876	; 0x130c
70000670:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000674:	4618      	mov	r0, r3
70000676:	f002 fdb3 	bl	700031e0 <memset>
   gProfileObject.logIndex = 0;
   gProfileObject.numEvents = PMU_MAX_EVENT_COUNTERS;
7000067a:	2203      	movs	r2, #3
7000067c:	f500 5380 	add.w	r3, r0, #4096	; 0x1000
   printk("PMU Initialized.\r\n");
70000680:	f644 60f0 	movw	r0, #20208	; 0x4ef0
   gProfileObject.bCycleCounter = 1; /* We use cycle counter */
70000684:	f883 5308 	strb.w	r5, [r3, #776]	; 0x308
   printk("PMU Initialized.\r\n");
70000688:	f2c7 0000 	movt	r0, #28672	; 0x7000
   gProfileObject.numEvents = PMU_MAX_EVENT_COUNTERS;
7000068c:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
   printk("PMU Initialized.\r\n");
70000690:	f000 fa06 	bl	70000aa0 <printk>
}
70000694:	4620      	mov	r0, r4
70000696:	bd38      	pop	{r3, r4, r5, pc}

70000698 <tm_initialize>:
   test_initialization_function();
70000698:	4700      	bx	r0
7000069a:	bf00      	nop

7000069c <tm_thread_create>:
{
7000069c:	b5f0      	push	{r4, r5, r6, r7, lr}
   tid = k_thread_create(&test_thread[thread_id], test_stack[thread_id], TM_TEST_STACK_SIZE, entry_function, NULL, NULL,
7000069e:	f245 04d8 	movw	r4, #20696	; 0x50d8
700006a2:	ebc0 1500 	rsb	r5, r0, r0, lsl #4
700006a6:	f2c7 0400 	movt	r4, #28672	; 0x7000
{
700006aa:	4613      	mov	r3, r2
700006ac:	b089      	sub	sp, #36	; 0x24
700006ae:	f04f 36ff 	mov.w	r6, #4294967295	; 0xffffffff
   tid = k_thread_create(&test_thread[thread_id], test_stack[thread_id], TM_TEST_STACK_SIZE, entry_function, NULL, NULL,
700006b2:	eb04 04c5 	add.w	r4, r4, r5, lsl #3
700006b6:	f04f 37ff 	mov.w	r7, #4294967295	; 0xffffffff
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
700006ba:	2500      	movs	r5, #0
700006bc:	f44f 6280 	mov.w	r2, #1024	; 0x400
700006c0:	9103      	str	r1, [sp, #12]
700006c2:	f247 1180 	movw	r1, #29056	; 0x7180
700006c6:	9504      	str	r5, [sp, #16]
700006c8:	f2c7 0100 	movt	r1, #28672	; 0x7000
700006cc:	e9cd 5501 	strd	r5, r5, [sp, #4]
700006d0:	eb01 2180 	add.w	r1, r1, r0, lsl #10
700006d4:	9500      	str	r5, [sp, #0]
700006d6:	4620      	mov	r0, r4
700006d8:	e9cd 6706 	strd	r6, r7, [sp, #24]
700006dc:	f001 fd48 	bl	70002170 <z_impl_k_thread_create>
700006e0:	4605      	mov	r5, r0
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_SUSPEND);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_suspend(thread);
700006e2:	4620      	mov	r0, r4
700006e4:	f001 feee 	bl	700024c4 <z_impl_k_thread_suspend>
	z_impl_k_wakeup(thread);
700006e8:	4620      	mov	r0, r4
700006ea:	f002 f923 	bl	70002934 <z_impl_k_wakeup>
}
700006ee:	1b60      	subs	r0, r4, r5
700006f0:	bf18      	it	ne
700006f2:	2001      	movne	r0, #1
700006f4:	b009      	add	sp, #36	; 0x24
700006f6:	bdf0      	pop	{r4, r5, r6, r7, pc}

700006f8 <tm_thread_resume>:
{
700006f8:	b508      	push	{r3, lr}
   k_thread_resume(&test_thread[thread_id]);
700006fa:	f245 03d8 	movw	r3, #20696	; 0x50d8
700006fe:	ebc0 1000 	rsb	r0, r0, r0, lsl #4
70000702:	f2c7 0300 	movt	r3, #28672	; 0x7000
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_RESUME);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_resume(thread);
70000706:	eb03 00c0 	add.w	r0, r3, r0, lsl #3
7000070a:	f002 f801 	bl	70002710 <z_impl_k_thread_resume>
}
7000070e:	2000      	movs	r0, #0
70000710:	bd08      	pop	{r3, pc}
70000712:	bf00      	nop

70000714 <tm_thread_suspend>:
{
70000714:	b508      	push	{r3, lr}
   k_thread_suspend(&test_thread[thread_id]);
70000716:	f245 03d8 	movw	r3, #20696	; 0x50d8
7000071a:	ebc0 1000 	rsb	r0, r0, r0, lsl #4
7000071e:	f2c7 0300 	movt	r3, #28672	; 0x7000
	z_impl_k_thread_suspend(thread);
70000722:	eb03 00c0 	add.w	r0, r3, r0, lsl #3
70000726:	f001 fecd 	bl	700024c4 <z_impl_k_thread_suspend>
}
7000072a:	2000      	movs	r0, #0
7000072c:	bd08      	pop	{r3, pc}
7000072e:	bf00      	nop

70000730 <tm_thread_exit>:
   k_thread_suspend(&test_thread[thread_id]);
70000730:	f245 03d8 	movw	r3, #20696	; 0x50d8
70000734:	ebc0 1000 	rsb	r0, r0, r0, lsl #4
70000738:	f2c7 0300 	movt	r3, #28672	; 0x7000
7000073c:	eb03 00c0 	add.w	r0, r3, r0, lsl #3
70000740:	f001 bec0 	b.w	700024c4 <z_impl_k_thread_suspend>

70000744 <tm_thread_sleep_ticks>:
   k_sleep(K_TICKS(ticks));
70000744:	17c1      	asrs	r1, r0, #31
	return z_impl_k_sleep(timeout);
70000746:	f002 b8e7 	b.w	70002918 <z_impl_k_sleep>
7000074a:	bf00      	nop

7000074c <tm_queue_send_from_isr>:
{
7000074c:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
70000750:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
   return k_msgq_put(&test_msgq[queue_id], message_ptr, K_FOREVER);
70000754:	f646 6c84 	movw	ip, #28292	; 0x6e84
70000758:	eb00 0040 	add.w	r0, r0, r0, lsl #1
7000075c:	f2c7 0c00 	movt	ip, #28672	; 0x7000
		union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm2 = { .val = timeout };
		return (int) arch_syscall_invoke4(parm0.x, parm1.x, parm2.split.lo, parm2.split.hi, K_SYSCALL_K_MSGQ_PUT);
	}
#endif
	compiler_barrier();
	return z_impl_k_msgq_put(msgq, data, timeout);
70000760:	eb0c 1000 	add.w	r0, ip, r0, lsl #4
70000764:	f001 bb3c 	b.w	70001de0 <z_impl_k_msgq_put>

70000768 <tm_mutex_create>:
   if (mutex_id < 0 || mutex_id >= TM_TEST_NUM_SEMAPHORES)
70000768:	2803      	cmp	r0, #3
7000076a:	d901      	bls.n	70000770 <tm_mutex_create+0x8>
      return TM_ERROR;
7000076c:	2001      	movs	r0, #1
}
7000076e:	4770      	bx	lr
{
70000770:	b508      	push	{r3, lr}
   k_mutex_init(&tm_mutex_array[mutex_id]);
70000772:	f646 6334 	movw	r3, #28212	; 0x6e34
70000776:	eb00 0080 	add.w	r0, r0, r0, lsl #2
7000077a:	f2c7 0300 	movt	r3, #28672	; 0x7000
	return z_impl_k_mutex_init(mutex);
7000077e:	eb03 0080 	add.w	r0, r3, r0, lsl #2
70000782:	f001 fba3 	bl	70001ecc <z_impl_k_mutex_init>
   return TM_SUCCESS;
70000786:	2000      	movs	r0, #0
}
70000788:	bd08      	pop	{r3, pc}
7000078a:	bf00      	nop

7000078c <tm_mutex_get>:
   if (mutex_id < 0 || mutex_id >= TM_TEST_NUM_SEMAPHORES)
7000078c:	2803      	cmp	r0, #3
7000078e:	d901      	bls.n	70000794 <tm_mutex_get+0x8>
      return TM_ERROR;
70000790:	2001      	movs	r0, #1
}
70000792:	4770      	bx	lr
{
70000794:	b508      	push	{r3, lr}
   status = k_mutex_lock(&tm_mutex_array[mutex_id], K_FOREVER);
70000796:	f646 6134 	movw	r1, #28212	; 0x6e34
7000079a:	eb00 0080 	add.w	r0, r0, r0, lsl #2
	return z_impl_k_mutex_lock(mutex, timeout);
7000079e:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
700007a2:	f2c7 0100 	movt	r1, #28672	; 0x7000
700007a6:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
700007aa:	eb01 0080 	add.w	r0, r1, r0, lsl #2
700007ae:	f001 fb95 	bl	70001edc <z_impl_k_mutex_lock>
   return (status == 0) ? TM_SUCCESS : TM_ERROR;
700007b2:	3800      	subs	r0, #0
700007b4:	bf18      	it	ne
700007b6:	2001      	movne	r0, #1
}
700007b8:	bd08      	pop	{r3, pc}
700007ba:	bf00      	nop

700007bc <tm_mutex_put>:
   if (mutex_id < 0 || mutex_id >= TM_TEST_NUM_SEMAPHORES)
700007bc:	2803      	cmp	r0, #3
700007be:	d901      	bls.n	700007c4 <tm_mutex_put+0x8>
      return TM_ERROR;
700007c0:	2001      	movs	r0, #1
}
700007c2:	4770      	bx	lr
{
700007c4:	b508      	push	{r3, lr}
   k_mutex_unlock(&tm_mutex_array[mutex_id]);
700007c6:	f646 6334 	movw	r3, #28212	; 0x6e34
700007ca:	eb00 0080 	add.w	r0, r0, r0, lsl #2
700007ce:	f2c7 0300 	movt	r3, #28672	; 0x7000
	return z_impl_k_mutex_unlock(mutex);
700007d2:	eb03 0080 	add.w	r0, r3, r0, lsl #2
700007d6:	f001 fbff 	bl	70001fd8 <z_impl_k_mutex_unlock>
   return TM_SUCCESS;
700007da:	2000      	movs	r0, #0
}
700007dc:	bd08      	pop	{r3, pc}
700007de:	bf00      	nop

700007e0 <tm_task_priority_get>:
   return (int) k_thread_priority_get(&test_thread[thread_id]);
700007e0:	f245 03d8 	movw	r3, #20696	; 0x50d8
700007e4:	ebc0 1000 	rsb	r0, r0, r0, lsl #4
700007e8:	f2c7 0300 	movt	r3, #28672	; 0x7000
	return z_impl_k_thread_priority_get(thread);
700007ec:	eb03 00c0 	add.w	r0, r3, r0, lsl #3
700007f0:	f001 bc86 	b.w	70002100 <z_impl_k_thread_priority_get>

700007f4 <tm_pmu_profile_start>:
 * - Read "start" values
 * - Store them in the next free slot
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_start(const char* name)
{
   uint32_t idx = gProfileObject.logIndex;
700007f4:	f645 3c28 	movw	ip, #23336	; 0x5b28
700007f8:	f2c7 0c00 	movt	ip, #28672	; 0x7000
{
700007fc:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   uint32_t idx = gProfileObject.logIndex;
70000800:	f8dc 4000 	ldr.w	r4, [ip]
   if (idx >= PMU_MAX_LOG_ENTRIES)
70000804:	2c3f      	cmp	r4, #63	; 0x3f
70000806:	d833      	bhi.n	70000870 <tm_pmu_profile_start+0x7c>
      /* no more space */
      return;
   }

   TM_PMUProfilePoint* p = &gProfileObject.point[idx];
   p->name = name;
70000808:	eb04 02c4 	add.w	r2, r4, r4, lsl #3

   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
7000080c:	f50c 5380 	add.w	r3, ip, #4096	; 0x1000
   p->name = name;
70000810:	eb04 0242 	add.w	r2, r4, r2, lsl #1
70000814:	ea4f 0ec4 	mov.w	lr, r4, lsl #3
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000818:	f8d3 5304 	ldr.w	r5, [r3, #772]	; 0x304
   p->name = name;
7000081c:	eb0c 0182 	add.w	r1, ip, r2, lsl #2
70000820:	0092      	lsls	r2, r2, #2
70000822:	6048      	str	r0, [r1, #4]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000824:	b1dd      	cbz	r5, 7000085e <tm_pmu_profile_start+0x6a>
70000826:	f24b 3680 	movw	r6, #45952	; 0xb380
7000082a:	3234      	adds	r2, #52	; 0x34
7000082c:	2300      	movs	r3, #0
7000082e:	f2c7 0600 	movt	r6, #28672	; 0x7000
70000832:	4462      	add	r2, ip
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
70000834:	461f      	mov	r7, r3
70000836:	f106 0804 	add.w	r8, r6, #4
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
7000083a:	ee09 3fbc 	mcr	15, 0, r3, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
7000083e:	ee09 7f5d 	mcr	15, 0, r7, cr9, cr13, {2}
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 2" : "=r" (val));
70000842:	ee19 0f5d 	mrc	15, 0, r0, cr9, cr13, {2}
   {
      pmu_select_event_counter(i);
      /* Reset the counters to 0 */
      pmu_write_evcounter(0);
      p->eventStart[i] = pmu_read_evcounter();
70000846:	f842 0f04 	str.w	r0, [r2, #4]!
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
7000084a:	310c      	adds	r1, #12

      /* Also store name & type */
      p->events[i].name = gPmuEventCfg[i].name;
7000084c:	f856 0033 	ldr.w	r0, [r6, r3, lsl #3]
70000850:	6088      	str	r0, [r1, #8]
      p->events[i].type = gPmuEventCfg[i].type;
70000852:	f858 0033 	ldr.w	r0, [r8, r3, lsl #3]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000856:	3301      	adds	r3, #1
      p->events[i].type = gPmuEventCfg[i].type;
70000858:	60c8      	str	r0, [r1, #12]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
7000085a:	42ab      	cmp	r3, r5
7000085c:	d1ed      	bne.n	7000083a <tm_pmu_profile_start+0x46>
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 0" : "=r" (val));
7000085e:	ee19 3f1d 	mrc	15, 0, r3, cr9, cr13, {0}
   }
   /* Immediately read them as "start" values */
   p->cycleCountStart = pmu_read_pmccntr();
70000862:	44a6      	add	lr, r4
70000864:	eb04 044e 	add.w	r4, r4, lr, lsl #1
70000868:	eb0c 0c84 	add.w	ip, ip, r4, lsl #2
7000086c:	f8cc 3008 	str.w	r3, [ip, #8]
}
70000870:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

70000874 <tm_pmu_profile_end>:
 * - Read PMU Registers for "end" values
 * - Compute delta
 * - Increase log index
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_end(const char* name)
{
70000874:	b570      	push	{r4, r5, r6, lr}
   uint32_t idx = gProfileObject.logIndex;
70000876:	f645 3e28 	movw	lr, #23336	; 0x5b28
7000087a:	f2c7 0e00 	movt	lr, #28672	; 0x7000
7000087e:	f8de 4000 	ldr.w	r4, [lr]
   if (idx >= PMU_MAX_LOG_ENTRIES)
70000882:	2c3f      	cmp	r4, #63	; 0x3f
70000884:	d83a      	bhi.n	700008fc <tm_pmu_profile_end+0x88>
70000886:	ee19 1f1d 	mrc	15, 0, r1, cr9, cr13, {0}
   //    return;
   // }

   /* Read end counters */
   p->cycleCountEnd = pmu_read_pmccntr();
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
7000088a:	f50e 5380 	add.w	r3, lr, #4096	; 0x1000
   p->cycleCountEnd = pmu_read_pmccntr();
7000088e:	eb04 0cc4 	add.w	ip, r4, r4, lsl #3
70000892:	00e5      	lsls	r5, r4, #3
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000894:	f8d3 6304 	ldr.w	r6, [r3, #772]	; 0x304
   p->cycleCountEnd = pmu_read_pmccntr();
70000898:	eb04 0c4c 	add.w	ip, r4, ip, lsl #1
7000089c:	eb0e 038c 	add.w	r3, lr, ip, lsl #2
700008a0:	ea4f 0c8c 	mov.w	ip, ip, lsl #2
700008a4:	60d9      	str	r1, [r3, #12]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700008a6:	b356      	cbz	r6, 700008fe <tm_pmu_profile_end+0x8a>
700008a8:	2300      	movs	r3, #0
700008aa:	f10c 0240 	add.w	r2, ip, #64	; 0x40
700008ae:	4472      	add	r2, lr
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
700008b0:	ee09 3fbc 	mcr	15, 0, r3, cr9, cr12, {5}
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 2" : "=r" (val));
700008b4:	ee19 0f5d 	mrc	15, 0, r0, cr9, cr13, {2}
   {
      pmu_select_event_counter(i);
      p->eventEnd[i] = pmu_read_evcounter();
700008b8:	f842 0f04 	str.w	r0, [r2, #4]!
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700008bc:	3301      	adds	r3, #1
700008be:	42b3      	cmp	r3, r6
700008c0:	d1f6      	bne.n	700008b0 <tm_pmu_profile_end+0x3c>
   }

   /* Compute deltas */
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
700008c2:	4425      	add	r5, r4
700008c4:	f10c 0034 	add.w	r0, ip, #52	; 0x34
700008c8:	eb04 0545 	add.w	r5, r4, r5, lsl #1
700008cc:	f10c 0c1c 	add.w	ip, ip, #28
700008d0:	eb0e 0585 	add.w	r5, lr, r5, lsl #2
700008d4:	eb03 0343 	add.w	r3, r3, r3, lsl #1
700008d8:	4470      	add	r0, lr
700008da:	68ae      	ldr	r6, [r5, #8]
700008dc:	44f4      	add	ip, lr
700008de:	2200      	movs	r2, #0
700008e0:	1b89      	subs	r1, r1, r6
700008e2:	6129      	str	r1, [r5, #16]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
   {
      uint32_t diff = p->eventEnd[i] - p->eventStart[i];
700008e4:	6901      	ldr	r1, [r0, #16]
700008e6:	f850 5f04 	ldr.w	r5, [r0, #4]!
700008ea:	1b49      	subs	r1, r1, r5
      p->events[i].value = diff;
700008ec:	f84c 1022 	str.w	r1, [ip, r2, lsl #2]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700008f0:	3203      	adds	r2, #3
700008f2:	429a      	cmp	r2, r3
700008f4:	d1f6      	bne.n	700008e4 <tm_pmu_profile_end+0x70>
   }

   /* Move to next log slot for future profileStart() */
   gProfileObject.logIndex++;
700008f6:	3401      	adds	r4, #1
700008f8:	f8ce 4000 	str.w	r4, [lr]
}
700008fc:	bd70      	pop	{r4, r5, r6, pc}
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
700008fe:	689a      	ldr	r2, [r3, #8]
   gProfileObject.logIndex++;
70000900:	3401      	adds	r4, #1
70000902:	f8ce 4000 	str.w	r4, [lr]
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
70000906:	1a8a      	subs	r2, r1, r2
70000908:	611a      	str	r2, [r3, #16]
   gProfileObject.logIndex++;
7000090a:	e7f7      	b.n	700008fc <tm_pmu_profile_end+0x88>

7000090c <tm_pmu_profile_print>:
 * tm_pmu_profile_print_entry(name)
 * - Search for an entry with the given name
 * - Print results
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_print(const char* name)
{
7000090c:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
70000910:	f645 3928 	movw	r9, #23336	; 0x5b28
{
70000914:	4680      	mov	r8, r0
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
70000916:	f2c7 0900 	movt	r9, #28672	; 0x7000
7000091a:	f8d9 a000 	ldr.w	sl, [r9]
7000091e:	f1ba 0f00 	cmp.w	sl, #0
70000922:	d00d      	beq.n	70000940 <tm_pmu_profile_print+0x34>
70000924:	464e      	mov	r6, r9
70000926:	2500      	movs	r5, #0
   {
      TM_PMUProfilePoint* p = &gProfileObject.point[i];
      if (p->name != NULL && strcmp(p->name, name) == 0)
70000928:	6877      	ldr	r7, [r6, #4]
7000092a:	4641      	mov	r1, r8
7000092c:	4638      	mov	r0, r7
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
7000092e:	364c      	adds	r6, #76	; 0x4c
      if (p->name != NULL && strcmp(p->name, name) == 0)
70000930:	b11f      	cbz	r7, 7000093a <tm_pmu_profile_print+0x2e>
70000932:	f7ff fb85 	bl	70000040 <strcmp>
70000936:	4604      	mov	r4, r0
70000938:	b158      	cbz	r0, 70000952 <tm_pmu_profile_print+0x46>
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
7000093a:	3501      	adds	r5, #1
7000093c:	4555      	cmp	r5, sl
7000093e:	d1f3      	bne.n	70000928 <tm_pmu_profile_print+0x1c>
         }
         printk("\r\n");
         return;
      }
   }
   printk("No profile entry found for name: %s\r\n", name);
70000940:	f644 703c 	movw	r0, #20284	; 0x4f3c
70000944:	4641      	mov	r1, r8
70000946:	f2c7 0000 	movt	r0, #28672	; 0x7000
}
7000094a:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   printk("No profile entry found for name: %s\r\n", name);
7000094e:	f000 b8a7 	b.w	70000aa0 <printk>
         printk("Profile Entry: %s\r\n", p->name);
70000952:	f644 7004 	movw	r0, #20228	; 0x4f04
70000956:	4639      	mov	r1, r7
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
70000958:	4e17      	ldr	r6, [pc, #92]	; (700009b8 <tm_pmu_profile_print+0xac>)
         printk("Profile Entry: %s\r\n", p->name);
7000095a:	f2c7 0000 	movt	r0, #28672	; 0x7000
7000095e:	f000 f89f 	bl	70000aa0 <printk>
         printk("Cycle Count: %u\r\n", p->cycleCountValue);
70000962:	f644 7018 	movw	r0, #20248	; 0x4f18
70000966:	eb05 03c5 	add.w	r3, r5, r5, lsl #3
7000096a:	f2c7 0000 	movt	r0, #28672	; 0x7000
7000096e:	eb05 0543 	add.w	r5, r5, r3, lsl #1
70000972:	eb09 0985 	add.w	r9, r9, r5, lsl #2
70000976:	f8d9 1010 	ldr.w	r1, [r9, #16]
7000097a:	f000 f891 	bl	70000aa0 <printk>
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
7000097e:	f8d6 3304 	ldr.w	r3, [r6, #772]	; 0x304
70000982:	b18b      	cbz	r3, 700009a8 <tm_pmu_profile_print+0x9c>
            printk("%s Count: %u\r\n", p->events[j].name, p->events[j].value);
70000984:	f644 752c 	movw	r5, #20268	; 0x4f2c
70000988:	f2c7 0500 	movt	r5, #28672	; 0x7000
7000098c:	f8d9 201c 	ldr.w	r2, [r9, #28]
70000990:	4628      	mov	r0, r5
70000992:	f8d9 1014 	ldr.w	r1, [r9, #20]
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
70000996:	3401      	adds	r4, #1
            printk("%s Count: %u\r\n", p->events[j].name, p->events[j].value);
70000998:	f000 f882 	bl	70000aa0 <printk>
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
7000099c:	f8d6 3304 	ldr.w	r3, [r6, #772]	; 0x304
700009a0:	f109 090c 	add.w	r9, r9, #12
700009a4:	42a3      	cmp	r3, r4
700009a6:	d8f1      	bhi.n	7000098c <tm_pmu_profile_print+0x80>
         printk("\r\n");
700009a8:	f644 6038 	movw	r0, #20024	; 0x4e38
}
700009ac:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
         printk("\r\n");
700009b0:	f2c7 0000 	movt	r0, #28672	; 0x7000
700009b4:	f000 b874 	b.w	70000aa0 <printk>
700009b8:	70006b28 	.word	0x70006b28

700009bc <free_list_add>:
	h->free_bytes += chunksz_to_bytes(h, chunk_size(h, c));
#endif
}

static void free_list_add(struct z_heap *h, chunkid_t c)
{
700009bc:	b530      	push	{r4, r5, lr}
	void *cmem = &buf[c];

	if (big_heap(h)) {
		return ((uint32_t *)cmem)[f];
	} else {
		return ((uint16_t *)cmem)[f];
700009be:	eb00 04c1 	add.w	r4, r0, r1, lsl #3
700009c2:	8863      	ldrh	r3, [r4, #2]
	return chunk_field(h, c, SIZE_AND_USED) & 1U;
}

static inline chunksz_t chunk_size(struct z_heap *h, chunkid_t c)
{
	return chunk_field(h, c, SIZE_AND_USED) >> 1;
700009c4:	085b      	lsrs	r3, r3, #1
}

static inline int bucket_idx(struct z_heap *h, chunksz_t sz)
{
	unsigned int usable_sz = sz - min_chunk_size(h) + 1;
	return 31 - __builtin_clz(usable_sz);
700009c6:	fab3 f383 	clz	r3, r3
700009ca:	f1c3 031f 	rsb	r3, r3, #31
	void *cmem = &buf[c];
700009ce:	ea4f 0cc1 	mov.w	ip, r1, lsl #3
	if (b->next == 0U) {
700009d2:	eb00 0583 	add.w	r5, r0, r3, lsl #2
		((uint16_t *)cmem)[f] = val;
700009d6:	f10c 0c04 	add.w	ip, ip, #4
700009da:	fa1f fe81 	uxth.w	lr, r1
700009de:	692a      	ldr	r2, [r5, #16]
700009e0:	b962      	cbnz	r2, 700009fc <free_list_add+0x40>
		h->avail_buckets |= BIT(bidx);
700009e2:	2401      	movs	r4, #1
700009e4:	f36e 020f 	bfi	r2, lr, #0, #16
700009e8:	f36e 421f 	bfi	r2, lr, #16, #16
700009ec:	409c      	lsls	r4, r3
700009ee:	68c3      	ldr	r3, [r0, #12]
700009f0:	4323      	orrs	r3, r4
700009f2:	60c3      	str	r3, [r0, #12]
		b->next = c;
700009f4:	6129      	str	r1, [r5, #16]
700009f6:	f840 200c 	str.w	r2, [r0, ip]
	if (!solo_free_header(h, c)) {
		int bidx = bucket_idx(h, chunk_size(h, c));
		free_list_add_bidx(h, c, bidx);
	}
}
700009fa:	bd30      	pop	{r4, r5, pc}
	void *cmem = &buf[c];
700009fc:	00d3      	lsls	r3, r2, #3
		return ((uint16_t *)cmem)[f];
700009fe:	3304      	adds	r3, #4
70000a00:	5ac1      	ldrh	r1, [r0, r3]
		((uint16_t *)cmem)[f] = val;
70000a02:	f820 100c 	strh.w	r1, [r0, ip]
70000a06:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
70000a0a:	80e2      	strh	r2, [r4, #6]
70000a0c:	f8a1 e006 	strh.w	lr, [r1, #6]
70000a10:	f820 e003 	strh.w	lr, [r0, r3]
70000a14:	bd30      	pop	{r4, r5, pc}
70000a16:	bf00      	nop

70000a18 <sys_heap_init>:
		__ASSERT(bytes / CHUNK_UNIT <= 0x7fffffffU, "heap size is too big");
	}

	/* Reserve the end marker chunk's header */
	__ASSERT(bytes > heap_footer_bytes(bytes), "heap size is too small");
	bytes -= heap_footer_bytes(bytes);
70000a18:	3a04      	subs	r2, #4
{
70000a1a:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}

	/* Round the start up, the end down */
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
70000a1e:	188d      	adds	r5, r1, r2
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
70000a20:	1dcc      	adds	r4, r1, #7
70000a22:	f024 0407 	bic.w	r4, r4, #7
	__ASSERT(heap_sz > chunksz(sizeof(struct z_heap)), "heap size is too small");

	struct z_heap *h = (struct z_heap *)addr;
	heap->heap = h;
	h->end_chunk = heap_sz;
	h->avail_buckets = 0;
70000a26:	f04f 0800 	mov.w	r8, #0
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
70000a2a:	f025 0507 	bic.w	r5, r5, #7
	heap->heap = h;
70000a2e:	6004      	str	r4, [r0, #0]
	chunksz_t heap_sz = (end - addr) / CHUNK_UNIT;
70000a30:	1b2d      	subs	r5, r5, r4
				     nb_buckets * sizeof(struct z_heap_bucket));

	__ASSERT(chunk0_size + min_chunk_size(h) <= heap_sz, "heap size is too small");

	for (int i = 0; i < nb_buckets; i++) {
		h->buckets[i].next = 0;
70000a32:	4641      	mov	r1, r8
70000a34:	f104 0010 	add.w	r0, r4, #16
	chunksz_t heap_sz = (end - addr) / CHUNK_UNIT;
70000a38:	08ef      	lsrs	r7, r5, #3
	return 31 - __builtin_clz(usable_sz);
70000a3a:	fab7 f287 	clz	r2, r7
	h->avail_buckets = 0;
70000a3e:	e9c4 7802 	strd	r7, r8, [r4, #8]
	chunksz_t chunk0_size = chunksz(sizeof(struct z_heap) +
70000a42:	f1c2 0624 	rsb	r6, r2, #36	; 0x24
	int nb_buckets = bucket_idx(h, heap_sz) + 1;
70000a46:	f1c2 0220 	rsb	r2, r2, #32
	chunksz_t chunk0_size = chunksz(sizeof(struct z_heap) +
70000a4a:	00b6      	lsls	r6, r6, #2
	return (bytes + CHUNK_UNIT - 1U) / CHUNK_UNIT;
70000a4c:	3607      	adds	r6, #7
		h->buckets[i].next = 0;
70000a4e:	0092      	lsls	r2, r2, #2
70000a50:	08f6      	lsrs	r6, r6, #3
70000a52:	f002 fbc5 	bl	700031e0 <memset>
		((uint16_t *)cmem)[f] = val;
70000a56:	f8a4 8000 	strh.w	r8, [r4]
	set_chunk_size(h, 0, chunk0_size);
	set_left_chunk_size(h, 0, 0);
	set_chunk_used(h, 0, true);

	/* chunk containing the free heap */
	set_chunk_size(h, chunk0_size, heap_sz - chunk0_size);
70000a5a:	1bbb      	subs	r3, r7, r6
	/* the end marker chunk */
	set_chunk_size(h, heap_sz, 0);
	set_left_chunk_size(h, heap_sz, heap_sz - chunk0_size);
	set_chunk_used(h, heap_sz, true);

	free_list_add(h, chunk0_size);
70000a5c:	4620      	mov	r0, r4
	chunk_set(h, c, SIZE_AND_USED, size << 1);
70000a5e:	0072      	lsls	r2, r6, #1
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
70000a60:	f042 0201 	orr.w	r2, r2, #1
	chunk_set(h, c, SIZE_AND_USED, size << 1);
70000a64:	0059      	lsls	r1, r3, #1
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
70000a66:	8062      	strh	r2, [r4, #2]
		((uint16_t *)cmem)[f] = val;
70000a68:	eb04 02c6 	add.w	r2, r4, r6, lsl #3
70000a6c:	8051      	strh	r1, [r2, #2]
70000a6e:	1962      	adds	r2, r4, r5
70000a70:	f824 6036 	strh.w	r6, [r4, r6, lsl #3]
70000a74:	4631      	mov	r1, r6
70000a76:	5363      	strh	r3, [r4, r5]
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
70000a78:	2301      	movs	r3, #1
70000a7a:	8053      	strh	r3, [r2, #2]
}
70000a7c:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
	free_list_add(h, chunk0_size);
70000a80:	f7ff bf9c 	b.w	700009bc <free_list_add>

70000a84 <arch_printk_char_out>:
{
	ARG_UNUSED(c);

	/* do nothing */
	return 0;
}
70000a84:	2000      	movs	r0, #0
70000a86:	4770      	bx	lr

70000a88 <char_out>:
}

static int char_out(int c, void *ctx_p)
{
	ARG_UNUSED(ctx_p);
	return _char_out(c);
70000a88:	f24b 3398 	movw	r3, #45976	; 0xb398
70000a8c:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000a90:	681b      	ldr	r3, [r3, #0]
70000a92:	4718      	bx	r3

70000a94 <__printk_hook_install>:
	_char_out = fn;
70000a94:	f24b 3398 	movw	r3, #45976	; 0xb398
70000a98:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000a9c:	6018      	str	r0, [r3, #0]
}
70000a9e:	4770      	bx	lr

70000aa0 <printk>:
 *
 * @param fmt formatted string to output
 */

void printk(const char *fmt, ...)
{
70000aa0:	b40f      	push	{r0, r1, r2, r3}
70000aa2:	b500      	push	{lr}
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000aa4:	f640 2089 	movw	r0, #2697	; 0xa89
{
70000aa8:	b087      	sub	sp, #28
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000aaa:	2300      	movs	r3, #0
{
70000aac:	aa08      	add	r2, sp, #32
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000aae:	f04f 0c02 	mov.w	ip, #2
70000ab2:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000ab6:	e9cd 3304 	strd	r3, r3, [sp, #16]
70000aba:	e9cd 3002 	strd	r3, r0, [sp, #8]
		(void) vfprintf(&console, fmt, ap);
70000abe:	a802      	add	r0, sp, #8
{
70000ac0:	f852 1b04 	ldr.w	r1, [r2], #4
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000ac4:	f88d c00a 	strb.w	ip, [sp, #10]
	va_list ap;

	va_start(ap, fmt);
70000ac8:	9201      	str	r2, [sp, #4]
		(void) vfprintf(&console, fmt, ap);
70000aca:	f002 fd61 	bl	70003590 <__l_vfprintf>

	vprintk(fmt, ap);

	va_end(ap);
}
70000ace:	b007      	add	sp, #28
70000ad0:	f85d eb04 	ldr.w	lr, [sp], #4
70000ad4:	b004      	add	sp, #16
70000ad6:	4770      	bx	lr

70000ad8 <z_thread_entry>:
 * This routine does not return, and is marked as such so the compiler won't
 * generate preamble code that is only used by functions that actually return.
 */
FUNC_NORETURN void z_thread_entry(k_thread_entry_t entry,
				 void *p1, void *p2, void *p3)
{
70000ad8:	468c      	mov	ip, r1
70000ada:	4604      	mov	r4, r0
70000adc:	4611      	mov	r1, r2

	sys_rand_get((uint8_t *)&stack_guard, sizeof(stack_guard));
	__stack_chk_guard = stack_guard;
	__stack_chk_guard <<= 8;
#endif	/* CONFIG_STACK_CANARIES */
	entry(p1, p2, p3);
70000ade:	4660      	mov	r0, ip
70000ae0:	461a      	mov	r2, r3
{
70000ae2:	b508      	push	{r3, lr}
	entry(p1, p2, p3);
70000ae4:	47a0      	blx	r4
	return z_impl_k_sched_current_thread_query();
70000ae6:	f001 ff4b 	bl	70002980 <z_impl_k_sched_current_thread_query>
	z_impl_k_thread_abort(thread);
70000aea:	f001 ff4f 	bl	7000298c <z_impl_k_thread_abort>
70000aee:	bf00      	nop

70000af0 <_ConfigAbsSyms>:
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_WARN_DEPRECATED, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_ENFORCE_ZEPHYR_STDINT, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_LEGACY_GENERATED_INCLUDE_PATH, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_BENCHMARK_NUM_ITERATIONS, 1000);

GEN_ABS_SYM_END
70000af0:	4770      	bx	lr
70000af2:	bf00      	nop

70000af4 <z_soc_irq_get_active>:

#include "soc.h"

unsigned int z_soc_irq_get_active(void)
{
	return z_vim_irq_get_active();
70000af4:	f000 bb4c 	b.w	70001190 <z_vim_irq_get_active>

70000af8 <z_soc_irq_eoi>:
}

void z_soc_irq_eoi(unsigned int irq)
{
	z_vim_irq_eoi(irq);
70000af8:	f000 bb70 	b.w	700011dc <z_vim_irq_eoi>

70000afc <z_soc_irq_init>:
}

void z_soc_irq_init(void)
{
	z_vim_irq_init();
70000afc:	f000 bb76 	b.w	700011ec <z_vim_irq_init>

70000b00 <z_soc_irq_priority_set>:
}

void z_soc_irq_priority_set(unsigned int irq, unsigned int prio, uint32_t flags)
{
	/* Configure interrupt type and priority */
	z_vim_irq_priority_set(irq, prio, flags);
70000b00:	f000 bbac 	b.w	7000125c <z_vim_irq_priority_set>

70000b04 <z_soc_irq_enable>:
}

void z_soc_irq_enable(unsigned int irq)
{
	/* Enable interrupt */
	z_vim_irq_enable(irq);
70000b04:	f000 bbd6 	b.w	700012b4 <z_vim_irq_enable>

70000b08 <soc_reset_hook>:
	/* Check if interrupt is enabled */
	return z_vim_irq_is_enabled(irq);
}

void soc_reset_hook(void)
{
70000b08:	b508      	push	{r3, lr}
 *
 */
static ALWAYS_INLINE void sys_cache_instr_enable(void)
{
#if defined(CONFIG_CACHE_MANAGEMENT) && defined(CONFIG_ICACHE)
	cache_instr_enable();
70000b0a:	f000 fa35 	bl	70000f78 <arch_icache_enable>
	/*
	 * Enable the caches only if configured to do so.
	 */
	sys_cache_instr_enable();
	sys_cache_data_enable();
70000b0e:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	cache_data_enable();
70000b12:	f000 ba23 	b.w	70000f5c <arch_dcache_enable>
70000b16:	bf00      	nop

70000b18 <z_arm_fatal_error>:

		LOG_ERR("Unhandled IRQn: %d", irqn);
	}
#endif

	z_fatal_error(reason, esf);
70000b18:	f000 bff8 	b.w	70001b0c <z_fatal_error>

70000b1c <z_do_kernel_oops>:
 * @param esf exception frame
 * @param callee_regs Callee-saved registers (R4-R11)
 * @param exc_return EXC_RETURN value present in LR after exception entry.
 */
void z_do_kernel_oops(const struct arch_esf *esf, _callee_saved_t *callee_regs, uint32_t exc_return)
{
70000b1c:	4601      	mov	r1, r0
	z_fatal_error(reason, esf);
70000b1e:	6800      	ldr	r0, [r0, #0]
70000b20:	f000 bff4 	b.w	70001b0c <z_fatal_error>

70000b24 <z_arm_nmi>:
 * Simply call what is installed in 'static void(*handler)(void)'.
 *
 */

void z_arm_nmi(void)
{
70000b24:	b508      	push	{r3, lr}
	handler();
70000b26:	f24b 33f8 	movw	r3, #46072	; 0xb3f8
70000b2a:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000b2e:	681b      	ldr	r3, [r3, #0]
70000b30:	4798      	blx	r3
	z_arm_int_exit();
}
70000b32:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_arm_int_exit();
70000b36:	f003 b8cb 	b.w	70003cd0 <__z_arm_int_exit_from_thumb>
70000b3a:	bf00      	nop

70000b3c <z_SysNmiOnReset>:
_ASM_FILE_PROLOGUE

GTEXT(z_SysNmiOnReset)

SECTION_FUNC(TEXT, z_SysNmiOnReset)
    wfi
70000b3c:	e320f003 	wfi
    b z_SysNmiOnReset
70000b40:	eafffffd 	b	70000b3c <z_SysNmiOnReset>

70000b44 <z_arm_undef_instruction>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_undef_instruction)
	/*
	 * The undefined instruction address is offset by 2 if the previous
	 * mode is Thumb; otherwise, it is offset by 4.
	 */
	push {r0}
70000b44:	e52d0004 	push	{r0}		; (str r0, [sp, #-4]!)
	mrs r0, spsr
70000b48:	e14f0000 	mrs	r0, SPSR
	tst r0, #T_BIT
70000b4c:	e3100020 	tst	r0, #32
	subeq lr, #4	/* ARM   (!T_BIT) */
70000b50:	024ee004 	subeq	lr, lr, #4
	subne lr, #2	/* Thumb (T_BIT) */
70000b54:	124ee002 	subne	lr, lr, #2
	pop {r0}
70000b58:	e49d0004 	pop	{r0}		; (ldr r0, [sp], #4)

	/*
	 * Store r0-r3, r12, lr, lr_und and spsr_und into the stack to
	 * construct an exception stack frame.
	 */
	srsdb sp!, #MODE_UND
70000b5c:	f96d051b 	srsdb	sp!, #27
	stmfd sp, {r0-r3, r12, lr}^
70000b60:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
	sub sp, #24
70000b64:	e24dd018 	sub	sp, sp, #24

	/* Increment exception nesting count */
	get_cpu r2
70000b68:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000b6c:	e3c22003 	bic	r2, r2, #3
	ldr r1, [r2, #___cpu_t_nested_OFFSET]
70000b70:	e5921000 	ldr	r1, [r2]
	add r1, r1, #1
70000b74:	e2811001 	add	r1, r1, #1
	str r1, [r2, #___cpu_t_nested_OFFSET]
70000b78:	e5821000 	str	r1, [r2]
	cps #MODE_UND

	mov r0, sp
	mov sp, r1
#else
	mov r0, sp
70000b7c:	e1a0000d 	mov	r0, sp
#endif

	bl z_arm_fault_undef_instruction
70000b80:	fa00001b 	blx	70000bf4 <z_arm_fault_undef_instruction>
	exception_exit

	b z_arm_exc_exit
70000b84:	ea000153 	b	700010d8 <z_arm_exc_exit>

70000b88 <z_arm_prefetch_abort>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_prefetch_abort)
	/*
	 * The faulting instruction address is always offset by 4 for the
	 * prefetch abort exceptions.
	 */
	sub lr, #4
70000b88:	e24ee004 	sub	lr, lr, #4

	exception_entry MODE_ABT
70000b8c:	f96d0517 	srsdb	sp!, #23
70000b90:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
70000b94:	e24dd018 	sub	sp, sp, #24
70000b98:	e1a0000d 	mov	r0, sp
70000b9c:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000ba0:	e3c22003 	bic	r2, r2, #3
70000ba4:	e5921000 	ldr	r1, [r2]
70000ba8:	e2811001 	add	r1, r1, #1
70000bac:	e5821000 	str	r1, [r2]
	bl z_arm_fault_prefetch
70000bb0:	fa000013 	blx	70000c04 <z_arm_fault_prefetch>
	exception_exit

	b z_arm_exc_exit
70000bb4:	ea000147 	b	700010d8 <z_arm_exc_exit>

70000bb8 <z_arm_data_abort>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_data_abort)
	/*
	 * The faulting instruction address is always offset by 8 for the data
	 * abort exceptions.
	 */
	sub lr, #8
70000bb8:	e24ee008 	sub	lr, lr, #8

	exception_entry MODE_ABT
70000bbc:	f96d0517 	srsdb	sp!, #23
70000bc0:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
70000bc4:	e24dd018 	sub	sp, sp, #24
70000bc8:	e1a0000d 	mov	r0, sp
70000bcc:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000bd0:	e3c22003 	bic	r2, r2, #3
70000bd4:	e5921000 	ldr	r1, [r2]
70000bd8:	e2811001 	add	r1, r1, #1
70000bdc:	e5821000 	str	r1, [r2]
	bl z_arm_fault_data
70000be0:	fa00002c 	blx	70000c98 <z_arm_fault_data>
	/*
	 * If z_arm_fault_data returns false, then we recovered from
	 * the error.  It may have updated $pc, so copy $pc back to
	 * the true esf from the one passed to z_arm_fault_data.
	 */
	cmp r0, #0
70000be4:	e3500000 	cmp	r0, #0
	ldreq r1, [sp, #24 + FPU_SF_SIZE]
70000be8:	059d1018 	ldreq	r1, [sp, #24]

	exception_exit

	streq r1, [sp, #24 + FPU_SF_SIZE]
70000bec:	058d1018 	streq	r1, [sp, #24]

	b z_arm_exc_exit
70000bf0:	ea000138 	b	700010d8 <z_arm_exc_exit>

70000bf4 <z_arm_fault_undef_instruction>:
 * @brief Undefined instruction fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_undef_instruction(struct arch_esf *esf)
{
70000bf4:	4601      	mov	r1, r0
	uint32_t reason = IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) ?
			  K_ERR_CPU_EXCEPTION :
			  K_ERR_ARM_UNDEFINED_INSTRUCTION;

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70000bf6:	202d      	movs	r0, #45	; 0x2d
{
70000bf8:	b508      	push	{r3, lr}
	z_arm_fatal_error(reason, esf);
70000bfa:	f7ff ff8d 	bl	70000b18 <z_arm_fatal_error>

	/* All undefined instructions are treated as fatal for now */
	return true;
}
70000bfe:	2001      	movs	r0, #1
70000c00:	bd08      	pop	{r3, pc}
70000c02:	bf00      	nop

70000c04 <z_arm_fault_prefetch>:
 * @brief Prefetch abort fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_prefetch(struct arch_esf *esf)
{
70000c04:	4601      	mov	r1, r0
70000c06:	b508      	push	{r3, lr}
    \return               Instruction Fault Status Register value
 */
__STATIC_FORCEINLINE uint32_t __get_IFSR(void)
{
  uint32_t result;
  __get_CP(15, 0, result, 5, 0, 1);
70000c08:	ee15 2f30 	mrc	15, 0, r2, cr5, cr0, {1}
	__get_CP(15, 0, result, 6, 0, 2);
70000c0c:	ee16 3f50 	mrc	15, 0, r3, cr6, cr0, {2}
	/* Read and parse Instruction Fault Status Register (IFSR) */
	uint32_t ifsr = __get_IFSR();
#if defined(CONFIG_AARCH32_ARMV8_R)
	uint32_t fs = ifsr & IFSR_STATUS_Msk;
#else
	uint32_t fs = ((ifsr & IFSR_FS1_Msk) >> 6) | (ifsr & IFSR_FS0_Msk);
70000c10:	0993      	lsrs	r3, r2, #6
70000c12:	f003 0310 	and.w	r3, r3, #16
70000c16:	f002 020f 	and.w	r2, r2, #15
70000c1a:	4313      	orrs	r3, r2
	switch (status) {
70000c1c:	2b19      	cmp	r3, #25
70000c1e:	d80e      	bhi.n	70000c3e <z_arm_fault_prefetch+0x3a>
70000c20:	e8df f003 	tbb	[pc, r3]
70000c24:	0d1c3717 	.word	0x0d1c3717
70000c28:	0d0d0d0d 	.word	0x0d0d0d0d
70000c2c:	0d0d0d23 	.word	0x0d0d0d23
70000c30:	0d0d280d 	.word	0x0d0d280d
70000c34:	0d0d0d0d 	.word	0x0d0d0d0d
70000c38:	0d2d0d0d 	.word	0x0d2d0d0d
70000c3c:	1232      	.short	0x1232
	uint32_t reason = K_ERR_CPU_EXCEPTION;
70000c3e:	2000      	movs	r0, #0
	if (IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) && (reason >= K_ERR_ARCH_START)) {
		reason = K_ERR_CPU_EXCEPTION;
	}

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70000c40:	f7ff ff6a 	bl	70000b18 <z_arm_fatal_error>

	/* All prefetch aborts are treated as fatal for now */
	return true;
}
70000c44:	2001      	movs	r0, #1
70000c46:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_PARITY_ERROR;
70000c48:	2033      	movs	r0, #51	; 0x33
	z_arm_fatal_error(reason, esf);
70000c4a:	f7ff ff65 	bl	70000b18 <z_arm_fatal_error>
}
70000c4e:	2001      	movs	r0, #1
70000c50:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_BACKGROUND_FAULT;
70000c52:	202f      	movs	r0, #47	; 0x2f
	z_arm_fatal_error(reason, esf);
70000c54:	f7ff ff60 	bl	70000b18 <z_arm_fatal_error>
}
70000c58:	2001      	movs	r0, #1
70000c5a:	bd08      	pop	{r3, pc}
	__get_CP(14, 0, result, 0, 1, 0);
70000c5c:	ee10 3e11 	mrc	14, 0, r3, cr0, cr1, {0}
		reason = K_ERR_ARM_DEBUG_EVENT;
70000c60:	2035      	movs	r0, #53	; 0x35
	z_arm_fatal_error(reason, esf);
70000c62:	f7ff ff59 	bl	70000b18 <z_arm_fatal_error>
}
70000c66:	2001      	movs	r0, #1
70000c68:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_EXTERNAL_ABORT;
70000c6a:	2031      	movs	r0, #49	; 0x31
	z_arm_fatal_error(reason, esf);
70000c6c:	f7ff ff54 	bl	70000b18 <z_arm_fatal_error>
}
70000c70:	2001      	movs	r0, #1
70000c72:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_PERMISSION_FAULT;
70000c74:	2030      	movs	r0, #48	; 0x30
	z_arm_fatal_error(reason, esf);
70000c76:	f7ff ff4f 	bl	70000b18 <z_arm_fatal_error>
}
70000c7a:	2001      	movs	r0, #1
70000c7c:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_EXTERNAL_ABORT;
70000c7e:	2032      	movs	r0, #50	; 0x32
	z_arm_fatal_error(reason, esf);
70000c80:	f7ff ff4a 	bl	70000b18 <z_arm_fatal_error>
}
70000c84:	2001      	movs	r0, #1
70000c86:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_PARITY_ERROR;
70000c88:	2034      	movs	r0, #52	; 0x34
	z_arm_fatal_error(reason, esf);
70000c8a:	f7ff ff45 	bl	70000b18 <z_arm_fatal_error>
}
70000c8e:	2001      	movs	r0, #1
70000c90:	bd08      	pop	{r3, pc}
	switch (status) {
70000c92:	202e      	movs	r0, #46	; 0x2e
70000c94:	e7d4      	b.n	70000c40 <z_arm_fault_prefetch+0x3c>
70000c96:	bf00      	nop

70000c98 <z_arm_fault_data>:
 * @brief Data abort fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_data(struct arch_esf *esf)
{
70000c98:	4601      	mov	r1, r0
70000c9a:	b508      	push	{r3, lr}
  __get_CP(15, 0, result, 5, 0, 0);
70000c9c:	ee15 2f10 	mrc	15, 0, r2, cr5, cr0, {0}
	__get_CP(15, 0, result, 6, 0, 0);
70000ca0:	ee16 3f10 	mrc	15, 0, r3, cr6, cr0, {0}
	/* Read and parse Data Fault Status Register (DFSR) */
	uint32_t dfsr = __get_DFSR();
#if defined(CONFIG_AARCH32_ARMV8_R)
	uint32_t fs = dfsr & DFSR_STATUS_Msk;
#else
	uint32_t fs = ((dfsr & DFSR_FS1_Msk) >> 6) | (dfsr & DFSR_FS0_Msk);
70000ca4:	0993      	lsrs	r3, r2, #6
70000ca6:	f003 0310 	and.w	r3, r3, #16
70000caa:	f002 020f 	and.w	r2, r2, #15
70000cae:	4313      	orrs	r3, r2
	switch (status) {
70000cb0:	2b19      	cmp	r3, #25
70000cb2:	d80e      	bhi.n	70000cd2 <z_arm_fault_data+0x3a>
70000cb4:	e8df f003 	tbb	[pc, r3]
70000cb8:	0d1c3717 	.word	0x0d1c3717
70000cbc:	0d0d0d0d 	.word	0x0d0d0d0d
70000cc0:	0d0d0d23 	.word	0x0d0d0d23
70000cc4:	0d0d280d 	.word	0x0d0d280d
70000cc8:	0d0d0d0d 	.word	0x0d0d0d0d
70000ccc:	0d2d0d0d 	.word	0x0d2d0d0d
70000cd0:	1232      	.short	0x1232
	uint32_t reason = K_ERR_CPU_EXCEPTION;
70000cd2:	2000      	movs	r0, #0
	if (IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) && (reason >= K_ERR_ARCH_START)) {
		reason = K_ERR_CPU_EXCEPTION;
	}

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70000cd4:	f7ff ff20 	bl	70000b18 <z_arm_fatal_error>

	/* All data aborts are treated as fatal for now */
	return true;
}
70000cd8:	2001      	movs	r0, #1
70000cda:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_PARITY_ERROR;
70000cdc:	2033      	movs	r0, #51	; 0x33
	z_arm_fatal_error(reason, esf);
70000cde:	f7ff ff1b 	bl	70000b18 <z_arm_fatal_error>
}
70000ce2:	2001      	movs	r0, #1
70000ce4:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_BACKGROUND_FAULT;
70000ce6:	202f      	movs	r0, #47	; 0x2f
	z_arm_fatal_error(reason, esf);
70000ce8:	f7ff ff16 	bl	70000b18 <z_arm_fatal_error>
}
70000cec:	2001      	movs	r0, #1
70000cee:	bd08      	pop	{r3, pc}
	__get_CP(14, 0, result, 0, 1, 0);
70000cf0:	ee10 3e11 	mrc	14, 0, r3, cr0, cr1, {0}
		reason = K_ERR_ARM_DEBUG_EVENT;
70000cf4:	2035      	movs	r0, #53	; 0x35
	z_arm_fatal_error(reason, esf);
70000cf6:	f7ff ff0f 	bl	70000b18 <z_arm_fatal_error>
}
70000cfa:	2001      	movs	r0, #1
70000cfc:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_EXTERNAL_ABORT;
70000cfe:	2031      	movs	r0, #49	; 0x31
	z_arm_fatal_error(reason, esf);
70000d00:	f7ff ff0a 	bl	70000b18 <z_arm_fatal_error>
}
70000d04:	2001      	movs	r0, #1
70000d06:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_PERMISSION_FAULT;
70000d08:	2030      	movs	r0, #48	; 0x30
	z_arm_fatal_error(reason, esf);
70000d0a:	f7ff ff05 	bl	70000b18 <z_arm_fatal_error>
}
70000d0e:	2001      	movs	r0, #1
70000d10:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_EXTERNAL_ABORT;
70000d12:	2032      	movs	r0, #50	; 0x32
	z_arm_fatal_error(reason, esf);
70000d14:	f7ff ff00 	bl	70000b18 <z_arm_fatal_error>
}
70000d18:	2001      	movs	r0, #1
70000d1a:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_PARITY_ERROR;
70000d1c:	2034      	movs	r0, #52	; 0x34
	z_arm_fatal_error(reason, esf);
70000d1e:	f7ff fefb 	bl	70000b18 <z_arm_fatal_error>
}
70000d22:	2001      	movs	r0, #1
70000d24:	bd08      	pop	{r3, pc}
	switch (status) {
70000d26:	202e      	movs	r0, #46	; 0x2e
70000d28:	e7d4      	b.n	70000cd4 <z_arm_fault_data+0x3c>
70000d2a:	bf00      	nop

70000d2c <z_arm_interrupt_init>:
	/*
	 * Initialise interrupt controller.
	 */
#ifdef CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER
	/* Invoke SoC-specific interrupt controller initialisation */
	z_soc_irq_init();
70000d2c:	f7ff bee6 	b.w	70000afc <z_soc_irq_init>

70000d30 <relocate_vector_table>:
		write_sysreg64(val, op1, CRm);				\
	}

MAKE_REG_HELPER(mpuir,	     0, 0, 0, 4);
MAKE_REG_HELPER(mpidr,	     0, 0, 0, 5);
MAKE_REG_HELPER(sctlr,	     0, 1, 0, 0);
70000d30:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}

void __weak relocate_vector_table(void)
{
#if defined(CONFIG_XIP) && (CONFIG_FLASH_BASE_ADDRESS != 0) ||                                     \
	!defined(CONFIG_XIP) && (CONFIG_SRAM_BASE_ADDRESS != 0)
	write_sctlr(read_sctlr() & ~HIVECS);
70000d34:	f423 5300 	bic.w	r3, r3, #8192	; 0x2000
70000d38:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
	size_t vector_size = (size_t)_vector_end - (size_t)_vector_start;
70000d3c:	f240 023c 	movw	r2, #60	; 0x3c
70000d40:	f240 0100 	movw	r1, #0
70000d44:	f2c7 0100 	movt	r1, #28672	; 0x7000
	(void)memcpy(VECTOR_ADDRESS, _vector_start, vector_size);
70000d48:	2000      	movs	r0, #0
	size_t vector_size = (size_t)_vector_end - (size_t)_vector_start;
70000d4a:	f2c7 0200 	movt	r2, #28672	; 0x7000
	(void)memcpy(VECTOR_ADDRESS, _vector_start, vector_size);
70000d4e:	1a52      	subs	r2, r2, r1
70000d50:	f002 b9de 	b.w	70003110 <memcpy>

70000d54 <z_arm_relocate_vector_table>:
#endif

#endif /* !CONFIG_AARCH32_ARMV8_R */

void z_arm_relocate_vector_table(void)
{
70000d54:	b508      	push	{r3, lr}
	relocate_vector_table();
70000d56:	f7ff ffeb 	bl	70000d30 <relocate_vector_table>
}
70000d5a:	bd08      	pop	{r3, pc}

70000d5c <__start>:
    ldr r0, =IMP_CSCTLR(CONFIG_CPU_CORTEX_R52_ICACHE_FLASH_WAY,
                        CONFIG_CPU_CORTEX_R52_DCACHE_FLASH_WAY)
    mcr p15, 1, r0, c9, c1, 0
#endif

    ldr r0, =arm_cpu_boot_params
70000d5c:	e59f0054 	ldr	r0, [pc, #84]	; 70000db8 <__start+0x5c>
    b 2f

_primary_core:
#endif

    ldr r4, =z_prep_c
70000d60:	e59f4054 	ldr	r4, [pc, #84]	; 70000dbc <__start+0x60>
    ldr r5, =(z_arm_fiq_stack + CONFIG_ARMV7_FIQ_STACK_SIZE)
70000d64:	e59f5054 	ldr	r5, [pc, #84]	; 70000dc0 <__start+0x64>
    ldr r6, =(z_interrupt_stacks + CONFIG_ISR_STACK_SIZE)
70000d68:	e59f6054 	ldr	r6, [pc, #84]	; 70000dc4 <__start+0x68>
    ldr r7, =(z_arm_abort_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000d6c:	e59f7054 	ldr	r7, [pc, #84]	; 70000dc8 <__start+0x6c>
    ldr r8, =(z_arm_undef_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000d70:	e59f8054 	ldr	r8, [pc, #84]	; 70000dcc <__start+0x70>
    ldr r9, =(z_arm_svc_stack + CONFIG_ARMV7_SVC_STACK_SIZE)
70000d74:	e59f9054 	ldr	r9, [pc, #84]	; 70000dd0 <__start+0x74>
    ldr r10, =(z_arm_sys_stack + CONFIG_ARMV7_SYS_STACK_SIZE)
70000d78:	e59fa054 	ldr	sl, [pc, #84]	; 70000dd4 <__start+0x78>
    /*
     * Configure stack.
     */

    /* FIQ mode stack */
    msr CPSR_c, #(MODE_FIQ | I_BIT | F_BIT)
70000d7c:	e321f0d1 	msr	CPSR_c, #209	; 0xd1
    mov sp, r5
70000d80:	e1a0d005 	mov	sp, r5

    /* IRQ mode stack */
    msr CPSR_c, #(MODE_IRQ | I_BIT | F_BIT)
70000d84:	e321f0d2 	msr	CPSR_c, #210	; 0xd2
    mov sp, r6
70000d88:	e1a0d006 	mov	sp, r6

    /* ABT mode stack */
    msr CPSR_c, #(MODE_ABT | I_BIT | F_BIT)
70000d8c:	e321f0d7 	msr	CPSR_c, #215	; 0xd7
    mov sp, r7
70000d90:	e1a0d007 	mov	sp, r7

    /* UND mode stack */
    msr CPSR_c, #(MODE_UND | I_BIT | F_BIT)
70000d94:	e321f0db 	msr	CPSR_c, #219	; 0xdb
    mov sp, r8
70000d98:	e1a0d008 	mov	sp, r8

    /* SVC mode stack */
    msr CPSR_c, #(MODE_SVC | I_BIT | F_BIT)
70000d9c:	e321f0d3 	msr	CPSR_c, #211	; 0xd3
    mov sp, r9
70000da0:	e1a0d009 	mov	sp, r9

    /* SYS mode stack */
    msr CPSR_c, #(MODE_SYS | I_BIT | F_BIT)
70000da4:	e321f0df 	msr	CPSR_c, #223	; 0xdf
    mov sp, r10
70000da8:	e1a0d00a 	mov	sp, sl

#if defined(CONFIG_SOC_RESET_HOOK)
    /* Execute platform-specific initialisation if applicable */
    bl soc_reset_hook
70000dac:	faffff55 	blx	70000b08 <soc_reset_hook>

#if defined(CONFIG_DISABLE_TCM_ECC)
    bl z_arm_tcm_disable_ecc
#endif

    bl z_arm_relocate_vector_table
70000db0:	faffffe7 	blx	70000d54 <z_arm_relocate_vector_table>

    bx r4
70000db4:	e12fff14 	bx	r4
    ldr r0, =arm_cpu_boot_params
70000db8:	7000b3fc 	.word	0x7000b3fc
    ldr r4, =z_prep_c
70000dbc:	70000de1 	.word	0x70000de1
    ldr r5, =(z_arm_fiq_stack + CONFIG_ARMV7_FIQ_STACK_SIZE)
70000dc0:	7000a280 	.word	0x7000a280
    ldr r6, =(z_interrupt_stacks + CONFIG_ISR_STACK_SIZE)
70000dc4:	7000aa80 	.word	0x7000aa80
    ldr r7, =(z_arm_abort_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000dc8:	7000a180 	.word	0x7000a180
    ldr r8, =(z_arm_undef_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000dcc:	7000a080 	.word	0x7000a080
    ldr r9, =(z_arm_svc_stack + CONFIG_ARMV7_SVC_STACK_SIZE)
70000dd0:	70009f80 	.word	0x70009f80
    ldr r10, =(z_arm_sys_stack + CONFIG_ARMV7_SYS_STACK_SIZE)
70000dd4:	70009d80 	.word	0x70009d80

70000dd8 <z_irq_spurious>:
 */
void z_irq_spurious(const void *unused)
{
	ARG_UNUSED(unused);

	z_arm_fatal_error(K_ERR_SPURIOUS_IRQ, NULL);
70000dd8:	2100      	movs	r1, #0
70000dda:	2001      	movs	r0, #1
70000ddc:	f7ff be9c 	b.w	70000b18 <z_arm_fatal_error>

70000de0 <z_prep_c>:
 *
 * This routine prepares for the execution of and runs C code.
 *
 */
void z_prep_c(void)
{
70000de0:	b508      	push	{r3, lr}
MAKE_REG_HELPER(prlar,	     0, 6, 3, 1);
MAKE_REG_HELPER(mair0,       0, 10, 2, 0);
MAKE_REG_HELPER(vbar,        0, 12, 0, 0);
MAKE_REG_HELPER(cntv_ctl,    0, 14,  3, 1);
MAKE_REG_HELPER(ctr,         0, 0, 0, 1);
MAKE_REG_HELPER(tpidruro,    0, 13, 0, 3);
70000de2:	f646 7358 	movw	r3, #28504	; 0x6f58
70000de6:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000dea:	ee0d 3f70 	mcr	15, 0, r3, cr13, cr0, {3}
	write_tpidruro((uintptr_t)&_kernel.cpus[0]);

#if defined(CONFIG_CPU_HAS_FPU)
	z_arm_floating_point_init();
#endif
	z_bss_zero();
70000dee:	f000 ff3f 	bl	70001c70 <z_bss_zero>
	z_data_copy();
#if ((defined(CONFIG_ARMV7_R) || defined(CONFIG_ARMV7_A)) && defined(CONFIG_INIT_STACKS))
	z_arm_init_stacks();
#endif
	z_arm_interrupt_init();
70000df2:	f7ff ff9b 	bl	70000d2c <z_arm_interrupt_init>
#if CONFIG_ARCH_CACHE
	arch_cache_init();
70000df6:	f000 f8cf 	bl	70000f98 <arch_cache_init>
	z_arm_mpu_init();
	z_arm_configure_static_mpu_regions();
#elif defined(CONFIG_ARM_AARCH32_MMU)
	z_arm_mmu_init();
#endif
	z_cstart();
70000dfa:	f000 ff47 	bl	70001c8c <z_cstart>
70000dfe:	bf00      	nop

70000e00 <arch_new_thread>:
 * of the ESF.
 */
void arch_new_thread(struct k_thread *thread, k_thread_stack_t *stack,
		     char *stack_ptr, k_thread_entry_t entry,
		     void *p1, void *p2, void *p3)
{
70000e00:	b430      	push	{r4, r5}
	}
#else
	iframe->pc = (uint32_t)z_thread_entry;
#endif

	iframe->a1 = (uint32_t)entry;
70000e02:	f842 3c20 	str.w	r3, [r2, #-32]
#if defined(CONFIG_BIG_ENDIAN)
	iframe->xpsr |= E_BIT;
#endif /* CONFIG_BIG_ENDIAN */

#if defined(CONFIG_COMPILER_ISA_THUMB2)
	iframe->xpsr |= T_BIT;
70000e06:	f240 153f 	movw	r5, #319	; 0x13f
{
70000e0a:	9b02      	ldr	r3, [sp, #8]
	iframe = Z_STACK_PTR_TO_FRAME(struct __basic_sf, stack_ptr);
70000e0c:	f1a2 0420 	sub.w	r4, r2, #32
	iframe->a2 = (uint32_t)p1;
70000e10:	f842 3c1c 	str.w	r3, [r2, #-28]
	iframe->pc = (uint32_t)z_thread_entry;
70000e14:	f640 23d9 	movw	r3, #2777	; 0xad9
		((uintptr_t)iframe - sizeof(struct __fpu_sf));
	memset(iframe, 0, sizeof(struct __fpu_sf));
#endif

	thread->callee_saved.psp = (uint32_t)iframe;
	thread->arch.basepri = 0;
70000e18:	2100      	movs	r1, #0
	iframe->pc = (uint32_t)z_thread_entry;
70000e1a:	f2c7 0300 	movt	r3, #28672	; 0x7000
	iframe->xpsr |= T_BIT;
70000e1e:	f842 5c04 	str.w	r5, [r2, #-4]
	iframe->pc = (uint32_t)z_thread_entry;
70000e22:	f842 3c08 	str.w	r3, [r2, #-8]
{
70000e26:	9b03      	ldr	r3, [sp, #12]
	iframe->a3 = (uint32_t)p2;
70000e28:	f842 3c18 	str.w	r3, [r2, #-24]
{
70000e2c:	9b04      	ldr	r3, [sp, #16]
	iframe->a4 = (uint32_t)p3;
70000e2e:	f842 3c14 	str.w	r3, [r2, #-20]
	thread->callee_saved.psp = (uint32_t)iframe;
70000e32:	6504      	str	r4, [r0, #80]	; 0x50
	thread->arch.basepri = 0;
70000e34:	66c1      	str	r1, [r0, #108]	; 0x6c
	thread->switch_handle = thread;
	/* thread birth happens through the exception return path */
	thread->arch.exception_depth = 1;
	thread->callee_saved.lr = (uint32_t)z_arm_cortex_ar_exit_exc;
#endif
}
70000e36:	bc30      	pop	{r4, r5}
70000e38:	4770      	bx	lr
70000e3a:	bf00      	nop

70000e3c <arch_cpu_idle>:

	/*
	 * Clear PRIMASK and flush instruction buffer to immediately service
	 * the wake-up interrupt.
	 */
	cpsie	i
70000e3c:	f1080080 	cpsie	i
	isb
70000e40:	f57ff06f 	isb	sy

	bx	lr
70000e44:	e12fff1e 	bx	lr

70000e48 <_isr_wrapper>:
	 * Save away r0-r3, r12 and lr_irq for the previous context to the
	 * process stack since they are clobbered here.  Also, save away lr
	 * and spsr_irq since we may swap processes and return to a different
	 * thread.
	 */
	sub lr, lr, #4
70000e48:	e24ee004 	sub	lr, lr, #4
	srsdb #MODE_SYS!
70000e4c:	f96d051f 	srsdb	sp!, #31
	cps #MODE_SYS
70000e50:	f102001f 	cps	#31
	push {r0-r3, r12, lr}
70000e54:	e92d500f 	push	{r0, r1, r2, r3, ip, lr}
	 * threads have high stack usage.
	 *
	 * When userspace is enabled, this also prevents leaking privileged
	 * information to the user mode.
	 */
	cps #MODE_SVC
70000e58:	f1020013 	cps	#19
	/*
	 * Preserve lr_svc which may contain the branch return address of the
	 * interrupted context in case of a nested interrupt. This value will
	 * be restored prior to exiting the interrupt in z_arm_int_exit.
	 */
	push {lr}
70000e5c:	e52de004 	push	{lr}		; (str lr, [sp, #-4]!)

	/* Align stack at double-word boundary */
	and r3, sp, #4
70000e60:	e20d3004 	and	r3, sp, #4
	sub sp, sp, r3
70000e64:	e04dd003 	sub	sp, sp, r3
	push {r2, r3}
70000e68:	e92d000c 	push	{r2, r3}

	/* Increment interrupt nesting count */
	get_cpu r2
70000e6c:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000e70:	e3c22003 	bic	r2, r2, #3
	ldr r0, [r2, #___cpu_t_nested_OFFSET]
70000e74:	e5920000 	ldr	r0, [r2]
	add r0, r0, #1
70000e78:	e2800001 	add	r0, r0, #1
	str r0, [r2, #___cpu_t_nested_OFFSET]
70000e7c:	e5820000 	str	r0, [r2]

	/* Get active IRQ number from the interrupt controller */
#if !defined(CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER)
	bl arm_gic_get_active
#else
	bl z_soc_irq_get_active
70000e80:	faffff1b 	blx	70000af4 <z_soc_irq_get_active>
#endif /* !CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER */
	push {r0, r1}
70000e84:	e92d0003 	push	{r0, r1}
	lsl r0, r0, #3	/* table is 8-byte wide */
70000e88:	e1a00180 	lsl	r0, r0, #3
	 * to note that most interrupt controllers require that the nested
	 * interrupts are handled after the active interrupt is acknowledged;
	 * this is be done through the `get_active` interrupt controller
	 * interface function.
	 */
	cpsie i
70000e8c:	f1080080 	cpsie	i

	/*
	 * Skip calling the isr if it is a spurious interrupt.
	 */
	mov r1, #CONFIG_NUM_IRQS
70000e90:	e3a01c02 	mov	r1, #512	; 0x200
	lsl r1, r1, #3
70000e94:	e1a01181 	lsl	r1, r1, #3
	cmp r0, r1
70000e98:	e1500001 	cmp	r0, r1
	bge spurious_continue
70000e9c:	aa000003 	bge	70000eb0 <spurious_continue>

	ldr r1, =_sw_isr_table
70000ea0:	e59f1018 	ldr	r1, [pc, #24]	; 70000ec0 <spurious_continue+0x10>
	add r1, r1, r0	/* table entry: ISRs must have their MSB set to stay
70000ea4:	e0811000 	add	r1, r1, r0
			 * in thumb mode */

	ldm r1!,{r0,r3}	/* arg in r0, ISR in r3 */
70000ea8:	e8b10009 	ldm	r1!, {r0, r3}
	blx r3		/* call ISR */
70000eac:	e12fff33 	blx	r3

70000eb0 <spurious_continue>:

spurious_continue:
	/* Signal end-of-interrupt */
	pop {r0, r1}
70000eb0:	e8bd0003 	pop	{r0, r1}
#if !defined(CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER)
	bl arm_gic_eoi
#else
	bl z_soc_irq_eoi
70000eb4:	faffff0f 	blx	70000af8 <z_soc_irq_eoi>
#endif

	/* Use 'bx' instead of 'b' because 'bx' can jump further, and use
	 * 'bx' instead of 'blx' because exception return is done in
	 * z_arm_int_exit() */
	ldr r1, =z_arm_int_exit
70000eb8:	e59f1004 	ldr	r1, [pc, #4]	; 70000ec4 <spurious_continue+0x14>
	bx r1
70000ebc:	e12fff11 	bx	r1
	ldr r1, =_sw_isr_table
70000ec0:	70003d50 	.word	0x70003d50
	ldr r1, =z_arm_int_exit
70000ec4:	70001080 	.word	0x70001080

70000ec8 <arch_dcache_invd_all>:

	return 0;
}

int arch_dcache_invd_all(void)
{
70000ec8:	b5f0      	push	{r4, r5, r6, r7, lr}
 */
__STATIC_FORCEINLINE uint32_t __get_CLIDR(void)
{
  uint32_t result;
//  __ASM volatile("MRC p15, 1, %0, c0, c0, 1" : "=r"(result) : : "memory");
  __get_CP(15, 1, result, 0, 0, 1);
70000eca:	ee30 6f30 	mrc	15, 1, r6, cr0, cr0, {1}
*/
__STATIC_FORCEINLINE void L1C_CleanInvalidateCache(uint32_t op) {
  uint32_t clidr;
  uint32_t cache_type;
  clidr =  __get_CLIDR();
  for(uint32_t i = 0U; i<7U; i++)
70000ece:	2400      	movs	r4, #0
  {
    cache_type = (clidr >> i*3U) & 0x7UL;
70000ed0:	eb04 0344 	add.w	r3, r4, r4, lsl #1
70000ed4:	fa26 f303 	lsr.w	r3, r6, r3
70000ed8:	f003 0307 	and.w	r3, r3, #7
    if ((cache_type >= 2U) && (cache_type <= 4U))
70000edc:	3b02      	subs	r3, #2
70000ede:	2b02      	cmp	r3, #2
    cache_type = (clidr >> i*3U) & 0x7UL;
70000ee0:	ea4f 0544 	mov.w	r5, r4, lsl #1
    if ((cache_type >= 2U) && (cache_type <= 4U))
70000ee4:	d831      	bhi.n	70000f4a <arch_dcache_invd_all+0x82>
  __set_CP(15, 2, value, 0, 0, 0);
70000ee6:	ee40 5f10 	mcr	15, 2, r5, cr0, cr0, {0}
  __get_CP(15, 1, result, 0, 0, 0);
70000eea:	ee30 7f10 	mrc	15, 1, r7, cr0, cr0, {0}
  num_ways = ((ccsidr & 0x00001FF8U) >> 3U) + 1U;
70000eee:	f3c7 0cc9 	ubfx	ip, r7, #3, #10
70000ef2:	f10c 0e01 	add.w	lr, ip, #1
  if (n < 2U) {
70000ef6:	f1bc 0f00 	cmp.w	ip, #0
70000efa:	d02b      	beq.n	70000f54 <arch_dcache_invd_all+0x8c>
70000efc:	4672      	mov	r2, lr
  uint8_t log = 0U;
70000efe:	2300      	movs	r3, #0
    t >>= 1U;
70000f00:	0852      	lsrs	r2, r2, #1
    log++;
70000f02:	1c59      	adds	r1, r3, #1
70000f04:	4618      	mov	r0, r3
  while(t > 1U)
70000f06:	2a01      	cmp	r2, #1
    log++;
70000f08:	b2cb      	uxtb	r3, r1
  while(t > 1U)
70000f0a:	d1f9      	bne.n	70000f00 <arch_dcache_invd_all+0x38>
  if (n & 1U) { log++; }
70000f0c:	f01e 0f01 	tst.w	lr, #1
70000f10:	bf1c      	itt	ne
70000f12:	3002      	addne	r0, #2
70000f14:	b2c3      	uxtbne	r3, r0
  if ((log2_num_ways < 0) || (log2_num_ways > 32)) {
70000f16:	2b20      	cmp	r3, #32
  shift_way = 32U - (uint32_t)log2_num_ways;
70000f18:	bf98      	it	ls
70000f1a:	f1c3 0e20 	rsbls	lr, r3, #32
  if ((log2_num_ways < 0) || (log2_num_ways > 32)) {
70000f1e:	d814      	bhi.n	70000f4a <arch_dcache_invd_all+0x82>
  log2_linesize = (ccsidr & 0x00000007U) + 2U + 2U;
70000f20:	f007 0007 	and.w	r0, r7, #7
70000f24:	3004      	adds	r0, #4
  num_sets = ((ccsidr & 0x0FFFE000U) >> 13U) + 1U;
70000f26:	f3c7 374e 	ubfx	r7, r7, #13, #15
    for(int32_t set = num_sets-1; set >= 0; set--)
70000f2a:	463b      	mov	r3, r7
      Dummy = (level << 1U) | (((uint32_t)set) << log2_linesize) | (((uint32_t)way) << shift_way);
70000f2c:	fa0c f10e 	lsl.w	r1, ip, lr
70000f30:	4329      	orrs	r1, r5
70000f32:	fa03 f200 	lsl.w	r2, r3, r0
70000f36:	430a      	orrs	r2, r1
/** \brief  Set DCISW
 */
__STATIC_FORCEINLINE void __set_DCISW(uint32_t value)
{
//  __ASM volatile("MCR p15, 0, %0, c7, c6, 2" : : "r"(value) : "memory")
  __set_CP(15, 0, value, 7, 6, 2);
70000f38:	ee07 2f56 	mcr	15, 0, r2, cr7, cr6, {2}
    for(int32_t set = num_sets-1; set >= 0; set--)
70000f3c:	3b01      	subs	r3, #1
70000f3e:	d2f8      	bcs.n	70000f32 <arch_dcache_invd_all+0x6a>
  for(int32_t way = num_ways-1; way >= 0; way--)
70000f40:	f1bc 0c01 	subs.w	ip, ip, #1
70000f44:	d2f1      	bcs.n	70000f2a <arch_dcache_invd_all+0x62>
  \details Ensures the apparent order of the explicit memory operations before
           and after the instruction, without ensuring their completion.
 */
__STATIC_FORCEINLINE  void __DMB(void)
{
  __ASM volatile ("dmb 0xF":::"memory");
70000f46:	f3bf 8f5f 	dmb	sy
  for(uint32_t i = 0U; i<7U; i++)
70000f4a:	3401      	adds	r4, #1
70000f4c:	2c07      	cmp	r4, #7
70000f4e:	d1bf      	bne.n	70000ed0 <arch_dcache_invd_all+0x8>
	L1C_InvalidateDCacheAll();

	return 0;
}
70000f50:	2000      	movs	r0, #0
70000f52:	bdf0      	pop	{r4, r5, r6, r7, pc}
70000f54:	f04f 0e20 	mov.w	lr, #32
70000f58:	e7e2      	b.n	70000f20 <arch_dcache_invd_all+0x58>
70000f5a:	bf00      	nop

70000f5c <arch_dcache_enable>:
{
70000f5c:	b508      	push	{r3, lr}
	arch_dcache_invd_all();
70000f5e:	f7ff ffb3 	bl	70000ec8 <arch_dcache_invd_all>
  __get_CP(15, 0, result, 1, 0, 0);
70000f62:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}
  __ASM volatile ("dsb 0xF":::"memory");
70000f66:	f3bf 8f4f 	dsb	sy
	val |= SCTLR_C_Msk;
70000f6a:	f043 0304 	orr.w	r3, r3, #4
  __set_CP(15, 0, sctlr, 1, 0, 0);
70000f6e:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
  __ASM volatile ("isb 0xF":::"memory");
70000f72:	f3bf 8f6f 	isb	sy
}
70000f76:	bd08      	pop	{r3, pc}

70000f78 <arch_icache_enable>:
  __set_CP(15, 0, value, 7, 5, 0);
70000f78:	2300      	movs	r3, #0
70000f7a:	ee07 3f15 	mcr	15, 0, r3, cr7, cr5, {0}
  __ASM volatile ("dsb 0xF":::"memory");
70000f7e:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
70000f82:	f3bf 8f6f 	isb	sy
  __get_CP(15, 0, result, 1, 0, 0);
70000f86:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}
#ifdef CONFIG_ICACHE

void arch_icache_enable(void)
{
	arch_icache_invd_all();
	__set_SCTLR(__get_SCTLR() | SCTLR_I_Msk);
70000f8a:	f443 5380 	orr.w	r3, r3, #4096	; 0x1000
  __set_CP(15, 0, sctlr, 1, 0, 0);
70000f8e:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
70000f92:	f3bf 8f6f 	isb	sy
	barrier_isync_fence_full();
}
70000f96:	4770      	bx	lr

70000f98 <arch_cache_init>:

#endif

void arch_cache_init(void)
{
}
70000f98:	4770      	bx	lr
70000f9a:	bf00      	nop

70000f9c <z_arm_do_swap>:
    bl z_thread_mark_switched_out
    pop {r0, lr}
#endif /* CONFIG_INSTRUMENT_THREAD_SWITCHING */

    /* load current _cpu into r1 and current k_thread into r2 */
    get_cpu r1
70000f9c:	ee1d1f70 	mrc	15, 0, r1, cr13, cr0, {3}
70000fa0:	e3c11003 	bic	r1, r1, #3
    ldr r2, [r1, #___cpu_t_current_OFFSET]
70000fa4:	e5912008 	ldr	r2, [r1, #8]
    /* Store LSB of LR (EXC_RETURN) to the thread's 'mode' word. */
    strb lr, [r2, #_thread_offset_to_mode_exc_return]
#endif

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
70000fa8:	e3a00030 	mov	r0, #48	; 0x30
    add r0, r2
70000fac:	e0800002 	add	r0, r0, r2

    /* Store rest of process context */
    cps #MODE_SYS
70000fb0:	f102001f 	cps	#31
    stm r0, {r4-r11, sp}
70000fb4:	e8802ff0 	stm	r0, {r4, r5, r6, r7, r8, r9, sl, fp, sp}
    cps #MODE_SVC
70000fb8:	f1020013 	cps	#19
    mov r0, #0
    str r0, [r1, #___cpu_t_fp_ctx_OFFSET]
#endif /* CONFIG_FPU_SHARING */

    /* fetch the thread to run from the ready queue cache */
    ldr r3, =_kernel
70000fbc:	e59f3028 	ldr	r3, [pc, #40]	; 70000fec <z_arm_do_swap+0x50>
    ldr r2, [r3, #_kernel_offset_to_ready_q_cache]
70000fc0:	e5932014 	ldr	r2, [r3, #20]

    str r2, [r1, #___cpu_t_current_OFFSET]
70000fc4:	e5812008 	str	r2, [r1, #8]
#endif

    /* Restore previous interrupt disable state (irq_lock key)
     * (We clear the arch.basepri field after restoring state)
     */
    ldr r0, [r2, #_thread_offset_to_basepri]
70000fc8:	e592006c 	ldr	r0, [r2, #108]	; 0x6c
    movs r3, #0
70000fcc:	e3b03000 	movs	r3, #0
    str r3, [r2, #_thread_offset_to_basepri]
70000fd0:	e582306c 	str	r3, [r2, #108]	; 0x6c

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
70000fd4:	e3a00030 	mov	r0, #48	; 0x30
    add r0, r2
70000fd8:	e0800002 	add	r0, r0, r2

    /* restore r4-r11 and sp for incoming thread */
    cps #MODE_SYS
70000fdc:	f102001f 	cps	#31
    ldm r0, {r4-r11, sp}
70000fe0:	e8902ff0 	ldm	r0, {r4, r5, r6, r7, r8, r9, sl, fp, sp}
    cps #MODE_SVC
70000fe4:	f1020013 	cps	#19
#endif /* CONFIG_INSTRUMENT_THREAD_SWITCHING */

    /*
     * Cortex-R: return to the caller (z_arm_{exc,int}_exit, or z_arm_svc)
     */
    bx lr
70000fe8:	e12fff1e 	bx	lr
    ldr r3, =_kernel
70000fec:	70006f58 	.word	0x70006f58

70000ff0 <z_arm_svc>:
    /*
     * Switch to system mode to store r0-r3 to the process stack pointer.
     * Save r12 and the lr as we could be swapping in another process and
     * returning to a different location.
     */
    srsdb #MODE_SYS!
70000ff0:	f96d051f 	srsdb	sp!, #31
    cps #MODE_SYS
70000ff4:	f102001f 	cps	#31
    push {r0-r3, r12, lr}
70000ff8:	e92d500f 	push	{r0, r1, r2, r3, ip, lr}
    ldr r0, [r2, #___cpu_t_fp_ctx_OFFSET]
    cmp r0, #0
    streq sp, [r2, #___cpu_t_fp_ctx_OFFSET]
#endif /* CONFIG_FPU_SHARING */

    mov ip, sp
70000ffc:	e1a0c00d 	mov	ip, sp

    cps #MODE_SVC
70001000:	f1020013 	cps	#19

    /*
     * Store lr_svc to the SVC mode stack. This value will be restored prior to
     * exiting the SVC call in z_arm_int_exit.
     */
    push {lr}
70001004:	e52de004 	push	{lr}		; (str lr, [sp, #-4]!)

    /* Align stack at double-word boundary */
    /* TODO: Question, why push {r2, r3} here */
    and r3, sp, #4
70001008:	e20d3004 	and	r3, sp, #4
    sub sp, sp, r3
7000100c:	e04dd003 	sub	sp, sp, r3
    push {r2, r3}
70001010:	e92d000c 	push	{r2, r3}

    /* Increment interrupt nesting count */
    get_cpu r2
70001014:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70001018:	e3c22003 	bic	r2, r2, #3
    ldr r0, [r2, #___cpu_t_nested_OFFSET]
7000101c:	e5920000 	ldr	r0, [r2]
    add r0, r0, #1
70001020:	e2800001 	add	r0, r0, #1
    str r0, [r2, #___cpu_t_nested_OFFSET]
70001024:	e5820000 	str	r0, [r2]

    /* Get SVC number */
    mrs r0, spsr
70001028:	e14f0000 	mrs	r0, SPSR
    tst r0, #0x20
7000102c:	e3100020 	tst	r0, #32

    ldreq r1, [lr, #-4]
70001030:	051e1004 	ldreq	r1, [lr, #-4]
    biceq r1, #0xff000000
70001034:	03c114ff 	biceq	r1, r1, #-16777216	; 0xff000000
    beq demux
70001038:	0a000001 	beq	70001044 <demux>

    ldr r1, [lr, #-2]
7000103c:	e51e1002 	ldr	r1, [lr, #-2]
    and r1, #0xff
70001040:	e20110ff 	and	r1, r1, #255	; 0xff

70001044 <demux>:
#if defined(CONFIG_USERSPACE)
    cmp r1, #_SVC_CALL_SYSTEM_CALL
    beq _do_syscall
#endif

    cmp r1, #_SVC_CALL_CONTEXT_SWITCH
70001044:	e3510000 	cmp	r1, #0
    beq _context_switch
70001048:	0a000001 	beq	70001054 <_context_switch>

    cmp r1, #_SVC_CALL_RUNTIME_EXCEPT
7000104c:	e3510002 	cmp	r1, #2
    beq _oops
70001050:	0a000001 	beq	7000105c <_oops>

70001054 <_context_switch>:
    b z_arm_int_exit
#endif

_context_switch:
    /* handler mode exit, to PendSV */
    bl z_arm_do_swap
70001054:	ebffffd0 	bl	70000f9c <z_arm_do_swap>

    b z_arm_int_exit
70001058:	ea000008 	b	70001080 <z_arm_int_exit>

7000105c <_oops>:

_oops:
    /*
     * Pass the exception frame to z_do_kernel_oops.
     */
    cps #MODE_SYS
7000105c:	f102001f 	cps	#31
    mov r0, sp
70001060:	e1a0000d 	mov	r0, sp
    cps #MODE_SVC
70001064:	f1020013 	cps	#19
    /* Zero callee_regs and exc_return (only used on Cortex-M) */
    mov r1, #0
70001068:	e3a01000 	mov	r1, #0
    mov r2, #0
7000106c:	e3a02000 	mov	r2, #0
    bl z_do_kernel_oops
70001070:	fafffea9 	blx	70000b1c <z_do_kernel_oops>
    b z_arm_int_exit
70001074:	ea000001 	b	70001080 <z_arm_int_exit>

70001078 <z_arm_cortex_r_svc>:
    b z_arm_int_exit
#endif

GTEXT(z_arm_cortex_r_svc)
SECTION_FUNC(TEXT, z_arm_cortex_r_svc)
    svc #_SVC_CALL_CONTEXT_SWITCH
70001078:	ef000000 	svc	0x00000000
    bx lr
7000107c:	e12fff1e 	bx	lr

70001080 <z_arm_int_exit>:
#endif /* CONFIG_STACK_SENTINEL */

	/* Disable nested interrupts while exiting, this should happens
	 * before context switch also, to ensure interrupts are disabled.
	 */
	cpsid i
70001080:	f10c0080 	cpsid	i

#ifdef CONFIG_PREEMPT_ENABLED
	/* Do not context switch if exiting a nested interrupt */
	get_cpu r3
70001084:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70001088:	e3c33003 	bic	r3, r3, #3
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
7000108c:	e5930000 	ldr	r0, [r3]
	cmp r0, #1
70001090:	e3500001 	cmp	r0, #1
	bhi __EXIT_INT
70001094:	8a000004 	bhi	700010ac <__EXIT_INT>

	ldr r1, [r3, #___cpu_t_current_OFFSET]
70001098:	e5931008 	ldr	r1, [r3, #8]
	ldr r2, =_kernel
7000109c:	e59f2094 	ldr	r2, [pc, #148]	; 70001138 <__EXIT_EXC+0x18>
	ldr r0, [r2, #_kernel_offset_to_ready_q_cache]
700010a0:	e5920014 	ldr	r0, [r2, #20]
	cmp r0, r1
700010a4:	e1500001 	cmp	r0, r1
	blne z_arm_do_swap
700010a8:	1bffffbb 	blne	70000f9c <z_arm_do_swap>

700010ac <__EXIT_INT>:
__EXIT_INT:
#endif /* CONFIG_PREEMPT_ENABLED */

	/* Decrement interrupt nesting count */
	get_cpu r2
700010ac:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
700010b0:	e3c22003 	bic	r2, r2, #3
	ldr r0, [r2, #___cpu_t_nested_OFFSET]
700010b4:	e5920000 	ldr	r0, [r2]
	sub r0, r0, #1
700010b8:	e2400001 	sub	r0, r0, #1
	str r0, [r2, #___cpu_t_nested_OFFSET]
700010bc:	e5820000 	str	r0, [r2]

	/* Restore previous stack pointer */
	pop {r2, r3}
700010c0:	e8bd000c 	pop	{r2, r3}
	add sp, sp, r3
700010c4:	e08dd003 	add	sp, sp, r3
	/*
	 * Restore lr_svc stored into the SVC mode stack by the mode entry
	 * function. This ensures that the return address of the interrupted
	 * context is preserved in case of interrupt nesting.
	 */
	pop {lr}
700010c8:	e49de004 	pop	{lr}		; (ldr lr, [sp], #4)
	 * IRQ mode and z_arm_svc for SVC mode.
	 *
	 * r0-r3 are either the values from the thread before it was switched
	 * out or they are the args to _new_thread for a new thread.
	 */
	cps #MODE_SYS
700010cc:	f102001f 	cps	#31

#if defined(CONFIG_FPU_SHARING)
	fpu_exc_exit
#endif

	pop {r0-r3, r12, lr}
700010d0:	e8bd500f 	pop	{r0, r1, r2, r3, ip, lr}
	userspace_exc_exit
	rfeia sp!
700010d4:	f8bd0a00 	rfeia	sp!

700010d8 <z_arm_exc_exit>:
 *
 * @param fatal True if exiting from a fatal fault; otherwise, false
 */
SECTION_SUBSEC_FUNC(TEXT, _HandlerModeExit, z_arm_exc_exit)
	/* Do not context switch if exiting a nested exception */
	get_cpu r3
700010d8:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
700010dc:	e3c33003 	bic	r3, r3, #3
	ldr r1, [r3, #___cpu_t_nested_OFFSET]
700010e0:	e5931000 	ldr	r1, [r3]
	cmp r1, #1
700010e4:	e3510001 	cmp	r1, #1
	bhi __EXIT_EXC
700010e8:	8a00000c 	bhi	70001120 <__EXIT_EXC>

	/* If the fault is not fatal, return to the current thread context */
	cmp r0, #0
700010ec:	e3500000 	cmp	r0, #0
	beq __EXIT_EXC
700010f0:	0a00000a 	beq	70001120 <__EXIT_EXC>

	/* Clean up exception stack frame */
#if defined(CONFIG_FPU_SHARING)
	add sp, sp, #___fpu_t_SIZEOF
#endif
	add sp, #32
700010f4:	e28dd020 	add	sp, sp, #32
	 *
	 * Note that z_arm_do_swap must be called in the SVC mode because it
	 * switches to the SVC mode during context switch and returns to the
	 * caller using lr_svc.
	 */
	cps #MODE_SVC
700010f8:	f1020013 	cps	#19
	bl z_arm_do_swap
700010fc:	ebffffa6 	bl	70000f9c <z_arm_do_swap>

	/* Decrement exception nesting count */
	get_cpu r3
70001100:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70001104:	e3c33003 	bic	r3, r3, #3
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
70001108:	e5930000 	ldr	r0, [r3]
	sub r0, r0, #1
7000110c:	e2400001 	sub	r0, r0, #1
	str r0, [r3, #___cpu_t_nested_OFFSET]
70001110:	e5830000 	str	r0, [r3]

	/* Return to the switched thread */
	cps #MODE_SYS
70001114:	f102001f 	cps	#31
#if defined(CONFIG_FPU_SHARING)
	fpu_exc_exit
#endif
	pop {r0-r3, r12, lr}
70001118:	e8bd500f 	pop	{r0, r1, r2, r3, ip, lr}
	userspace_exc_exit
	rfeia sp!
7000111c:	f8bd0a00 	rfeia	sp!

70001120 <__EXIT_EXC>:

__EXIT_EXC:
	/* Decrement exception nesting count */
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
70001120:	e5930000 	ldr	r0, [r3]
	sub r0, r0, #1
70001124:	e2400001 	sub	r0, r0, #1
	str r0, [r3, #___cpu_t_nested_OFFSET]
70001128:	e5830000 	str	r0, [r3]
#endif
	/*
	 * Restore r0-r3, r12, lr, lr_und and spsr_und from the exception stack
	 * and return to the current thread.
	 */
	ldmia sp, {r0-r3, r12, lr}^
7000112c:	e8dd500f 	ldm	sp, {r0, r1, r2, r3, ip, lr}^
	add sp, #24
70001130:	e28dd018 	add	sp, sp, #24
	rfeia sp!
70001134:	f8bd0a00 	rfeia	sp!
	ldr r2, =_kernel
70001138:	70006f58 	.word	0x70006f58

7000113c <picolibc_put>:
}
#include <zephyr/syscalls/zephyr_fputc_mrsh.c>
#endif

static int picolibc_put(char a, FILE *f)
{
7000113c:	b508      	push	{r3, lr}
	(*_stdout_hook)(a);
7000113e:	f646 7344 	movw	r3, #28484	; 0x6f44
70001142:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001146:	681b      	ldr	r3, [r3, #0]
70001148:	4798      	blx	r3
	zephyr_fputc(a, f);
	return 0;
}
7000114a:	2000      	movs	r0, #0
7000114c:	bd08      	pop	{r3, pc}
7000114e:	bf00      	nop

70001150 <__stdout_hook_install>:
FILE *const stdout = &__stdout;
STDIO_ALIAS(stderr);

void __stdout_hook_install(int (*hook)(int))
{
	_stdout_hook = hook;
70001150:	f646 7144 	movw	r1, #28484	; 0x6f44
	__stdout.flags |= _FDEV_SETUP_WRITE;
70001154:	f24b 4328 	movw	r3, #46120	; 0xb428
70001158:	f2c7 0300 	movt	r3, #28672	; 0x7000
7000115c:	789a      	ldrb	r2, [r3, #2]
	_stdout_hook = hook;
7000115e:	f2c7 0100 	movt	r1, #28672	; 0x7000
	__stdout.flags |= _FDEV_SETUP_WRITE;
70001162:	f042 0202 	orr.w	r2, r2, #2
	_stdout_hook = hook;
70001166:	6008      	str	r0, [r1, #0]
	__stdout.flags |= _FDEV_SETUP_WRITE;
70001168:	709a      	strb	r2, [r3, #2]
}
7000116a:	4770      	bx	lr

7000116c <malloc_prepare>:
			break;
		}
		heap_size >>= 1;
	}
#else
	heap_base = UINT_TO_POINTER(HEAP_BASE);
7000116c:	4907      	ldr	r1, [pc, #28]	; (7000118c <malloc_prepare+0x20>)
	z_malloc_partition.start = POINTER_TO_UINT(heap_base);
	z_malloc_partition.size = heap_size;
	z_malloc_partition.attr = K_MEM_PARTITION_P_RW_U_RW;
#endif

	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
7000116e:	f646 7048 	movw	r0, #28488	; 0x6f48
70001172:	f2c7 0000 	movt	r0, #28672	; 0x7000
	heap_base = UINT_TO_POINTER(HEAP_BASE);
70001176:	f021 0107 	bic.w	r1, r1, #7
	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
7000117a:	f1c1 42e0 	rsb	r2, r1, #1879048192	; 0x70000000
7000117e:	f502 3200 	add.w	r2, r2, #131072	; 0x20000
{
70001182:	b508      	push	{r3, lr}
	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
70001184:	f7ff fc48 	bl	70000a18 <sys_heap_init>

	return 0;
}
70001188:	2000      	movs	r0, #0
7000118a:	bd08      	pop	{r3, pc}
7000118c:	7000b463 	.word	0x7000b463

70001190 <z_vim_irq_get_active>:

static ALWAYS_INLINE uint32_t sys_read32(mem_addr_t addr)
{
	uint32_t val;

	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001190:	2318      	movs	r3, #24
70001192:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
70001196:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001198:	f3bf 8f5f 	dmb	sy
7000119c:	2320      	movs	r3, #32
7000119e:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
700011a2:	681b      	ldr	r3, [r3, #0]
700011a4:	f3bf 8f5f 	dmb	sy
	actirq = sys_read32(VIM_ACTIRQ);

	/* Check if the irq number is valid, else return invalid irq number.
	 * which will be considered as spurious interrupt
	 */
	if ((actirq & (VIM_ACTIRQ_VALID_MASK)) == 0) {
700011a8:	2b00      	cmp	r3, #0
700011aa:	da14      	bge.n	700011d6 <z_vim_irq_get_active+0x46>
		return CONFIG_NUM_IRQS + 1;
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(actirq & VIM_PRIIRQ_NUM_MASK);
700011ac:	f3c3 0009 	ubfx	r0, r3, #0, #10
700011b0:	f3bf 8f5f 	dmb	sy
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(actirq & VIM_PRIIRQ_NUM_MASK);

	/* Ack the interrupt in IRQSTS register */
	sys_write32(BIT(irq_bit_num), VIM_IRQSTS(irq_group_num));
700011b4:	2101      	movs	r1, #1
700011b6:	f44f 6282 	mov.w	r2, #1040	; 0x410
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(actirq & VIM_PRIIRQ_NUM_MASK);
700011ba:	f003 0c1f 	and.w	ip, r3, #31
	sys_write32(BIT(irq_bit_num), VIM_IRQSTS(irq_group_num));
700011be:	f6c2 72ff 	movt	r2, #12287	; 0x2fff
700011c2:	f403 7378 	and.w	r3, r3, #992	; 0x3e0
700011c6:	fa01 f10c 	lsl.w	r1, r1, ip
700011ca:	441a      	add	r2, r3
}

static ALWAYS_INLINE void sys_write32(uint32_t data, mem_addr_t addr)
{
	barrier_dmem_fence_full();
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700011cc:	6011      	str	r1, [r2, #0]

	if (irq_group_num > VIM_MAX_GROUP_NUM) {
700011ce:	f5b0 7f08 	cmp.w	r0, #544	; 0x220
700011d2:	d200      	bcs.n	700011d6 <z_vim_irq_get_active+0x46>
		return (CONFIG_NUM_IRQS + 1);
	}

	return (actirq & VIM_ACTIRQ_NUM_MASK);
}
700011d4:	4770      	bx	lr
		return CONFIG_NUM_IRQS + 1;
700011d6:	f240 2001 	movw	r0, #513	; 0x201
700011da:	4770      	bx	lr

700011dc <z_vim_irq_eoi>:
700011dc:	f3bf 8f5f 	dmb	sy
700011e0:	2318      	movs	r3, #24
700011e2:	2200      	movs	r2, #0
700011e4:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
700011e8:	601a      	str	r2, [r3, #0]

void z_vim_irq_eoi(unsigned int irq)
{
	sys_write32(0, VIM_IRQVEC);
}
700011ea:	4770      	bx	lr

700011ec <z_vim_irq_init>:
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700011ec:	2004      	movs	r0, #4
700011ee:	f6c2 70ff 	movt	r0, #12287	; 0x2fff

void z_vim_irq_init(void)
{
700011f2:	b500      	push	{lr}
700011f4:	6800      	ldr	r0, [r0, #0]
700011f6:	f3bf 8f5f 	dmb	sy
	uint32_t num_of_irqs = sys_read32(VIM_INFO) & VIM_INFO_INTERRUPTS_MASK;
700011fa:	f3c0 000a 	ubfx	r0, r0, #0, #11
	unsigned int irq;

	LOG_DBG("VIM: Number of IRQs = %u\n", num_of_irqs);

	/* make sure all IRQs are initially disabled and cleared */
	for (irq = 0; irq < num_of_irqs; irq+=32)
700011fe:	b1b8      	cbz	r0, 70001230 <z_vim_irq_init+0x44>
	{
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
70001200:	f240 4e0c 	movw	lr, #1036	; 0x40c
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
70001204:	f240 4c04 	movw	ip, #1028	; 0x404
	for (irq = 0; irq < num_of_irqs; irq+=32)
70001208:	2300      	movs	r3, #0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000120a:	f06f 4200 	mvn.w	r2, #2147483648	; 0x80000000
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
7000120e:	f6c2 7eff 	movt	lr, #12287	; 0x2fff
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
70001212:	f6c2 7cff 	movt	ip, #12287	; 0x2fff
70001216:	f3bf 8f5f 	dmb	sy
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
7000121a:	eb03 010e 	add.w	r1, r3, lr
7000121e:	600a      	str	r2, [r1, #0]
70001220:	f3bf 8f5f 	dmb	sy
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
70001224:	eb03 010c 	add.w	r1, r3, ip
70001228:	600a      	str	r2, [r1, #0]
	for (irq = 0; irq < num_of_irqs; irq+=32)
7000122a:	3320      	adds	r3, #32
7000122c:	4298      	cmp	r0, r3
7000122e:	d8f2      	bhi.n	70001216 <z_vim_irq_init+0x2a>
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001230:	2318      	movs	r3, #24
70001232:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
70001236:	681a      	ldr	r2, [r3, #0]
70001238:	f3bf 8f5f 	dmb	sy
7000123c:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001240:	2200      	movs	r2, #0
70001242:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001244:	231c      	movs	r3, #28
70001246:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
7000124a:	6819      	ldr	r1, [r3, #0]
7000124c:	f3bf 8f5f 	dmb	sy
70001250:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001254:	601a      	str	r2, [r3, #0]
	/* ACK and clear pending IRQs */
	(void) sys_read32(VIM_IRQVEC);
	sys_write32(0, VIM_IRQVEC);
	(void) sys_read32(VIM_FIQVEC);
	sys_write32(0, VIM_FIQVEC);
}
70001256:	f85d fb04 	ldr.w	pc, [sp], #4
7000125a:	bf00      	nop

7000125c <z_vim_irq_priority_set>:

void z_vim_irq_priority_set(unsigned int irq, unsigned int prio, uint32_t flags)
{
	uint32_t irq_group_num, irq_bit_num, regval;

	if (irq > CONFIG_NUM_IRQS || prio > VIM_PRI_INT_MAX ||
7000125c:	290f      	cmp	r1, #15
7000125e:	bf98      	it	ls
70001260:	f5b0 7f00 	cmpls.w	r0, #512	; 0x200
70001264:	d824      	bhi.n	700012b0 <z_vim_irq_priority_set+0x54>
	    (flags != IRQ_TYPE_EDGE && flags != IRQ_TYPE_LEVEL)) {
70001266:	1e93      	subs	r3, r2, #2
	if (irq > CONFIG_NUM_IRQS || prio > VIM_PRI_INT_MAX ||
70001268:	f033 0302 	bics.w	r3, r3, #2
7000126c:	d120      	bne.n	700012b0 <z_vim_irq_priority_set+0x54>
7000126e:	f3bf 8f5f 	dmb	sy
		LOG_ERR("%s: Invalid argument irq = %u prio = %u flags = %u\n",
			__func__, irq, prio, flags);
		return;
	}

	sys_write8(prio, VIM_PRI_INT(irq));
70001272:	f100 6340 	add.w	r3, r0, #201326592	; 0xc000000
70001276:	f5a3 5370 	sub.w	r3, r3, #15360	; 0x3c00
7000127a:	009b      	lsls	r3, r3, #2
	__asm__ volatile("strb %0, [%1]" : : "r" (data), "r" (addr));
7000127c:	7019      	strb	r1, [r3, #0]

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	regval = sys_read32(VIM_INTTYPE(irq_group_num));
7000127e:	f240 431c 	movw	r3, #1052	; 0x41c
70001282:	f020 011f 	bic.w	r1, r0, #31
70001286:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
7000128a:	440b      	add	r3, r1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000128c:	6819      	ldr	r1, [r3, #0]
7000128e:	f3bf 8f5f 	dmb	sy

	if (flags == IRQ_TYPE_EDGE) {
		regval |= (BIT(irq_bit_num));
70001292:	f04f 0c01 	mov.w	ip, #1
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
70001296:	f000 001f 	and.w	r0, r0, #31
	if (flags == IRQ_TYPE_EDGE) {
7000129a:	2a04      	cmp	r2, #4
		regval |= (BIT(irq_bit_num));
7000129c:	fa0c f000 	lsl.w	r0, ip, r0
700012a0:	bf0c      	ite	eq
700012a2:	ea40 0201 	orreq.w	r2, r0, r1
	} else {
		regval &= ~(BIT(irq_bit_num));
700012a6:	ea21 0200 	bicne.w	r2, r1, r0
700012aa:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700012ae:	601a      	str	r2, [r3, #0]
	}

	sys_write32(regval, VIM_INTTYPE(irq_group_num));
}
700012b0:	4770      	bx	lr
700012b2:	bf00      	nop

700012b4 <z_vim_irq_enable>:

void z_vim_irq_enable(unsigned int irq)
{
	uint32_t irq_group_num, irq_bit_num;

	if (irq > CONFIG_NUM_IRQS) {
700012b4:	f5b0 7f00 	cmp.w	r0, #512	; 0x200
700012b8:	d80d      	bhi.n	700012d6 <z_vim_irq_enable+0x22>
700012ba:	f3bf 8f5f 	dmb	sy
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	sys_write32(BIT(irq_bit_num), VIM_INTR_EN_SET(irq_group_num));
700012be:	2201      	movs	r2, #1
700012c0:	f44f 6381 	mov.w	r3, #1032	; 0x408
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
700012c4:	f000 011f 	and.w	r1, r0, #31
	sys_write32(BIT(irq_bit_num), VIM_INTR_EN_SET(irq_group_num));
700012c8:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
700012cc:	f020 001f 	bic.w	r0, r0, #31
700012d0:	408a      	lsls	r2, r1
700012d2:	4403      	add	r3, r0
700012d4:	601a      	str	r2, [r3, #0]
}
700012d6:	4770      	bx	lr

700012d8 <console_out>:
		 * function MUST return the byte output.
		 */
		return c;
	}

	if ('\n' == c) {
700012d8:	280a      	cmp	r0, #10
{
700012da:	b538      	push	{r3, r4, r5, lr}
700012dc:	4604      	mov	r4, r0
	if ('\n' == c) {
700012de:	d00d      	beq.n	700012fc <console_out+0x24>
700012e0:	f643 553c 	movw	r5, #15676	; 0x3d3c
700012e4:	f2c7 0500 	movt	r5, #28672	; 0x7000

static inline void z_impl_uart_poll_out(const struct device *dev, unsigned char out_char)
{
	const struct uart_driver_api *api = (const struct uart_driver_api *)dev->api;

	api->poll_out(dev, out_char);
700012e8:	68ab      	ldr	r3, [r5, #8]
700012ea:	f643 503c 	movw	r0, #15676	; 0x3d3c
700012ee:	b2e1      	uxtb	r1, r4
700012f0:	f2c7 0000 	movt	r0, #28672	; 0x7000
700012f4:	685b      	ldr	r3, [r3, #4]
700012f6:	4798      	blx	r3
	 * As errors cannot be returned, ignore the return value
	 */
	(void)pm_device_runtime_put_async(uart_console_dev, K_MSEC(1));

	return c;
}
700012f8:	4620      	mov	r0, r4
700012fa:	bd38      	pop	{r3, r4, r5, pc}
700012fc:	f643 553c 	movw	r5, #15676	; 0x3d3c
70001300:	210d      	movs	r1, #13
70001302:	f2c7 0500 	movt	r5, #28672	; 0x7000
70001306:	4628      	mov	r0, r5
70001308:	68ab      	ldr	r3, [r5, #8]
7000130a:	685b      	ldr	r3, [r3, #4]
7000130c:	4798      	blx	r3
		return;
	}
#endif
	compiler_barrier();
	z_impl_uart_poll_out(dev, out_char);
}
7000130e:	e7eb      	b.n	700012e8 <console_out+0x10>

70001310 <uart_console_init>:
 * @brief Initialize one UART as the console/debug port
 *
 * @return 0 if successful, otherwise failed.
 */
static int uart_console_init(void)
{
70001310:	b508      	push	{r3, lr}
		union { uintptr_t x; const struct device * val; } parm0 = { .val = dev };
		return (bool) arch_syscall_invoke1(parm0.x, K_SYSCALL_DEVICE_IS_READY);
	}
#endif
	compiler_barrier();
	return z_impl_device_is_ready(dev);
70001312:	f643 503c 	movw	r0, #15676	; 0x3d3c
70001316:	f2c7 0000 	movt	r0, #28672	; 0x7000
7000131a:	f000 fbe1 	bl	70001ae0 <z_impl_device_is_ready>
	if (!device_is_ready(uart_console_dev)) {
7000131e:	b168      	cbz	r0, 7000133c <uart_console_init+0x2c>
	__stdout_hook_install(console_out);
70001320:	f241 20d9 	movw	r0, #4825	; 0x12d9
70001324:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001328:	f7ff ff12 	bl	70001150 <__stdout_hook_install>
	__printk_hook_install(console_out);
7000132c:	f241 20d9 	movw	r0, #4825	; 0x12d9
70001330:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001334:	f7ff fbae 	bl	70000a94 <__printk_hook_install>
		return -ENODEV;
	}

	uart_console_hook_install();

	return 0;
70001338:	2000      	movs	r0, #0
}
7000133a:	bd08      	pop	{r3, pc}
		return -ENODEV;
7000133c:	f06f 0012 	mvn.w	r0, #18
}
70001340:	bd08      	pop	{r3, pc}
70001342:	bf00      	nop

70001344 <pinctrl_lookup_state>:
#include <zephyr/drivers/pinctrl.h>

int pinctrl_lookup_state(const struct pinctrl_dev_config *config, uint8_t id,
			 const struct pinctrl_state **state)
{
	*state = &config->states[0];
70001344:	6803      	ldr	r3, [r0, #0]
70001346:	6013      	str	r3, [r2, #0]
	while (*state < &config->states[config->state_cnt]) {
70001348:	f890 c004 	ldrb.w	ip, [r0, #4]
7000134c:	eb03 0ccc 	add.w	ip, r3, ip, lsl #3
70001350:	4563      	cmp	r3, ip
70001352:	d21f      	bcs.n	70001394 <pinctrl_lookup_state+0x50>
		if (id == (*state)->id) {
70001354:	f893 c005 	ldrb.w	ip, [r3, #5]
70001358:	458c      	cmp	ip, r1
			return 0;
		}

		(*state)++;
7000135a:	f103 0308 	add.w	r3, r3, #8
		if (id == (*state)->id) {
7000135e:	d017      	beq.n	70001390 <pinctrl_lookup_state+0x4c>
{
70001360:	b500      	push	{lr}
70001362:	e005      	b.n	70001370 <pinctrl_lookup_state+0x2c>
		if (id == (*state)->id) {
70001364:	f893 c005 	ldrb.w	ip, [r3, #5]
70001368:	458c      	cmp	ip, r1
		(*state)++;
7000136a:	f103 0308 	add.w	r3, r3, #8
		if (id == (*state)->id) {
7000136e:	d00c      	beq.n	7000138a <pinctrl_lookup_state+0x46>
		(*state)++;
70001370:	6013      	str	r3, [r2, #0]
	while (*state < &config->states[config->state_cnt]) {
70001372:	f890 c004 	ldrb.w	ip, [r0, #4]
70001376:	f8d0 e000 	ldr.w	lr, [r0]
7000137a:	eb0e 0ccc 	add.w	ip, lr, ip, lsl #3
7000137e:	4563      	cmp	r3, ip
70001380:	d3f0      	bcc.n	70001364 <pinctrl_lookup_state+0x20>
	}

	return -ENOENT;
70001382:	f06f 0001 	mvn.w	r0, #1
}
70001386:	f85d fb04 	ldr.w	pc, [sp], #4
			return 0;
7000138a:	2000      	movs	r0, #0
}
7000138c:	f85d fb04 	ldr.w	pc, [sp], #4
			return 0;
70001390:	2000      	movs	r0, #0
}
70001392:	4770      	bx	lr
	return -ENOENT;
70001394:	f06f 0001 	mvn.w	r0, #1
70001398:	4770      	bx	lr
7000139a:	bf00      	nop

7000139c <pinctrl_ti_k3_init>:

static int pinctrl_ti_k3_init(const struct device *dev)
{
	DEVICE_MMIO_MAP(dev, K_MEM_CACHE_NONE);
	return 0;
}
7000139c:	2000      	movs	r0, #0
7000139e:	4770      	bx	lr

700013a0 <pinctrl_configure_pins>:
	uintptr_t virt_reg_base = DEVICE_MMIO_GET(dev);
700013a0:	f24b 4338 	movw	r3, #46136	; 0xb438
700013a4:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
700013a8:	b410      	push	{r4}
	uintptr_t virt_reg_base = DEVICE_MMIO_GET(dev);
700013aa:	681c      	ldr	r4, [r3, #0]
	for (uint8_t i = 0; i < pin_cnt; i++) {
700013ac:	b151      	cbz	r1, 700013c4 <pinctrl_configure_pins+0x24>
700013ae:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
		sys_write32(pins[i].value, virt_reg_base + pins[i].offset);
700013b2:	6842      	ldr	r2, [r0, #4]
700013b4:	f850 3b08 	ldr.w	r3, [r0], #8
700013b8:	4423      	add	r3, r4
700013ba:	f3bf 8f5f 	dmb	sy
700013be:	601a      	str	r2, [r3, #0]
	for (uint8_t i = 0; i < pin_cnt; i++) {
700013c0:	4288      	cmp	r0, r1
700013c2:	d1f6      	bne.n	700013b2 <pinctrl_configure_pins+0x12>
}
700013c4:	bc10      	pop	{r4}
700013c6:	2000      	movs	r0, #0
700013c8:	4770      	bx	lr
700013ca:	bf00      	nop

700013cc <uart_ns16550_config_get>:
};

#ifdef CONFIG_UART_USE_RUNTIME_CONFIGURE
static int uart_ns16550_config_get(const struct device *dev,
				   struct uart_config *cfg)
{
700013cc:	4603      	mov	r3, r0
	cfg->stop_bits = data->uart_config.stop_bits;
	cfg->data_bits = data->uart_config.data_bits;
	cfg->flow_ctrl = data->uart_config.flow_ctrl;

	return 0;
}
700013ce:	2000      	movs	r0, #0
	struct uart_ns16550_dev_data *data = dev->data;
700013d0:	691b      	ldr	r3, [r3, #16]
	cfg->baudrate = data->uart_config.baudrate;
700013d2:	681a      	ldr	r2, [r3, #0]
700013d4:	600a      	str	r2, [r1, #0]
	cfg->parity = data->uart_config.parity;
700013d6:	791a      	ldrb	r2, [r3, #4]
700013d8:	710a      	strb	r2, [r1, #4]
	cfg->stop_bits = data->uart_config.stop_bits;
700013da:	795a      	ldrb	r2, [r3, #5]
700013dc:	714a      	strb	r2, [r1, #5]
	cfg->data_bits = data->uart_config.data_bits;
700013de:	799a      	ldrb	r2, [r3, #6]
700013e0:	718a      	strb	r2, [r1, #6]
	cfg->flow_ctrl = data->uart_config.flow_ctrl;
700013e2:	79db      	ldrb	r3, [r3, #7]
700013e4:	71cb      	strb	r3, [r1, #7]
}
700013e6:	4770      	bx	lr

700013e8 <uart_ns16550_poll_out>:
 * @param dev UART device struct
 * @param c Character to send
 */
static void uart_ns16550_poll_out(const struct device *dev,
					   unsigned char c)
{
700013e8:	b410      	push	{r4}
	key = __get_BASEPRI();
	__set_BASEPRI_MAX(_EXC_IRQ_DEFAULT_PRIO);
	__ISB();
#elif defined(CONFIG_ARMV7_R) || defined(CONFIG_AARCH32_ARMV8_R) \
	|| defined(CONFIG_ARMV7_A)
	__asm__ volatile(
700013ea:	f3ef 8400 	mrs	r4, CPSR
700013ee:	f004 0480 	and.w	r4, r4, #128	; 0x80
700013f2:	b672      	cpsid	i
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	while ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_THRE) == 0) {
700013f4:	f04f 0c05 	mov.w	ip, #5
		port = DEVICE_MMIO_GET(dev);
700013f8:	6842      	ldr	r2, [r0, #4]
	while ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_THRE) == 0) {
700013fa:	7d13      	ldrb	r3, [r2, #20]
700013fc:	6812      	ldr	r2, [r2, #0]
700013fe:	fb1c 2303 	smlabb	r3, ip, r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001402:	681b      	ldr	r3, [r3, #0]
70001404:	f3bf 8f5f 	dmb	sy
70001408:	069b      	lsls	r3, r3, #26
7000140a:	d5f5      	bpl.n	700013f8 <uart_ns16550_poll_out+0x10>
		port = DEVICE_MMIO_GET(dev);
7000140c:	6843      	ldr	r3, [r0, #4]
7000140e:	681b      	ldr	r3, [r3, #0]
70001410:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001414:	6019      	str	r1, [r3, #0]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	__set_BASEPRI(key);
	__ISB();
#elif defined(CONFIG_ARMV7_R) || defined(CONFIG_AARCH32_ARMV8_R) \
	|| defined(CONFIG_ARMV7_A)
	if (key != 0U) {
70001416:	b904      	cbnz	r4, 7000141a <uart_ns16550_poll_out+0x32>
  \details Enables IRQ interrupts by clearing the I-bit in the CPSR.
           Can only be executed in Privileged modes.
 */
__STATIC_FORCEINLINE void __enable_irq(void)
{
  __ASM volatile ("cpsie i" : : : "memory");
70001418:	b662      	cpsie	i
	}

	ns16550_outbyte(dev_cfg, THR(dev), c);

	k_spin_unlock(&data->lock, key);
}
7000141a:	bc10      	pop	{r4}
7000141c:	4770      	bx	lr
7000141e:	bf00      	nop

70001420 <uart_ns16550_err_check>:
	__asm__ volatile(
70001420:	f3ef 8200 	mrs	r2, CPSR
70001424:	f002 0280 	and.w	r2, r2, #128	; 0x80
70001428:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000142a:	6843      	ldr	r3, [r0, #4]
static int uart_ns16550_err_check(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);
	int check = (ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_EOB_MASK);
7000142c:	7d19      	ldrb	r1, [r3, #20]
7000142e:	2005      	movs	r0, #5
70001430:	681b      	ldr	r3, [r3, #0]
70001432:	fb10 3001 	smlabb	r0, r0, r1, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001436:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001438:	f3bf 8f5f 	dmb	sy
	if (key != 0U) {
7000143c:	b902      	cbnz	r2, 70001440 <uart_ns16550_err_check+0x20>
  __ASM volatile ("cpsie i" : : : "memory");
7000143e:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return check >> 1;
}
70001440:	f3c0 0043 	ubfx	r0, r0, #1, #4
70001444:	4770      	bx	lr
70001446:	bf00      	nop

70001448 <uart_ns16550_fifo_fill>:
 * @return Number of bytes sent
 */
static int uart_ns16550_fifo_fill(const struct device *dev,
				  const uint8_t *tx_data,
				  int size)
{
70001448:	b470      	push	{r4, r5, r6}
	struct uart_ns16550_dev_data *data = dev->data;
7000144a:	6905      	ldr	r5, [r0, #16]
	__asm__ volatile(
7000144c:	f3ef 8600 	mrs	r6, CPSR
70001450:	f006 0680 	and.w	r6, r6, #128	; 0x80
70001454:	b672      	cpsid	i
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	int i;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
70001456:	2a00      	cmp	r2, #0
70001458:	dd15      	ble.n	70001486 <uart_ns16550_fifo_fill+0x3e>
7000145a:	4684      	mov	ip, r0
7000145c:	3901      	subs	r1, #1
7000145e:	2000      	movs	r0, #0
70001460:	e00a      	b.n	70001478 <uart_ns16550_fifo_fill+0x30>
		port = DEVICE_MMIO_GET(dev);
70001462:	f8dc 4004 	ldr.w	r4, [ip, #4]
			sys_write32(val, port);
70001466:	f811 3f01 	ldrb.w	r3, [r1, #1]!
		port = DEVICE_MMIO_GET(dev);
7000146a:	6824      	ldr	r4, [r4, #0]
  __ASM volatile ("dmb 0xF":::"memory");
7000146c:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001470:	6023      	str	r3, [r4, #0]
	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
70001472:	3001      	adds	r0, #1
70001474:	4282      	cmp	r2, r0
70001476:	d002      	beq.n	7000147e <uart_ns16550_fifo_fill+0x36>
70001478:	7a2b      	ldrb	r3, [r5, #8]
7000147a:	4283      	cmp	r3, r0
7000147c:	dcf1      	bgt.n	70001462 <uart_ns16550_fifo_fill+0x1a>
	if (key != 0U) {
7000147e:	b906      	cbnz	r6, 70001482 <uart_ns16550_fifo_fill+0x3a>
  __ASM volatile ("cpsie i" : : : "memory");
70001480:	b662      	cpsie	i
	}

	k_spin_unlock(&data->lock, key);

	return i;
}
70001482:	bc70      	pop	{r4, r5, r6}
70001484:	4770      	bx	lr
	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
70001486:	2000      	movs	r0, #0
70001488:	e7f9      	b.n	7000147e <uart_ns16550_fifo_fill+0x36>
7000148a:	bf00      	nop

7000148c <uart_ns16550_irq_tx_enable>:
	__asm__ volatile(
7000148c:	f3ef 8100 	mrs	r1, CPSR
70001490:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001494:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70001496:	6843      	ldr	r3, [r0, #4]
		for (uint8_t i = 0U; i < num_cpu_states; i++) {
			pm_policy_state_lock_get(cpu_states[i].state, PM_ALL_SUBSTATES);
		}
	}
#endif
	ns16550_outbyte(dev_cfg, IER(dev), ns16550_inbyte(dev_cfg, IER(dev)) | IER_TBE);
70001498:	7d1a      	ldrb	r2, [r3, #20]
7000149a:	681b      	ldr	r3, [r3, #0]
7000149c:	441a      	add	r2, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000149e:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700014a0:	f3bf 8f5f 	dmb	sy
700014a4:	f3bf 8f5f 	dmb	sy
700014a8:	f043 0302 	orr.w	r3, r3, #2
			sys_write32(val, port);
700014ac:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700014ae:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
700014b0:	b901      	cbnz	r1, 700014b4 <uart_ns16550_irq_tx_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
700014b2:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);
}
700014b4:	4770      	bx	lr
700014b6:	bf00      	nop

700014b8 <uart_ns16550_irq_tx_disable>:
	__asm__ volatile(
700014b8:	f3ef 8100 	mrs	r1, CPSR
700014bc:	f001 0180 	and.w	r1, r1, #128	; 0x80
700014c0:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700014c2:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
700014c4:	7d13      	ldrb	r3, [r2, #20]
700014c6:	6812      	ldr	r2, [r2, #0]
700014c8:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700014ca:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700014cc:	f3bf 8f5f 	dmb	sy
700014d0:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
700014d4:	f002 02fd 	and.w	r2, r2, #253	; 0xfd
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700014d8:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
700014da:	b901      	cbnz	r1, 700014de <uart_ns16550_irq_tx_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
700014dc:	b662      	cpsie	i
			pm_policy_state_lock_put(cpu_states[i].state, PM_ALL_SUBSTATES);
		}
	}
#endif
	k_spin_unlock(&data->lock, key);
}
700014de:	4770      	bx	lr

700014e0 <uart_ns16550_irq_tx_ready>:
	__asm__ volatile(
700014e0:	f3ef 8300 	mrs	r3, CPSR
700014e4:	f003 0380 	and.w	r3, r3, #128	; 0x80
700014e8:	b672      	cpsid	i
static int uart_ns16550_irq_tx_ready(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((IIRC(dev) & IIR_ID) == IIR_THRE) ? 1 : 0;
700014ea:	6902      	ldr	r2, [r0, #16]
700014ec:	7a50      	ldrb	r0, [r2, #9]
700014ee:	f000 0006 	and.w	r0, r0, #6
700014f2:	f1a0 0002 	sub.w	r0, r0, #2
700014f6:	fab0 f080 	clz	r0, r0
700014fa:	0940      	lsrs	r0, r0, #5
	if (key != 0U) {
700014fc:	b903      	cbnz	r3, 70001500 <uart_ns16550_irq_tx_ready+0x20>
700014fe:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
70001500:	4770      	bx	lr
70001502:	bf00      	nop

70001504 <uart_ns16550_irq_tx_complete>:
	__asm__ volatile(
70001504:	f3ef 8200 	mrs	r2, CPSR
70001508:	f002 0280 	and.w	r2, r2, #128	; 0x80
7000150c:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000150e:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((ns16550_inbyte(dev_cfg, LSR(dev)) & (LSR_TEMT | LSR_THRE))
70001510:	7d19      	ldrb	r1, [r3, #20]
70001512:	2005      	movs	r0, #5
70001514:	681b      	ldr	r3, [r3, #0]
70001516:	fb10 3001 	smlabb	r0, r0, r1, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000151a:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("dmb 0xF":::"memory");
7000151c:	f3bf 8f5f 	dmb	sy
				== (LSR_TEMT | LSR_THRE)) ? 1 : 0;
70001520:	f000 0060 	and.w	r0, r0, #96	; 0x60
70001524:	f1a0 0060 	sub.w	r0, r0, #96	; 0x60
70001528:	fab0 f080 	clz	r0, r0
7000152c:	0940      	lsrs	r0, r0, #5
	if (key != 0U) {
7000152e:	b902      	cbnz	r2, 70001532 <uart_ns16550_irq_tx_complete+0x2e>
  __ASM volatile ("cpsie i" : : : "memory");
70001530:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
70001532:	4770      	bx	lr

70001534 <uart_ns16550_irq_rx_enable>:
	__asm__ volatile(
70001534:	f3ef 8100 	mrs	r1, CPSR
70001538:	f001 0180 	and.w	r1, r1, #128	; 0x80
7000153c:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000153e:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev), ns16550_inbyte(dev_cfg, IER(dev)) | IER_RXRDY);
70001540:	7d1a      	ldrb	r2, [r3, #20]
70001542:	681b      	ldr	r3, [r3, #0]
70001544:	441a      	add	r2, r3
70001546:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001548:	f3bf 8f5f 	dmb	sy
7000154c:	f3bf 8f5f 	dmb	sy
70001550:	f043 0301 	orr.w	r3, r3, #1
			sys_write32(val, port);
70001554:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001556:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
70001558:	b901      	cbnz	r1, 7000155c <uart_ns16550_irq_rx_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
7000155a:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);
}
7000155c:	4770      	bx	lr
7000155e:	bf00      	nop

70001560 <uart_ns16550_irq_rx_disable>:
	__asm__ volatile(
70001560:	f3ef 8100 	mrs	r1, CPSR
70001564:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001568:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000156a:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
7000156c:	7d13      	ldrb	r3, [r2, #20]
7000156e:	6812      	ldr	r2, [r2, #0]
70001570:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001572:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001574:	f3bf 8f5f 	dmb	sy
70001578:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
7000157c:	f002 02fe 	and.w	r2, r2, #254	; 0xfe
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001580:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
70001582:	b901      	cbnz	r1, 70001586 <uart_ns16550_irq_rx_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
70001584:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) & (~IER_RXRDY));

	k_spin_unlock(&data->lock, key);
}
70001586:	4770      	bx	lr

70001588 <uart_ns16550_irq_rx_ready>:
	__asm__ volatile(
70001588:	f3ef 8300 	mrs	r3, CPSR
7000158c:	f003 0380 	and.w	r3, r3, #128	; 0x80
70001590:	b672      	cpsid	i
static int uart_ns16550_irq_rx_ready(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((IIRC(dev) & IIR_ID) == IIR_RBRF) ? 1 : 0;
70001592:	6902      	ldr	r2, [r0, #16]
70001594:	7a50      	ldrb	r0, [r2, #9]
70001596:	f000 0006 	and.w	r0, r0, #6
7000159a:	f1a0 0004 	sub.w	r0, r0, #4
7000159e:	fab0 f080 	clz	r0, r0
700015a2:	0940      	lsrs	r0, r0, #5
	if (key != 0U) {
700015a4:	b903      	cbnz	r3, 700015a8 <uart_ns16550_irq_rx_ready+0x20>
700015a6:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
700015a8:	4770      	bx	lr
700015aa:	bf00      	nop

700015ac <uart_ns16550_irq_err_enable>:
	__asm__ volatile(
700015ac:	f3ef 8100 	mrs	r1, CPSR
700015b0:	f001 0180 	and.w	r1, r1, #128	; 0x80
700015b4:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700015b6:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
700015b8:	7d1a      	ldrb	r2, [r3, #20]
700015ba:	681b      	ldr	r3, [r3, #0]
700015bc:	441a      	add	r2, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700015be:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700015c0:	f3bf 8f5f 	dmb	sy
700015c4:	f3bf 8f5f 	dmb	sy
700015c8:	f043 0304 	orr.w	r3, r3, #4
			sys_write32(val, port);
700015cc:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700015ce:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
700015d0:	b901      	cbnz	r1, 700015d4 <uart_ns16550_irq_err_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
700015d2:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) | IER_LSR);

	k_spin_unlock(&data->lock, key);
}
700015d4:	4770      	bx	lr
700015d6:	bf00      	nop

700015d8 <uart_ns16550_irq_err_disable>:
	__asm__ volatile(
700015d8:	f3ef 8100 	mrs	r1, CPSR
700015dc:	f001 0180 	and.w	r1, r1, #128	; 0x80
700015e0:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700015e2:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
700015e4:	7d13      	ldrb	r3, [r2, #20]
700015e6:	6812      	ldr	r2, [r2, #0]
700015e8:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700015ea:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700015ec:	f3bf 8f5f 	dmb	sy
700015f0:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
700015f4:	f002 02fb 	and.w	r2, r2, #251	; 0xfb
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700015f8:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
700015fa:	b901      	cbnz	r1, 700015fe <uart_ns16550_irq_err_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
700015fc:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) & (~IER_LSR));

	k_spin_unlock(&data->lock, key);
}
700015fe:	4770      	bx	lr

70001600 <uart_ns16550_irq_is_pending>:
	__asm__ volatile(
70001600:	f3ef 8300 	mrs	r3, CPSR
70001604:	f003 0380 	and.w	r3, r3, #128	; 0x80
70001608:	b672      	cpsid	i
static int uart_ns16550_irq_is_pending(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = (!(IIRC(dev) & IIR_NIP)) ? 1 : 0;
7000160a:	6902      	ldr	r2, [r0, #16]
7000160c:	7a50      	ldrb	r0, [r2, #9]
7000160e:	43c0      	mvns	r0, r0
70001610:	f000 0001 	and.w	r0, r0, #1
	if (key != 0U) {
70001614:	b903      	cbnz	r3, 70001618 <uart_ns16550_irq_is_pending+0x18>
70001616:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
70001618:	4770      	bx	lr
7000161a:	bf00      	nop

7000161c <uart_ns16550_irq_update>:
	__asm__ volatile(
7000161c:	f3ef 8200 	mrs	r2, CPSR
70001620:	f002 0280 	and.w	r2, r2, #128	; 0x80
70001624:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70001626:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	IIRC(dev) = ns16550_inbyte(dev_cfg, IIR(dev));
70001628:	6901      	ldr	r1, [r0, #16]
7000162a:	7d18      	ldrb	r0, [r3, #20]
7000162c:	681b      	ldr	r3, [r3, #0]
7000162e:	eb03 0340 	add.w	r3, r3, r0, lsl #1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001632:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001634:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
70001638:	724b      	strb	r3, [r1, #9]
	if (key != 0U) {
7000163a:	b902      	cbnz	r2, 7000163e <uart_ns16550_irq_update+0x22>
  __ASM volatile ("cpsie i" : : : "memory");
7000163c:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return 1;
}
7000163e:	2001      	movs	r0, #1
70001640:	4770      	bx	lr
70001642:	bf00      	nop

70001644 <uart_ns16550_irq_callback_set>:
 */
static void uart_ns16550_irq_callback_set(const struct device *dev,
					  uart_irq_callback_user_data_t cb,
					  void *cb_data)
{
	struct uart_ns16550_dev_data * const dev_data = dev->data;
70001644:	6903      	ldr	r3, [r0, #16]
	__asm__ volatile(
70001646:	f3ef 8000 	mrs	r0, CPSR
7000164a:	f000 0080 	and.w	r0, r0, #128	; 0x80
7000164e:	b672      	cpsid	i
	k_spinlock_key_t key = k_spin_lock(&dev_data->lock);

	dev_data->cb = cb;
	dev_data->cb_data = cb_data;
70001650:	e9c3 1203 	strd	r1, r2, [r3, #12]
	if (key != 0U) {
70001654:	b900      	cbnz	r0, 70001658 <uart_ns16550_irq_callback_set+0x14>
70001656:	b662      	cpsie	i

	k_spin_unlock(&dev_data->lock, key);
}
70001658:	4770      	bx	lr
7000165a:	bf00      	nop

7000165c <uart_ns16550_isr>:
 *
 * @param arg Argument to ISR.
 */
static void uart_ns16550_isr(const struct device *dev)
{
	struct uart_ns16550_dev_data * const dev_data = dev->data;
7000165c:	6902      	ldr	r2, [r0, #16]
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;

	if (dev_data->cb) {
7000165e:	68d3      	ldr	r3, [r2, #12]
70001660:	b10b      	cbz	r3, 70001666 <uart_ns16550_isr+0xa>
		dev_data->cb(dev, dev_data->cb_data);
70001662:	6911      	ldr	r1, [r2, #16]
70001664:	4718      	bx	r3
	uint8_t cached_ier = ns16550_inbyte(dev_cfg, IER(dev));

	ns16550_outbyte(dev_cfg, IER(dev), 0U);
	ns16550_outbyte(dev_cfg, IER(dev), cached_ier);
#endif
}
70001666:	4770      	bx	lr

70001668 <uart_ns16550_irq_config_func0>:
#define UART_NS16550_DEVICE_INIT(n)                                                  \
	COND_CODE_1(DT_INST_ON_BUS(n, pcie),                                         \
		    (UART_NS16550_DEVICE_PCIE_INIT(n)),                              \
		    (UART_NS16550_DEVICE_IO_MMIO_INIT(n)))

DT_INST_FOREACH_STATUS_OKAY(UART_NS16550_DEVICE_INIT)
70001668:	20d2      	movs	r0, #210	; 0xd2
7000166a:	2200      	movs	r2, #0
7000166c:	b508      	push	{r3, lr}
7000166e:	210f      	movs	r1, #15
70001670:	f7ff fa46 	bl	70000b00 <z_soc_irq_priority_set>
70001674:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
70001678:	20d2      	movs	r0, #210	; 0xd2
7000167a:	f7ff ba43 	b.w	70000b04 <z_soc_irq_enable>
7000167e:	bf00      	nop

70001680 <uart_ns16550_configure>:
{
70001680:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
	uint32_t pclk = 0U;
70001684:	f04f 0900 	mov.w	r9, #0
{
70001688:	b083      	sub	sp, #12
	struct uart_ns16550_dev_data * const dev_data = dev->data;
7000168a:	6906      	ldr	r6, [r0, #16]
{
7000168c:	4604      	mov	r4, r0
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
7000168e:	f8d0 8004 	ldr.w	r8, [r0, #4]
{
70001692:	460d      	mov	r5, r1
	uint32_t pclk = 0U;
70001694:	f8cd 9000 	str.w	r9, [sp]
	__asm__ volatile(
70001698:	f3ef 8700 	mrs	r7, CPSR
7000169c:	f007 0780 	and.w	r7, r7, #128	; 0x80
700016a0:	b672      	cpsid	i
	if (dev_cfg->pincfg != NULL) {
700016a2:	f8d8 0018 	ldr.w	r0, [r8, #24]
700016a6:	b158      	cbz	r0, 700016c0 <uart_ns16550_configure+0x40>
				      uint8_t id)
{
	int ret;
	const struct pinctrl_state *state;

	ret = pinctrl_lookup_state(config, id, &state);
700016a8:	4649      	mov	r1, r9
700016aa:	aa01      	add	r2, sp, #4
700016ac:	f7ff fe4a 	bl	70001344 <pinctrl_lookup_state>
	if (ret < 0) {
700016b0:	4548      	cmp	r0, r9
700016b2:	db05      	blt.n	700016c0 <uart_ns16550_configure+0x40>
		return ret;
	}

	return pinctrl_apply_state_direct(config, state);
700016b4:	9b01      	ldr	r3, [sp, #4]
	return pinctrl_configure_pins(state->pins, state->pin_cnt, reg);
700016b6:	464a      	mov	r2, r9
700016b8:	7919      	ldrb	r1, [r3, #4]
700016ba:	6818      	ldr	r0, [r3, #0]
700016bc:	f7ff fe70 	bl	700013a0 <pinctrl_configure_pins>
	dev_data->iir_cache = 0U;
700016c0:	2300      	movs	r3, #0
	uint32_t mdr = ns16550_inbyte(dev_cfg, MDR1(dev));
700016c2:	2208      	movs	r2, #8
	dev_data->iir_cache = 0U;
700016c4:	7273      	strb	r3, [r6, #9]
		port = DEVICE_MMIO_GET(dev);
700016c6:	6861      	ldr	r1, [r4, #4]
	uint32_t mdr = ns16550_inbyte(dev_cfg, MDR1(dev));
700016c8:	7d0b      	ldrb	r3, [r1, #20]
700016ca:	6809      	ldr	r1, [r1, #0]
700016cc:	fb12 1303 	smlabb	r3, r2, r3, r1
700016d0:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700016d2:	f3bf 8f5f 	dmb	sy
		port = DEVICE_MMIO_GET(dev);
700016d6:	6861      	ldr	r1, [r4, #4]
	ns16550_outbyte(dev_cfg, MDR1(dev), mdr);
700016d8:	7d08      	ldrb	r0, [r1, #20]
700016da:	6809      	ldr	r1, [r1, #0]
700016dc:	fb12 1200 	smlabb	r2, r2, r0, r1
700016e0:	f3bf 8f5f 	dmb	sy
	mdr = ((mdr & ~MDR1_MODE_SELECT_FIELD_MASK) | ((((MDR1_STD_MODE) <<
700016e4:	f003 03f8 	and.w	r3, r3, #248	; 0xf8
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700016e8:	6013      	str	r3, [r2, #0]
	if (dev_cfg->sys_clk_freq != 0U) {
700016ea:	f8d8 3004 	ldr.w	r3, [r8, #4]
700016ee:	2b00      	cmp	r3, #0
700016f0:	f000 80ad 	beq.w	7000184e <uart_ns16550_configure+0x1ce>
		pclk = dev_cfg->sys_clk_freq;
700016f4:	9300      	str	r3, [sp, #0]
	set_baud_rate(dev, cfg->baudrate, pclk);
700016f6:	6829      	ldr	r1, [r5, #0]
	if ((baud_rate != 0U) && (pclk != 0U)) {
700016f8:	2900      	cmp	r1, #0
700016fa:	bf18      	it	ne
700016fc:	2b00      	cmpne	r3, #0
700016fe:	d168      	bne.n	700017d2 <uart_ns16550_configure+0x152>
	switch (cfg->data_bits) {
70001700:	79aa      	ldrb	r2, [r5, #6]
70001702:	2a03      	cmp	r2, #3
70001704:	d862      	bhi.n	700017cc <uart_ns16550_configure+0x14c>
	switch (cfg->stop_bits) {
70001706:	796b      	ldrb	r3, [r5, #5]
70001708:	2b01      	cmp	r3, #1
7000170a:	f000 80af 	beq.w	7000186c <uart_ns16550_configure+0x1ec>
7000170e:	2b03      	cmp	r3, #3
70001710:	bf08      	it	eq
70001712:	f04f 0e04 	moveq.w	lr, #4
70001716:	d159      	bne.n	700017cc <uart_ns16550_configure+0x14c>
	switch (cfg->parity) {
70001718:	792b      	ldrb	r3, [r5, #4]
7000171a:	b113      	cbz	r3, 70001722 <uart_ns16550_configure+0xa2>
7000171c:	2b02      	cmp	r3, #2
7000171e:	d155      	bne.n	700017cc <uart_ns16550_configure+0x14c>
70001720:	2310      	movs	r3, #16
	dev_data->uart_config = *cfg;
70001722:	e895 0003 	ldmia.w	r5, {r0, r1}
	ns16550_outbyte(dev_cfg, LCR(dev),
70001726:	f04f 0c03 	mov.w	ip, #3
	dev_data->uart_config = *cfg;
7000172a:	e886 0003 	stmia.w	r6, {r0, r1}
		port = DEVICE_MMIO_GET(dev);
7000172e:	6861      	ldr	r1, [r4, #4]
	ns16550_outbyte(dev_cfg, LCR(dev),
70001730:	7d08      	ldrb	r0, [r1, #20]
70001732:	6809      	ldr	r1, [r1, #0]
70001734:	fb1c 1c00 	smlabb	ip, ip, r0, r1
70001738:	f3bf 8f5f 	dmb	sy
7000173c:	ea42 020e 	orr.w	r2, r2, lr
			sys_write32(val, port);
70001740:	4313      	orrs	r3, r2
70001742:	f8cc 3000 	str.w	r3, [ip]
		port = DEVICE_MMIO_GET(dev);
70001746:	6862      	ldr	r2, [r4, #4]
	if (cfg->flow_ctrl == UART_CFG_FLOW_CTRL_RTS_CTS) {
70001748:	79eb      	ldrb	r3, [r5, #7]
7000174a:	2b01      	cmp	r3, #1
7000174c:	bf0c      	ite	eq
7000174e:	212b      	moveq	r1, #43	; 0x2b
70001750:	210b      	movne	r1, #11
	ns16550_outbyte(dev_cfg, MDC(dev), mdc);
70001752:	6813      	ldr	r3, [r2, #0]
70001754:	7d12      	ldrb	r2, [r2, #20]
70001756:	eb03 0382 	add.w	r3, r3, r2, lsl #2
7000175a:	f3bf 8f5f 	dmb	sy
7000175e:	6019      	str	r1, [r3, #0]
		port = DEVICE_MMIO_GET(dev);
70001760:	6863      	ldr	r3, [r4, #4]
	ns16550_outbyte(dev_cfg, FCR(dev),
70001762:	7d1a      	ldrb	r2, [r3, #20]
70001764:	6819      	ldr	r1, [r3, #0]
70001766:	2302      	movs	r3, #2
70001768:	fb13 1202 	smlabb	r2, r3, r2, r1
7000176c:	f3bf 8f5f 	dmb	sy
70001770:	21a7      	movs	r1, #167	; 0xa7
70001772:	6011      	str	r1, [r2, #0]
		port = DEVICE_MMIO_GET(dev);
70001774:	6862      	ldr	r2, [r4, #4]
	if ((ns16550_inbyte(dev_cfg, IIR(dev)) & IIR_FE) == IIR_FE) {
70001776:	7d11      	ldrb	r1, [r2, #20]
70001778:	6812      	ldr	r2, [r2, #0]
7000177a:	fb13 2301 	smlabb	r3, r3, r1, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000177e:	681b      	ldr	r3, [r3, #0]
70001780:	f3bf 8f5f 	dmb	sy
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
70001784:	2205      	movs	r2, #5
	if ((ns16550_inbyte(dev_cfg, IIR(dev)) & IIR_FE) == IIR_FE) {
70001786:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
		dev_data->fifo_size = 64;
7000178a:	2bc0      	cmp	r3, #192	; 0xc0
7000178c:	bf14      	ite	ne
7000178e:	2301      	movne	r3, #1
70001790:	2340      	moveq	r3, #64	; 0x40
70001792:	7233      	strb	r3, [r6, #8]
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
70001794:	6863      	ldr	r3, [r4, #4]
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
70001796:	7d19      	ldrb	r1, [r3, #20]
70001798:	681b      	ldr	r3, [r3, #0]
7000179a:	fb12 3301 	smlabb	r3, r2, r1, r3
7000179e:	681b      	ldr	r3, [r3, #0]
700017a0:	f3bf 8f5f 	dmb	sy
700017a4:	07db      	lsls	r3, r3, #31
700017a6:	d504      	bpl.n	700017b2 <uart_ns16550_configure+0x132>
		port = DEVICE_MMIO_GET(dev);
700017a8:	6863      	ldr	r3, [r4, #4]
700017aa:	681b      	ldr	r3, [r3, #0]
700017ac:	681b      	ldr	r3, [r3, #0]
700017ae:	f3bf 8f5f 	dmb	sy
700017b2:	6862      	ldr	r2, [r4, #4]
	ns16550_outbyte(dev_cfg, IER(dev), 0x00);
700017b4:	7d13      	ldrb	r3, [r2, #20]
700017b6:	6812      	ldr	r2, [r2, #0]
700017b8:	4413      	add	r3, r2
700017ba:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700017be:	2000      	movs	r0, #0
700017c0:	6018      	str	r0, [r3, #0]
	if (key != 0U) {
700017c2:	b907      	cbnz	r7, 700017c6 <uart_ns16550_configure+0x146>
  __ASM volatile ("cpsie i" : : : "memory");
700017c4:	b662      	cpsie	i
};
700017c6:	b003      	add	sp, #12
700017c8:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	switch (cfg->parity) {
700017cc:	f06f 0085 	mvn.w	r0, #133	; 0x85
700017d0:	e7f7      	b.n	700017c2 <uart_ns16550_configure+0x142>
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
700017d2:	6860      	ldr	r0, [r4, #4]
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
700017d4:	7d02      	ldrb	r2, [r0, #20]
700017d6:	f04f 0c03 	mov.w	ip, #3
	return ((pclk + (baud_rate << 3)) / baud_rate) >> 4;
700017da:	eb03 03c1 	add.w	r3, r3, r1, lsl #3
	struct uart_ns16550_dev_data * const dev_data = dev->data;
700017de:	f8d4 e010 	ldr.w	lr, [r4, #16]
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
700017e2:	6800      	ldr	r0, [r0, #0]
	return ((pclk + (baud_rate << 3)) / baud_rate) >> 4;
700017e4:	fbb3 f3f1 	udiv	r3, r3, r1
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
700017e8:	fb1c 0202 	smlabb	r2, ip, r2, r0
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700017ec:	6812      	ldr	r2, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700017ee:	f3bf 8f5f 	dmb	sy
		port = DEVICE_MMIO_GET(dev);
700017f2:	6860      	ldr	r0, [r4, #4]
		ns16550_outbyte(dev_cfg, LCR(dev), LCR_DLAB | lcr_cache);
700017f4:	f890 8014 	ldrb.w	r8, [r0, #20]
700017f8:	6800      	ldr	r0, [r0, #0]
700017fa:	fb1c 0808 	smlabb	r8, ip, r8, r0
700017fe:	f3bf 8f5f 	dmb	sy
70001802:	f062 007f 	orn	r0, r2, #127	; 0x7f
			sys_write32(val, port);
70001806:	b2c0      	uxtb	r0, r0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001808:	f8c8 0000 	str.w	r0, [r8]
		port = DEVICE_MMIO_GET(dev);
7000180c:	6860      	ldr	r0, [r4, #4]
7000180e:	f8d0 8000 	ldr.w	r8, [r0]
70001812:	f3bf 8f5f 	dmb	sy
70001816:	f3c3 1007 	ubfx	r0, r3, #4, #8
7000181a:	f8c8 0000 	str.w	r0, [r8]
7000181e:	f8d4 8004 	ldr.w	r8, [r4, #4]
		ns16550_outbyte(dev_cfg, BRDH(dev), (unsigned char)((divisor >> 8) & 0xff));
70001822:	f898 0014 	ldrb.w	r0, [r8, #20]
70001826:	f8d8 8000 	ldr.w	r8, [r8]
7000182a:	4440      	add	r0, r8
7000182c:	f3bf 8f5f 	dmb	sy
70001830:	f3c3 3307 	ubfx	r3, r3, #12, #8
70001834:	6003      	str	r3, [r0, #0]
		port = DEVICE_MMIO_GET(dev);
70001836:	6863      	ldr	r3, [r4, #4]
		ns16550_outbyte(dev_cfg, LCR(dev), lcr_cache);
70001838:	7d18      	ldrb	r0, [r3, #20]
7000183a:	681b      	ldr	r3, [r3, #0]
7000183c:	fb1c 3300 	smlabb	r3, ip, r0, r3
70001840:	f3bf 8f5f 	dmb	sy
70001844:	b2d2      	uxtb	r2, r2
70001846:	601a      	str	r2, [r3, #0]
		dev_data->uart_config.baudrate = baud_rate;
70001848:	f8ce 1000 	str.w	r1, [lr]
7000184c:	e758      	b.n	70001700 <uart_ns16550_configure+0x80>
		if (!device_is_ready(dev_cfg->clock_dev)) {
7000184e:	f8d8 0008 	ldr.w	r0, [r8, #8]
70001852:	f000 f945 	bl	70001ae0 <z_impl_device_is_ready>
70001856:	b180      	cbz	r0, 7000187a <uart_ns16550_configure+0x1fa>
					   dev_cfg->clock_subsys,
70001858:	e9d8 0102 	ldrd	r0, r1, [r8, #8]
					 uint32_t *rate)
{
	const struct clock_control_driver_api *api =
		(const struct clock_control_driver_api *)dev->api;

	if (api->get_rate == NULL) {
7000185c:	6883      	ldr	r3, [r0, #8]
7000185e:	68db      	ldr	r3, [r3, #12]
70001860:	b15b      	cbz	r3, 7000187a <uart_ns16550_configure+0x1fa>
		return -ENOSYS;
	}

	return api->get_rate(dev, sys, rate);
70001862:	466a      	mov	r2, sp
70001864:	4798      	blx	r3
		if (clock_control_get_rate(dev_cfg->clock_dev,
70001866:	b940      	cbnz	r0, 7000187a <uart_ns16550_configure+0x1fa>
	set_baud_rate(dev, cfg->baudrate, pclk);
70001868:	9b00      	ldr	r3, [sp, #0]
7000186a:	e744      	b.n	700016f6 <uart_ns16550_configure+0x76>
		uart_cfg.stop_bits = LCR_1_STB;
7000186c:	f04f 0e00 	mov.w	lr, #0
	switch (cfg->parity) {
70001870:	792b      	ldrb	r3, [r5, #4]
70001872:	2b00      	cmp	r3, #0
70001874:	f47f af52 	bne.w	7000171c <uart_ns16550_configure+0x9c>
70001878:	e753      	b.n	70001722 <uart_ns16550_configure+0xa2>
			ret = -EINVAL;
7000187a:	f06f 0015 	mvn.w	r0, #21
7000187e:	e7a0      	b.n	700017c2 <uart_ns16550_configure+0x142>

70001880 <uart_ns16550_init>:
{
70001880:	b570      	push	{r4, r5, r6, lr}
	ret = uart_ns16550_configure(dev, &data->uart_config);
70001882:	6901      	ldr	r1, [r0, #16]
{
70001884:	4604      	mov	r4, r0
	const struct uart_ns16550_dev_config *dev_cfg = dev->config;
70001886:	6846      	ldr	r6, [r0, #4]
	ret = uart_ns16550_configure(dev, &data->uart_config);
70001888:	f7ff fefa 	bl	70001680 <uart_ns16550_configure>
	if (ret != 0) {
7000188c:	4605      	mov	r5, r0
7000188e:	b910      	cbnz	r0, 70001896 <uart_ns16550_init+0x16>
	dev_cfg->irq_config_func(dev);
70001890:	6933      	ldr	r3, [r6, #16]
70001892:	4620      	mov	r0, r4
70001894:	4798      	blx	r3
}
70001896:	4628      	mov	r0, r5
70001898:	bd70      	pop	{r4, r5, r6, pc}
7000189a:	bf00      	nop

7000189c <uart_ns16550_fifo_read>:
{
7000189c:	b530      	push	{r4, r5, lr}
	__asm__ volatile(
7000189e:	f3ef 8400 	mrs	r4, CPSR
700018a2:	f004 0480 	and.w	r4, r4, #128	; 0x80
700018a6:	b672      	cpsid	i
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
700018a8:	2a00      	cmp	r2, #0
700018aa:	dd1d      	ble.n	700018e8 <uart_ns16550_fifo_read+0x4c>
700018ac:	4686      	mov	lr, r0
700018ae:	f101 3cff 	add.w	ip, r1, #4294967295	; 0xffffffff
700018b2:	2000      	movs	r0, #0
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
700018b4:	2505      	movs	r5, #5
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
700018b6:	f8de 1004 	ldr.w	r1, [lr, #4]
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
700018ba:	7d0b      	ldrb	r3, [r1, #20]
700018bc:	6809      	ldr	r1, [r1, #0]
700018be:	fb15 1303 	smlabb	r3, r5, r3, r1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700018c2:	681b      	ldr	r3, [r3, #0]
700018c4:	f3bf 8f5f 	dmb	sy
700018c8:	07db      	lsls	r3, r3, #31
700018ca:	d50a      	bpl.n	700018e2 <uart_ns16550_fifo_read+0x46>
		port = DEVICE_MMIO_GET(dev);
700018cc:	f8de 3004 	ldr.w	r3, [lr, #4]
700018d0:	681b      	ldr	r3, [r3, #0]
700018d2:	681b      	ldr	r3, [r3, #0]
700018d4:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
700018d8:	f80c 3f01 	strb.w	r3, [ip, #1]!
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
700018dc:	3001      	adds	r0, #1
700018de:	4282      	cmp	r2, r0
700018e0:	d1e9      	bne.n	700018b6 <uart_ns16550_fifo_read+0x1a>
	if (key != 0U) {
700018e2:	b904      	cbnz	r4, 700018e6 <uart_ns16550_fifo_read+0x4a>
  __ASM volatile ("cpsie i" : : : "memory");
700018e4:	b662      	cpsie	i
}
700018e6:	bd30      	pop	{r4, r5, pc}
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
700018e8:	2000      	movs	r0, #0
700018ea:	e7fa      	b.n	700018e2 <uart_ns16550_fifo_read+0x46>

700018ec <uart_ns16550_poll_in>:
{
700018ec:	b410      	push	{r4}
	__asm__ volatile(
700018ee:	f3ef 8200 	mrs	r2, CPSR
700018f2:	f002 0280 	and.w	r2, r2, #128	; 0x80
700018f6:	b672      	cpsid	i
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
700018f8:	6843      	ldr	r3, [r0, #4]
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
700018fa:	f893 c014 	ldrb.w	ip, [r3, #20]
700018fe:	681c      	ldr	r4, [r3, #0]
70001900:	2305      	movs	r3, #5
70001902:	fb13 430c 	smlabb	r3, r3, ip, r4
70001906:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001908:	f3bf 8f5f 	dmb	sy
7000190c:	07db      	lsls	r3, r3, #31
7000190e:	d50a      	bpl.n	70001926 <uart_ns16550_poll_in+0x3a>
		port = DEVICE_MMIO_GET(dev);
70001910:	6843      	ldr	r3, [r0, #4]
70001912:	681b      	ldr	r3, [r3, #0]
70001914:	681b      	ldr	r3, [r3, #0]
70001916:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
7000191a:	700b      	strb	r3, [r1, #0]
		return 0;
7000191c:	2000      	movs	r0, #0
	if (key != 0U) {
7000191e:	b902      	cbnz	r2, 70001922 <uart_ns16550_poll_in+0x36>
  __ASM volatile ("cpsie i" : : : "memory");
70001920:	b662      	cpsie	i
}
70001922:	bc10      	pop	{r4}
70001924:	4770      	bx	lr
	return -1;
70001926:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
7000192a:	e7f8      	b.n	7000191e <uart_ns16550_poll_in+0x32>

7000192c <sys_clock_driver_init>:
	return delta_ticks;
}

static int sys_clock_driver_init(void)
{
	last_cycle = 0;
7000192c:	f646 7354 	movw	r3, #28500	; 0x6f54

	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
70001930:	2202      	movs	r2, #2
{
70001932:	b510      	push	{r4, lr}
	last_cycle = 0;
70001934:	2400      	movs	r4, #0
70001936:	f2c7 0300 	movt	r3, #28672	; 0x7000
	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
7000193a:	210f      	movs	r1, #15
7000193c:	209f      	movs	r0, #159	; 0x9f
	last_cycle = 0;
7000193e:	601c      	str	r4, [r3, #0]
	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
70001940:	f7ff f8de 	bl	70000b00 <z_soc_irq_priority_set>
70001944:	2338      	movs	r3, #56	; 0x38
70001946:	f2c0 2347 	movt	r3, #583	; 0x247
7000194a:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
7000194c:	f3bf 8f5f 	dmb	sy
70001950:	f3bf 8f5f 	dmb	sy
	reg_val = (reg_val & ~(mask)) | (data << shift);
70001954:	f022 0220 	bic.w	r2, r2, #32
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001958:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000195a:	681a      	ldr	r2, [r3, #0]
7000195c:	f3bf 8f5f 	dmb	sy
70001960:	f3bf 8f5f 	dmb	sy
70001964:	f042 0202 	orr.w	r2, r2, #2
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001968:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000196a:	212c      	movs	r1, #44	; 0x2c
7000196c:	f2c0 2147 	movt	r1, #583	; 0x247
70001970:	680a      	ldr	r2, [r1, #0]
70001972:	f3bf 8f5f 	dmb	sy
70001976:	f3bf 8f5f 	dmb	sy
7000197a:	f042 0201 	orr.w	r2, r2, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000197e:	600a      	str	r2, [r1, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001980:	223c      	movs	r2, #60	; 0x3c
70001982:	f2c0 2247 	movt	r2, #583	; 0x247
70001986:	6811      	ldr	r1, [r2, #0]
70001988:	f3bf 8f5f 	dmb	sy
7000198c:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001990:	6014      	str	r4, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001992:	2240      	movs	r2, #64	; 0x40
70001994:	f2c0 2247 	movt	r2, #583	; 0x247
70001998:	6811      	ldr	r1, [r2, #0]
7000199a:	f3bf 8f5f 	dmb	sy
7000199e:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700019a2:	6014      	str	r4, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700019a4:	224c      	movs	r2, #76	; 0x4c
700019a6:	f2c0 2247 	movt	r2, #583	; 0x247
700019aa:	6811      	ldr	r1, [r2, #0]
700019ac:	f3bf 8f5f 	dmb	sy
700019b0:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700019b4:	f246 11a8 	movw	r1, #25000	; 0x61a8
700019b8:	6011      	str	r1, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700019ba:	681a      	ldr	r2, [r3, #0]
700019bc:	f3bf 8f5f 	dmb	sy
700019c0:	f3bf 8f5f 	dmb	sy
700019c4:	f042 0240 	orr.w	r2, r2, #64	; 0x40
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700019c8:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700019ca:	681a      	ldr	r2, [r3, #0]
700019cc:	f3bf 8f5f 	dmb	sy
700019d0:	f3bf 8f5f 	dmb	sy
700019d4:	f042 0201 	orr.w	r2, r2, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700019d8:	601a      	str	r2, [r3, #0]
	TI_DM_TIMER_WRITE(1, TCLR, CE);

	/* Start the timer */
	TI_DM_TIMER_WRITE(1, TCLR, ST);

	irq_enable(TIMER_IRQ_NUM);
700019da:	209f      	movs	r0, #159	; 0x9f
700019dc:	f7ff f892 	bl	70000b04 <z_soc_irq_enable>

	return 0;
}
700019e0:	4620      	mov	r0, r4
700019e2:	bd10      	pop	{r4, pc}

700019e4 <ti_dmtimer_isr>:
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700019e4:	2228      	movs	r2, #40	; 0x28
700019e6:	f2c0 2247 	movt	r2, #583	; 0x247
700019ea:	6813      	ldr	r3, [r2, #0]
700019ec:	f3bf 8f5f 	dmb	sy
	if (!TI_DM_TIMER_READ(IRQSTATUS)) {
700019f0:	b33b      	cbz	r3, 70001a42 <ti_dmtimer_isr+0x5e>
{
700019f2:	b410      	push	{r4}
	__asm__ volatile(
700019f4:	f3ef 8400 	mrs	r4, CPSR
700019f8:	f004 0480 	and.w	r4, r4, #128	; 0x80
700019fc:	b672      	cpsid	i
700019fe:	233c      	movs	r3, #60	; 0x3c
70001a00:	f2c0 2347 	movt	r3, #583	; 0x247
70001a04:	681b      	ldr	r3, [r3, #0]
70001a06:	f3bf 8f5f 	dmb	sy
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001a0a:	f646 7154 	movw	r1, #28500	; 0x6f54
70001a0e:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001a12:	6808      	ldr	r0, [r1, #0]
	last_cycle = curr_cycle;
70001a14:	600b      	str	r3, [r1, #0]
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001a16:	1a18      	subs	r0, r3, r0
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70001a18:	f24b 5389 	movw	r3, #46473	; 0xb589
70001a1c:	f2c1 43f8 	movt	r3, #5368	; 0x14f8
70001a20:	08c0      	lsrs	r0, r0, #3
70001a22:	fba3 3000 	umull	r3, r0, r3, r0
70001a26:	0a00      	lsrs	r0, r0, #8
70001a28:	6813      	ldr	r3, [r2, #0]
70001a2a:	f3bf 8f5f 	dmb	sy
70001a2e:	f3bf 8f5f 	dmb	sy
	reg_val = (reg_val & ~(mask)) | (data << shift);
70001a32:	f043 0301 	orr.w	r3, r3, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001a36:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
70001a38:	b904      	cbnz	r4, 70001a3c <ti_dmtimer_isr+0x58>
  __ASM volatile ("cpsie i" : : : "memory");
70001a3a:	b662      	cpsie	i
}
70001a3c:	bc10      	pop	{r4}
	sys_clock_announce(delta_ticks);
70001a3e:	f001 b8bd 	b.w	70002bbc <sys_clock_announce>
70001a42:	4770      	bx	lr

70001a44 <sys_clock_set_timeout>:
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
70001a44:	1c43      	adds	r3, r0, #1
70001a46:	d028      	beq.n	70001a9a <sys_clock_set_timeout+0x56>
	ticks = CLAMP(ticks, 1, (int32_t)MAX_TICKS);
70001a48:	2801      	cmp	r0, #1
70001a4a:	bfd8      	it	le
70001a4c:	f246 10a8 	movwle	r0, #25000	; 0x61a8
70001a50:	dd0a      	ble.n	70001a68 <sys_clock_set_timeout+0x24>
70001a52:	f649 7315 	movw	r3, #40725	; 0x9f15
	uint32_t next_cycle = curr_cycle + (ticks * CYC_PER_TICK);
70001a56:	f246 12a8 	movw	r2, #25000	; 0x61a8
	ticks = CLAMP(ticks, 1, (int32_t)MAX_TICKS);
70001a5a:	f2c0 0302 	movt	r3, #2
70001a5e:	4298      	cmp	r0, r3
70001a60:	bfa8      	it	ge
70001a62:	4618      	movge	r0, r3
	uint32_t next_cycle = curr_cycle + (ticks * CYC_PER_TICK);
70001a64:	fb02 f000 	mul.w	r0, r2, r0
	__asm__ volatile(
70001a68:	f3ef 8100 	mrs	r1, CPSR
70001a6c:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001a70:	b672      	cpsid	i
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001a72:	233c      	movs	r3, #60	; 0x3c
70001a74:	f2c0 2347 	movt	r3, #583	; 0x247
70001a78:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001a7a:	f3bf 8f5f 	dmb	sy
70001a7e:	224c      	movs	r2, #76	; 0x4c
70001a80:	f2c0 2247 	movt	r2, #583	; 0x247
70001a84:	f8d2 c000 	ldr.w	ip, [r2]
70001a88:	f3bf 8f5f 	dmb	sy
70001a8c:	f3bf 8f5f 	dmb	sy
70001a90:	4403      	add	r3, r0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001a92:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
70001a94:	b901      	cbnz	r1, 70001a98 <sys_clock_set_timeout+0x54>
  __ASM volatile ("cpsie i" : : : "memory");
70001a96:	b662      	cpsie	i
}
70001a98:	4770      	bx	lr
70001a9a:	f645 20c8 	movw	r0, #23240	; 0x5ac8
70001a9e:	f6cf 70ff 	movt	r0, #65535	; 0xffff
70001aa2:	e7e1      	b.n	70001a68 <sys_clock_set_timeout+0x24>

70001aa4 <sys_clock_elapsed>:
	__asm__ volatile(
70001aa4:	f3ef 8100 	mrs	r1, CPSR
70001aa8:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001aac:	b672      	cpsid	i
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001aae:	233c      	movs	r3, #60	; 0x3c
70001ab0:	f2c0 2347 	movt	r3, #583	; 0x247
70001ab4:	6818      	ldr	r0, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001ab6:	f3bf 8f5f 	dmb	sy
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001aba:	f646 7254 	movw	r2, #28500	; 0x6f54
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70001abe:	f24b 5389 	movw	r3, #46473	; 0xb589
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001ac2:	f2c7 0200 	movt	r2, #28672	; 0x7000
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70001ac6:	f2c1 43f8 	movt	r3, #5368	; 0x14f8
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001aca:	6812      	ldr	r2, [r2, #0]
70001acc:	1a80      	subs	r0, r0, r2
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70001ace:	08c0      	lsrs	r0, r0, #3
70001ad0:	fba3 3000 	umull	r3, r0, r3, r0
70001ad4:	0a00      	lsrs	r0, r0, #8
	if (key != 0U) {
70001ad6:	b901      	cbnz	r1, 70001ada <sys_clock_elapsed+0x36>
  __ASM volatile ("cpsie i" : : : "memory");
70001ad8:	b662      	cpsie	i
}
70001ada:	4770      	bx	lr

70001adc <z_device_state_init>:
void z_device_state_init(void)
{
	STRUCT_SECTION_FOREACH(device, dev) {
		k_object_init(dev);
	}
}
70001adc:	4770      	bx	lr
70001ade:	bf00      	nop

70001ae0 <z_impl_device_is_ready>:
{
	/*
	 * if an invalid device pointer is passed as argument, this call
	 * reports the `device` as not ready for usage.
	 */
	if (dev == NULL) {
70001ae0:	b140      	cbz	r0, 70001af4 <z_impl_device_is_ready+0x14>
		return false;
	}

	return dev->state->initialized && (dev->state->init_res == 0U);
70001ae2:	68c3      	ldr	r3, [r0, #12]
70001ae4:	7858      	ldrb	r0, [r3, #1]
70001ae6:	f010 0001 	ands.w	r0, r0, #1
70001aea:	bf1e      	ittt	ne
70001aec:	7818      	ldrbne	r0, [r3, #0]
70001aee:	fab0 f080 	clzne	r0, r0
70001af2:	0940      	lsrne	r0, r0, #5
}
70001af4:	4770      	bx	lr
70001af6:	bf00      	nop

70001af8 <arch_system_halt>:
	__asm__ volatile(
70001af8:	f3ef 8300 	mrs	r3, CPSR
70001afc:	f003 0380 	and.w	r3, r3, #128	; 0x80
70001b00:	b672      	cpsid	i
	/* TODO: What's the best way to totally halt the system if SMP
	 * is enabled?
	 */

	(void)arch_irq_lock();
	for (;;) {
70001b02:	e7fe      	b.n	70001b02 <arch_system_halt+0xa>

70001b04 <k_sys_fatal_error_handler>:
/* LCOV_EXCL_STOP */

/* LCOV_EXCL_START */
__weak void k_sys_fatal_error_handler(unsigned int reason,
				      const struct arch_esf *esf)
{
70001b04:	b508      	push	{r3, lr}
	ARG_UNUSED(esf);

	LOG_PANIC();
	LOG_ERR("Halting system");
	arch_system_halt(reason);
70001b06:	f7ff fff7 	bl	70001af8 <arch_system_halt>
70001b0a:	bf00      	nop

70001b0c <z_fatal_error>:
	arch_system_halt(reason);
}
/* LCOV_EXCL_STOP */

void z_fatal_error(unsigned int reason, const struct arch_esf *esf)
{
70001b0c:	b538      	push	{r3, r4, r5, lr}
70001b0e:	f3ef 8500 	mrs	r5, CPSR
70001b12:	f005 0580 	and.w	r5, r5, #128	; 0x80
70001b16:	b672      	cpsid	i

	struct k_thread *ret = _current_cpu->current;

	arch_irq_unlock(k);
#else
	struct k_thread *ret = _kernel.cpus[0].current;
70001b18:	f646 7258 	movw	r2, #28504	; 0x6f58
70001b1c:	f2c7 0200 	movt	r2, #28672	; 0x7000
70001b20:	6894      	ldr	r4, [r2, #8]
	 * an IRQ or exception was being handled, or thread context.
	 *
	 * See #17656
	 */
#if defined(CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION)
	if ((esf != NULL) && arch_is_in_nested_exception(esf)) {
70001b22:	b161      	cbz	r1, 70001b3e <z_fatal_error+0x32>
70001b24:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
		LOG_ERR("Current thread: %p (%s)", thread, thread_name_get(thread));
	}

	coredump(reason, esf, thread);

	k_sys_fatal_error_handler(reason, esf);
70001b28:	f7ff ffec 	bl	70001b04 <k_sys_fatal_error_handler>
70001b2c:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
	if (key != 0U) {
70001b30:	b905      	cbnz	r5, 70001b34 <z_fatal_error+0x28>
70001b32:	b662      	cpsie	i
70001b34:	4620      	mov	r0, r4
	arch_irq_unlock(key);

	if (IS_ENABLED(CONFIG_MULTITHREADING)) {
		k_thread_abort(thread);
	}
}
70001b36:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
70001b3a:	f000 bf27 	b.w	7000298c <z_impl_k_thread_abort>
	k_sys_fatal_error_handler(reason, esf);
70001b3e:	f7ff ffe1 	bl	70001b04 <k_sys_fatal_error_handler>
		if ((esf != NULL) && arch_is_in_nested_exception(esf)) {
70001b42:	e7f5      	b.n	70001b30 <z_fatal_error+0x24>

70001b44 <z_sys_init_run_level>:
		/* End marker */
		__init_end,
	};
	const struct init_entry *entry;

	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001b44:	f644 73f0 	movw	r3, #20464	; 0x4ff0
70001b48:	1c42      	adds	r2, r0, #1
70001b4a:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
70001b4e:	b570      	push	{r4, r5, r6, lr}
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001b50:	f853 4020 	ldr.w	r4, [r3, r0, lsl #2]
70001b54:	f853 6022 	ldr.w	r6, [r3, r2, lsl #2]
70001b58:	42b4      	cmp	r4, r6
70001b5a:	d314      	bcc.n	70001b86 <z_sys_init_run_level+0x42>
70001b5c:	e01b      	b.n	70001b96 <z_sys_init_run_level+0x52>
		rc = entry->init_fn.dev(dev);
70001b5e:	4628      	mov	r0, r5
	if (entry->init_fn.dev != NULL) {
70001b60:	b14b      	cbz	r3, 70001b76 <z_sys_init_run_level+0x32>
		rc = entry->init_fn.dev(dev);
70001b62:	4798      	blx	r3
		if (rc != 0) {
70001b64:	b138      	cbz	r0, 70001b76 <z_sys_init_run_level+0x32>
			dev->state->init_res = rc;
70001b66:	68eb      	ldr	r3, [r5, #12]
			if (rc < 0) {
70001b68:	2800      	cmp	r0, #0
70001b6a:	bfb8      	it	lt
70001b6c:	4240      	neglt	r0, r0
			if (rc > UINT8_MAX) {
70001b6e:	28ff      	cmp	r0, #255	; 0xff
70001b70:	bfa8      	it	ge
70001b72:	20ff      	movge	r0, #255	; 0xff
			dev->state->init_res = rc;
70001b74:	7018      	strb	r0, [r3, #0]
	dev->state->initialized = true;
70001b76:	68ea      	ldr	r2, [r5, #12]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001b78:	3408      	adds	r4, #8
	dev->state->initialized = true;
70001b7a:	7853      	ldrb	r3, [r2, #1]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001b7c:	42a6      	cmp	r6, r4
	dev->state->initialized = true;
70001b7e:	f043 0301 	orr.w	r3, r3, #1
70001b82:	7053      	strb	r3, [r2, #1]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001b84:	d907      	bls.n	70001b96 <z_sys_init_run_level+0x52>

		sys_trace_sys_init_enter(entry, level);
		if (dev != NULL) {
			result = do_device_init(entry);
		} else {
			result = entry->init_fn.sys();
70001b86:	e9d4 3500 	ldrd	r3, r5, [r4]
		if (dev != NULL) {
70001b8a:	2d00      	cmp	r5, #0
70001b8c:	d1e7      	bne.n	70001b5e <z_sys_init_run_level+0x1a>
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001b8e:	3408      	adds	r4, #8
			result = entry->init_fn.sys();
70001b90:	4798      	blx	r3
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001b92:	42a6      	cmp	r6, r4
70001b94:	d8f7      	bhi.n	70001b86 <z_sys_init_run_level+0x42>
		}
		sys_trace_sys_init_exit(entry, level, result);
	}
}
70001b96:	bd70      	pop	{r4, r5, r6, pc}

70001b98 <bg_thread_main>:
	 * may perform memory management tasks (except for
	 * k_mem_map_phys_bare() which is allowed at any time)
	 */
	z_mem_manage_init();
#endif /* CONFIG_MMU */
	z_sys_post_kernel = true;
70001b98:	f646 737c 	movw	r3, #28540	; 0x6f7c
70001b9c:	2201      	movs	r2, #1
70001b9e:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
70001ba2:	b5f0      	push	{r4, r5, r6, r7, lr}

#if CONFIG_IRQ_OFFLOAD
	arch_irq_offload_init();
#endif
	z_sys_init_run_level(INIT_LEVEL_POST_KERNEL);
70001ba4:	2003      	movs	r0, #3
{
70001ba6:	b087      	sub	sp, #28
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001ba8:	f644 5650 	movw	r6, #19792	; 0x4d50
70001bac:	f644 5580 	movw	r5, #19840	; 0x4d80
	z_sys_post_kernel = true;
70001bb0:	701a      	strb	r2, [r3, #0]
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001bb2:	f2c7 0600 	movt	r6, #28672	; 0x7000
	z_sys_init_run_level(INIT_LEVEL_POST_KERNEL);
70001bb6:	f7ff ffc5 	bl	70001b44 <z_sys_init_run_level>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001bba:	f2c7 0500 	movt	r5, #28672	; 0x7000
#endif

#if defined(CONFIG_STACK_POINTER_RANDOM) && (CONFIG_STACK_POINTER_RANDOM != 0)
	z_stack_adjust_initialized = 1;
#endif /* CONFIG_STACK_POINTER_RANDOM */
	boot_banner();
70001bbe:	f001 f915 	bl	70002dec <boot_banner>

	void z_init_static(void);
	z_init_static();
70001bc2:	f000 f8d3 	bl	70001d6c <z_init_static>

	/* Final init level before app starts */
	z_sys_init_run_level(INIT_LEVEL_APPLICATION);
70001bc6:	2004      	movs	r0, #4
70001bc8:	f7ff ffbc 	bl	70001b44 <z_sys_init_run_level>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001bcc:	42ae      	cmp	r6, r5
70001bce:	d217      	bcs.n	70001c00 <bg_thread_main+0x68>
70001bd0:	4634      	mov	r4, r6
		z_setup_new_thread(
70001bd2:	6a67      	ldr	r7, [r4, #36]	; 0x24
70001bd4:	e9d4 2302 	ldrd	r2, r3, [r4, #8]
70001bd8:	e9d4 0100 	ldrd	r0, r1, [r4]
70001bdc:	9705      	str	r7, [sp, #20]
70001bde:	6a27      	ldr	r7, [r4, #32]
70001be0:	9704      	str	r7, [sp, #16]
70001be2:	69e7      	ldr	r7, [r4, #28]
70001be4:	9703      	str	r7, [sp, #12]
70001be6:	69a7      	ldr	r7, [r4, #24]
70001be8:	9702      	str	r7, [sp, #8]
70001bea:	6967      	ldr	r7, [r4, #20]
70001bec:	9701      	str	r7, [sp, #4]
70001bee:	6927      	ldr	r7, [r4, #16]
70001bf0:	9700      	str	r7, [sp, #0]
70001bf2:	f000 fa8d 	bl	70002110 <z_setup_new_thread>
		thread_data->init_thread->init_data = thread_data;
70001bf6:	6823      	ldr	r3, [r4, #0]
70001bf8:	655c      	str	r4, [r3, #84]	; 0x54
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001bfa:	3430      	adds	r4, #48	; 0x30
70001bfc:	42ac      	cmp	r4, r5
70001bfe:	d3e8      	bcc.n	70001bd2 <bg_thread_main+0x3a>
	k_sched_lock();
70001c00:	f000 fda0 	bl	70002744 <k_sched_lock>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001c04:	42ae      	cmp	r6, r5
70001c06:	d222      	bcs.n	70001c4e <bg_thread_main+0xb6>
70001c08:	f644 5450 	movw	r4, #19792	; 0x4d50

extern void z_thread_timeout(struct _timeout *timeout);

static inline void z_add_thread_timeout(struct k_thread *thread, k_timeout_t ticks)
{
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
70001c0c:	f242 57c5 	movw	r7, #9669	; 0x25c5
70001c10:	f2c7 0400 	movt	r4, #28672	; 0x7000
70001c14:	f2c7 0700 	movt	r7, #28672	; 0x7000
70001c18:	e005      	b.n	70001c26 <bg_thread_main+0x8e>
	z_impl_k_wakeup(thread);
70001c1a:	4630      	mov	r0, r6
70001c1c:	f000 fe8a 	bl	70002934 <z_impl_k_wakeup>
70001c20:	3430      	adds	r4, #48	; 0x30
70001c22:	42ac      	cmp	r4, r5
70001c24:	d213      	bcs.n	70001c4e <bg_thread_main+0xb6>
		k_timeout_t init_delay = Z_THREAD_INIT_DELAY(thread_data);
70001c26:	e9d4 230a 	ldrd	r2, r3, [r4, #40]	; 0x28
		if (!K_TIMEOUT_EQ(init_delay, K_FOREVER)) {
70001c2a:	f1b3 3fff 	cmp.w	r3, #4294967295	; 0xffffffff
70001c2e:	bf08      	it	eq
70001c30:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
70001c34:	d0f4      	beq.n	70001c20 <bg_thread_main+0x88>
			thread_schedule_new(thread_data->init_thread,
70001c36:	6826      	ldr	r6, [r4, #0]


static inline void thread_schedule_new(struct k_thread *thread, k_timeout_t delay)
{
#ifdef CONFIG_SYS_CLOCK_EXISTS
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
70001c38:	ea52 0003 	orrs.w	r0, r2, r3
70001c3c:	4639      	mov	r1, r7
70001c3e:	f106 0018 	add.w	r0, r6, #24
70001c42:	d0ea      	beq.n	70001c1a <bg_thread_main+0x82>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001c44:	3430      	adds	r4, #48	; 0x30
70001c46:	f000 feff 	bl	70002a48 <z_add_timeout>
70001c4a:	42ac      	cmp	r4, r5
70001c4c:	d3eb      	bcc.n	70001c26 <bg_thread_main+0x8e>
	k_sched_unlock();
70001c4e:	f000 fd89 	bl	70002764 <k_sched_unlock>
	char **argv = prepare_main_args(&argc);
	(void)main(argc, argv);
#else
	extern int main(void);

	(void)main();
70001c52:	f7fe fb67 	bl	70000324 <main>
 * Exceptions raised by this thread may be recoverable.
 * (This is the default tag for a thread.)
 */
static inline void z_thread_essential_clear(struct k_thread *thread)
{
	thread->base.user_options &= ~K_ESSENTIAL;
70001c56:	f245 6300 	movw	r3, #22016	; 0x5600
70001c5a:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001c5e:	7b1a      	ldrb	r2, [r3, #12]
70001c60:	f022 0201 	bic.w	r2, r2, #1
70001c64:	731a      	strb	r2, [r3, #12]

#ifdef CONFIG_COVERAGE_DUMP
	/* Dump coverage data once the main() has exited. */
	gcov_coverage_dump();
#endif /* CONFIG_COVERAGE_DUMP */
} /* LCOV_EXCL_LINE ... because we just dumped final coverage data */
70001c66:	b007      	add	sp, #28
70001c68:	bdf0      	pop	{r4, r5, r6, r7, pc}
70001c6a:	bf00      	nop

70001c6c <z_early_memset>:
	(void) memset(dst, c, n);
70001c6c:	f001 bab8 	b.w	700031e0 <memset>

70001c70 <z_bss_zero>:
	z_early_memset(__bss_start, 0, __bss_end - __bss_start);
70001c70:	f646 7280 	movw	r2, #28544	; 0x6f80
70001c74:	f245 0060 	movw	r0, #20576	; 0x5060
70001c78:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001c7c:	2100      	movs	r1, #0
70001c7e:	f2c7 0200 	movt	r2, #28672	; 0x7000
70001c82:	1a12      	subs	r2, r2, r0
{
70001c84:	b508      	push	{r3, lr}
	z_early_memset(__bss_start, 0, __bss_end - __bss_start);
70001c86:	f7ff fff1 	bl	70001c6c <z_early_memset>
}
70001c8a:	bd08      	pop	{r3, pc}

70001c8c <z_cstart>:
 * @return Does not return
 */
__boot_func
FUNC_NO_STACK_PROTECTOR
FUNC_NORETURN void z_cstart(void)
{
70001c8c:	b580      	push	{r7, lr}
	/* gcov hook needed to get the coverage report.*/
	gcov_static_init();

	/* initialize early init calls */
	z_sys_init_run_level(INIT_LEVEL_EARLY);
70001c8e:	2000      	movs	r0, #0
{
70001c90:	b086      	sub	sp, #24
	z_sys_init_run_level(INIT_LEVEL_EARLY);
70001c92:	f7ff ff57 	bl	70001b44 <z_sys_init_run_level>
	return ret;
}

static ALWAYS_INLINE void arch_current_thread_set(struct k_thread *thread)
{
	_current_cpu->current = thread;
70001c96:	f646 7458 	movw	r4, #28504	; 0x6f58
{
	dummy_thread->base.thread_state = _THREAD_DUMMY;
#ifdef CONFIG_SCHED_CPU_MASK
	dummy_thread->base.cpu_mask = -1;
#endif /* CONFIG_SCHED_CPU_MASK */
	dummy_thread->base.user_options = K_ESSENTIAL;
70001c9a:	f245 6378 	movw	r3, #22136	; 0x5678
	dummy_thread->mem_domain_info.mem_domain = &k_mem_domain_default;
#endif /* CONFIG_USERSPACE */
#if (K_HEAP_MEM_POOL_SIZE > 0)
	k_thread_system_pool_assign(dummy_thread);
#else
	dummy_thread->resource_pool = NULL;
70001c9e:	2500      	movs	r5, #0
	dummy_thread->base.user_options = K_ESSENTIAL;
70001ca0:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001ca4:	f240 1201 	movw	r2, #257	; 0x101
70001ca8:	f2c7 0400 	movt	r4, #28672	; 0x7000
	dummy_thread->resource_pool = NULL;
70001cac:	669d      	str	r5, [r3, #104]	; 0x68
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001cae:	2701      	movs	r7, #1
	dummy_thread->base.user_options = K_ESSENTIAL;
70001cb0:	819a      	strh	r2, [r3, #12]
	_kernel.ready_q.cache = &z_main_thread;
70001cb2:	f245 6600 	movw	r6, #22016	; 0x5600
70001cb6:	60a3      	str	r3, [r4, #8]

#if defined(CONFIG_MULTITHREADING)
	z_dummy_thread_init(&_thread_dummy);
#endif /* CONFIG_MULTITHREADING */
	/* do any necessary initialization of static devices */
	z_device_state_init();
70001cb8:	f7ff ff10 	bl	70001adc <z_device_state_init>
#endif
#if CONFIG_BOARD_EARLY_INIT_HOOK
	board_early_init_hook();
#endif
	/* perform basic hardware initialization */
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_1);
70001cbc:	2001      	movs	r0, #1
	_kernel.ready_q.cache = &z_main_thread;
70001cbe:	f2c7 0600 	movt	r6, #28672	; 0x7000
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_1);
70001cc2:	f7ff ff3f 	bl	70001b44 <z_sys_init_run_level>
#if defined(CONFIG_SMP)
	arch_smp_init();
#endif
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_2);
70001cc6:	2002      	movs	r0, #2
70001cc8:	f7ff ff3c 	bl	70001b44 <z_sys_init_run_level>
	z_sched_init();
70001ccc:	f000 fd84 	bl	700027d8 <z_sched_init>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001cd0:	f644 73e8 	movw	r3, #20456	; 0x4fe8
70001cd4:	f64a 3180 	movw	r1, #43904	; 0xab80
70001cd8:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001cdc:	f44f 6280 	mov.w	r2, #1024	; 0x400
70001ce0:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001ce4:	9305      	str	r3, [sp, #20]
70001ce6:	f641 3399 	movw	r3, #7065	; 0x1b99
70001cea:	4630      	mov	r0, r6
70001cec:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001cf0:	e9cd 5703 	strd	r5, r7, [sp, #12]
70001cf4:	9502      	str	r5, [sp, #8]
70001cf6:	e9cd 5500 	strd	r5, r5, [sp]
	_kernel.ready_q.cache = &z_main_thread;
70001cfa:	6166      	str	r6, [r4, #20]
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001cfc:	f000 fa08 	bl	70002110 <z_setup_new_thread>
	thread->base.thread_state &= ~_THREAD_SLEEPING;
70001d00:	7b73      	ldrb	r3, [r6, #13]
	z_ready_thread(&z_main_thread);
70001d02:	4630      	mov	r0, r6
70001d04:	f023 0304 	bic.w	r3, r3, #4
70001d08:	7373      	strb	r3, [r6, #13]
70001d0a:	f000 fbcf 	bl	700024ac <z_ready_thread>
	z_setup_new_thread(thread, stack,
70001d0e:	230f      	movs	r3, #15
70001d10:	f245 5688 	movw	r6, #21896	; 0x5588
70001d14:	f64a 2180 	movw	r1, #43648	; 0xaa80
70001d18:	f2c7 0600 	movt	r6, #28672	; 0x7000
70001d1c:	9303      	str	r3, [sp, #12]
70001d1e:	f641 53cd 	movw	r3, #7629	; 0x1dcd
70001d22:	f44f 7280 	mov.w	r2, #256	; 0x100
70001d26:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001d2a:	4630      	mov	r0, r6
70001d2c:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001d30:	e9cd 7504 	strd	r7, r5, [sp, #16]
70001d34:	e9cd 5501 	strd	r5, r5, [sp, #4]
70001d38:	9400      	str	r4, [sp, #0]
70001d3a:	f000 f9e9 	bl	70002110 <z_setup_new_thread>
70001d3e:	7b73      	ldrb	r3, [r6, #13]
	_kernel.cpus[id].irq_stack =
70001d40:	4a09      	ldr	r2, [pc, #36]	; (70001d68 <z_cstart+0xdc>)
70001d42:	f023 0304 	bic.w	r3, r3, #4
70001d46:	6062      	str	r2, [r4, #4]
	_kernel.cpus[id].idle_thread = &z_idle_threads[id];
70001d48:	60e6      	str	r6, [r4, #12]
70001d4a:	7373      	strb	r3, [r6, #13]
	_kernel.cpus[id].id = id;
70001d4c:	7425      	strb	r5, [r4, #16]
	__asm__ volatile(
70001d4e:	f3ef 8100 	mrs	r1, CPSR
70001d52:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001d56:	b672      	cpsid	i
	struct k_thread *ret = _kernel.cpus[0].current;
70001d58:	68a3      	ldr	r3, [r4, #8]

static ALWAYS_INLINE int arch_swap(unsigned int key)
{
	/* store off key and return value */
	arch_current_thread()->arch.basepri = key;
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
70001d5a:	f06f 020a 	mvn.w	r2, #10
70001d5e:	e9c3 121b 	strd	r1, r2, [r3, #108]	; 0x6c

	z_arm_cortex_r_svc();
70001d62:	f7ff e98a 	blx	70001078 <z_arm_cortex_r_svc>
70001d66:	b662      	cpsie	i
	CODE_UNREACHABLE; /* LCOV_EXCL_LINE */
70001d68:	7000aa80 	.word	0x7000aa80

70001d6c <z_init_static>:
	__do_global_ctors_aux();
	__do_init_array_aux();
#elif defined(__CCAC__) /* ARC MWDT */
	__do_global_ctors_aux();
#endif
}
70001d6c:	4770      	bx	lr
70001d6e:	bf00      	nop

70001d70 <init_mem_slab_obj_core_list>:
#endif /* CONFIG_OBJ_CORE_STATS_MEM_SLAB */
#endif /* CONFIG_OBJ_CORE_MEM_SLAB */

	/* Initialize statically defined mem_slabs */

	STRUCT_SECTION_FOREACH(k_mem_slab, slab) {
70001d70:	f24b 415c 	movw	r1, #46172	; 0xb45c
70001d74:	f24b 4c5c 	movw	ip, #46172	; 0xb45c
70001d78:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001d7c:	f2c7 0c00 	movt	ip, #28672	; 0x7000
70001d80:	4561      	cmp	r1, ip
70001d82:	d221      	bcs.n	70001dc8 <init_mem_slab_obj_core_list+0x58>
{
70001d84:	b410      	push	{r4}
	CHECKIF(((slab->info.block_size | (uintptr_t)slab->buffer) &
70001d86:	694c      	ldr	r4, [r1, #20]
70001d88:	688b      	ldr	r3, [r1, #8]
70001d8a:	ea43 0004 	orr.w	r0, r3, r4
70001d8e:	f010 0003 	ands.w	r0, r0, #3
70001d92:	d116      	bne.n	70001dc2 <init_mem_slab_obj_core_list+0x52>
	p = slab->buffer + slab->info.block_size * (slab->info.num_blocks - 1);
70001d94:	690a      	ldr	r2, [r1, #16]
	slab->free_list = NULL;
70001d96:	60c8      	str	r0, [r1, #12]
	p = slab->buffer + slab->info.block_size * (slab->info.num_blocks - 1);
70001d98:	3a01      	subs	r2, #1
70001d9a:	fb04 3202 	mla	r2, r4, r2, r3
	while (p >= slab->buffer) {
70001d9e:	4293      	cmp	r3, r2
70001da0:	d901      	bls.n	70001da6 <init_mem_slab_obj_core_list+0x36>
70001da2:	e008      	b.n	70001db6 <init_mem_slab_obj_core_list+0x46>
		p -= slab->info.block_size;
70001da4:	461a      	mov	r2, r3
		*(char **)p = slab->free_list;
70001da6:	6010      	str	r0, [r2, #0]
		p -= slab->info.block_size;
70001da8:	4610      	mov	r0, r2
70001daa:	694b      	ldr	r3, [r1, #20]
	while (p >= slab->buffer) {
70001dac:	688c      	ldr	r4, [r1, #8]
		p -= slab->info.block_size;
70001dae:	1ad3      	subs	r3, r2, r3
	while (p >= slab->buffer) {
70001db0:	42a3      	cmp	r3, r4
70001db2:	d2f7      	bcs.n	70001da4 <init_mem_slab_obj_core_list+0x34>
70001db4:	60ca      	str	r2, [r1, #12]
	STRUCT_SECTION_FOREACH(k_mem_slab, slab) {
70001db6:	311c      	adds	r1, #28
70001db8:	4561      	cmp	r1, ip
70001dba:	d3e4      	bcc.n	70001d86 <init_mem_slab_obj_core_list+0x16>
70001dbc:	2000      	movs	r0, #0
#endif /* CONFIG_OBJ_CORE_MEM_SLAB */
	}

out:
	return rc;
}
70001dbe:	bc10      	pop	{r4}
70001dc0:	4770      	bx	lr
70001dc2:	f06f 0015 	mvn.w	r0, #21
	return rc;
70001dc6:	e7fa      	b.n	70001dbe <init_mem_slab_obj_core_list+0x4e>
70001dc8:	2000      	movs	r0, #0
}
70001dca:	4770      	bx	lr

70001dcc <idle>:
#include <wait_q.h>

LOG_MODULE_DECLARE(os, CONFIG_KERNEL_LOG_LEVEL);

void idle(void *unused1, void *unused2, void *unused3)
{
70001dcc:	b508      	push	{r3, lr}
70001dce:	f3ef 8300 	mrs	r3, CPSR
70001dd2:	f003 0380 	and.w	r3, r3, #128	; 0x80
70001dd6:	b672      	cpsid	i
 * @note In some architectures, before returning, the function unmasks interrupts
 * unconditionally.
 */
static inline void k_cpu_idle(void)
{
	arch_cpu_idle();
70001dd8:	f7ff e830 	blx	70000e3c <arch_cpu_idle>
70001ddc:	e7f7      	b.n	70001dce <idle+0x2>
70001dde:	bf00      	nop

70001de0 <z_impl_k_msgq_put>:
	return 0;
}


int z_impl_k_msgq_put(struct k_msgq *msgq, const void *data, k_timeout_t timeout)
{
70001de0:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
70001de4:	4604      	mov	r4, r0
70001de6:	b082      	sub	sp, #8
70001de8:	460d      	mov	r5, r1
70001dea:	4616      	mov	r6, r2

	struct k_thread *pending_thread;
	k_spinlock_key_t key;
	int result;

	key = k_spin_lock(&msgq->lock);
70001dec:	f100 0708 	add.w	r7, r0, #8
70001df0:	f3ef 8800 	mrs	r8, CPSR
70001df4:	f008 0880 	and.w	r8, r8, #128	; 0x80
70001df8:	b672      	cpsid	i

	SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_msgq, put, msgq, timeout);

	if (msgq->used_msgs < msgq->max_msgs) {
70001dfa:	6a02      	ldr	r2, [r0, #32]
70001dfc:	68c0      	ldr	r0, [r0, #12]
70001dfe:	4282      	cmp	r2, r0
70001e00:	d224      	bcs.n	70001e4c <z_impl_k_msgq_put+0x6c>
 * @return true if empty, false otherwise
 */

static inline bool sys_dlist_is_empty(sys_dlist_t *list)
{
	return list->head == list;
70001e02:	f8d4 9000 	ldr.w	r9, [r4]
	__ASSERT_EVAL(, int key = arch_irq_lock(); arch_irq_unlock(key),
		      !arch_irq_unlocked(key), "");

	LOCK_SCHED_SPINLOCK {
		thread = _priq_wait_best(&wait_q->waitq);
		if (unlikely(thread != NULL)) {
70001e06:	f1b9 0f00 	cmp.w	r9, #0
70001e0a:	bf18      	it	ne
70001e0c:	454c      	cmpne	r4, r9
70001e0e:	d135      	bne.n	70001e7c <z_impl_k_msgq_put+0x9c>
			return 0;
		} else {
			/* put message in queue */
			__ASSERT_NO_MSG(msgq->write_ptr >= msgq->buffer_start &&
					msgq->write_ptr < msgq->buffer_end);
			(void)memcpy(msgq->write_ptr, (char *)data, msgq->msg_size);
70001e10:	68a2      	ldr	r2, [r4, #8]
			msgq->used_msgs++;
#ifdef CONFIG_POLL
			handle_poll_events(msgq, K_POLL_STATE_MSGQ_DATA_AVAILABLE);
#endif /* CONFIG_POLL */
		}
		result = 0;
70001e12:	2600      	movs	r6, #0
			(void)memcpy(msgq->write_ptr, (char *)data, msgq->msg_size);
70001e14:	69e0      	ldr	r0, [r4, #28]
70001e16:	f001 f97b 	bl	70003110 <memcpy>
			msgq->write_ptr += msgq->msg_size;
70001e1a:	69e3      	ldr	r3, [r4, #28]
70001e1c:	68a2      	ldr	r2, [r4, #8]
	z_handle_obj_poll_events(&msgq->poll_events, state);
70001e1e:	2110      	movs	r1, #16
70001e20:	f104 0024 	add.w	r0, r4, #36	; 0x24
			msgq->write_ptr += msgq->msg_size;
70001e24:	4413      	add	r3, r2
			if (msgq->write_ptr == msgq->buffer_end) {
70001e26:	6962      	ldr	r2, [r4, #20]
			msgq->write_ptr += msgq->msg_size;
70001e28:	61e3      	str	r3, [r4, #28]
			if (msgq->write_ptr == msgq->buffer_end) {
70001e2a:	4293      	cmp	r3, r2
				msgq->write_ptr = msgq->buffer_start;
70001e2c:	bf04      	itt	eq
70001e2e:	6923      	ldreq	r3, [r4, #16]
70001e30:	61e3      	streq	r3, [r4, #28]
			msgq->used_msgs++;
70001e32:	6a23      	ldr	r3, [r4, #32]
70001e34:	3301      	adds	r3, #1
70001e36:	6223      	str	r3, [r4, #32]
	z_handle_obj_poll_events(&msgq->poll_events, state);
70001e38:	f000 ffc2 	bl	70002dc0 <z_handle_obj_poll_events>
		return result;
	}

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_msgq, put, msgq, timeout, result);

	z_reschedule(&msgq->lock, key);
70001e3c:	4641      	mov	r1, r8
70001e3e:	4638      	mov	r0, r7
70001e40:	f000 fc4a 	bl	700026d8 <z_reschedule>

	return result;
}
70001e44:	4630      	mov	r0, r6
70001e46:	b002      	add	sp, #8
70001e48:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
70001e4c:	ea56 0203 	orrs.w	r2, r6, r3
		result = -ENOMSG;
70001e50:	bf08      	it	eq
70001e52:	f06f 0622 	mvneq.w	r6, #34	; 0x22
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
70001e56:	d0f1      	beq.n	70001e3c <z_impl_k_msgq_put+0x5c>
		result = z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
70001e58:	4622      	mov	r2, r4
70001e5a:	f646 7458 	movw	r4, #28504	; 0x6f58
70001e5e:	4641      	mov	r1, r8
70001e60:	f2c7 0400 	movt	r4, #28672	; 0x7000
70001e64:	4638      	mov	r0, r7
		arch_current_thread()->base.swap_data = (void *) data;
70001e66:	68a4      	ldr	r4, [r4, #8]
70001e68:	6165      	str	r5, [r4, #20]
		result = z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
70001e6a:	e9cd 6300 	strd	r6, r3, [sp]
70001e6e:	f000 fbad 	bl	700025cc <z_pend_curr>
70001e72:	4606      	mov	r6, r0
}
70001e74:	4630      	mov	r0, r6
70001e76:	b002      	add	sp, #8
70001e78:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
 */

static inline void sys_dlist_remove(sys_dnode_t *node)
{
	sys_dnode_t *const prev = node->prev;
	sys_dnode_t *const next = node->next;
70001e7c:	e9d9 3200 	ldrd	r3, r2, [r9]
	thread->base.pended_on = NULL;
70001e80:	f04f 0a00 	mov.w	sl, #0

	prev->next = next;
70001e84:	6013      	str	r3, [r2, #0]
}

static inline int z_abort_thread_timeout(struct k_thread *thread)
{
	return z_abort_timeout(&thread->base.timeout);
70001e86:	f109 0018 	add.w	r0, r9, #24
	next->prev = prev;
70001e8a:	605a      	str	r2, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
70001e8c:	f899 300d 	ldrb.w	r3, [r9, #13]
	node->next = NULL;
70001e90:	2200      	movs	r2, #0
70001e92:	f023 0302 	bic.w	r3, r3, #2
70001e96:	f8c9 a008 	str.w	sl, [r9, #8]
			return 0;
70001e9a:	4656      	mov	r6, sl
70001e9c:	f889 300d 	strb.w	r3, [r9, #13]
70001ea0:	2300      	movs	r3, #0
70001ea2:	e9c9 2300 	strd	r2, r3, [r9]
70001ea6:	f000 fe61 	bl	70002b6c <z_abort_timeout>
			(void)memcpy(pending_thread->base.swap_data, data,
70001eaa:	68a2      	ldr	r2, [r4, #8]
70001eac:	f8d9 0014 	ldr.w	r0, [r9, #20]
70001eb0:	4629      	mov	r1, r5
70001eb2:	f001 f92d 	bl	70003110 <memcpy>
}

static ALWAYS_INLINE void
arch_thread_return_value_set(struct k_thread *thread, unsigned int value)
{
	thread->arch.swap_return_value = value;
70001eb6:	f8c9 a070 	str.w	sl, [r9, #112]	; 0x70
			z_ready_thread(pending_thread);
70001eba:	4648      	mov	r0, r9
70001ebc:	f000 faf6 	bl	700024ac <z_ready_thread>
			z_reschedule(&msgq->lock, key);
70001ec0:	4641      	mov	r1, r8
70001ec2:	4638      	mov	r0, r7
70001ec4:	f000 fc08 	bl	700026d8 <z_reschedule>
			return 0;
70001ec8:	e7bc      	b.n	70001e44 <z_impl_k_msgq_put+0x64>
70001eca:	bf00      	nop

70001ecc <z_impl_k_mutex_init>:
#ifdef CONFIG_OBJ_CORE_MUTEX
static struct k_obj_type obj_type_mutex;
#endif /* CONFIG_OBJ_CORE_MUTEX */

int z_impl_k_mutex_init(struct k_mutex *mutex)
{
70001ecc:	4603      	mov	r3, r0
	mutex->owner = NULL;
70001ece:	2200      	movs	r2, #0
#endif /* CONFIG_OBJ_CORE_MUTEX */

	SYS_PORT_TRACING_OBJ_INIT(k_mutex, mutex, 0);

	return 0;
}
70001ed0:	4610      	mov	r0, r2
	mutex->lock_count = 0U;
70001ed2:	e9c3 2202 	strd	r2, r2, [r3, #8]
	list->head = (sys_dnode_t *)list;
70001ed6:	601b      	str	r3, [r3, #0]
70001ed8:	605b      	str	r3, [r3, #4]
}
70001eda:	4770      	bx	lr

70001edc <z_impl_k_mutex_lock>:
	}
	return false;
}

int z_impl_k_mutex_lock(struct k_mutex *mutex, k_timeout_t timeout)
{
70001edc:	b570      	push	{r4, r5, r6, lr}
70001ede:	4604      	mov	r4, r0
70001ee0:	b084      	sub	sp, #16
70001ee2:	f3ef 8500 	mrs	r5, CPSR
70001ee6:	f005 0580 	and.w	r5, r5, #128	; 0x80
70001eea:	b672      	cpsid	i

	SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_mutex, lock, mutex, timeout);

	key = k_spin_lock(&lock);

	if (likely((mutex->lock_count == 0U) || (mutex->owner == arch_current_thread()))) {
70001eec:	68c1      	ldr	r1, [r0, #12]
70001eee:	b979      	cbnz	r1, 70001f10 <z_impl_k_mutex_lock+0x34>
70001ef0:	f646 7358 	movw	r3, #28504	; 0x6f58
70001ef4:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001ef8:	6898      	ldr	r0, [r3, #8]

		mutex->owner_orig_prio = (mutex->lock_count == 0U) ?
					arch_current_thread()->base.prio :
70001efa:	f990 300e 	ldrsb.w	r3, [r0, #14]
		mutex->owner_orig_prio = (mutex->lock_count == 0U) ?
70001efe:	6123      	str	r3, [r4, #16]
					mutex->owner_orig_prio;

		mutex->lock_count++;
70001f00:	3101      	adds	r1, #1
70001f02:	e9c4 0102 	strd	r0, r1, [r4, #8]
	if (key != 0U) {
70001f06:	b905      	cbnz	r5, 70001f0a <z_impl_k_mutex_lock+0x2e>
70001f08:	b662      	cpsie	i

		k_spin_unlock(&lock, key);

		SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_mutex, lock, mutex, timeout, 0);

		return 0;
70001f0a:	2000      	movs	r0, #0
	}

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_mutex, lock, mutex, timeout, -EAGAIN);

	return -EAGAIN;
}
70001f0c:	b004      	add	sp, #16
70001f0e:	bd70      	pop	{r4, r5, r6, pc}
	if (likely((mutex->lock_count == 0U) || (mutex->owner == arch_current_thread()))) {
70001f10:	68a6      	ldr	r6, [r4, #8]
70001f12:	f646 7058 	movw	r0, #28504	; 0x6f58
70001f16:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001f1a:	6880      	ldr	r0, [r0, #8]
70001f1c:	4286      	cmp	r6, r0
					arch_current_thread()->base.prio :
70001f1e:	bf08      	it	eq
70001f20:	6923      	ldreq	r3, [r4, #16]
	if (likely((mutex->lock_count == 0U) || (mutex->owner == arch_current_thread()))) {
70001f22:	d0ec      	beq.n	70001efe <z_impl_k_mutex_lock+0x22>
	if (unlikely(K_TIMEOUT_EQ(timeout, K_NO_WAIT))) {
70001f24:	ea52 0103 	orrs.w	r1, r2, r3
70001f28:	d050      	beq.n	70001fcc <z_impl_k_mutex_lock+0xf0>
	new_prio = new_prio_for_inheritance(arch_current_thread()->base.prio,
70001f2a:	f990 100e 	ldrsb.w	r1, [r0, #14]
70001f2e:	f996 000e 	ldrsb.w	r0, [r6, #14]
	return z_is_under_prio_ceiling(prio) ? prio : CONFIG_PRIORITY_CEILING;
70001f32:	4281      	cmp	r1, r0
70001f34:	bfa8      	it	ge
70001f36:	4601      	movge	r1, r0
70001f38:	f06f 0c7e 	mvn.w	ip, #126	; 0x7e
70001f3c:	4561      	cmp	r1, ip
70001f3e:	bfb8      	it	lt
70001f40:	4661      	movlt	r1, ip
	if (z_is_prio_higher(new_prio, mutex->owner->base.prio)) {
70001f42:	4288      	cmp	r0, r1
	bool resched = false;
70001f44:	bfd8      	it	le
70001f46:	2600      	movle	r6, #0
	if (z_is_prio_higher(new_prio, mutex->owner->base.prio)) {
70001f48:	dc37      	bgt.n	70001fba <z_impl_k_mutex_lock+0xde>
	int got_mutex = z_pend_curr(&lock, key, &mutex->wait_q, timeout);
70001f4a:	f646 7078 	movw	r0, #28536	; 0x6f78
70001f4e:	4629      	mov	r1, r5
70001f50:	9200      	str	r2, [sp, #0]
70001f52:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001f56:	9301      	str	r3, [sp, #4]
70001f58:	4622      	mov	r2, r4
70001f5a:	f000 fb37 	bl	700025cc <z_pend_curr>
	if (got_mutex == 0) {
70001f5e:	2800      	cmp	r0, #0
70001f60:	d0d3      	beq.n	70001f0a <z_impl_k_mutex_lock+0x2e>
	__asm__ volatile(
70001f62:	f3ef 8500 	mrs	r5, CPSR
70001f66:	f005 0580 	and.w	r5, r5, #128	; 0x80
70001f6a:	b672      	cpsid	i
	if (likely(mutex->owner != NULL)) {
70001f6c:	68a0      	ldr	r0, [r4, #8]
70001f6e:	b190      	cbz	r0, 70001f96 <z_impl_k_mutex_lock+0xba>
	return list->head == list;
70001f70:	6823      	ldr	r3, [r4, #0]
			new_prio_for_inheritance(waiter->base.prio, mutex->owner_orig_prio) :
70001f72:	6921      	ldr	r1, [r4, #16]
70001f74:	429c      	cmp	r4, r3
70001f76:	d00a      	beq.n	70001f8e <z_impl_k_mutex_lock+0xb2>
70001f78:	b14b      	cbz	r3, 70001f8e <z_impl_k_mutex_lock+0xb2>
70001f7a:	f993 300e 	ldrsb.w	r3, [r3, #14]
70001f7e:	4299      	cmp	r1, r3
70001f80:	bfa8      	it	ge
70001f82:	4619      	movge	r1, r3
70001f84:	f06f 037e 	mvn.w	r3, #126	; 0x7e
70001f88:	4299      	cmp	r1, r3
70001f8a:	bfb8      	it	lt
70001f8c:	4619      	movlt	r1, r3
	if (mutex->owner->base.prio != new_prio) {
70001f8e:	f990 300e 	ldrsb.w	r3, [r0, #14]
70001f92:	4299      	cmp	r1, r3
70001f94:	d105      	bne.n	70001fa2 <z_impl_k_mutex_lock+0xc6>
	if (resched) {
70001f96:	b946      	cbnz	r6, 70001faa <z_impl_k_mutex_lock+0xce>
	if (key != 0U) {
70001f98:	b905      	cbnz	r5, 70001f9c <z_impl_k_mutex_lock+0xc0>
70001f9a:	b662      	cpsie	i
	return -EAGAIN;
70001f9c:	f06f 000a 	mvn.w	r0, #10
70001fa0:	e7b4      	b.n	70001f0c <z_impl_k_mutex_lock+0x30>
		return z_thread_prio_set(mutex->owner, new_prio);
70001fa2:	f000 fb47 	bl	70002634 <z_thread_prio_set>
		resched = adjust_owner_prio(mutex, new_prio) || resched;
70001fa6:	2800      	cmp	r0, #0
70001fa8:	d0f5      	beq.n	70001f96 <z_impl_k_mutex_lock+0xba>
		z_reschedule(&lock, key);
70001faa:	f646 7078 	movw	r0, #28536	; 0x6f78
70001fae:	4629      	mov	r1, r5
70001fb0:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001fb4:	f000 fb90 	bl	700026d8 <z_reschedule>
70001fb8:	e7f0      	b.n	70001f9c <z_impl_k_mutex_lock+0xc0>
70001fba:	e9cd 2302 	strd	r2, r3, [sp, #8]
		return z_thread_prio_set(mutex->owner, new_prio);
70001fbe:	4630      	mov	r0, r6
70001fc0:	f000 fb38 	bl	70002634 <z_thread_prio_set>
70001fc4:	e9dd 2302 	ldrd	r2, r3, [sp, #8]
70001fc8:	4606      	mov	r6, r0
70001fca:	e7be      	b.n	70001f4a <z_impl_k_mutex_lock+0x6e>
70001fcc:	b905      	cbnz	r5, 70001fd0 <z_impl_k_mutex_lock+0xf4>
70001fce:	b662      	cpsie	i
		return -EBUSY;
70001fd0:	f06f 000f 	mvn.w	r0, #15
70001fd4:	e79a      	b.n	70001f0c <z_impl_k_mutex_lock+0x30>
70001fd6:	bf00      	nop

70001fd8 <z_impl_k_mutex_unlock>:

	__ASSERT(!arch_is_in_isr(), "mutexes cannot be used inside ISRs");

	SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_mutex, unlock, mutex);

	CHECKIF(mutex->owner == NULL) {
70001fd8:	6882      	ldr	r2, [r0, #8]
70001fda:	2a00      	cmp	r2, #0
70001fdc:	d04d      	beq.n	7000207a <z_impl_k_mutex_unlock+0xa2>
{
70001fde:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
70001fe0:	f646 7358 	movw	r3, #28504	; 0x6f58
70001fe4:	f2c7 0300 	movt	r3, #28672	; 0x7000
		return -EINVAL;
	}
	/*
	 * The current thread does not own the mutex.
	 */
	CHECKIF(mutex->owner != arch_current_thread()) {
70001fe8:	689b      	ldr	r3, [r3, #8]
70001fea:	429a      	cmp	r2, r3
70001fec:	d142      	bne.n	70002074 <z_impl_k_mutex_unlock+0x9c>

	/*
	 * If we are the owner and count is greater than 1, then decrement
	 * the count and return and keep current thread as the owner.
	 */
	if (mutex->lock_count > 1U) {
70001fee:	68c3      	ldr	r3, [r0, #12]
70001ff0:	4604      	mov	r4, r0
70001ff2:	2b01      	cmp	r3, #1
70001ff4:	d903      	bls.n	70001ffe <z_impl_k_mutex_unlock+0x26>
		mutex->lock_count--;
70001ff6:	3b01      	subs	r3, #1
70001ff8:	60c3      	str	r3, [r0, #12]


k_mutex_unlock_return:
	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_mutex, unlock, mutex, 0);

	return 0;
70001ffa:	2000      	movs	r0, #0
}
70001ffc:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	__asm__ volatile(
70001ffe:	f3ef 8600 	mrs	r6, CPSR
70002002:	f006 0680 	and.w	r6, r6, #128	; 0x80
70002006:	b672      	cpsid	i
	adjust_owner_prio(mutex, mutex->owner_orig_prio);
70002008:	6901      	ldr	r1, [r0, #16]
7000200a:	6880      	ldr	r0, [r0, #8]
	if (mutex->owner->base.prio != new_prio) {
7000200c:	f990 300e 	ldrsb.w	r3, [r0, #14]
70002010:	4299      	cmp	r1, r3
70002012:	d10a      	bne.n	7000202a <z_impl_k_mutex_unlock+0x52>
70002014:	6825      	ldr	r5, [r4, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002016:	42ac      	cmp	r4, r5
70002018:	d000      	beq.n	7000201c <z_impl_k_mutex_unlock+0x44>
		if (unlikely(thread != NULL)) {
7000201a:	b94d      	cbnz	r5, 70002030 <z_impl_k_mutex_unlock+0x58>
	mutex->owner = new_owner;
7000201c:	2300      	movs	r3, #0
		mutex->lock_count = 0U;
7000201e:	e9c4 3302 	strd	r3, r3, [r4, #8]
	if (key != 0U) {
70002022:	2e00      	cmp	r6, #0
70002024:	d1e9      	bne.n	70001ffa <z_impl_k_mutex_unlock+0x22>
70002026:	b662      	cpsie	i
}
70002028:	e7e7      	b.n	70001ffa <z_impl_k_mutex_unlock+0x22>
		return z_thread_prio_set(mutex->owner, new_prio);
7000202a:	f000 fb03 	bl	70002634 <z_thread_prio_set>
7000202e:	e7f1      	b.n	70002014 <z_impl_k_mutex_unlock+0x3c>
	sys_dnode_t *const next = node->next;
70002030:	e9d5 3200 	ldrd	r3, r2, [r5]
	thread->base.pended_on = NULL;
70002034:	2700      	movs	r7, #0
	prev->next = next;
70002036:	6013      	str	r3, [r2, #0]
70002038:	f105 0018 	add.w	r0, r5, #24
	next->prev = prev;
7000203c:	605a      	str	r2, [r3, #4]
	node->next = NULL;
7000203e:	2200      	movs	r2, #0
70002040:	60af      	str	r7, [r5, #8]
70002042:	2300      	movs	r3, #0
70002044:	e9c5 2300 	strd	r2, r3, [r5]
70002048:	7b6b      	ldrb	r3, [r5, #13]
7000204a:	f023 0302 	bic.w	r3, r3, #2
7000204e:	736b      	strb	r3, [r5, #13]
70002050:	f000 fd8c 	bl	70002b6c <z_abort_timeout>
	mutex->owner = new_owner;
70002054:	60a5      	str	r5, [r4, #8]
		z_ready_thread(new_owner);
70002056:	4628      	mov	r0, r5
		mutex->owner_orig_prio = new_owner->base.prio;
70002058:	f995 300e 	ldrsb.w	r3, [r5, #14]
7000205c:	6123      	str	r3, [r4, #16]
7000205e:	672f      	str	r7, [r5, #112]	; 0x70
		z_ready_thread(new_owner);
70002060:	f000 fa24 	bl	700024ac <z_ready_thread>
		z_reschedule(&lock, key);
70002064:	f646 7078 	movw	r0, #28536	; 0x6f78
70002068:	4631      	mov	r1, r6
7000206a:	f2c7 0000 	movt	r0, #28672	; 0x7000
7000206e:	f000 fb33 	bl	700026d8 <z_reschedule>
70002072:	e7c2      	b.n	70001ffa <z_impl_k_mutex_unlock+0x22>
		return -EPERM;
70002074:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
}
70002078:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		return -EINVAL;
7000207a:	f06f 0015 	mvn.w	r0, #21
}
7000207e:	4770      	bx	lr

70002080 <z_impl_k_sem_give>:
	return false;
#endif /* CONFIG_POLL */
}

void z_impl_k_sem_give(struct k_sem *sem)
{
70002080:	b570      	push	{r4, r5, r6, lr}
	__asm__ volatile(
70002082:	f3ef 8500 	mrs	r5, CPSR
70002086:	f005 0580 	and.w	r5, r5, #128	; 0x80
7000208a:	b672      	cpsid	i
	return list->head == list;
7000208c:	6804      	ldr	r4, [r0, #0]
		if (unlikely(thread != NULL)) {
7000208e:	2c00      	cmp	r4, #0
70002090:	bf18      	it	ne
70002092:	42a0      	cmpne	r0, r4
70002094:	d113      	bne.n	700020be <z_impl_k_sem_give+0x3e>

	if (unlikely(thread != NULL)) {
		arch_thread_return_value_set(thread, 0);
		z_ready_thread(thread);
	} else {
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
70002096:	e9d0 3202 	ldrd	r3, r2, [r0, #8]
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
7000209a:	2102      	movs	r1, #2
7000209c:	3010      	adds	r0, #16
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
7000209e:	429a      	cmp	r2, r3
700020a0:	bf18      	it	ne
700020a2:	3301      	addne	r3, #1
700020a4:	f840 3c08 	str.w	r3, [r0, #-8]
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
700020a8:	f000 fe8a 	bl	70002dc0 <z_handle_obj_poll_events>
		resched = handle_poll_events(sem);
	}

	if (unlikely(resched)) {
		z_reschedule(&lock, key);
700020ac:	f646 7078 	movw	r0, #28536	; 0x6f78
700020b0:	4629      	mov	r1, r5
700020b2:	f2c7 0000 	movt	r0, #28672	; 0x7000
	} else {
		k_spin_unlock(&lock, key);
	}

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_sem, give, sem);
}
700020b6:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		z_reschedule(&lock, key);
700020ba:	f000 bb0d 	b.w	700026d8 <z_reschedule>
	sys_dnode_t *const next = node->next;
700020be:	e9d4 3200 	ldrd	r3, r2, [r4]
	thread->base.pended_on = NULL;
700020c2:	2600      	movs	r6, #0
	prev->next = next;
700020c4:	6013      	str	r3, [r2, #0]
	node->next = NULL;
700020c6:	2100      	movs	r1, #0
	next->prev = prev;
700020c8:	605a      	str	r2, [r3, #4]
	node->next = NULL;
700020ca:	2000      	movs	r0, #0
700020cc:	7b63      	ldrb	r3, [r4, #13]
700020ce:	60a6      	str	r6, [r4, #8]
700020d0:	e9c4 0100 	strd	r0, r1, [r4]
700020d4:	f023 0302 	bic.w	r3, r3, #2
700020d8:	f104 0018 	add.w	r0, r4, #24
700020dc:	7363      	strb	r3, [r4, #13]
700020de:	f000 fd45 	bl	70002b6c <z_abort_timeout>
700020e2:	6726      	str	r6, [r4, #112]	; 0x70
		z_ready_thread(thread);
700020e4:	4620      	mov	r0, r4
700020e6:	f000 f9e1 	bl	700024ac <z_ready_thread>
700020ea:	e7df      	b.n	700020ac <z_impl_k_sem_give+0x2c>

700020ec <k_is_in_isr>:
700020ec:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
#include <zephyr/arch/arm/cortex_a_r/lib_helpers.h>
#include <zephyr/arch/arm/cortex_a_r/tpidruro.h>

static ALWAYS_INLINE _cpu_t *arch_curr_cpu(void)
{
	return (_cpu_t *)(read_tpidruro() & TPIDRURO_CURR_CPU);
700020f0:	f023 0303 	bic.w	r3, r3, #3
#endif

/* Check the CPSR mode bits to see if we are in IRQ or FIQ mode */
static ALWAYS_INLINE bool arch_is_in_isr(void)
{
	return (arch_curr_cpu()->nested != 0U);
700020f4:	6818      	ldr	r0, [r3, #0]
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data)

bool k_is_in_isr(void)
{
	return arch_is_in_isr();
}
700020f6:	3800      	subs	r0, #0
700020f8:	bf18      	it	ne
700020fa:	2001      	movne	r0, #1
700020fc:	4770      	bx	lr
700020fe:	bf00      	nop

70002100 <z_impl_k_thread_priority_get>:
#endif /* CONFIG_USERSPACE */

int z_impl_k_thread_priority_get(k_tid_t thread)
{
	return thread->base.prio;
}
70002100:	f990 000e 	ldrsb.w	r0, [r0, #14]
70002104:	4770      	bx	lr
70002106:	bf00      	nop

70002108 <z_impl_k_thread_name_set>:

	SYS_PORT_TRACING_OBJ_FUNC(k_thread, name_set, thread, -ENOSYS);

	return -ENOSYS;
#endif /* CONFIG_THREAD_NAME */
}
70002108:	f06f 0057 	mvn.w	r0, #87	; 0x57
7000210c:	4770      	bx	lr
7000210e:	bf00      	nop

70002110 <z_setup_new_thread>:
		stack_buf_size = stack_obj_size - K_THREAD_STACK_RESERVED;
	} else
#endif /* CONFIG_USERSPACE */
	{
		/* Object cannot host a user mode thread */
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
70002110:	3207      	adds	r2, #7
70002112:	f022 0207 	bic.w	r2, r2, #7
char *z_setup_new_thread(struct k_thread *new_thread,
			 k_thread_stack_t *stack, size_t stack_size,
			 k_thread_entry_t entry,
			 void *p1, void *p2, void *p3,
			 int prio, uint32_t options, const char *name)
{
70002116:	e92d 4370 	stmdb	sp!, {r4, r5, r6, r8, r9, lr}
	stack_ptr = (char *)stack + stack_obj_size;
7000211a:	188d      	adds	r5, r1, r2
	SYS_DLIST_FOR_EACH_CONTAINER(&((wq)->waitq), thread_ptr, \
				     base.qnode_dlist)

static inline void z_waitq_init(_wait_q_t *w)
{
	sys_dlist_init(&w->waitq);
7000211c:	f100 0258 	add.w	r2, r0, #88	; 0x58

void z_init_thread_base(struct _thread_base *thread_base, int priority,
		       uint32_t initial_state, unsigned int options)
{
	/* k_q_node is initialized upon first insertion in a list */
	thread_base->pended_on = NULL;
70002120:	2600      	movs	r6, #0
{
70002122:	b084      	sub	sp, #16
	list->head = (sys_dnode_t *)list;
70002124:	e9c0 2216 	strd	r2, r2, [r0, #88]	; 0x58
	thread_base->user_options = (uint8_t)options;
	thread_base->thread_state = (uint8_t)initial_state;
70002128:	2204      	movs	r2, #4
	thread_base->pended_on = NULL;
7000212a:	6086      	str	r6, [r0, #8]
	node->next = NULL;
7000212c:	f04f 0800 	mov.w	r8, #0
	thread_base->thread_state = (uint8_t)initial_state;
70002130:	7342      	strb	r2, [r0, #13]
70002132:	f04f 0900 	mov.w	r9, #0
{
70002136:	9a0a      	ldr	r2, [sp, #40]	; 0x28
70002138:	4604      	mov	r4, r0

	thread_base->prio = priority;

	thread_base->sched_locked = 0U;
7000213a:	73c6      	strb	r6, [r0, #15]
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
7000213c:	9200      	str	r2, [sp, #0]
{
7000213e:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70002140:	9201      	str	r2, [sp, #4]
{
70002142:	9a0c      	ldr	r2, [sp, #48]	; 0x30
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70002144:	9202      	str	r2, [sp, #8]
{
70002146:	9a0d      	ldr	r2, [sp, #52]	; 0x34
	thread_base->prio = priority;
70002148:	7382      	strb	r2, [r0, #14]
{
7000214a:	9a0e      	ldr	r2, [sp, #56]	; 0x38
	thread_base->user_options = (uint8_t)options;
7000214c:	7302      	strb	r2, [r0, #12]
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
7000214e:	462a      	mov	r2, r5
70002150:	e9c0 8906 	strd	r8, r9, [r0, #24]
70002154:	f7fe fe54 	bl	70000e00 <arch_new_thread>
70002158:	f646 7358 	movw	r3, #28504	; 0x6f58
	new_thread->init_data = NULL;
7000215c:	6566      	str	r6, [r4, #84]	; 0x54
7000215e:	f2c7 0300 	movt	r3, #28672	; 0x7000
}
70002162:	4628      	mov	r0, r5
	new_thread->resource_pool = arch_current_thread()->resource_pool;
70002164:	689b      	ldr	r3, [r3, #8]
70002166:	6e9b      	ldr	r3, [r3, #104]	; 0x68
70002168:	66a3      	str	r3, [r4, #104]	; 0x68
}
7000216a:	b004      	add	sp, #16
7000216c:	e8bd 8370 	ldmia.w	sp!, {r4, r5, r6, r8, r9, pc}

70002170 <z_impl_k_thread_create>:
{
70002170:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
70002174:	f100 0658 	add.w	r6, r0, #88	; 0x58
	thread_base->pended_on = NULL;
70002178:	2500      	movs	r5, #0
{
7000217a:	b085      	sub	sp, #20
	list->head = (sys_dnode_t *)list;
7000217c:	e9c0 6616 	strd	r6, r6, [r0, #88]	; 0x58
	thread_base->thread_state = (uint8_t)initial_state;
70002180:	2604      	movs	r6, #4
	thread_base->pended_on = NULL;
70002182:	6085      	str	r5, [r0, #8]
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
70002184:	3207      	adds	r2, #7
	thread_base->thread_state = (uint8_t)initial_state;
70002186:	7346      	strb	r6, [r0, #13]
	node->next = NULL;
70002188:	f04f 0800 	mov.w	r8, #0
{
7000218c:	9e0c      	ldr	r6, [sp, #48]	; 0x30
7000218e:	f04f 0900 	mov.w	r9, #0
	thread_base->sched_locked = 0U;
70002192:	73c5      	strb	r5, [r0, #15]
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
70002194:	f022 0207 	bic.w	r2, r2, #7
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70002198:	9600      	str	r6, [sp, #0]
7000219a:	440a      	add	r2, r1
{
7000219c:	9e0d      	ldr	r6, [sp, #52]	; 0x34
7000219e:	4604      	mov	r4, r0
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
700021a0:	9601      	str	r6, [sp, #4]
{
700021a2:	9e0e      	ldr	r6, [sp, #56]	; 0x38
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
700021a4:	9602      	str	r6, [sp, #8]
{
700021a6:	9e0f      	ldr	r6, [sp, #60]	; 0x3c
	thread_base->prio = priority;
700021a8:	7386      	strb	r6, [r0, #14]
{
700021aa:	9e10      	ldr	r6, [sp, #64]	; 0x40
	thread_base->user_options = (uint8_t)options;
700021ac:	7306      	strb	r6, [r0, #12]
700021ae:	e9c0 8906 	strd	r8, r9, [r0, #24]
{
700021b2:	e9dd 7612 	ldrd	r7, r6, [sp, #72]	; 0x48
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
700021b6:	f7fe fe23 	bl	70000e00 <arch_new_thread>
	new_thread->init_data = NULL;
700021ba:	6565      	str	r5, [r4, #84]	; 0x54
700021bc:	f646 7358 	movw	r3, #28504	; 0x6f58
700021c0:	f2c7 0300 	movt	r3, #28672	; 0x7000
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
700021c4:	f1b6 3fff 	cmp.w	r6, #4294967295	; 0xffffffff
700021c8:	bf08      	it	eq
700021ca:	f1b7 3fff 	cmpeq.w	r7, #4294967295	; 0xffffffff
	new_thread->resource_pool = arch_current_thread()->resource_pool;
700021ce:	689b      	ldr	r3, [r3, #8]
700021d0:	6e9b      	ldr	r3, [r3, #104]	; 0x68
700021d2:	66a3      	str	r3, [r4, #104]	; 0x68
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
700021d4:	d103      	bne.n	700021de <z_impl_k_thread_create+0x6e>
}
700021d6:	4620      	mov	r0, r4
700021d8:	b005      	add	sp, #20
700021da:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
700021de:	ea56 0307 	orrs.w	r3, r6, r7
700021e2:	d106      	bne.n	700021f2 <z_impl_k_thread_create+0x82>
700021e4:	4620      	mov	r0, r4
700021e6:	f000 fba5 	bl	70002934 <z_impl_k_wakeup>
700021ea:	4620      	mov	r0, r4
700021ec:	b005      	add	sp, #20
700021ee:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
700021f2:	f242 51c5 	movw	r1, #9669	; 0x25c5
700021f6:	f104 0018 	add.w	r0, r4, #24
700021fa:	463a      	mov	r2, r7
700021fc:	4633      	mov	r3, r6
700021fe:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002202:	f000 fc21 	bl	70002a48 <z_add_timeout>
70002206:	4620      	mov	r0, r4
70002208:	b005      	add	sp, #20
7000220a:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
7000220e:	bf00      	nop

70002210 <unready_thread>:
}
#include <zephyr/syscalls/k_thread_resume_mrsh.c>
#endif /* CONFIG_USERSPACE */

static void unready_thread(struct k_thread *thread)
{
70002210:	b410      	push	{r4}
	return (thread->base.thread_state & state) != 0U;
70002212:	7b43      	ldrb	r3, [r0, #13]
	if (z_is_thread_queued(thread)) {
70002214:	061c      	lsls	r4, r3, #24
70002216:	d509      	bpl.n	7000222c <unready_thread+0x1c>
70002218:	2200      	movs	r2, #0
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000221a:	f003 037f 	and.w	r3, r3, #127	; 0x7f
	sys_dnode_t *const next = node->next;
7000221e:	e9d0 1400 	ldrd	r1, r4, [r0]
70002222:	7343      	strb	r3, [r0, #13]
	prev->next = next;
70002224:	6021      	str	r1, [r4, #0]
	next->prev = prev;
70002226:	604c      	str	r4, [r1, #4]
	node->next = NULL;
70002228:	6002      	str	r2, [r0, #0]
7000222a:	6042      	str	r2, [r0, #4]
7000222c:	f646 7358 	movw	r3, #28504	; 0x6f58
70002230:	f2c7 0300 	movt	r3, #28672	; 0x7000
	return list->head == list;
70002234:	4619      	mov	r1, r3
70002236:	689c      	ldr	r4, [r3, #8]
70002238:	f851 2f18 	ldr.w	r2, [r1, #24]!
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
7000223c:	428a      	cmp	r2, r1
7000223e:	bf18      	it	ne
70002240:	2a00      	cmpne	r2, #0
70002242:	bf08      	it	eq
70002244:	68da      	ldreq	r2, [r3, #12]
					 int preempt_ok)
{
	/* Preemption is OK if it's being explicitly allowed by
	 * software state (e.g. the thread called k_yield())
	 */
	if (preempt_ok != 0) {
70002246:	42a0      	cmp	r0, r4
70002248:	d006      	beq.n	70002258 <unready_thread+0x48>
	}

	__ASSERT(arch_current_thread() != NULL, "");

	/* Or if we're pended/suspended/dummy (duh) */
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
7000224a:	7b61      	ldrb	r1, [r4, #13]
7000224c:	06c9      	lsls	r1, r1, #27
7000224e:	d103      	bne.n	70002258 <unready_thread+0x48>
	}

	/* Otherwise we have to be running a preemptible thread or
	 * switching to a metairq
	 */
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
70002250:	89e1      	ldrh	r1, [r4, #14]
		_kernel.ready_q.cache = arch_current_thread();
70002252:	297f      	cmp	r1, #127	; 0x7f
70002254:	bf88      	it	hi
70002256:	4622      	movhi	r2, r4
70002258:	615a      	str	r2, [r3, #20]
		dequeue_thread(thread);
	}
	update_cache(thread == arch_current_thread());
}
7000225a:	bc10      	pop	{r4}
7000225c:	4770      	bx	lr
7000225e:	bf00      	nop

70002260 <add_to_waitq_locked>:

/* _sched_spinlock must be held */
static void add_to_waitq_locked(struct k_thread *thread, _wait_q_t *wait_q)
{
70002260:	b538      	push	{r3, r4, r5, lr}
70002262:	460d      	mov	r5, r1
	unready_thread(thread);
70002264:	f7ff ffd4 	bl	70002210 <unready_thread>
	thread->base.thread_state |= _THREAD_PENDING;
70002268:	7b43      	ldrb	r3, [r0, #13]
7000226a:	f043 0302 	orr.w	r3, r3, #2
7000226e:	7343      	strb	r3, [r0, #13]
	z_mark_thread_as_pending(thread);

	SYS_PORT_TRACING_FUNC(k_thread, sched_pend, thread);

	if (wait_q != NULL) {
70002270:	b1bd      	cbz	r5, 700022a2 <add_to_waitq_locked+0x42>
		thread->base.pended_on = wait_q;
70002272:	6085      	str	r5, [r0, #8]
70002274:	4604      	mov	r4, r0
70002276:	682b      	ldr	r3, [r5, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002278:	429d      	cmp	r5, r3
7000227a:	d00d      	beq.n	70002298 <add_to_waitq_locked+0x38>
static ALWAYS_INLINE void z_priq_dumb_add(sys_dlist_t *pq,
					  struct k_thread *thread)
{
	struct k_thread *t;

	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
7000227c:	b163      	cbz	r3, 70002298 <add_to_waitq_locked+0x38>
	int32_t b2 = thread_2->base.prio;
7000227e:	f993 c00e 	ldrsb.w	ip, [r3, #14]
	int32_t b1 = thread_1->base.prio;
70002282:	f994 200e 	ldrsb.w	r2, [r4, #14]
	if (b1 != b2) {
70002286:	4562      	cmp	r2, ip
70002288:	d001      	beq.n	7000228e <add_to_waitq_locked+0x2e>
		if (z_sched_prio_cmp(thread, t) > 0) {
7000228a:	4594      	cmp	ip, r2
7000228c:	dc0a      	bgt.n	700022a4 <add_to_waitq_locked+0x44>
	return (node == list->tail) ? NULL : node->next;
7000228e:	686a      	ldr	r2, [r5, #4]
70002290:	4293      	cmp	r3, r2
70002292:	d002      	beq.n	7000229a <add_to_waitq_locked+0x3a>
70002294:	681b      	ldr	r3, [r3, #0]
70002296:	e7f1      	b.n	7000227c <add_to_waitq_locked+0x1c>
70002298:	686a      	ldr	r2, [r5, #4]
	node->prev = tail;
7000229a:	e9c4 5200 	strd	r5, r2, [r4]
	tail->next = node;
7000229e:	6014      	str	r4, [r2, #0]
	list->tail = node;
700022a0:	606c      	str	r4, [r5, #4]
		_priq_wait_add(&wait_q->waitq, thread);
	}
}
700022a2:	bd38      	pop	{r3, r4, r5, pc}
	sys_dnode_t *const prev = successor->prev;
700022a4:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
700022a6:	e9c4 3200 	strd	r3, r2, [r4]
	prev->next = node;
700022aa:	6014      	str	r4, [r2, #0]
	successor->prev = node;
700022ac:	605c      	str	r4, [r3, #4]
700022ae:	bd38      	pop	{r3, r4, r5, pc}

700022b0 <ready_thread>:
	return (thread->base.thread_state & state) != 0U;
700022b0:	7b43      	ldrb	r3, [r0, #13]
	if (!z_is_thread_queued(thread) && z_is_thread_ready(thread)) {
700022b2:	0619      	lsls	r1, r3, #24
700022b4:	d403      	bmi.n	700022be <ready_thread+0xe>
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
700022b6:	06da      	lsls	r2, r3, #27
700022b8:	d101      	bne.n	700022be <ready_thread+0xe>
	return node->next != NULL;
700022ba:	6982      	ldr	r2, [r0, #24]
700022bc:	b102      	cbz	r2, 700022c0 <ready_thread+0x10>
700022be:	4770      	bx	lr
	return list->head == list;
700022c0:	f646 7c58 	movw	ip, #28504	; 0x6f58
	thread->base.thread_state |= _THREAD_QUEUED;
700022c4:	f063 037f 	orn	r3, r3, #127	; 0x7f
700022c8:	f2c7 0c00 	movt	ip, #28672	; 0x7000
{
700022cc:	b430      	push	{r4, r5}
	thread->base.thread_state |= _THREAD_QUEUED;
700022ce:	7343      	strb	r3, [r0, #13]
700022d0:	4665      	mov	r5, ip
	return (node == list->tail) ? NULL : node->next;
700022d2:	f8dc 401c 	ldr.w	r4, [ip, #28]
	return list->head == list;
700022d6:	f855 3f18 	ldr.w	r3, [r5, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
700022da:	42ab      	cmp	r3, r5
700022dc:	bf08      	it	eq
700022de:	2300      	moveq	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
700022e0:	b15b      	cbz	r3, 700022fa <ready_thread+0x4a>
	int32_t b2 = thread_2->base.prio;
700022e2:	f993 100e 	ldrsb.w	r1, [r3, #14]
	int32_t b1 = thread_1->base.prio;
700022e6:	f990 200e 	ldrsb.w	r2, [r0, #14]
	if (b1 != b2) {
700022ea:	428a      	cmp	r2, r1
700022ec:	d001      	beq.n	700022f2 <ready_thread+0x42>
		if (z_sched_prio_cmp(thread, t) > 0) {
700022ee:	4291      	cmp	r1, r2
700022f0:	dc20      	bgt.n	70002334 <ready_thread+0x84>
	return (node == list->tail) ? NULL : node->next;
700022f2:	42a3      	cmp	r3, r4
700022f4:	d001      	beq.n	700022fa <ready_thread+0x4a>
700022f6:	681b      	ldr	r3, [r3, #0]
700022f8:	e7f2      	b.n	700022e0 <ready_thread+0x30>
	node->prev = tail;
700022fa:	e9c0 5400 	strd	r5, r4, [r0]
	tail->next = node;
700022fe:	6020      	str	r0, [r4, #0]
	list->tail = node;
70002300:	f8cc 001c 	str.w	r0, [ip, #28]
	return list->head == list;
70002304:	f8dc 3018 	ldr.w	r3, [ip, #24]
70002308:	f8dc 2008 	ldr.w	r2, [ip, #8]
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
7000230c:	7b51      	ldrb	r1, [r2, #13]
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
7000230e:	2b00      	cmp	r3, #0
70002310:	bf18      	it	ne
70002312:	42ab      	cmpne	r3, r5
70002314:	bf08      	it	eq
70002316:	f8dc 300c 	ldreq.w	r3, [ip, #12]
7000231a:	06c9      	lsls	r1, r1, #27
7000231c:	d107      	bne.n	7000232e <ready_thread+0x7e>
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
7000231e:	89d1      	ldrh	r1, [r2, #14]
70002320:	297f      	cmp	r1, #127	; 0x7f
		_kernel.ready_q.cache = arch_current_thread();
70002322:	bf88      	it	hi
70002324:	f8cc 2014 	strhi.w	r2, [ip, #20]
70002328:	d901      	bls.n	7000232e <ready_thread+0x7e>
}
7000232a:	bc30      	pop	{r4, r5}
7000232c:	4770      	bx	lr
		_kernel.ready_q.cache = thread;
7000232e:	f8cc 3014 	str.w	r3, [ip, #20]
}
70002332:	e7fa      	b.n	7000232a <ready_thread+0x7a>
	sys_dnode_t *const prev = successor->prev;
70002334:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
70002336:	e9c0 3200 	strd	r3, r2, [r0]
	prev->next = node;
7000233a:	6010      	str	r0, [r2, #0]
	successor->prev = node;
7000233c:	6058      	str	r0, [r3, #4]
}
7000233e:	e7e1      	b.n	70002304 <ready_thread+0x54>

70002340 <z_thread_halt>:
		halt_thread(thread, terminate ? _THREAD_DEAD : _THREAD_SUSPENDED);
70002340:	2a00      	cmp	r2, #0
70002342:	bf0c      	ite	eq
70002344:	2210      	moveq	r2, #16
70002346:	2208      	movne	r2, #8
{
70002348:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	bool dummify = false;

	/* We hold the lock, and the thread is known not to be running
	 * anywhere.
	 */
	if ((thread->base.thread_state & new_state) == 0U) {
7000234c:	7b43      	ldrb	r3, [r0, #13]
{
7000234e:	460f      	mov	r7, r1
	if ((thread->base.thread_state & new_state) == 0U) {
70002350:	ea12 0103 	ands.w	r1, r2, r3
70002354:	bf18      	it	ne
70002356:	f646 7358 	movwne	r3, #28504	; 0x6f58
{
7000235a:	4605      	mov	r5, r0
7000235c:	bf18      	it	ne
7000235e:	f2c7 0300 	movtne	r3, #28672	; 0x7000
	if ((thread->base.thread_state & new_state) == 0U) {
70002362:	d122      	bne.n	700023aa <z_thread_halt+0x6a>
		thread->base.thread_state |= new_state;
70002364:	ea42 0003 	orr.w	r0, r2, r3
		if (z_is_thread_queued(thread)) {
70002368:	09db      	lsrs	r3, r3, #7
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000236a:	bf17      	itett	ne
7000236c:	f000 007f 	andne.w	r0, r0, #127	; 0x7f
		thread->base.thread_state |= new_state;
70002370:	7368      	strbeq	r0, [r5, #13]
	thread->base.thread_state &= ~_THREAD_QUEUED;
70002372:	7368      	strbne	r0, [r5, #13]
	sys_dnode_t *const next = node->next;
70002374:	e9d5 3000 	ldrdne	r3, r0, [r5]
	prev->next = next;
70002378:	bf1e      	ittt	ne
7000237a:	6003      	strne	r3, [r0, #0]
	next->prev = prev;
7000237c:	6058      	strne	r0, [r3, #4]
	node->prev = NULL;
7000237e:	e9c5 1100 	strdne	r1, r1, [r5]
			dequeue_thread(thread);
		}

		if (new_state == _THREAD_DEAD) {
70002382:	2a08      	cmp	r2, #8
70002384:	d029      	beq.n	700023da <z_thread_halt+0x9a>
	return list->head == list;
70002386:	f646 7358 	movw	r3, #28504	; 0x6f58
7000238a:	f2c7 0300 	movt	r3, #28672	; 0x7000
7000238e:	461a      	mov	r2, r3
70002390:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002394:	4291      	cmp	r1, r2
70002396:	d05f      	beq.n	70002458 <z_thread_halt+0x118>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002398:	2900      	cmp	r1, #0
7000239a:	d069      	beq.n	70002470 <z_thread_halt+0x130>
		_kernel.ready_q.cache = thread;
7000239c:	6159      	str	r1, [r3, #20]
  __ASM volatile ("dmb 0xF":::"memory");
7000239e:	f3bf 8f5f 	dmb	sy
	thread->base.thread_state &= ~(_THREAD_ABORTING | _THREAD_SUSPENDING);
700023a2:	7b6a      	ldrb	r2, [r5, #13]
700023a4:	f022 0260 	bic.w	r2, r2, #96	; 0x60
700023a8:	736a      	strb	r2, [r5, #13]
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
700023aa:	689a      	ldr	r2, [r3, #8]
700023ac:	4295      	cmp	r5, r2
700023ae:	d003      	beq.n	700023b8 <z_thread_halt+0x78>
	if (key != 0U) {
700023b0:	b907      	cbnz	r7, 700023b4 <z_thread_halt+0x74>
  __ASM volatile ("cpsie i" : : : "memory");
700023b2:	b662      	cpsie	i
}
700023b4:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
700023b8:	ee1d 2f70 	mrc	15, 0, r2, cr13, cr0, {3}
700023bc:	f022 0203 	bic.w	r2, r2, #3
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
700023c0:	6812      	ldr	r2, [r2, #0]
700023c2:	2a00      	cmp	r2, #0
700023c4:	d1f4      	bne.n	700023b0 <z_thread_halt+0x70>
700023c6:	689b      	ldr	r3, [r3, #8]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700023c8:	f06f 020a 	mvn.w	r2, #10
700023cc:	e9c3 721b 	strd	r7, r2, [r3, #108]	; 0x6c
	z_arm_cortex_r_svc();
700023d0:	f7fe ee52 	blx	70001078 <z_arm_cortex_r_svc>
700023d4:	2f00      	cmp	r7, #0
700023d6:	d0ec      	beq.n	700023b2 <z_thread_halt+0x72>
700023d8:	e7ec      	b.n	700023b4 <z_thread_halt+0x74>
			if (thread->base.pended_on != NULL) {
700023da:	68ab      	ldr	r3, [r5, #8]
700023dc:	b15b      	cbz	r3, 700023f6 <z_thread_halt+0xb6>
	sys_dnode_t *const next = node->next;
700023de:	e9d5 3100 	ldrd	r3, r1, [r5]
	node->next = NULL;
700023e2:	2200      	movs	r2, #0
	prev->next = next;
700023e4:	600b      	str	r3, [r1, #0]
	next->prev = prev;
700023e6:	6059      	str	r1, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
700023e8:	7b6b      	ldrb	r3, [r5, #13]
	node->prev = NULL;
700023ea:	e9c5 2200 	strd	r2, r2, [r5]
700023ee:	f023 0302 	bic.w	r3, r3, #2
700023f2:	60aa      	str	r2, [r5, #8]
700023f4:	736b      	strb	r3, [r5, #13]
	return z_abort_timeout(&thread->base.timeout);
700023f6:	f105 0018 	add.w	r0, r5, #24
700023fa:	f000 fbb7 	bl	70002b6c <z_abort_timeout>
	return list->head == list;
700023fe:	6dac      	ldr	r4, [r5, #88]	; 0x58
}

static inline struct k_thread *z_waitq_head(_wait_q_t *w)
{
	return (struct k_thread *)sys_dlist_peek_head(&w->waitq);
70002400:	f105 0858 	add.w	r8, r5, #88	; 0x58
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002404:	45a0      	cmp	r8, r4
70002406:	d019      	beq.n	7000243c <z_thread_halt+0xfc>
	for (thread = z_waitq_head(wait_q); thread != NULL; thread = z_waitq_head(wait_q)) {
70002408:	b1c4      	cbz	r4, 7000243c <z_thread_halt+0xfc>
	node->next = NULL;
7000240a:	2600      	movs	r6, #0
7000240c:	e000      	b.n	70002410 <z_thread_halt+0xd0>
7000240e:	b1ac      	cbz	r4, 7000243c <z_thread_halt+0xfc>
	sys_dnode_t *const next = node->next;
70002410:	e9d4 3200 	ldrd	r3, r2, [r4]
70002414:	f104 0018 	add.w	r0, r4, #24
	prev->next = next;
70002418:	6013      	str	r3, [r2, #0]
	next->prev = prev;
7000241a:	605a      	str	r2, [r3, #4]
7000241c:	7b63      	ldrb	r3, [r4, #13]
	node->prev = NULL;
7000241e:	e9c4 6600 	strd	r6, r6, [r4]
70002422:	f023 0302 	bic.w	r3, r3, #2
70002426:	60a6      	str	r6, [r4, #8]
70002428:	7363      	strb	r3, [r4, #13]
7000242a:	f000 fb9f 	bl	70002b6c <z_abort_timeout>
	thread->arch.swap_return_value = value;
7000242e:	6726      	str	r6, [r4, #112]	; 0x70
		ready_thread(thread);
70002430:	4620      	mov	r0, r4
70002432:	f7ff ff3d 	bl	700022b0 <ready_thread>
	return list->head == list;
70002436:	6dac      	ldr	r4, [r5, #88]	; 0x58
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002438:	45a0      	cmp	r8, r4
7000243a:	d1e8      	bne.n	7000240e <z_thread_halt+0xce>
7000243c:	f646 7358 	movw	r3, #28504	; 0x6f58
70002440:	f2c7 0300 	movt	r3, #28672	; 0x7000
			 * ISR that preempted it requires clearing the
			 * arch_current_thread() pointer so the upcoming context
			 * switch doesn't clobber the now-freed
			 * memory
			 */
			if (thread == arch_current_thread() && arch_is_in_isr()) {
70002444:	689a      	ldr	r2, [r3, #8]
70002446:	4295      	cmp	r5, r2
70002448:	d014      	beq.n	70002474 <z_thread_halt+0x134>
	return list->head == list;
7000244a:	461a      	mov	r2, r3
7000244c:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002450:	4291      	cmp	r1, r2
70002452:	d001      	beq.n	70002458 <z_thread_halt+0x118>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002454:	2900      	cmp	r1, #0
70002456:	d1a1      	bne.n	7000239c <z_thread_halt+0x5c>
		_kernel.ready_q.cache = thread;
70002458:	68da      	ldr	r2, [r3, #12]
7000245a:	615a      	str	r2, [r3, #20]
  __ASM volatile ("dmb 0xF":::"memory");
7000245c:	f3bf 8f5f 	dmb	sy
	thread->base.thread_state &= ~(_THREAD_ABORTING | _THREAD_SUSPENDING);
70002460:	7b6a      	ldrb	r2, [r5, #13]
70002462:	f022 0260 	bic.w	r2, r2, #96	; 0x60
70002466:	736a      	strb	r2, [r5, #13]
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
70002468:	689a      	ldr	r2, [r3, #8]
7000246a:	4295      	cmp	r5, r2
7000246c:	d1a0      	bne.n	700023b0 <z_thread_halt+0x70>
7000246e:	e7a3      	b.n	700023b8 <z_thread_halt+0x78>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002470:	68d9      	ldr	r1, [r3, #12]
#ifdef CONFIG_SMP
		unpend_all(&thread->halt_queue);
#endif /* CONFIG_SMP */
		update_cache(1);

		if (new_state == _THREAD_SUSPENDED) {
70002472:	e793      	b.n	7000239c <z_thread_halt+0x5c>
70002474:	ee1d 2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70002478:	f022 0203 	bic.w	r2, r2, #3
			if (thread == arch_current_thread() && arch_is_in_isr()) {
7000247c:	6812      	ldr	r2, [r2, #0]
7000247e:	2a00      	cmp	r2, #0
70002480:	d0e3      	beq.n	7000244a <z_thread_halt+0x10a>
	return list->head == list;
70002482:	461a      	mov	r2, r3
70002484:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002488:	4291      	cmp	r1, r2
7000248a:	d00c      	beq.n	700024a6 <z_thread_halt+0x166>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
7000248c:	b159      	cbz	r1, 700024a6 <z_thread_halt+0x166>
		_kernel.ready_q.cache = thread;
7000248e:	6159      	str	r1, [r3, #20]
70002490:	f245 6278 	movw	r2, #22136	; 0x5678
70002494:	f240 1101 	movw	r1, #257	; 0x101
70002498:	f2c7 0200 	movt	r2, #28672	; 0x7000
7000249c:	8191      	strh	r1, [r2, #12]
	dummy_thread->resource_pool = NULL;
7000249e:	2100      	movs	r1, #0
	_current_cpu->current = thread;
700024a0:	609a      	str	r2, [r3, #8]
700024a2:	6691      	str	r1, [r2, #104]	; 0x68
#ifdef CONFIG_TIMESLICE_PER_THREAD
	dummy_thread->base.slice_ticks = 0;
#endif /* CONFIG_TIMESLICE_PER_THREAD */

	arch_current_thread_set(dummy_thread);
}
700024a4:	e7da      	b.n	7000245c <z_thread_halt+0x11c>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700024a6:	68d9      	ldr	r1, [r3, #12]
		 * code.  Note that we must leave a non-null switch
		 * handle for any threads spinning in join() (this can
		 * never be used, as our thread is flagged dead, but
		 * it must not be NULL otherwise join can deadlock).
		 */
		if (dummify && !IS_ENABLED(CONFIG_ARCH_POSIX)) {
700024a8:	e7f1      	b.n	7000248e <z_thread_halt+0x14e>
700024aa:	bf00      	nop

700024ac <z_ready_thread>:
{
700024ac:	b510      	push	{r4, lr}
	__asm__ volatile(
700024ae:	f3ef 8400 	mrs	r4, CPSR
700024b2:	f004 0480 	and.w	r4, r4, #128	; 0x80
700024b6:	b672      	cpsid	i
			ready_thread(thread);
700024b8:	f7ff fefa 	bl	700022b0 <ready_thread>
	if (key != 0U) {
700024bc:	b904      	cbnz	r4, 700024c0 <z_ready_thread+0x14>
  __ASM volatile ("cpsie i" : : : "memory");
700024be:	b662      	cpsie	i
}
700024c0:	bd10      	pop	{r4, pc}
700024c2:	bf00      	nop

700024c4 <z_impl_k_thread_suspend>:
	struct k_thread *ret = _kernel.cpus[0].current;
700024c4:	f646 7358 	movw	r3, #28504	; 0x6f58
700024c8:	f2c7 0300 	movt	r3, #28672	; 0x7000
	if (thread == arch_current_thread() && !arch_is_in_isr() && !IS_ENABLED(CONFIG_SMP)) {
700024cc:	689a      	ldr	r2, [r3, #8]
700024ce:	4282      	cmp	r2, r0
700024d0:	d00e      	beq.n	700024f0 <z_impl_k_thread_suspend+0x2c>
	__asm__ volatile(
700024d2:	f3ef 8100 	mrs	r1, CPSR
700024d6:	f001 0180 	and.w	r1, r1, #128	; 0x80
700024da:	b672      	cpsid	i
	if ((thread->base.thread_state & _THREAD_SUSPENDED) != 0U) {
700024dc:	7b42      	ldrb	r2, [r0, #13]
700024de:	f012 0210 	ands.w	r2, r2, #16
700024e2:	d002      	beq.n	700024ea <z_impl_k_thread_suspend+0x26>
	if (key != 0U) {
700024e4:	b919      	cbnz	r1, 700024ee <z_impl_k_thread_suspend+0x2a>
700024e6:	b662      	cpsie	i
}
700024e8:	4770      	bx	lr
	z_thread_halt(thread, key, false);
700024ea:	f7ff bf29 	b.w	70002340 <z_thread_halt>
700024ee:	4770      	bx	lr
700024f0:	ee1d 1f70 	mrc	15, 0, r1, cr13, cr0, {3}
700024f4:	f021 0103 	bic.w	r1, r1, #3
	if (thread == arch_current_thread() && !arch_is_in_isr() && !IS_ENABLED(CONFIG_SMP)) {
700024f8:	6809      	ldr	r1, [r1, #0]
700024fa:	2900      	cmp	r1, #0
700024fc:	d1e9      	bne.n	700024d2 <z_impl_k_thread_suspend+0xe>
{
700024fe:	b570      	push	{r4, r5, r6, lr}
	__asm__ volatile(
70002500:	f3ef 8400 	mrs	r4, CPSR
70002504:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002508:	b672      	cpsid	i
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000250a:	7b50      	ldrb	r0, [r2, #13]
	sys_dnode_t *const prev = node->prev;
7000250c:	6856      	ldr	r6, [r2, #4]
	sys_dnode_t *const next = node->next;
7000250e:	6815      	ldr	r5, [r2, #0]
70002510:	f000 007f 	and.w	r0, r0, #127	; 0x7f
70002514:	f040 0010 	orr.w	r0, r0, #16
70002518:	7350      	strb	r0, [r2, #13]
	return list->head == list;
7000251a:	4618      	mov	r0, r3
	prev->next = next;
7000251c:	6035      	str	r5, [r6, #0]
	next->prev = prev;
7000251e:	606e      	str	r6, [r5, #4]
	node->next = NULL;
70002520:	6011      	str	r1, [r2, #0]
70002522:	6051      	str	r1, [r2, #4]
	return list->head == list;
70002524:	f850 2f18 	ldr.w	r2, [r0, #24]!
70002528:	6899      	ldr	r1, [r3, #8]
	arch_current_thread()->arch.basepri = key;
7000252a:	66cc      	str	r4, [r1, #108]	; 0x6c
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
7000252c:	4282      	cmp	r2, r0
7000252e:	bf18      	it	ne
70002530:	2a00      	cmpne	r2, #0
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
70002532:	f06f 000a 	mvn.w	r0, #10
70002536:	bf08      	it	eq
70002538:	68da      	ldreq	r2, [r3, #12]
7000253a:	6708      	str	r0, [r1, #112]	; 0x70
		_kernel.ready_q.cache = thread;
7000253c:	615a      	str	r2, [r3, #20]
	z_arm_cortex_r_svc();
7000253e:	f7fe ed9c 	blx	70001078 <z_arm_cortex_r_svc>
	if (key != 0U) {
70002542:	b904      	cbnz	r4, 70002546 <z_impl_k_thread_suspend+0x82>
  __ASM volatile ("cpsie i" : : : "memory");
70002544:	b662      	cpsie	i
}
70002546:	bd70      	pop	{r4, r5, r6, pc}

70002548 <z_unpend_thread_no_timeout>:
	__asm__ volatile(
70002548:	f3ef 8100 	mrs	r1, CPSR
7000254c:	f001 0180 	and.w	r1, r1, #128	; 0x80
70002550:	b672      	cpsid	i
		if (thread->base.pended_on != NULL) {
70002552:	6883      	ldr	r3, [r0, #8]
70002554:	b193      	cbz	r3, 7000257c <z_unpend_thread_no_timeout+0x34>
	sys_dnode_t *const next = node->next;
70002556:	e9d0 3200 	ldrd	r3, r2, [r0]
{
7000255a:	b430      	push	{r4, r5}
	prev->next = next;
7000255c:	6013      	str	r3, [r2, #0]
	node->next = NULL;
7000255e:	2400      	movs	r4, #0
	next->prev = prev;
70002560:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70002562:	2500      	movs	r5, #0
70002564:	7b43      	ldrb	r3, [r0, #13]
70002566:	2200      	movs	r2, #0
70002568:	e9c0 4500 	strd	r4, r5, [r0]
7000256c:	f023 0302 	bic.w	r3, r3, #2
70002570:	6082      	str	r2, [r0, #8]
70002572:	7343      	strb	r3, [r0, #13]
	if (key != 0U) {
70002574:	b901      	cbnz	r1, 70002578 <z_unpend_thread_no_timeout+0x30>
70002576:	b662      	cpsie	i
}
70002578:	bc30      	pop	{r4, r5}
7000257a:	4770      	bx	lr
7000257c:	b909      	cbnz	r1, 70002582 <z_unpend_thread_no_timeout+0x3a>
7000257e:	b662      	cpsie	i
	K_SPINLOCK(&_sched_spinlock) {
70002580:	4770      	bx	lr
70002582:	4770      	bx	lr

70002584 <z_sched_wake_thread>:
{
70002584:	b5d0      	push	{r4, r6, r7, lr}
	__asm__ volatile(
70002586:	f3ef 8400 	mrs	r4, CPSR
7000258a:	f004 0480 	and.w	r4, r4, #128	; 0x80
7000258e:	b672      	cpsid	i
		bool killed = (thread->base.thread_state &
70002590:	7b43      	ldrb	r3, [r0, #13]
		if (!killed) {
70002592:	f013 0128 	ands.w	r1, r3, #40	; 0x28
70002596:	d112      	bne.n	700025be <z_sched_wake_thread+0x3a>
			if (thread->base.pended_on != NULL) {
70002598:	6882      	ldr	r2, [r0, #8]
7000259a:	b15a      	cbz	r2, 700025b4 <z_sched_wake_thread+0x30>
	sys_dnode_t *const next = node->next;
7000259c:	e9d0 3200 	ldrd	r3, r2, [r0]
	node->next = NULL;
700025a0:	2600      	movs	r6, #0
	prev->next = next;
700025a2:	6013      	str	r3, [r2, #0]
	node->next = NULL;
700025a4:	2700      	movs	r7, #0
	next->prev = prev;
700025a6:	605a      	str	r2, [r3, #4]
700025a8:	7b43      	ldrb	r3, [r0, #13]
	node->next = NULL;
700025aa:	e9c0 6700 	strd	r6, r7, [r0]
700025ae:	f003 03fd 	and.w	r3, r3, #253	; 0xfd
700025b2:	6081      	str	r1, [r0, #8]
	thread->base.thread_state &= ~_THREAD_SLEEPING;
700025b4:	f023 0304 	bic.w	r3, r3, #4
700025b8:	7343      	strb	r3, [r0, #13]
			ready_thread(thread);
700025ba:	f7ff fe79 	bl	700022b0 <ready_thread>
	if (key != 0U) {
700025be:	b904      	cbnz	r4, 700025c2 <z_sched_wake_thread+0x3e>
700025c0:	b662      	cpsie	i
}
700025c2:	bdd0      	pop	{r4, r6, r7, pc}

700025c4 <z_thread_timeout>:
	z_sched_wake_thread(thread, true);
700025c4:	2101      	movs	r1, #1
700025c6:	3818      	subs	r0, #24
700025c8:	f7ff bfdc 	b.w	70002584 <z_sched_wake_thread>

700025cc <z_pend_curr>:
{
700025cc:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
700025ce:	e9dd 7606 	ldrd	r7, r6, [sp, #24]
700025d2:	460d      	mov	r5, r1
700025d4:	4611      	mov	r1, r2
	__asm__ volatile(
700025d6:	f3ef 8300 	mrs	r3, CPSR
700025da:	f003 0380 	and.w	r3, r3, #128	; 0x80
700025de:	b672      	cpsid	i
700025e0:	f646 7458 	movw	r4, #28504	; 0x6f58
700025e4:	f2c7 0400 	movt	r4, #28672	; 0x7000
700025e8:	68a0      	ldr	r0, [r4, #8]
	add_to_waitq_locked(thread, wait_q);
700025ea:	f7ff fe39 	bl	70002260 <add_to_waitq_locked>
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
700025ee:	f1b6 3fff 	cmp.w	r6, #4294967295	; 0xffffffff
700025f2:	bf08      	it	eq
700025f4:	f1b7 3fff 	cmpeq.w	r7, #4294967295	; 0xffffffff
700025f8:	d008      	beq.n	7000260c <z_pend_curr+0x40>
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
700025fa:	f242 51c5 	movw	r1, #9669	; 0x25c5
700025fe:	463a      	mov	r2, r7
70002600:	4633      	mov	r3, r6
70002602:	3018      	adds	r0, #24
70002604:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002608:	f000 fa1e 	bl	70002a48 <z_add_timeout>
7000260c:	68a3      	ldr	r3, [r4, #8]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
7000260e:	f06f 020a 	mvn.w	r2, #10
70002612:	e9c3 521b 	strd	r5, r2, [r3, #108]	; 0x6c
	z_arm_cortex_r_svc();
70002616:	f7fe ed30 	blx	70001078 <z_arm_cortex_r_svc>
	if (key != 0U) {
7000261a:	b905      	cbnz	r5, 7000261e <z_pend_curr+0x52>
7000261c:	b662      	cpsie	i
	return arch_current_thread()->arch.swap_return_value;
7000261e:	68a3      	ldr	r3, [r4, #8]
}
70002620:	6f18      	ldr	r0, [r3, #112]	; 0x70
70002622:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}

70002624 <z_unpend_thread>:
{
70002624:	b510      	push	{r4, lr}
	z_unpend_thread_no_timeout(thread);
70002626:	f7ff ff8f 	bl	70002548 <z_unpend_thread_no_timeout>
}
7000262a:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	return z_abort_timeout(&thread->base.timeout);
7000262e:	3018      	adds	r0, #24
70002630:	f000 ba9c 	b.w	70002b6c <z_abort_timeout>

70002634 <z_thread_prio_set>:
{
70002634:	b470      	push	{r4, r5, r6}
70002636:	4604      	mov	r4, r0
	__asm__ volatile(
70002638:	f3ef 8500 	mrs	r5, CPSR
7000263c:	f005 0580 	and.w	r5, r5, #128	; 0x80
70002640:	b672      	cpsid	i
	uint8_t state = thread->base.thread_state;
70002642:	7b42      	ldrb	r2, [r0, #13]
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
70002644:	06d3      	lsls	r3, r2, #27
				thread->base.prio = prio;
70002646:	b249      	sxtb	r1, r1
70002648:	d101      	bne.n	7000264e <z_thread_prio_set+0x1a>
	return node->next != NULL;
7000264a:	6983      	ldr	r3, [r0, #24]
7000264c:	b12b      	cbz	r3, 7000265a <z_thread_prio_set+0x26>
			thread->base.prio = prio;
7000264e:	73a1      	strb	r1, [r4, #14]
70002650:	2000      	movs	r0, #0
	if (key != 0U) {
70002652:	b905      	cbnz	r5, 70002656 <z_thread_prio_set+0x22>
70002654:	b662      	cpsie	i
}
70002656:	bc70      	pop	{r4, r5, r6}
70002658:	4770      	bx	lr
	sys_dnode_t *const next = node->next;
7000265a:	e9d0 3000 	ldrd	r3, r0, [r0]
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000265e:	f002 027f 	and.w	r2, r2, #127	; 0x7f
	return list->head == list;
70002662:	f646 7c58 	movw	ip, #28504	; 0x6f58
70002666:	7362      	strb	r2, [r4, #13]
70002668:	f2c7 0c00 	movt	ip, #28672	; 0x7000
	prev->next = next;
7000266c:	6003      	str	r3, [r0, #0]
	node->next = NULL;
7000266e:	2200      	movs	r2, #0
	next->prev = prev;
70002670:	6058      	str	r0, [r3, #4]
	node->next = NULL;
70002672:	2300      	movs	r3, #0
	thread->base.thread_state |= _THREAD_QUEUED;
70002674:	7b60      	ldrb	r0, [r4, #13]
				thread->base.prio = prio;
70002676:	73a1      	strb	r1, [r4, #14]
70002678:	e9c4 2300 	strd	r2, r3, [r4]
	return list->head == list;
7000267c:	4666      	mov	r6, ip
	thread->base.thread_state |= _THREAD_QUEUED;
7000267e:	f060 037f 	orn	r3, r0, #127	; 0x7f
70002682:	7363      	strb	r3, [r4, #13]
70002684:	f856 3f18 	ldr.w	r3, [r6, #24]!
	return (node == list->tail) ? NULL : node->next;
70002688:	f8dc 001c 	ldr.w	r0, [ip, #28]
	return sys_dlist_is_empty(list) ? NULL : list->head;
7000268c:	42b3      	cmp	r3, r6
7000268e:	bf08      	it	eq
70002690:	2300      	moveq	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
70002692:	b153      	cbz	r3, 700026aa <z_thread_prio_set+0x76>
	int32_t b2 = thread_2->base.prio;
70002694:	f993 200e 	ldrsb.w	r2, [r3, #14]
	if (b1 != b2) {
70002698:	4291      	cmp	r1, r2
7000269a:	d001      	beq.n	700026a0 <z_thread_prio_set+0x6c>
		if (z_sched_prio_cmp(thread, t) > 0) {
7000269c:	428a      	cmp	r2, r1
7000269e:	dc15      	bgt.n	700026cc <z_thread_prio_set+0x98>
	return (node == list->tail) ? NULL : node->next;
700026a0:	4283      	cmp	r3, r0
700026a2:	d002      	beq.n	700026aa <z_thread_prio_set+0x76>
700026a4:	681b      	ldr	r3, [r3, #0]
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
700026a6:	2b00      	cmp	r3, #0
700026a8:	d1f4      	bne.n	70002694 <z_thread_prio_set+0x60>
	node->prev = tail;
700026aa:	e9c4 6000 	strd	r6, r0, [r4]
	tail->next = node;
700026ae:	6004      	str	r4, [r0, #0]
	list->tail = node;
700026b0:	f8cc 401c 	str.w	r4, [ip, #28]
	return list->head == list;
700026b4:	f8dc 3018 	ldr.w	r3, [ip, #24]
700026b8:	2001      	movs	r0, #1
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700026ba:	2b00      	cmp	r3, #0
700026bc:	bf18      	it	ne
700026be:	42b3      	cmpne	r3, r6
700026c0:	bf08      	it	eq
700026c2:	f8dc 300c 	ldreq.w	r3, [ip, #12]
		_kernel.ready_q.cache = thread;
700026c6:	f8cc 3014 	str.w	r3, [ip, #20]
700026ca:	e7c2      	b.n	70002652 <z_thread_prio_set+0x1e>
	sys_dnode_t *const prev = successor->prev;
700026cc:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
700026ce:	e9c4 3200 	strd	r3, r2, [r4]
	prev->next = node;
700026d2:	6014      	str	r4, [r2, #0]
	successor->prev = node;
700026d4:	605c      	str	r4, [r3, #4]
}
700026d6:	e7ed      	b.n	700026b4 <z_thread_prio_set+0x80>

700026d8 <z_reschedule>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
700026d8:	b9c1      	cbnz	r1, 7000270c <z_reschedule+0x34>
{
700026da:	b508      	push	{r3, lr}
700026dc:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
700026e0:	f023 0303 	bic.w	r3, r3, #3
	return arch_irq_unlocked(key) && !arch_is_in_isr();
700026e4:	681a      	ldr	r2, [r3, #0]
700026e6:	b97a      	cbnz	r2, 70002708 <z_reschedule+0x30>
700026e8:	f646 7358 	movw	r3, #28504	; 0x6f58
700026ec:	f2c7 0300 	movt	r3, #28672	; 0x7000
700026f0:	6899      	ldr	r1, [r3, #8]
	if (resched(key.key) && need_swap()) {
700026f2:	695b      	ldr	r3, [r3, #20]
700026f4:	428b      	cmp	r3, r1
700026f6:	d007      	beq.n	70002708 <z_reschedule+0x30>
	arch_current_thread()->arch.basepri = key;
700026f8:	66ca      	str	r2, [r1, #108]	; 0x6c
700026fa:	f06f 030a 	mvn.w	r3, #10
700026fe:	670b      	str	r3, [r1, #112]	; 0x70
	z_arm_cortex_r_svc();
70002700:	f7fe ecba 	blx	70001078 <z_arm_cortex_r_svc>
70002704:	b662      	cpsie	i
}
70002706:	bd08      	pop	{r3, pc}
70002708:	b662      	cpsie	i
7000270a:	bd08      	pop	{r3, pc}
7000270c:	4770      	bx	lr
7000270e:	bf00      	nop

70002710 <z_impl_k_thread_resume>:
{
70002710:	b510      	push	{r4, lr}
	__asm__ volatile(
70002712:	f3ef 8400 	mrs	r4, CPSR
70002716:	f004 0480 	and.w	r4, r4, #128	; 0x80
7000271a:	b672      	cpsid	i
	return (thread->base.thread_state & _THREAD_SUSPENDED) != 0U;
7000271c:	7b42      	ldrb	r2, [r0, #13]
	if (!z_is_thread_suspended(thread)) {
7000271e:	06d3      	lsls	r3, r2, #27
70002720:	d402      	bmi.n	70002728 <z_impl_k_thread_resume+0x18>
	if (key != 0U) {
70002722:	b904      	cbnz	r4, 70002726 <z_impl_k_thread_resume+0x16>
70002724:	b662      	cpsie	i
}
70002726:	bd10      	pop	{r4, pc}
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
70002728:	f022 0210 	bic.w	r2, r2, #16
7000272c:	7342      	strb	r2, [r0, #13]
	ready_thread(thread);
7000272e:	f7ff fdbf 	bl	700022b0 <ready_thread>
	z_reschedule(&_sched_spinlock, key);
70002732:	f646 7078 	movw	r0, #28536	; 0x6f78
70002736:	4621      	mov	r1, r4
70002738:	f2c7 0000 	movt	r0, #28672	; 0x7000
}
7000273c:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&_sched_spinlock, key);
70002740:	f7ff bfca 	b.w	700026d8 <z_reschedule>

70002744 <k_sched_lock>:
	__asm__ volatile(
70002744:	f3ef 8100 	mrs	r1, CPSR
70002748:	f001 0180 	and.w	r1, r1, #128	; 0x80
7000274c:	b672      	cpsid	i
7000274e:	f646 7358 	movw	r3, #28504	; 0x6f58
70002752:	f2c7 0300 	movt	r3, #28672	; 0x7000
70002756:	689a      	ldr	r2, [r3, #8]
	--arch_current_thread()->base.sched_locked;
70002758:	7bd3      	ldrb	r3, [r2, #15]
7000275a:	3b01      	subs	r3, #1
7000275c:	73d3      	strb	r3, [r2, #15]
	if (key != 0U) {
7000275e:	b901      	cbnz	r1, 70002762 <k_sched_lock+0x1e>
70002760:	b662      	cpsie	i
}
70002762:	4770      	bx	lr

70002764 <k_sched_unlock>:
{
70002764:	b510      	push	{r4, lr}
	__asm__ volatile(
70002766:	f3ef 8400 	mrs	r4, CPSR
7000276a:	f004 0480 	and.w	r4, r4, #128	; 0x80
7000276e:	b672      	cpsid	i
70002770:	f646 7058 	movw	r0, #28504	; 0x6f58
70002774:	f2c7 0000 	movt	r0, #28672	; 0x7000
	return list->head == list;
70002778:	4601      	mov	r1, r0
7000277a:	6882      	ldr	r2, [r0, #8]
		++arch_current_thread()->base.sched_locked;
7000277c:	7bd3      	ldrb	r3, [r2, #15]
7000277e:	3301      	adds	r3, #1
70002780:	73d3      	strb	r3, [r2, #15]
70002782:	f851 3f18 	ldr.w	r3, [r1, #24]!
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002786:	428b      	cmp	r3, r1
70002788:	bf18      	it	ne
7000278a:	2b00      	cmpne	r3, #0
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
7000278c:	7b51      	ldrb	r1, [r2, #13]
7000278e:	bf08      	it	eq
70002790:	68c3      	ldreq	r3, [r0, #12]
70002792:	06c9      	lsls	r1, r1, #27
70002794:	d103      	bne.n	7000279e <k_sched_unlock+0x3a>
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
70002796:	89d1      	ldrh	r1, [r2, #14]
70002798:	297f      	cmp	r1, #127	; 0x7f
7000279a:	bf88      	it	hi
7000279c:	4613      	movhi	r3, r2
7000279e:	6143      	str	r3, [r0, #20]
	if (key != 0U) {
700027a0:	b904      	cbnz	r4, 700027a4 <k_sched_unlock+0x40>
700027a2:	b662      	cpsie	i
	__asm__ volatile(
700027a4:	f3ef 8300 	mrs	r3, CPSR
700027a8:	f003 0380 	and.w	r3, r3, #128	; 0x80
700027ac:	b672      	cpsid	i
	return arch_irq_unlocked(key) && !arch_is_in_isr();
700027ae:	b983      	cbnz	r3, 700027d2 <k_sched_unlock+0x6e>
700027b0:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
700027b4:	f023 0303 	bic.w	r3, r3, #3
700027b8:	681b      	ldr	r3, [r3, #0]
700027ba:	b95b      	cbnz	r3, 700027d4 <k_sched_unlock+0x70>
700027bc:	6882      	ldr	r2, [r0, #8]
	if (resched(key) && need_swap()) {
700027be:	6941      	ldr	r1, [r0, #20]
700027c0:	4291      	cmp	r1, r2
700027c2:	d007      	beq.n	700027d4 <k_sched_unlock+0x70>
	arch_current_thread()->arch.basepri = key;
700027c4:	66d3      	str	r3, [r2, #108]	; 0x6c
700027c6:	f06f 010a 	mvn.w	r1, #10
700027ca:	6711      	str	r1, [r2, #112]	; 0x70
	z_arm_cortex_r_svc();
700027cc:	f7fe ec54 	blx	70001078 <z_arm_cortex_r_svc>
700027d0:	b662      	cpsie	i
}
700027d2:	bd10      	pop	{r4, pc}
700027d4:	b662      	cpsie	i
700027d6:	bd10      	pop	{r4, pc}

700027d8 <z_sched_init>:
{
700027d8:	4a02      	ldr	r2, [pc, #8]	; (700027e4 <z_sched_init+0xc>)
	list->head = (sys_dnode_t *)list;
700027da:	4613      	mov	r3, r2
700027dc:	f843 2918 	str.w	r2, [r3], #-24
700027e0:	61da      	str	r2, [r3, #28]
}
700027e2:	4770      	bx	lr
700027e4:	70006f70 	.word	0x70006f70

700027e8 <z_impl_k_yield>:
{
700027e8:	b570      	push	{r4, r5, r6, lr}
700027ea:	f3ef 8600 	mrs	r6, CPSR
700027ee:	f006 0680 	and.w	r6, r6, #128	; 0x80
700027f2:	b672      	cpsid	i
700027f4:	f646 7c58 	movw	ip, #28504	; 0x6f58
700027f8:	f2c7 0c00 	movt	ip, #28672	; 0x7000
	return list->head == list;
700027fc:	4665      	mov	r5, ip
700027fe:	f8dc 3008 	ldr.w	r3, [ip, #8]
	thread->base.thread_state &= ~_THREAD_QUEUED;
70002802:	7b5a      	ldrb	r2, [r3, #13]
70002804:	f002 027f 	and.w	r2, r2, #127	; 0x7f
70002808:	735a      	strb	r2, [r3, #13]
	node->next = NULL;
7000280a:	2200      	movs	r2, #0
	sys_dnode_t *const prev = node->prev;
7000280c:	6858      	ldr	r0, [r3, #4]
	sys_dnode_t *const next = node->next;
7000280e:	6819      	ldr	r1, [r3, #0]
	prev->next = next;
70002810:	6001      	str	r1, [r0, #0]
	next->prev = prev;
70002812:	6048      	str	r0, [r1, #4]
	node->next = NULL;
70002814:	601a      	str	r2, [r3, #0]
70002816:	605a      	str	r2, [r3, #4]
70002818:	f8dc 0008 	ldr.w	r0, [ip, #8]
	thread->base.thread_state |= _THREAD_QUEUED;
7000281c:	7b43      	ldrb	r3, [r0, #13]
7000281e:	f063 037f 	orn	r3, r3, #127	; 0x7f
70002822:	7343      	strb	r3, [r0, #13]
	return list->head == list;
70002824:	f855 3f18 	ldr.w	r3, [r5, #24]!
	return (node == list->tail) ? NULL : node->next;
70002828:	f8dc 401c 	ldr.w	r4, [ip, #28]
	return sys_dlist_is_empty(list) ? NULL : list->head;
7000282c:	42ab      	cmp	r3, r5
7000282e:	bf08      	it	eq
70002830:	4613      	moveq	r3, r2
70002832:	b163      	cbz	r3, 7000284e <z_impl_k_yield+0x66>
	int32_t b2 = thread_2->base.prio;
70002834:	f993 100e 	ldrsb.w	r1, [r3, #14]
	int32_t b1 = thread_1->base.prio;
70002838:	f990 200e 	ldrsb.w	r2, [r0, #14]
	if (b1 != b2) {
7000283c:	428a      	cmp	r2, r1
7000283e:	d001      	beq.n	70002844 <z_impl_k_yield+0x5c>
		if (z_sched_prio_cmp(thread, t) > 0) {
70002840:	4291      	cmp	r1, r2
70002842:	dc1e      	bgt.n	70002882 <z_impl_k_yield+0x9a>
	return (node == list->tail) ? NULL : node->next;
70002844:	42a3      	cmp	r3, r4
70002846:	d002      	beq.n	7000284e <z_impl_k_yield+0x66>
70002848:	681b      	ldr	r3, [r3, #0]
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
7000284a:	2b00      	cmp	r3, #0
7000284c:	d1f2      	bne.n	70002834 <z_impl_k_yield+0x4c>
	node->prev = tail;
7000284e:	e9c0 5400 	strd	r5, r4, [r0]
	tail->next = node;
70002852:	6020      	str	r0, [r4, #0]
	list->tail = node;
70002854:	f8cc 001c 	str.w	r0, [ip, #28]
	return list->head == list;
70002858:	f8dc 3018 	ldr.w	r3, [ip, #24]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
7000285c:	f06f 010a 	mvn.w	r1, #10
70002860:	f8dc 2008 	ldr.w	r2, [ip, #8]
	arch_current_thread()->arch.basepri = key;
70002864:	66d6      	str	r6, [r2, #108]	; 0x6c
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002866:	42ab      	cmp	r3, r5
70002868:	bf18      	it	ne
7000286a:	2b00      	cmpne	r3, #0
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
7000286c:	6711      	str	r1, [r2, #112]	; 0x70
7000286e:	bf08      	it	eq
70002870:	f8dc 300c 	ldreq.w	r3, [ip, #12]
		_kernel.ready_q.cache = thread;
70002874:	f8cc 3014 	str.w	r3, [ip, #20]
	z_arm_cortex_r_svc();
70002878:	f7fe ebfe 	blx	70001078 <z_arm_cortex_r_svc>
	if (key != 0U) {
7000287c:	b906      	cbnz	r6, 70002880 <z_impl_k_yield+0x98>
7000287e:	b662      	cpsie	i
}
70002880:	bd70      	pop	{r4, r5, r6, pc}
	sys_dnode_t *const prev = successor->prev;
70002882:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
70002884:	e9c0 3200 	strd	r3, r2, [r0]
	prev->next = node;
70002888:	6010      	str	r0, [r2, #0]
	successor->prev = node;
7000288a:	6058      	str	r0, [r3, #4]
}
7000288c:	e7e4      	b.n	70002858 <z_impl_k_yield+0x70>
7000288e:	bf00      	nop

70002890 <z_tick_sleep>:
	if (ticks == 0) {
70002890:	ea50 0301 	orrs.w	r3, r0, r1
{
70002894:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	if (ticks == 0) {
70002898:	d039      	beq.n	7000290e <z_tick_sleep+0x7e>
7000289a:	4604      	mov	r4, r0
	if (Z_TICK_ABS(ticks) <= 0) {
7000289c:	1c83      	adds	r3, r0, #2
7000289e:	460d      	mov	r5, r1
700028a0:	f171 33ff 	sbcs.w	r3, r1, #4294967295	; 0xffffffff
		expected_wakeup_ticks = Z_TICK_ABS(ticks);
700028a4:	bfbc      	itt	lt
700028a6:	f06f 0001 	mvnlt.w	r0, #1
700028aa:	1b06      	sublt	r6, r0, r4
	if (Z_TICK_ABS(ticks) <= 0) {
700028ac:	da2b      	bge.n	70002906 <z_tick_sleep+0x76>
	__asm__ volatile(
700028ae:	f3ef 8800 	mrs	r8, CPSR
700028b2:	f008 0880 	and.w	r8, r8, #128	; 0x80
700028b6:	b672      	cpsid	i
700028b8:	f646 7758 	movw	r7, #28504	; 0x6f58
700028bc:	f2c7 0700 	movt	r7, #28672	; 0x7000
	unready_thread(arch_current_thread());
700028c0:	68b8      	ldr	r0, [r7, #8]
700028c2:	f7ff fca5 	bl	70002210 <unready_thread>
700028c6:	68b8      	ldr	r0, [r7, #8]
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
700028c8:	f242 51c5 	movw	r1, #9669	; 0x25c5
700028cc:	4622      	mov	r2, r4
700028ce:	462b      	mov	r3, r5
700028d0:	f2c7 0100 	movt	r1, #28672	; 0x7000
700028d4:	3018      	adds	r0, #24
700028d6:	f000 f8b7 	bl	70002a48 <z_add_timeout>
700028da:	68bb      	ldr	r3, [r7, #8]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700028dc:	f06f 010a 	mvn.w	r1, #10
	thread->base.thread_state |= _THREAD_SLEEPING;
700028e0:	7b5a      	ldrb	r2, [r3, #13]
700028e2:	f042 0204 	orr.w	r2, r2, #4
700028e6:	e9c3 811b 	strd	r8, r1, [r3, #108]	; 0x6c
700028ea:	735a      	strb	r2, [r3, #13]
	z_arm_cortex_r_svc();
700028ec:	f7fe ebc4 	blx	70001078 <z_arm_cortex_r_svc>
	if (key != 0U) {
700028f0:	f1b8 0f00 	cmp.w	r8, #0
700028f4:	d100      	bne.n	700028f8 <z_tick_sleep+0x68>
700028f6:	b662      	cpsie	i
	uint32_t left_ticks = expected_wakeup_ticks - sys_clock_tick_get_32();
700028f8:	f000 fa02 	bl	70002d00 <sys_clock_tick_get_32>
700028fc:	1a30      	subs	r0, r6, r0
	if (ticks > 0) {
700028fe:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
}
70002902:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		expected_wakeup_ticks = ticks + sys_clock_tick_get_32();
70002906:	f000 f9fb 	bl	70002d00 <sys_clock_tick_get_32>
7000290a:	1906      	adds	r6, r0, r4
7000290c:	e7cf      	b.n	700028ae <z_tick_sleep+0x1e>
	z_impl_k_yield();
7000290e:	f7ff ff6b 	bl	700027e8 <z_impl_k_yield>
		return 0;
70002912:	2000      	movs	r0, #0
}
70002914:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

70002918 <z_impl_k_sleep>:
{
70002918:	b538      	push	{r3, r4, r5, lr}
7000291a:	4605      	mov	r5, r0
7000291c:	460c      	mov	r4, r1
	ticks = z_tick_sleep(ticks);
7000291e:	f7ff ffb7 	bl	70002890 <z_tick_sleep>
	int32_t ret = K_TIMEOUT_EQ(timeout, K_FOREVER) ? K_TICKS_FOREVER :
70002922:	f1b4 3fff 	cmp.w	r4, #4294967295	; 0xffffffff
70002926:	bf08      	it	eq
70002928:	f1b5 3fff 	cmpeq.w	r5, #4294967295	; 0xffffffff
7000292c:	bf08      	it	eq
7000292e:	f04f 30ff 	moveq.w	r0, #4294967295	; 0xffffffff
}
70002932:	bd38      	pop	{r3, r4, r5, pc}

70002934 <z_impl_k_wakeup>:
{
70002934:	b538      	push	{r3, r4, r5, lr}
70002936:	4604      	mov	r4, r0
	return z_abort_timeout(&thread->base.timeout);
70002938:	3018      	adds	r0, #24
7000293a:	f000 f917 	bl	70002b6c <z_abort_timeout>
	__asm__ volatile(
7000293e:	f3ef 8500 	mrs	r5, CPSR
70002942:	f005 0580 	and.w	r5, r5, #128	; 0x80
70002946:	b672      	cpsid	i
	return (thread->base.thread_state & _THREAD_SLEEPING) != 0U;
70002948:	7b63      	ldrb	r3, [r4, #13]
	if (!z_is_thread_sleeping(thread)) {
7000294a:	075a      	lsls	r2, r3, #29
7000294c:	d402      	bmi.n	70002954 <z_impl_k_wakeup+0x20>
	if (key != 0U) {
7000294e:	b905      	cbnz	r5, 70002952 <z_impl_k_wakeup+0x1e>
70002950:	b662      	cpsie	i
}
70002952:	bd38      	pop	{r3, r4, r5, pc}
	ready_thread(thread);
70002954:	4620      	mov	r0, r4
	thread->base.thread_state &= ~_THREAD_SLEEPING;
70002956:	f023 0304 	bic.w	r3, r3, #4
7000295a:	7363      	strb	r3, [r4, #13]
7000295c:	f7ff fca8 	bl	700022b0 <ready_thread>
70002960:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70002964:	f023 0303 	bic.w	r3, r3, #3
	if (arch_is_in_isr()) {
70002968:	681b      	ldr	r3, [r3, #0]
7000296a:	2b00      	cmp	r3, #0
7000296c:	d1ef      	bne.n	7000294e <z_impl_k_wakeup+0x1a>
		z_reschedule(&_sched_spinlock, key);
7000296e:	f646 7078 	movw	r0, #28536	; 0x6f78
70002972:	4629      	mov	r1, r5
70002974:	f2c7 0000 	movt	r0, #28672	; 0x7000
}
70002978:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		z_reschedule(&_sched_spinlock, key);
7000297c:	f7ff beac 	b.w	700026d8 <z_reschedule>

70002980 <z_impl_k_sched_current_thread_query>:
70002980:	f646 7358 	movw	r3, #28504	; 0x6f58
70002984:	f2c7 0300 	movt	r3, #28672	; 0x7000
}
70002988:	6898      	ldr	r0, [r3, #8]
7000298a:	4770      	bx	lr

7000298c <z_impl_k_thread_abort>:
	__asm__ volatile(
7000298c:	f3ef 8100 	mrs	r1, CPSR
70002990:	f001 0180 	and.w	r1, r1, #128	; 0x80
70002994:	b672      	cpsid	i
	return (thread->base.user_options & K_ESSENTIAL) == K_ESSENTIAL;
70002996:	7b02      	ldrb	r2, [r0, #12]

void z_thread_abort(struct k_thread *thread)
{
	k_spinlock_key_t key = k_spin_lock(&_sched_spinlock);

	if (z_is_thread_essential(thread)) {
70002998:	07d2      	lsls	r2, r2, #31
7000299a:	d409      	bmi.n	700029b0 <z_impl_k_thread_abort+0x24>
		__ASSERT(false, "aborting essential thread %p", thread);
		k_panic();
		return;
	}

	if ((thread->base.thread_state & _THREAD_DEAD) != 0U) {
7000299c:	7b43      	ldrb	r3, [r0, #13]
7000299e:	071b      	lsls	r3, r3, #28
700029a0:	d502      	bpl.n	700029a8 <z_impl_k_thread_abort+0x1c>
	if (key != 0U) {
700029a2:	b921      	cbnz	r1, 700029ae <z_impl_k_thread_abort+0x22>
700029a4:	b662      	cpsie	i
}
700029a6:	4770      	bx	lr
		k_spin_unlock(&_sched_spinlock, key);
		return;
	}

	z_thread_halt(thread, key, true);
700029a8:	2201      	movs	r2, #1
700029aa:	f7ff bcc9 	b.w	70002340 <z_thread_halt>
	z_thread_abort(thread);

	__ASSERT_NO_MSG((thread->base.thread_state & _THREAD_DEAD) != 0);

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_thread, abort, thread);
}
700029ae:	4770      	bx	lr
700029b0:	b901      	cbnz	r1, 700029b4 <z_impl_k_thread_abort+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
700029b2:	b662      	cpsie	i
		k_panic();
700029b4:	2004      	movs	r0, #4
700029b6:	b500      	push	{lr}
700029b8:	b662      	cpsie	i
700029ba:	df02      	svc	2
700029bc:	f85d eb04 	ldr.w	lr, [sp], #4
		return;
700029c0:	4770      	bx	lr
700029c2:	bf00      	nop

700029c4 <z_sched_wake>:

/*
 * future scheduler.h API implementations
 */
bool z_sched_wake(_wait_q_t *wait_q, int swap_retval, void *swap_data)
{
700029c4:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	__asm__ volatile(
700029c8:	f3ef 8800 	mrs	r8, CPSR
700029cc:	f008 0880 	and.w	r8, r8, #128	; 0x80
700029d0:	b672      	cpsid	i
	return list->head == list;
700029d2:	6804      	ldr	r4, [r0, #0]
	bool ret = false;

	K_SPINLOCK(&_sched_spinlock) {
		thread = _priq_wait_best(&wait_q->waitq);

		if (thread != NULL) {
700029d4:	42a0      	cmp	r0, r4
700029d6:	bf18      	it	ne
700029d8:	2c00      	cmpne	r4, #0
700029da:	bf14      	ite	ne
700029dc:	2501      	movne	r5, #1
700029de:	2500      	moveq	r5, #0
700029e0:	d106      	bne.n	700029f0 <z_sched_wake+0x2c>
	if (key != 0U) {
700029e2:	f1b8 0f00 	cmp.w	r8, #0
700029e6:	d100      	bne.n	700029ea <z_sched_wake+0x26>
700029e8:	b662      	cpsie	i
			ret = true;
		}
	}

	return ret;
}
700029ea:	4628      	mov	r0, r5
700029ec:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	sys_dnode_t *const next = node->next;
700029f0:	e9d4 3000 	ldrd	r3, r0, [r4]
	node->next = NULL;
700029f4:	2600      	movs	r6, #0
z_thread_return_value_set_with_data(struct k_thread *thread,
				   unsigned int value,
				   void *data)
{
	arch_thread_return_value_set(thread, value);
	thread->base.swap_data = data;
700029f6:	6162      	str	r2, [r4, #20]
700029f8:	2700      	movs	r7, #0
	thread->arch.swap_return_value = value;
700029fa:	6721      	str	r1, [r4, #112]	; 0x70
	thread->base.pended_on = NULL;
700029fc:	2200      	movs	r2, #0
	prev->next = next;
700029fe:	6003      	str	r3, [r0, #0]
	next->prev = prev;
70002a00:	6058      	str	r0, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
70002a02:	7b63      	ldrb	r3, [r4, #13]
70002a04:	f023 0302 	bic.w	r3, r3, #2
	node->next = NULL;
70002a08:	e9c4 6700 	strd	r6, r7, [r4]
70002a0c:	f104 0018 	add.w	r0, r4, #24
70002a10:	7363      	strb	r3, [r4, #13]
70002a12:	60a2      	str	r2, [r4, #8]
70002a14:	f000 f8aa 	bl	70002b6c <z_abort_timeout>
			ready_thread(thread);
70002a18:	4620      	mov	r0, r4
70002a1a:	f7ff fc49 	bl	700022b0 <ready_thread>
			ret = true;
70002a1e:	e7e0      	b.n	700029e2 <z_sched_wake+0x1e>

70002a20 <z_sched_wait>:

int z_sched_wait(struct k_spinlock *lock, k_spinlock_key_t key,
		 _wait_q_t *wait_q, k_timeout_t timeout, void **data)
{
70002a20:	b510      	push	{r4, lr}
70002a22:	b082      	sub	sp, #8
	int ret = z_pend_curr(lock, key, wait_q, timeout);
70002a24:	e9dd 3404 	ldrd	r3, r4, [sp, #16]
70002a28:	e9cd 3400 	strd	r3, r4, [sp]
{
70002a2c:	9c06      	ldr	r4, [sp, #24]
	int ret = z_pend_curr(lock, key, wait_q, timeout);
70002a2e:	f7ff fdcd 	bl	700025cc <z_pend_curr>

	if (data != NULL) {
70002a32:	b134      	cbz	r4, 70002a42 <z_sched_wait+0x22>
70002a34:	f646 7358 	movw	r3, #28504	; 0x6f58
70002a38:	f2c7 0300 	movt	r3, #28672	; 0x7000
		*data = arch_current_thread()->base.swap_data;
70002a3c:	689b      	ldr	r3, [r3, #8]
70002a3e:	695b      	ldr	r3, [r3, #20]
70002a40:	6023      	str	r3, [r4, #0]
	}
	return ret;
}
70002a42:	b002      	add	sp, #8
70002a44:	bd10      	pop	{r4, pc}
70002a46:	bf00      	nop

70002a48 <z_add_timeout>:
}

void z_add_timeout(struct _timeout *to, _timeout_func_t fn,
		   k_timeout_t timeout)
{
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
70002a48:	f1b3 3fff 	cmp.w	r3, #4294967295	; 0xffffffff
70002a4c:	bf08      	it	eq
70002a4e:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
70002a52:	f000 808a 	beq.w	70002b6a <z_add_timeout+0x122>
{
70002a56:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
70002a58:	4606      	mov	r6, r0
70002a5a:	461d      	mov	r5, r3
70002a5c:	4614      	mov	r4, r2
70002a5e:	4618      	mov	r0, r3
#ifdef CONFIG_KERNEL_COHERENCE
	__ASSERT_NO_MSG(arch_mem_coherent(to));
#endif /* CONFIG_KERNEL_COHERENCE */

	__ASSERT(!sys_dnode_is_linked(&to->node), "");
	to->fn = fn;
70002a60:	60b1      	str	r1, [r6, #8]
	__asm__ volatile(
70002a62:	f3ef 8700 	mrs	r7, CPSR
70002a66:	f007 0780 	and.w	r7, r7, #128	; 0x80
70002a6a:	b672      	cpsid	i

	K_SPINLOCK(&timeout_lock) {
		struct _timeout *t;

		if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) &&
70002a6c:	3201      	adds	r2, #1
70002a6e:	f175 33ff 	sbcs.w	r3, r5, #4294967295	; 0xffffffff
70002a72:	da5f      	bge.n	70002b34 <z_add_timeout+0xec>
		    (Z_TICK_ABS(timeout.ticks) >= 0)) {
			k_ticks_t ticks = Z_TICK_ABS(timeout.ticks) - curr_tick;
70002a74:	f245 62f0 	movw	r2, #22256	; 0x56f0
70002a78:	f06f 0301 	mvn.w	r3, #1
70002a7c:	f2c7 0200 	movt	r2, #28672	; 0x7000
70002a80:	e9d2 1500 	ldrd	r1, r5, [r2]
70002a84:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
70002a88:	1a5b      	subs	r3, r3, r1
70002a8a:	eb62 0505 	sbc.w	r5, r2, r5
70002a8e:	1b1c      	subs	r4, r3, r4
70002a90:	eb65 0500 	sbc.w	r5, r5, r0

			to->dticks = MAX(1, ticks);
70002a94:	2c01      	cmp	r4, #1
70002a96:	f175 0300 	sbcs.w	r3, r5, #0
70002a9a:	bfbc      	itt	lt
70002a9c:	2401      	movlt	r4, #1
70002a9e:	2500      	movlt	r5, #0
70002aa0:	6134      	str	r4, [r6, #16]
	return list->head == list;
70002aa2:	f24b 4050 	movw	r0, #46160	; 0xb450
70002aa6:	6175      	str	r5, [r6, #20]
70002aa8:	f2c7 0000 	movt	r0, #28672	; 0x7000
	return (node == list->tail) ? NULL : node->next;
70002aac:	e9d0 2c00 	ldrd	r2, ip, [r0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002ab0:	4282      	cmp	r2, r0
70002ab2:	d011      	beq.n	70002ad8 <z_add_timeout+0x90>
		} else {
			to->dticks = timeout.ticks + 1 + elapsed();
		}

		for (t = first(); t != NULL; t = next(t)) {
70002ab4:	b182      	cbz	r2, 70002ad8 <z_add_timeout+0x90>
			if (t->dticks > to->dticks) {
70002ab6:	e9d2 3104 	ldrd	r3, r1, [r2, #16]
70002aba:	429c      	cmp	r4, r3
70002abc:	eb75 0e01 	sbcs.w	lr, r5, r1
70002ac0:	db48      	blt.n	70002b54 <z_add_timeout+0x10c>
				t->dticks -= to->dticks;
				sys_dlist_insert(&t->node, &to->node);
				break;
			}
			to->dticks -= t->dticks;
70002ac2:	1ae3      	subs	r3, r4, r3
70002ac4:	461c      	mov	r4, r3
70002ac6:	eb65 0501 	sbc.w	r5, r5, r1
	return (node == list->tail) ? NULL : node->next;
70002aca:	4562      	cmp	r2, ip
70002acc:	e9c6 3504 	strd	r3, r5, [r6, #16]
70002ad0:	d002      	beq.n	70002ad8 <z_add_timeout+0x90>
70002ad2:	6812      	ldr	r2, [r2, #0]
		for (t = first(); t != NULL; t = next(t)) {
70002ad4:	2a00      	cmp	r2, #0
70002ad6:	d1ee      	bne.n	70002ab6 <z_add_timeout+0x6e>
	node->prev = tail;
70002ad8:	e9c6 0c00 	strd	r0, ip, [r6]
	tail->next = node;
70002adc:	f8cc 6000 	str.w	r6, [ip]
	list->tail = node;
70002ae0:	6046      	str	r6, [r0, #4]
	return list->head == list;
70002ae2:	6804      	ldr	r4, [r0, #0]

		if (t == NULL) {
			sys_dlist_append(&timeout_list, &to->node);
		}

		if (to == first() && announce_remaining == 0) {
70002ae4:	1a20      	subs	r0, r4, r0
70002ae6:	bf18      	it	ne
70002ae8:	2001      	movne	r0, #1
70002aea:	42a6      	cmp	r6, r4
70002aec:	bf18      	it	ne
70002aee:	2000      	movne	r0, #0
70002af0:	b910      	cbnz	r0, 70002af8 <z_add_timeout+0xb0>
	if (key != 0U) {
70002af2:	b907      	cbnz	r7, 70002af6 <z_add_timeout+0xae>
70002af4:	b662      	cpsie	i
			sys_clock_set_timeout(next_timeout(), false);
		}
	}
}
70002af6:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		if (to == first() && announce_remaining == 0) {
70002af8:	f646 7378 	movw	r3, #28536	; 0x6f78
70002afc:	f2c7 0300 	movt	r3, #28672	; 0x7000
70002b00:	681b      	ldr	r3, [r3, #0]
70002b02:	2b00      	cmp	r3, #0
70002b04:	d1f5      	bne.n	70002af2 <z_add_timeout+0xaa>
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002b06:	f7fe ffcd 	bl	70001aa4 <sys_clock_elapsed>
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
70002b0a:	6923      	ldr	r3, [r4, #16]
70002b0c:	6962      	ldr	r2, [r4, #20]
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002b0e:	4601      	mov	r1, r0
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
70002b10:	1a18      	subs	r0, r3, r0
70002b12:	eb62 73e1 	sbc.w	r3, r2, r1, asr #31
			sys_clock_set_timeout(next_timeout(), false);
70002b16:	2100      	movs	r1, #0
		ret = MAX(0, to->dticks - ticks_elapsed);
70002b18:	2b00      	cmp	r3, #0
70002b1a:	bfbc      	itt	lt
70002b1c:	2000      	movlt	r0, #0
70002b1e:	2300      	movlt	r3, #0
			sys_clock_set_timeout(next_timeout(), false);
70002b20:	f1b0 4f00 	cmp.w	r0, #2147483648	; 0x80000000
70002b24:	f173 0300 	sbcs.w	r3, r3, #0
70002b28:	bfa8      	it	ge
70002b2a:	f06f 4000 	mvnge.w	r0, #2147483648	; 0x80000000
70002b2e:	f7fe ff89 	bl	70001a44 <sys_clock_set_timeout>
70002b32:	e7de      	b.n	70002af2 <z_add_timeout+0xaa>
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002b34:	f646 7278 	movw	r2, #28536	; 0x6f78
			to->dticks = timeout.ticks + 1 + elapsed();
70002b38:	3401      	adds	r4, #1
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002b3a:	f2c7 0200 	movt	r2, #28672	; 0x7000
			to->dticks = timeout.ticks + 1 + elapsed();
70002b3e:	f145 0500 	adc.w	r5, r5, #0
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002b42:	6813      	ldr	r3, [r2, #0]
70002b44:	2b00      	cmp	r3, #0
70002b46:	d1ab      	bne.n	70002aa0 <z_add_timeout+0x58>
70002b48:	f7fe ffac 	bl	70001aa4 <sys_clock_elapsed>
			to->dticks = timeout.ticks + 1 + elapsed();
70002b4c:	1904      	adds	r4, r0, r4
70002b4e:	eb45 75e0 	adc.w	r5, r5, r0, asr #31
70002b52:	e7a5      	b.n	70002aa0 <z_add_timeout+0x58>
				t->dticks -= to->dticks;
70002b54:	1b1b      	subs	r3, r3, r4
	sys_dnode_t *const prev = successor->prev;
70002b56:	6854      	ldr	r4, [r2, #4]
70002b58:	eb61 0105 	sbc.w	r1, r1, r5
70002b5c:	e9c2 3104 	strd	r3, r1, [r2, #16]
	node->next = successor;
70002b60:	e9c6 2400 	strd	r2, r4, [r6]
	prev->next = node;
70002b64:	6026      	str	r6, [r4, #0]
	successor->prev = node;
70002b66:	6056      	str	r6, [r2, #4]
		if (t == NULL) {
70002b68:	e7bb      	b.n	70002ae2 <z_add_timeout+0x9a>
70002b6a:	4770      	bx	lr

70002b6c <z_abort_timeout>:

int z_abort_timeout(struct _timeout *to)
{
70002b6c:	b430      	push	{r4, r5}
	__asm__ volatile(
70002b6e:	f3ef 8500 	mrs	r5, CPSR
70002b72:	f005 0580 	and.w	r5, r5, #128	; 0x80
70002b76:	b672      	cpsid	i
	return node->next != NULL;
70002b78:	6802      	ldr	r2, [r0, #0]
	int ret = -EINVAL;

	K_SPINLOCK(&timeout_lock) {
		if (sys_dnode_is_linked(&to->node)) {
70002b7a:	b1e2      	cbz	r2, 70002bb6 <z_abort_timeout+0x4a>
	return (node == list->tail) ? NULL : node->next;
70002b7c:	f24b 4150 	movw	r1, #46160	; 0xb450
70002b80:	4603      	mov	r3, r0
70002b82:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002b86:	6849      	ldr	r1, [r1, #4]
70002b88:	4288      	cmp	r0, r1
70002b8a:	d009      	beq.n	70002ba0 <z_abort_timeout+0x34>
		next(t)->dticks += t->dticks;
70002b8c:	6904      	ldr	r4, [r0, #16]
70002b8e:	6911      	ldr	r1, [r2, #16]
70002b90:	6950      	ldr	r0, [r2, #20]
70002b92:	1909      	adds	r1, r1, r4
70002b94:	695c      	ldr	r4, [r3, #20]
70002b96:	eb40 0004 	adc.w	r0, r0, r4
70002b9a:	e9c2 1004 	strd	r1, r0, [r2, #16]
	sys_dnode_t *const next = node->next;
70002b9e:	681a      	ldr	r2, [r3, #0]
	sys_dnode_t *const prev = node->prev;
70002ba0:	685c      	ldr	r4, [r3, #4]
	node->next = NULL;
70002ba2:	2100      	movs	r1, #0
	prev->next = next;
70002ba4:	6022      	str	r2, [r4, #0]
			remove_timeout(to);
			ret = 0;
70002ba6:	4608      	mov	r0, r1
	next->prev = prev;
70002ba8:	6054      	str	r4, [r2, #4]
	node->next = NULL;
70002baa:	6019      	str	r1, [r3, #0]
70002bac:	6059      	str	r1, [r3, #4]
	if (key != 0U) {
70002bae:	b905      	cbnz	r5, 70002bb2 <z_abort_timeout+0x46>
70002bb0:	b662      	cpsie	i
		}
	}

	return ret;
}
70002bb2:	bc30      	pop	{r4, r5}
70002bb4:	4770      	bx	lr
	int ret = -EINVAL;
70002bb6:	f06f 0015 	mvn.w	r0, #21
70002bba:	e7f8      	b.n	70002bae <z_abort_timeout+0x42>

70002bbc <sys_clock_announce>:
	}
	return ret;
}

void sys_clock_announce(int32_t ticks)
{
70002bbc:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
70002bc0:	4603      	mov	r3, r0
	__asm__ volatile(
70002bc2:	f3ef 8800 	mrs	r8, CPSR
70002bc6:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002bca:	b672      	cpsid	i
	return list->head == list;
70002bcc:	f24b 4950 	movw	r9, #46160	; 0xb450
		announce_remaining += ticks;
		k_spin_unlock(&timeout_lock, key);
		return;
	}

	announce_remaining = ticks;
70002bd0:	f646 7a78 	movw	sl, #28536	; 0x6f78
70002bd4:	f2c7 0900 	movt	r9, #28672	; 0x7000
70002bd8:	f2c7 0a00 	movt	sl, #28672	; 0x7000
70002bdc:	f8ca 0000 	str.w	r0, [sl]
70002be0:	f8d9 0000 	ldr.w	r0, [r9]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002be4:	4548      	cmp	r0, r9
70002be6:	bf04      	itt	eq
70002be8:	f245 65f0 	movweq	r5, #22256	; 0x56f0
70002bec:	f2c7 0500 	movteq	r5, #28672	; 0x7000
70002bf0:	d068      	beq.n	70002cc4 <sys_clock_announce+0x108>

	struct _timeout *t;

	for (t = first();
	     (t != NULL) && (t->dticks <= announce_remaining);
70002bf2:	2800      	cmp	r0, #0
70002bf4:	d076      	beq.n	70002ce4 <sys_clock_announce+0x128>
70002bf6:	f245 65f0 	movw	r5, #22256	; 0x56f0
	node->next = NULL;
70002bfa:	f04f 0b00 	mov.w	fp, #0
	     t = first()) {
		int dt = t->dticks;

		curr_tick += dt;
		t->dticks = 0;
70002bfe:	2600      	movs	r6, #0
70002c00:	f2c7 0500 	movt	r5, #28672	; 0x7000
70002c04:	2700      	movs	r7, #0
	     (t != NULL) && (t->dticks <= announce_remaining);
70002c06:	e9d0 4204 	ldrd	r4, r2, [r0, #16]
70002c0a:	17d9      	asrs	r1, r3, #31
70002c0c:	42a3      	cmp	r3, r4
70002c0e:	eb71 0c02 	sbcs.w	ip, r1, r2
70002c12:	db29      	blt.n	70002c68 <sys_clock_announce+0xac>
		curr_tick += dt;
70002c14:	e9d5 3200 	ldrd	r3, r2, [r5]
	sys_dnode_t *const prev = node->prev;
70002c18:	6841      	ldr	r1, [r0, #4]
		t->dticks = 0;
70002c1a:	e9c0 6704 	strd	r6, r7, [r0, #16]
		curr_tick += dt;
70002c1e:	191b      	adds	r3, r3, r4
70002c20:	eb42 72e4 	adc.w	r2, r2, r4, asr #31
70002c24:	602b      	str	r3, [r5, #0]
	sys_dnode_t *const next = node->next;
70002c26:	6803      	ldr	r3, [r0, #0]
	prev->next = next;
70002c28:	600b      	str	r3, [r1, #0]
70002c2a:	606a      	str	r2, [r5, #4]
	next->prev = prev;
70002c2c:	6059      	str	r1, [r3, #4]
	node->next = NULL;
70002c2e:	f8c0 b000 	str.w	fp, [r0]
70002c32:	f8c0 b004 	str.w	fp, [r0, #4]
	if (key != 0U) {
70002c36:	f1b8 0f00 	cmp.w	r8, #0
70002c3a:	d100      	bne.n	70002c3e <sys_clock_announce+0x82>
70002c3c:	b662      	cpsie	i
		remove_timeout(t);

		k_spin_unlock(&timeout_lock, key);
		t->fn(t);
70002c3e:	6883      	ldr	r3, [r0, #8]
70002c40:	4798      	blx	r3
	__asm__ volatile(
70002c42:	f3ef 8800 	mrs	r8, CPSR
70002c46:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002c4a:	b672      	cpsid	i
		key = k_spin_lock(&timeout_lock);
		announce_remaining -= dt;
70002c4c:	f8da 3000 	ldr.w	r3, [sl]
	return list->head == list;
70002c50:	f8d9 0000 	ldr.w	r0, [r9]
70002c54:	1b1b      	subs	r3, r3, r4
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002c56:	4548      	cmp	r0, r9
70002c58:	f8ca 3000 	str.w	r3, [sl]
70002c5c:	d032      	beq.n	70002cc4 <sys_clock_announce+0x108>
	     (t != NULL) && (t->dticks <= announce_remaining);
70002c5e:	2800      	cmp	r0, #0
70002c60:	d1d1      	bne.n	70002c06 <sys_clock_announce+0x4a>
	return list->head == list;
70002c62:	4604      	mov	r4, r0
70002c64:	17d9      	asrs	r1, r3, #31
70002c66:	e006      	b.n	70002c76 <sys_clock_announce+0xba>
	}

	if (t != NULL) {
		t->dticks -= announce_remaining;
70002c68:	1ae4      	subs	r4, r4, r3
70002c6a:	eb62 0201 	sbc.w	r2, r2, r1
70002c6e:	6104      	str	r4, [r0, #16]
70002c70:	f8d9 4000 	ldr.w	r4, [r9]
70002c74:	6142      	str	r2, [r0, #20]
	}

	curr_tick += announce_remaining;
70002c76:	682a      	ldr	r2, [r5, #0]
70002c78:	18d2      	adds	r2, r2, r3
70002c7a:	686b      	ldr	r3, [r5, #4]
70002c7c:	602a      	str	r2, [r5, #0]
70002c7e:	eb43 0301 	adc.w	r3, r3, r1
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002c82:	454c      	cmp	r4, r9
70002c84:	606b      	str	r3, [r5, #4]
	announce_remaining = 0;
70002c86:	f04f 0300 	mov.w	r3, #0
70002c8a:	f8ca 3000 	str.w	r3, [sl]
70002c8e:	d024      	beq.n	70002cda <sys_clock_announce+0x11e>
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002c90:	f7fe ff08 	bl	70001aa4 <sys_clock_elapsed>
	if ((to == NULL) ||
70002c94:	b31c      	cbz	r4, 70002cde <sys_clock_announce+0x122>
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
70002c96:	e9d4 3204 	ldrd	r3, r2, [r4, #16]
70002c9a:	1a1b      	subs	r3, r3, r0
70002c9c:	eb62 72e0 	sbc.w	r2, r2, r0, asr #31
	if ((to == NULL) ||
70002ca0:	f1b3 4f00 	cmp.w	r3, #2147483648	; 0x80000000
70002ca4:	f172 0100 	sbcs.w	r1, r2, #0
70002ca8:	da19      	bge.n	70002cde <sys_clock_announce+0x122>
		ret = MAX(0, to->dticks - ticks_elapsed);
70002caa:	2a00      	cmp	r2, #0
70002cac:	bfac      	ite	ge
70002cae:	4618      	movge	r0, r3
70002cb0:	2000      	movlt	r0, #0

	sys_clock_set_timeout(next_timeout(), false);
70002cb2:	2100      	movs	r1, #0
70002cb4:	f7fe fec6 	bl	70001a44 <sys_clock_set_timeout>
	if (key != 0U) {
70002cb8:	f1b8 0f00 	cmp.w	r8, #0
70002cbc:	d100      	bne.n	70002cc0 <sys_clock_announce+0x104>
70002cbe:	b662      	cpsie	i
	k_spin_unlock(&timeout_lock, key);

#ifdef CONFIG_TIMESLICING
	z_time_slice();
#endif /* CONFIG_TIMESLICING */
}
70002cc0:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
	curr_tick += announce_remaining;
70002cc4:	682a      	ldr	r2, [r5, #0]
70002cc6:	18d2      	adds	r2, r2, r3
70002cc8:	602a      	str	r2, [r5, #0]
	announce_remaining = 0;
70002cca:	f04f 0200 	mov.w	r2, #0
70002cce:	f8ca 2000 	str.w	r2, [sl]
	curr_tick += announce_remaining;
70002cd2:	686a      	ldr	r2, [r5, #4]
70002cd4:	eb42 72e3 	adc.w	r2, r2, r3, asr #31
70002cd8:	606a      	str	r2, [r5, #4]
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002cda:	f7fe fee3 	bl	70001aa4 <sys_clock_elapsed>
		ret = MAX_WAIT;
70002cde:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
70002ce2:	e7e6      	b.n	70002cb2 <sys_clock_announce+0xf6>
	announce_remaining = 0;
70002ce4:	f8ca 0000 	str.w	r0, [sl]
	curr_tick += announce_remaining;
70002ce8:	f245 62f0 	movw	r2, #22256	; 0x56f0
70002cec:	f2c7 0200 	movt	r2, #28672	; 0x7000
70002cf0:	e9d2 1000 	ldrd	r1, r0, [r2]
70002cf4:	18c9      	adds	r1, r1, r3
70002cf6:	eb40 70e3 	adc.w	r0, r0, r3, asr #31
70002cfa:	e9c2 1000 	strd	r1, r0, [r2]
70002cfe:	e7ec      	b.n	70002cda <sys_clock_announce+0x11e>

70002d00 <sys_clock_tick_get_32>:
	}
	return t;
}

uint32_t sys_clock_tick_get_32(void)
{
70002d00:	b510      	push	{r4, lr}
	__asm__ volatile(
70002d02:	f3ef 8400 	mrs	r4, CPSR
70002d06:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002d0a:	b672      	cpsid	i
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002d0c:	f646 7378 	movw	r3, #28536	; 0x6f78
70002d10:	2000      	movs	r0, #0
70002d12:	f2c7 0300 	movt	r3, #28672	; 0x7000
70002d16:	681b      	ldr	r3, [r3, #0]
70002d18:	b90b      	cbnz	r3, 70002d1e <sys_clock_tick_get_32+0x1e>
70002d1a:	f7fe fec3 	bl	70001aa4 <sys_clock_elapsed>
		t = curr_tick + elapsed();
70002d1e:	f245 63f0 	movw	r3, #22256	; 0x56f0
70002d22:	f2c7 0300 	movt	r3, #28672	; 0x7000
70002d26:	681b      	ldr	r3, [r3, #0]
70002d28:	18c0      	adds	r0, r0, r3
	if (key != 0U) {
70002d2a:	b904      	cbnz	r4, 70002d2e <sys_clock_tick_get_32+0x2e>
70002d2c:	b662      	cpsie	i
#ifdef CONFIG_TICKLESS_KERNEL
	return (uint32_t)sys_clock_tick_get();
#else
	return (uint32_t)curr_tick;
#endif /* CONFIG_TICKLESS_KERNEL */
}
70002d2e:	bd10      	pop	{r4, pc}

70002d30 <signal_poll_event.constprop.0>:
}
#include <zephyr/syscalls/k_poll_mrsh.c>
#endif /* CONFIG_USERSPACE */

/* must be called with interrupts locked */
static int signal_poll_event(struct k_poll_event *event, uint32_t state)
70002d30:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
{
	struct z_poller *poller = event->poller;
70002d34:	6886      	ldr	r6, [r0, #8]
static int signal_poll_event(struct k_poll_event *event, uint32_t state)
70002d36:	4604      	mov	r4, r0
70002d38:	460d      	mov	r5, r1
	int retcode = 0;

	if (poller != NULL) {
70002d3a:	b136      	cbz	r6, 70002d4a <signal_poll_event.constprop.0+0x1a>
		if (poller->mode == MODE_POLL) {
70002d3c:	7873      	ldrb	r3, [r6, #1]
70002d3e:	2b01      	cmp	r3, #1
70002d40:	d022      	beq.n	70002d88 <signal_poll_event.constprop.0+0x58>
			retcode = signal_poller(event, state);
		} else if (poller->mode == MODE_TRIGGERED) {
70002d42:	2b02      	cmp	r3, #2
70002d44:	d00c      	beq.n	70002d60 <signal_poll_event.constprop.0+0x30>
		} else {
			/* Poller is not poll or triggered mode. No action needed.*/
			;
		}

		poller->is_polling = false;
70002d46:	2300      	movs	r3, #0
70002d48:	7033      	strb	r3, [r6, #0]
	event->state |= state;
70002d4a:	68e3      	ldr	r3, [r4, #12]
	event->poller = NULL;
70002d4c:	2000      	movs	r0, #0
70002d4e:	60a0      	str	r0, [r4, #8]
	event->state |= state;
70002d50:	f3c3 3286 	ubfx	r2, r3, #14, #7
70002d54:	4315      	orrs	r5, r2
70002d56:	f365 3394 	bfi	r3, r5, #14, #7
70002d5a:	60e3      	str	r3, [r4, #12]
		}
	}

	set_event_ready(event, state);
	return retcode;
}
70002d5c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
{
	struct z_poller *poller = event->poller;
	struct k_work_poll *twork =
		CONTAINER_OF(poller, struct k_work_poll, poller);

	if (poller->is_polling && twork->workq != NULL) {
70002d60:	7833      	ldrb	r3, [r6, #0]
70002d62:	2b00      	cmp	r3, #0
70002d64:	d0ef      	beq.n	70002d46 <signal_poll_event.constprop.0+0x16>
70002d66:	f856 7c04 	ldr.w	r7, [r6, #-4]
70002d6a:	2f00      	cmp	r7, #0
70002d6c:	d0eb      	beq.n	70002d46 <signal_poll_event.constprop.0+0x16>
		struct k_work_q *work_q = twork->workq;

		z_abort_timeout(&twork->timeout);
70002d6e:	f106 0014 	add.w	r0, r6, #20
70002d72:	f7ff fefb 	bl	70002b6c <z_abort_timeout>
		twork->poll_result = 0;
70002d76:	2300      	movs	r3, #0
		z_work_submit_to_queue(work_q, &twork->work);
70002d78:	4638      	mov	r0, r7
		z_abort_timeout(&twork->timeout);
70002d7a:	f1a6 0814 	sub.w	r8, r6, #20
		twork->poll_result = 0;
70002d7e:	62f3      	str	r3, [r6, #44]	; 0x2c
		z_work_submit_to_queue(work_q, &twork->work);
70002d80:	4641      	mov	r1, r8
70002d82:	f000 f977 	bl	70003074 <z_work_submit_to_queue>
70002d86:	e7de      	b.n	70002d46 <signal_poll_event.constprop.0+0x16>
	if (!z_is_thread_pending(thread)) {
70002d88:	f816 3c53 	ldrb.w	r3, [r6, #-83]
70002d8c:	079a      	lsls	r2, r3, #30
70002d8e:	d5da      	bpl.n	70002d46 <signal_poll_event.constprop.0+0x16>
	return p ? CONTAINER_OF(p, struct k_thread, poller) : NULL;
70002d90:	f1a6 0760 	sub.w	r7, r6, #96	; 0x60
	z_unpend_thread(thread);
70002d94:	4638      	mov	r0, r7
70002d96:	f7ff fc45 	bl	70002624 <z_unpend_thread>
	arch_thread_return_value_set(thread,
70002d9a:	2d08      	cmp	r5, #8
70002d9c:	bf14      	ite	ne
70002d9e:	2300      	movne	r3, #0
70002da0:	f06f 0303 	mvneq.w	r3, #3
70002da4:	6133      	str	r3, [r6, #16]
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
70002da6:	f816 3c53 	ldrb.w	r3, [r6, #-83]
70002daa:	06db      	lsls	r3, r3, #27
70002dac:	d1cb      	bne.n	70002d46 <signal_poll_event.constprop.0+0x16>
70002dae:	f856 3c48 	ldr.w	r3, [r6, #-72]
70002db2:	2b00      	cmp	r3, #0
70002db4:	d1c7      	bne.n	70002d46 <signal_poll_event.constprop.0+0x16>
	z_ready_thread(thread);
70002db6:	4638      	mov	r0, r7
70002db8:	f7ff fb78 	bl	700024ac <z_ready_thread>
	return 0;
70002dbc:	e7c3      	b.n	70002d46 <signal_poll_event.constprop.0+0x16>
70002dbe:	bf00      	nop

70002dc0 <z_handle_obj_poll_events>:
{
70002dc0:	4603      	mov	r3, r0
70002dc2:	b510      	push	{r4, lr}
	__asm__ volatile(
70002dc4:	f3ef 8400 	mrs	r4, CPSR
70002dc8:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002dcc:	b672      	cpsid	i
	return list->head == list;
70002dce:	6800      	ldr	r0, [r0, #0]

static inline sys_dnode_t *sys_dlist_get(sys_dlist_t *list)
{
	sys_dnode_t *node = NULL;

	if (!sys_dlist_is_empty(list)) {
70002dd0:	4283      	cmp	r3, r0
70002dd2:	d008      	beq.n	70002de6 <z_handle_obj_poll_events+0x26>
	sys_dnode_t *const next = node->next;
70002dd4:	e9d0 3200 	ldrd	r3, r2, [r0]
	prev->next = next;
70002dd8:	6013      	str	r3, [r2, #0]
	next->prev = prev;
70002dda:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70002ddc:	2300      	movs	r3, #0
70002dde:	6003      	str	r3, [r0, #0]
70002de0:	6043      	str	r3, [r0, #4]
		(void) signal_poll_event(poll_event, state);
70002de2:	f7ff ffa5 	bl	70002d30 <signal_poll_event.constprop.0>
	if (key != 0U) {
70002de6:	b904      	cbnz	r4, 70002dea <z_handle_obj_poll_events+0x2a>
70002de8:	b662      	cpsie	i
}
70002dea:	bd10      	pop	{r4, pc}

70002dec <boot_banner>:
	  */
	printk("\x1b[3J\x1b[2J\x1b[H");
#endif /* CONFIG_BOOT_CLEAR_SCREEN */

#ifdef CONFIG_BOOT_BANNER
	printk("*** " CONFIG_BOOT_BANNER_STRING " " BANNER_VERSION BANNER_POSTFIX " ***\n");
70002dec:	f245 0008 	movw	r0, #20488	; 0x5008
70002df0:	f2c7 0000 	movt	r0, #28672	; 0x7000
70002df4:	f7fd be54 	b.w	70000aa0 <printk>

70002df8 <statics_init>:

	SYS_PORT_TRACING_OBJ_INIT(k_heap, heap);
}

static int statics_init(void)
{
70002df8:	b538      	push	{r3, r4, r5, lr}
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70002dfa:	f24b 445c 	movw	r4, #46172	; 0xb45c
70002dfe:	f24b 455c 	movw	r5, #46172	; 0xb45c
70002e02:	f2c7 0400 	movt	r4, #28672	; 0x7000
70002e06:	f2c7 0500 	movt	r5, #28672	; 0x7000
70002e0a:	42ac      	cmp	r4, r5
70002e0c:	d20b      	bcs.n	70002e26 <statics_init+0x2e>
	sys_heap_init(&heap->heap, mem, bytes);
70002e0e:	e9d4 1201 	ldrd	r1, r2, [r4, #4]
70002e12:	f104 030c 	add.w	r3, r4, #12
70002e16:	4620      	mov	r0, r4
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70002e18:	3414      	adds	r4, #20
	list->head = (sys_dnode_t *)list;
70002e1a:	601b      	str	r3, [r3, #0]
70002e1c:	605b      	str	r3, [r3, #4]
	sys_heap_init(&heap->heap, mem, bytes);
70002e1e:	f7fd fdfb 	bl	70000a18 <sys_heap_init>
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70002e22:	42ac      	cmp	r4, r5
70002e24:	d3f3      	bcc.n	70002e0e <statics_init+0x16>
		{
			k_heap_init(heap, heap->heap.init_mem, heap->heap.init_bytes);
		}
	}
	return 0;
}
70002e26:	2000      	movs	r0, #0
70002e28:	bd38      	pop	{r3, r4, r5, pc}
70002e2a:	bf00      	nop

70002e2c <k_sys_work_q_init>:

struct k_work_q k_sys_work_q;

static int k_sys_work_q_init(void)
{
	struct k_work_queue_config cfg = {
70002e2c:	f644 51cc 	movw	r1, #19916	; 0x4dcc
		.name = "sysworkq",
		.no_yield = IS_ENABLED(CONFIG_SYSTEM_WORKQUEUE_NO_YIELD),
		.essential = true,
	};

	k_work_queue_start(&k_sys_work_q,
70002e30:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
	struct k_work_queue_config cfg = {
70002e34:	f2c7 0100 	movt	r1, #28672	; 0x7000
{
70002e38:	b510      	push	{r4, lr}
	struct k_work_queue_config cfg = {
70002e3a:	c903      	ldmia	r1, {r0, r1}
{
70002e3c:	b084      	sub	sp, #16
	k_work_queue_start(&k_sys_work_q,
70002e3e:	f44f 6280 	mov.w	r2, #1024	; 0x400
	struct k_work_queue_config cfg = {
70002e42:	ac02      	add	r4, sp, #8
	k_work_queue_start(&k_sys_work_q,
70002e44:	9400      	str	r4, [sp, #0]
	struct k_work_queue_config cfg = {
70002e46:	e884 0003 	stmia.w	r4, {r0, r1}
	k_work_queue_start(&k_sys_work_q,
70002e4a:	f64a 7180 	movw	r1, #44928	; 0xaf80
70002e4e:	f245 60f8 	movw	r0, #22264	; 0x56f8
70002e52:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002e56:	f2c7 0000 	movt	r0, #28672	; 0x7000
70002e5a:	f000 f91b 	bl	70003094 <k_work_queue_start>
			    sys_work_q_stack,
			    K_KERNEL_STACK_SIZEOF(sys_work_q_stack),
			    CONFIG_SYSTEM_WORKQUEUE_PRIORITY, &cfg);
	return 0;
}
70002e5e:	2000      	movs	r0, #0
70002e60:	b004      	add	sp, #16
70002e62:	bd10      	pop	{r4, pc}

70002e64 <work_queue_main>:
/* Loop executed by a work queue thread.
 *
 * @param workq_ptr pointer to the work queue structure
 */
static void work_queue_main(void *workq_ptr, void *p2, void *p3)
{
70002e64:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
 *
 * @return A pointer on the first node of the list (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_head(sys_slist_t *list)
{
	return list->head;
70002e68:	f245 7690 	movw	r6, #22416	; 0x5790
70002e6c:	b084      	sub	sp, #16
70002e6e:	4605      	mov	r5, r0
70002e70:	f2c7 0600 	movt	r6, #28672	; 0x7000
	return node->next;
70002e74:	2700      	movs	r7, #0
	__asm__ volatile(
70002e76:	f3ef 8800 	mrs	r8, CPSR
70002e7a:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002e7e:	b672      	cpsid	i
	return list->head;
70002e80:	6fac      	ldr	r4, [r5, #120]	; 0x78
 *
 * @return A pointer to the first node of the list (or NULL if empty)
 */
static inline sys_snode_t *sys_slist_get(sys_slist_t *list);

Z_GENLIST_GET(slist, snode)
70002e82:	2c00      	cmp	r4, #0
70002e84:	d060      	beq.n	70002f48 <work_queue_main+0xe4>
Z_GENLIST_GET_NOT_EMPTY(slist, snode)
70002e86:	6fea      	ldr	r2, [r5, #124]	; 0x7c
	return node->next;
70002e88:	6823      	ldr	r3, [r4, #0]
	list->head = node;
70002e8a:	67ab      	str	r3, [r5, #120]	; 0x78
Z_GENLIST_GET_NOT_EMPTY(slist, snode)
70002e8c:	4294      	cmp	r4, r2
	list->tail = node;
70002e8e:	bf08      	it	eq
70002e90:	67eb      	streq	r3, [r5, #124]	; 0x7c
	*flagp |= BIT(bit);
70002e92:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
70002e96:	f043 0302 	orr.w	r3, r3, #2
70002e9a:	f8c5 3090 	str.w	r3, [r5, #144]	; 0x90
	*flagp &= ~BIT(bit);
70002e9e:	68e3      	ldr	r3, [r4, #12]
			 * of struct k_work object that has been placed at address NULL,
			 * which should never happen, even line 'if (work != NULL)'
			 * ensures that.
			 * This means that if node is not NULL, then work will not be NULL.
			 */
			handler = work->handler;
70002ea0:	6862      	ldr	r2, [r4, #4]
	*flagp &= ~BIT(bit);
70002ea2:	f023 0304 	bic.w	r3, r3, #4
70002ea6:	f043 0301 	orr.w	r3, r3, #1
70002eaa:	60e3      	str	r3, [r4, #12]
	if (key != 0U) {
70002eac:	f1b8 0f00 	cmp.w	r8, #0
70002eb0:	d100      	bne.n	70002eb4 <work_queue_main+0x50>
70002eb2:	b662      	cpsie	i
		}

		k_spin_unlock(&lock, key);

		__ASSERT_NO_MSG(handler != NULL);
		handler(work);
70002eb4:	4620      	mov	r0, r4
70002eb6:	4790      	blx	r2
	__asm__ volatile(
70002eb8:	f3ef 8800 	mrs	r8, CPSR
70002ebc:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002ec0:	b672      	cpsid	i
	*flagp &= ~BIT(bit);
70002ec2:	68e2      	ldr	r2, [r4, #12]
70002ec4:	f022 0301 	bic.w	r3, r2, #1
		 * yield to prevent starving other threads.
		 */
		key = k_spin_lock(&lock);

		flag_clear(&work->flags, K_WORK_RUNNING_BIT);
		if (flag_test(&work->flags, K_WORK_FLUSHING_BIT)) {
70002ec8:	06d1      	lsls	r1, r2, #27
	*flagp &= ~BIT(bit);
70002eca:	bf58      	it	pl
70002ecc:	60e3      	strpl	r3, [r4, #12]
		if (flag_test(&work->flags, K_WORK_FLUSHING_BIT)) {
70002ece:	d432      	bmi.n	70002f36 <work_queue_main+0xd2>
			finalize_flush_locked(work);
		}
		if (flag_test(&work->flags, K_WORK_CANCELING_BIT)) {
70002ed0:	079a      	lsls	r2, r3, #30
70002ed2:	d410      	bmi.n	70002ef6 <work_queue_main+0x92>
	*flagp &= ~BIT(bit);
70002ed4:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
70002ed8:	f023 0302 	bic.w	r3, r3, #2
	return (*flagp & BIT(bit)) != 0U;
70002edc:	f3c3 2200 	ubfx	r2, r3, #8, #1
	*flagp &= ~BIT(bit);
70002ee0:	f8c5 3090 	str.w	r3, [r5, #144]	; 0x90
	if (key != 0U) {
70002ee4:	f1b8 0f00 	cmp.w	r8, #0
70002ee8:	d100      	bne.n	70002eec <work_queue_main+0x88>
70002eea:	b662      	cpsie	i
		k_spin_unlock(&lock, key);

		/* Optionally yield to prevent the work queue from
		 * starving other threads.
		 */
		if (yield) {
70002eec:	2a00      	cmp	r2, #0
70002eee:	d1c2      	bne.n	70002e76 <work_queue_main+0x12>
70002ef0:	f7ff fc7a 	bl	700027e8 <z_impl_k_yield>
}
70002ef4:	e7bf      	b.n	70002e76 <work_queue_main+0x12>
	return list->head;
70002ef6:	6830      	ldr	r0, [r6, #0]
	*flagp &= ~BIT(bit);
70002ef8:	f023 0302 	bic.w	r3, r3, #2
70002efc:	60e3      	str	r3, [r4, #12]
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(&pending_cancels, wc, tmp, node) {
70002efe:	2800      	cmp	r0, #0
70002f00:	d0e8      	beq.n	70002ed4 <work_queue_main+0x70>
		if (wc->work == work) {
70002f02:	6842      	ldr	r2, [r0, #4]
	return node->next;
70002f04:	2100      	movs	r1, #0
70002f06:	6803      	ldr	r3, [r0, #0]
70002f08:	4294      	cmp	r4, r2
70002f0a:	d007      	beq.n	70002f1c <work_queue_main+0xb8>
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(&pending_cancels, wc, tmp, node) {
70002f0c:	2b00      	cmp	r3, #0
70002f0e:	d0e1      	beq.n	70002ed4 <work_queue_main+0x70>
			sys_slist_remove(&pending_cancels, prev, &wc->node);
70002f10:	4601      	mov	r1, r0
70002f12:	4618      	mov	r0, r3
Z_GENLIST_PEEK_NEXT(slist, snode)
70002f14:	681b      	ldr	r3, [r3, #0]
		if (wc->work == work) {
70002f16:	6842      	ldr	r2, [r0, #4]
70002f18:	4294      	cmp	r4, r2
70002f1a:	d1f7      	bne.n	70002f0c <work_queue_main+0xa8>
	return node->next;
70002f1c:	6803      	ldr	r3, [r0, #0]
 */
static inline void sys_slist_remove(sys_slist_t *list,
				    sys_snode_t *prev_node,
				    sys_snode_t *node);

Z_GENLIST_REMOVE(slist, snode)
70002f1e:	2900      	cmp	r1, #0
70002f20:	d042      	beq.n	70002fa8 <work_queue_main+0x144>
	parent->next = child;
70002f22:	600b      	str	r3, [r1, #0]
Z_GENLIST_REMOVE(slist, snode)
70002f24:	6873      	ldr	r3, [r6, #4]
70002f26:	4283      	cmp	r3, r0
	list->tail = node;
70002f28:	bf08      	it	eq
70002f2a:	6071      	streq	r1, [r6, #4]
	parent->next = child;
70002f2c:	f840 7b08 	str.w	r7, [r0], #8
	z_impl_k_sem_give(sem);
70002f30:	f7ff f8a6 	bl	70002080 <z_impl_k_sem_give>
}
70002f34:	e7ce      	b.n	70002ed4 <work_queue_main+0x70>
	*flagp &= ~BIT(bit);
70002f36:	f022 0211 	bic.w	r2, r2, #17
70002f3a:	60e2      	str	r2, [r4, #12]
	z_impl_k_sem_give(sem);
70002f3c:	f104 0010 	add.w	r0, r4, #16
70002f40:	f7ff f89e 	bl	70002080 <z_impl_k_sem_give>
	return (*flagp & BIT(bit)) != 0U;
70002f44:	68e3      	ldr	r3, [r4, #12]
};
70002f46:	e7c3      	b.n	70002ed0 <work_queue_main+0x6c>
	return (*flagp & BIT(bit)) != 0U;
70002f48:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
	*flagp &= ~BIT(bit);
70002f4c:	f023 0204 	bic.w	r2, r3, #4
		} else if (flag_test_and_clear(&queue->flags,
70002f50:	075c      	lsls	r4, r3, #29
	*flagp &= ~BIT(bit);
70002f52:	f8c5 2090 	str.w	r2, [r5, #144]	; 0x90
		} else if (flag_test_and_clear(&queue->flags,
70002f56:	f3c3 0180 	ubfx	r1, r3, #2, #1
70002f5a:	d40a      	bmi.n	70002f72 <work_queue_main+0x10e>
		} else if (flag_test(&queue->flags, K_WORK_QUEUE_STOP_BIT)) {
70002f5c:	06d0      	lsls	r0, r2, #27
70002f5e:	d511      	bpl.n	70002f84 <work_queue_main+0x120>
	*flagp = flags;
70002f60:	f8c5 1090 	str.w	r1, [r5, #144]	; 0x90
70002f64:	f1b8 0f00 	cmp.w	r8, #0
70002f68:	d100      	bne.n	70002f6c <work_queue_main+0x108>
70002f6a:	b662      	cpsie	i
			k_yield();
		}
	}
}
70002f6c:	b004      	add	sp, #16
70002f6e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
			(void)z_sched_wake_all(&queue->drainq, 1, NULL);
70002f72:	f105 0488 	add.w	r4, r5, #136	; 0x88
static inline bool z_sched_wake_all(_wait_q_t *wait_q, int swap_retval,
				    void *swap_data)
{
	bool woken = false;

	while (z_sched_wake(wait_q, swap_retval, swap_data)) {
70002f76:	2200      	movs	r2, #0
70002f78:	2101      	movs	r1, #1
70002f7a:	4620      	mov	r0, r4
70002f7c:	f7ff fd22 	bl	700029c4 <z_sched_wake>
70002f80:	2800      	cmp	r0, #0
70002f82:	d1f8      	bne.n	70002f76 <work_queue_main+0x112>
					   K_FOREVER, NULL);
70002f84:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
70002f88:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
			(void)z_sched_wait(&lock, key, &queue->notifyq,
70002f8c:	f646 707c 	movw	r0, #28540	; 0x6f7c
70002f90:	4641      	mov	r1, r8
70002f92:	e9cd 2300 	strd	r2, r3, [sp]
70002f96:	2300      	movs	r3, #0
70002f98:	f105 0280 	add.w	r2, r5, #128	; 0x80
70002f9c:	9302      	str	r3, [sp, #8]
70002f9e:	f2c7 0000 	movt	r0, #28672	; 0x7000
70002fa2:	f7ff fd3d 	bl	70002a20 <z_sched_wait>
			continue;
70002fa6:	e766      	b.n	70002e76 <work_queue_main+0x12>
Z_GENLIST_REMOVE(slist, snode)
70002fa8:	6872      	ldr	r2, [r6, #4]
	list->head = node;
70002faa:	6033      	str	r3, [r6, #0]
Z_GENLIST_REMOVE(slist, snode)
70002fac:	4282      	cmp	r2, r0
	list->tail = node;
70002fae:	bf08      	it	eq
70002fb0:	6073      	streq	r3, [r6, #4]
70002fb2:	e7bb      	b.n	70002f2c <work_queue_main+0xc8>

70002fb4 <submit_to_queue_locked>:
{
70002fb4:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	return (*flagp & BIT(bit)) != 0U;
70002fb6:	68c3      	ldr	r3, [r0, #12]
{
70002fb8:	460d      	mov	r5, r1
	if (flag_test(&work->flags, K_WORK_CANCELING_BIT)) {
70002fba:	079a      	lsls	r2, r3, #30
70002fbc:	f3c3 0640 	ubfx	r6, r3, #1, #1
70002fc0:	d407      	bmi.n	70002fd2 <submit_to_queue_locked+0x1e>
	} else if (!flag_test(&work->flags, K_WORK_QUEUED_BIT)) {
70002fc2:	075f      	lsls	r7, r3, #29
	return (*flagp & BIT(bit)) != 0U;
70002fc4:	f3c3 0280 	ubfx	r2, r3, #2, #1
	} else if (!flag_test(&work->flags, K_WORK_QUEUED_BIT)) {
70002fc8:	d506      	bpl.n	70002fd8 <submit_to_queue_locked+0x24>
		*queuep = NULL;
70002fca:	2300      	movs	r3, #0
}
70002fcc:	4630      	mov	r0, r6
		*queuep = NULL;
70002fce:	602b      	str	r3, [r5, #0]
}
70002fd0:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		ret = -EBUSY;
70002fd2:	f06f 060f 	mvn.w	r6, #15
70002fd6:	e7f8      	b.n	70002fca <submit_to_queue_locked+0x16>
		if (*queuep == NULL) {
70002fd8:	680f      	ldr	r7, [r1, #0]
70002fda:	4604      	mov	r4, r0
70002fdc:	2f00      	cmp	r7, #0
70002fde:	d032      	beq.n	70003046 <submit_to_queue_locked+0x92>
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002fe0:	07db      	lsls	r3, r3, #31
		ret = 1;
70002fe2:	bf58      	it	pl
70002fe4:	2601      	movpl	r6, #1
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002fe6:	d504      	bpl.n	70002ff2 <submit_to_queue_locked+0x3e>
			*queuep = work->queue;
70002fe8:	68a7      	ldr	r7, [r4, #8]
			ret = 2;
70002fea:	2602      	movs	r6, #2
			*queuep = work->queue;
70002fec:	602f      	str	r7, [r5, #0]
	if (queue == NULL) {
70002fee:	2f00      	cmp	r7, #0
70002ff0:	d03d      	beq.n	7000306e <submit_to_queue_locked+0xba>
70002ff2:	f646 7358 	movw	r3, #28504	; 0x6f58
70002ff6:	f2c7 0300 	movt	r3, #28672	; 0x7000
	bool chained = (arch_current_thread() == &queue->thread) && !k_is_in_isr();
70002ffa:	689b      	ldr	r3, [r3, #8]
70002ffc:	42bb      	cmp	r3, r7
70002ffe:	d02d      	beq.n	7000305c <submit_to_queue_locked+0xa8>
	return (*flagp & BIT(bit)) != 0U;
70003000:	f8d7 0090 	ldr.w	r0, [r7, #144]	; 0x90
70003004:	f3c0 0380 	ubfx	r3, r0, #2, #1
70003008:	f3c0 01c0 	ubfx	r1, r0, #3, #1
	if (!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT)) {
7000300c:	07c0      	lsls	r0, r0, #31
7000300e:	d52b      	bpl.n	70003068 <submit_to_queue_locked+0xb4>
	} else if (draining && !chained) {
70003010:	f082 0201 	eor.w	r2, r2, #1
70003014:	4213      	tst	r3, r2
70003016:	d1dc      	bne.n	70002fd2 <submit_to_queue_locked+0x1e>
	} else if (plugged && !draining) {
70003018:	f083 0301 	eor.w	r3, r3, #1
7000301c:	4019      	ands	r1, r3
7000301e:	d1d8      	bne.n	70002fd2 <submit_to_queue_locked+0x1e>
	parent->next = child;
70003020:	6021      	str	r1, [r4, #0]
	return list->tail;
70003022:	6ffb      	ldr	r3, [r7, #124]	; 0x7c
Z_GENLIST_APPEND(slist, snode)
70003024:	b1bb      	cbz	r3, 70003056 <submit_to_queue_locked+0xa2>
	parent->next = child;
70003026:	601c      	str	r4, [r3, #0]
	list->tail = node;
70003028:	67fc      	str	r4, [r7, #124]	; 0x7c
		rv = z_sched_wake(&queue->notifyq, 0, NULL);
7000302a:	2200      	movs	r2, #0
7000302c:	f107 0080 	add.w	r0, r7, #128	; 0x80
70003030:	4611      	mov	r1, r2
70003032:	f7ff fcc7 	bl	700029c4 <z_sched_wake>
	*flagp |= BIT(bit);
70003036:	68e3      	ldr	r3, [r4, #12]
}
70003038:	4630      	mov	r0, r6
	*flagp |= BIT(bit);
7000303a:	f043 0304 	orr.w	r3, r3, #4
7000303e:	60e3      	str	r3, [r4, #12]
			work->queue = *queuep;
70003040:	682b      	ldr	r3, [r5, #0]
70003042:	60a3      	str	r3, [r4, #8]
}
70003044:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
			*queuep = work->queue;
70003046:	6887      	ldr	r7, [r0, #8]
70003048:	600f      	str	r7, [r1, #0]
	return (*flagp & BIT(bit)) != 0U;
7000304a:	68c3      	ldr	r3, [r0, #12]
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
7000304c:	07de      	lsls	r6, r3, #31
		ret = 1;
7000304e:	bf58      	it	pl
70003050:	2601      	movpl	r6, #1
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70003052:	d5cc      	bpl.n	70002fee <submit_to_queue_locked+0x3a>
70003054:	e7c8      	b.n	70002fe8 <submit_to_queue_locked+0x34>
	list->head = node;
70003056:	67bc      	str	r4, [r7, #120]	; 0x78
70003058:	67fc      	str	r4, [r7, #124]	; 0x7c
	if (queue != NULL) {
7000305a:	e7e6      	b.n	7000302a <submit_to_queue_locked+0x76>
	bool chained = (arch_current_thread() == &queue->thread) && !k_is_in_isr();
7000305c:	f7ff f846 	bl	700020ec <k_is_in_isr>
70003060:	f080 0201 	eor.w	r2, r0, #1
70003064:	b2d2      	uxtb	r2, r2
70003066:	e7cb      	b.n	70003000 <submit_to_queue_locked+0x4c>
		ret = -ENODEV;
70003068:	f06f 0612 	mvn.w	r6, #18
7000306c:	e7ad      	b.n	70002fca <submit_to_queue_locked+0x16>
		return -EINVAL;
7000306e:	f06f 0615 	mvn.w	r6, #21
70003072:	e7aa      	b.n	70002fca <submit_to_queue_locked+0x16>

70003074 <z_work_submit_to_queue>:
{
70003074:	b510      	push	{r4, lr}
70003076:	b082      	sub	sp, #8
70003078:	9001      	str	r0, [sp, #4]
7000307a:	4608      	mov	r0, r1
	__asm__ volatile(
7000307c:	f3ef 8400 	mrs	r4, CPSR
70003080:	f004 0480 	and.w	r4, r4, #128	; 0x80
70003084:	b672      	cpsid	i
	int ret = submit_to_queue_locked(work, &queue);
70003086:	a901      	add	r1, sp, #4
70003088:	f7ff ff94 	bl	70002fb4 <submit_to_queue_locked>
	if (key != 0U) {
7000308c:	b904      	cbnz	r4, 70003090 <z_work_submit_to_queue+0x1c>
7000308e:	b662      	cpsie	i
}
70003090:	b002      	add	sp, #8
70003092:	bd10      	pop	{r4, pc}

70003094 <k_work_queue_start>:
void k_work_queue_start(struct k_work_q *queue,
			k_thread_stack_t *stack,
			size_t stack_size,
			int prio,
			const struct k_work_queue_config *cfg)
{
70003094:	b5f0      	push	{r4, r5, r6, r7, lr}
70003096:	4604      	mov	r4, r0
70003098:	b089      	sub	sp, #36	; 0x24
	list->head = NULL;
7000309a:	2000      	movs	r0, #0
7000309c:	67a0      	str	r0, [r4, #120]	; 0x78
7000309e:	67e0      	str	r0, [r4, #124]	; 0x7c
	sys_dlist_init(&w->waitq);
700030a0:	f104 0080 	add.w	r0, r4, #128	; 0x80
700030a4:	9d0e      	ldr	r5, [sp, #56]	; 0x38
	list->tail = (sys_dnode_t *)list;
700030a6:	e9c4 0020 	strd	r0, r0, [r4, #128]	; 0x80
700030aa:	f104 0088 	add.w	r0, r4, #136	; 0x88
700030ae:	e9c4 0022 	strd	r0, r0, [r4, #136]	; 0x88
	__ASSERT_NO_MSG(queue);
	__ASSERT_NO_MSG(stack);
	__ASSERT_NO_MSG(!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT));
	uint32_t flags = K_WORK_QUEUE_STARTED;
700030b2:	2001      	movs	r0, #1

	sys_slist_init(&queue->pending);
	z_waitq_init(&queue->notifyq);
	z_waitq_init(&queue->drainq);

	if ((cfg != NULL) && cfg->no_yield) {
700030b4:	b12d      	cbz	r5, 700030c2 <k_work_queue_start+0x2e>
700030b6:	792e      	ldrb	r6, [r5, #4]
		flags |= K_WORK_QUEUE_NO_YIELD;
700030b8:	f240 1001 	movw	r0, #257	; 0x101
700030bc:	2e00      	cmp	r6, #0
700030be:	bf08      	it	eq
700030c0:	2001      	moveq	r0, #1
	*flagp = flags;
700030c2:	f04f 36ff 	mov.w	r6, #4294967295	; 0xffffffff
700030c6:	f04f 37ff 	mov.w	r7, #4294967295	; 0xffffffff
700030ca:	f8c4 0090 	str.w	r0, [r4, #144]	; 0x90
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
700030ce:	9303      	str	r3, [sp, #12]
700030d0:	2000      	movs	r0, #0
700030d2:	e9cd 6706 	strd	r6, r7, [sp, #24]
700030d6:	f642 6365 	movw	r3, #11877	; 0x2e65
700030da:	9004      	str	r0, [sp, #16]
700030dc:	f2c7 0300 	movt	r3, #28672	; 0x7000
700030e0:	e9cd 0001 	strd	r0, r0, [sp, #4]
700030e4:	4620      	mov	r0, r4
700030e6:	9400      	str	r4, [sp, #0]
700030e8:	f7ff f842 	bl	70002170 <z_impl_k_thread_create>

	(void)k_thread_create(&queue->thread, stack, stack_size,
			      work_queue_main, queue, NULL, NULL,
			      prio, 0, K_FOREVER);

	if ((cfg != NULL) && (cfg->name != NULL)) {
700030ec:	b155      	cbz	r5, 70003104 <k_work_queue_start+0x70>
700030ee:	6829      	ldr	r1, [r5, #0]
700030f0:	b111      	cbz	r1, 700030f8 <k_work_queue_start+0x64>
	return z_impl_k_thread_name_set(thread, str);
700030f2:	4620      	mov	r0, r4
700030f4:	f7ff f808 	bl	70002108 <z_impl_k_thread_name_set>
		k_thread_name_set(&queue->thread, cfg->name);
	}

	if ((cfg != NULL) && (cfg->essential)) {
700030f8:	796b      	ldrb	r3, [r5, #5]
700030fa:	b11b      	cbz	r3, 70003104 <k_work_queue_start+0x70>
		queue->thread.base.user_options |= K_ESSENTIAL;
700030fc:	7b23      	ldrb	r3, [r4, #12]
700030fe:	f043 0301 	orr.w	r3, r3, #1
70003102:	7323      	strb	r3, [r4, #12]
	z_impl_k_wakeup(thread);
70003104:	4620      	mov	r0, r4
	}

	k_thread_start(&queue->thread);

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_work_queue, start, queue);
}
70003106:	b009      	add	sp, #36	; 0x24
70003108:	e8bd 40f0 	ldmia.w	sp!, {r4, r5, r6, r7, lr}
7000310c:	f7ff bc12 	b.w	70002934 <z_impl_k_wakeup>

70003110 <memcpy>:
  long *aligned_dst;
  const long *aligned_src;

  /* If the size is small, or either SRC or DST is unaligned,
     then punt into the byte copy loop.  This should be rare.  */
  if (!TOO_SMALL(len0) && !UNALIGNED (src, dst))
70003110:	2a0f      	cmp	r2, #15
70003112:	d913      	bls.n	7000313c <memcpy+0x2c>
70003114:	ea40 0301 	orr.w	r3, r0, r1
70003118:	f013 0303 	ands.w	r3, r3, #3
  char *dst = dst0;
7000311c:	bf1c      	itt	ne
7000311e:	4603      	movne	r3, r0
       /* Pick up any residual with a byte copier.  */
      dst = (char*)aligned_dst;
      src = (char*)aligned_src;
    }

  while (len0--)
70003120:	f102 3cff 	addne.w	ip, r2, #4294967295	; 0xffffffff
  if (!TOO_SMALL(len0) && !UNALIGNED (src, dst))
70003124:	d010      	beq.n	70003148 <memcpy+0x38>
70003126:	f10c 0c01 	add.w	ip, ip, #1
7000312a:	3b01      	subs	r3, #1
7000312c:	448c      	add	ip, r1
    *dst++ = *src++;
7000312e:	f811 2b01 	ldrb.w	r2, [r1], #1
70003132:	f803 2f01 	strb.w	r2, [r3, #1]!
  while (len0--)
70003136:	458c      	cmp	ip, r1
70003138:	d1f9      	bne.n	7000312e <memcpy+0x1e>
7000313a:	4770      	bx	lr
  char *dst = dst0;
7000313c:	4603      	mov	r3, r0
  while (len0--)
7000313e:	f102 3cff 	add.w	ip, r2, #4294967295	; 0xffffffff
70003142:	2a00      	cmp	r2, #0
70003144:	d1ef      	bne.n	70003126 <memcpy+0x16>

  return dst0;
#endif /* not PREFER_SIZE_OVER_SPEED */
}
70003146:	4770      	bx	lr
{
70003148:	b5f0      	push	{r4, r5, r6, r7, lr}
7000314a:	4684      	mov	ip, r0
7000314c:	f1a2 0710 	sub.w	r7, r2, #16
70003150:	468e      	mov	lr, r1
70003152:	093f      	lsrs	r7, r7, #4
70003154:	3701      	adds	r7, #1
          *aligned_dst++ = *aligned_src++;
70003156:	f8de 4008 	ldr.w	r4, [lr, #8]
7000315a:	3301      	adds	r3, #1
7000315c:	f8de 6000 	ldr.w	r6, [lr]
70003160:	429f      	cmp	r7, r3
70003162:	f8de 5004 	ldr.w	r5, [lr, #4]
70003166:	f10c 0c10 	add.w	ip, ip, #16
7000316a:	f84c 4c08 	str.w	r4, [ip, #-8]
7000316e:	f10e 0e10 	add.w	lr, lr, #16
70003172:	f85e 4c04 	ldr.w	r4, [lr, #-4]
70003176:	f84c 6c10 	str.w	r6, [ip, #-16]
7000317a:	f84c 5c0c 	str.w	r5, [ip, #-12]
7000317e:	f84c 4c04 	str.w	r4, [ip, #-4]
      while (len0 >= BIGBLOCKSIZE)
70003182:	d8e8      	bhi.n	70003156 <memcpy+0x46>
      while (len0 >= LITTLEBLOCKSIZE)
70003184:	f012 0f0c 	tst.w	r2, #12
          len0 -= BIGBLOCKSIZE;
70003188:	f002 050f 	and.w	r5, r2, #15
          *aligned_dst++ = *aligned_src++;
7000318c:	eb01 1107 	add.w	r1, r1, r7, lsl #4
          len0 -= BIGBLOCKSIZE;
70003190:	bf08      	it	eq
70003192:	462a      	moveq	r2, r5
          *aligned_dst++ = *aligned_src++;
70003194:	eb00 1307 	add.w	r3, r0, r7, lsl #4
      while (len0 >= LITTLEBLOCKSIZE)
70003198:	d013      	beq.n	700031c2 <memcpy+0xb2>
7000319a:	3d04      	subs	r5, #4
7000319c:	f025 0c03 	bic.w	ip, r5, #3
700031a0:	1f1c      	subs	r4, r3, #4
700031a2:	08ad      	lsrs	r5, r5, #2
          *aligned_dst++ = *aligned_src++;
700031a4:	460e      	mov	r6, r1
700031a6:	449c      	add	ip, r3
          *aligned_dst++ = *aligned_src++;
700031a8:	f856 7b04 	ldr.w	r7, [r6], #4
700031ac:	f844 7f04 	str.w	r7, [r4, #4]!
      while (len0 >= LITTLEBLOCKSIZE)
700031b0:	4564      	cmp	r4, ip
700031b2:	d1f9      	bne.n	700031a8 <memcpy+0x98>
700031b4:	1c6c      	adds	r4, r5, #1
          len0 -= LITTLEBLOCKSIZE;
700031b6:	f002 0203 	and.w	r2, r2, #3
          *aligned_dst++ = *aligned_src++;
700031ba:	eb03 0384 	add.w	r3, r3, r4, lsl #2
700031be:	eb01 0184 	add.w	r1, r1, r4, lsl #2
  while (len0--)
700031c2:	f102 3cff 	add.w	ip, r2, #4294967295	; 0xffffffff
700031c6:	f10c 0c01 	add.w	ip, ip, #1
700031ca:	3b01      	subs	r3, #1
700031cc:	448c      	add	ip, r1
700031ce:	b12a      	cbz	r2, 700031dc <memcpy+0xcc>
    *dst++ = *src++;
700031d0:	f811 2b01 	ldrb.w	r2, [r1], #1
700031d4:	f803 2f01 	strb.w	r2, [r3, #1]!
  while (len0--)
700031d8:	458c      	cmp	ip, r1
700031da:	d1f9      	bne.n	700031d0 <memcpy+0xc0>
}
700031dc:	bdf0      	pop	{r4, r5, r6, r7, pc}
700031de:	bf00      	nop

700031e0 <memset>:
  unsigned long buffer;
  unsigned long *aligned_addr;
  unsigned int d = c & 0xff;	/* To avoid sign extension, copy C to an
				   unsigned variable.  */

  while (UNALIGNED (s))
700031e0:	0783      	lsls	r3, r0, #30
{
700031e2:	b530      	push	{r4, r5, lr}
  while (UNALIGNED (s))
700031e4:	d04a      	beq.n	7000327c <memset+0x9c>
    {
      if (n--)
700031e6:	1e54      	subs	r4, r2, #1
700031e8:	2a00      	cmp	r2, #0
700031ea:	d041      	beq.n	70003270 <memset+0x90>
  char *s = (char *) m;
700031ec:	4603      	mov	r3, r0
        *s++ = (char) c;
700031ee:	b2ca      	uxtb	r2, r1
700031f0:	e001      	b.n	700031f6 <memset+0x16>
      if (n--)
700031f2:	3c01      	subs	r4, #1
700031f4:	d33c      	bcc.n	70003270 <memset+0x90>
        *s++ = (char) c;
700031f6:	f803 2b01 	strb.w	r2, [r3], #1
  while (UNALIGNED (s))
700031fa:	079d      	lsls	r5, r3, #30
700031fc:	d1f9      	bne.n	700031f2 <memset+0x12>
      else
        return m;
    }

  if (!TOO_SMALL (n))
700031fe:	2c03      	cmp	r4, #3
70003200:	d92f      	bls.n	70003262 <memset+0x82>
  unsigned int d = c & 0xff;	/* To avoid sign extension, copy C to an
70003202:	b2cd      	uxtb	r5, r1
      buffer |= (buffer << 16);
      for (i = 32; i < LBLOCKSIZE * 8; i <<= 1)
        buffer = (buffer << i) | buffer;

      /* Unroll the loop.  */
      while (n >= LBLOCKSIZE*4)
70003204:	2c0f      	cmp	r4, #15
70003206:	eb05 2505 	add.w	r5, r5, r5, lsl #8
7000320a:	eb05 4505 	add.w	r5, r5, r5, lsl #16
7000320e:	d938      	bls.n	70003282 <memset+0xa2>
70003210:	f1a4 0210 	sub.w	r2, r4, #16
70003214:	f022 0c0f 	bic.w	ip, r2, #15
70003218:	f103 0e10 	add.w	lr, r3, #16
7000321c:	44e6      	add	lr, ip
7000321e:	ea4f 1c12 	mov.w	ip, r2, lsr #4
70003222:	461a      	mov	r2, r3
        {
          *aligned_addr++ = buffer;
70003224:	6015      	str	r5, [r2, #0]
      while (n >= LBLOCKSIZE*4)
70003226:	3210      	adds	r2, #16
          *aligned_addr++ = buffer;
70003228:	f842 5c0c 	str.w	r5, [r2, #-12]
7000322c:	f842 5c08 	str.w	r5, [r2, #-8]
70003230:	f842 5c04 	str.w	r5, [r2, #-4]
      while (n >= LBLOCKSIZE*4)
70003234:	4572      	cmp	r2, lr
70003236:	d1f5      	bne.n	70003224 <memset+0x44>
          *aligned_addr++ = buffer;
          *aligned_addr++ = buffer;
          *aligned_addr++ = buffer;
70003238:	f10c 0201 	add.w	r2, ip, #1
          n -= 4*LBLOCKSIZE;
        }

      while (n >= LBLOCKSIZE)
7000323c:	f014 0f0c 	tst.w	r4, #12
          *aligned_addr++ = buffer;
70003240:	eb03 1202 	add.w	r2, r3, r2, lsl #4
          n -= 4*LBLOCKSIZE;
70003244:	f004 0c0f 	and.w	ip, r4, #15
      while (n >= LBLOCKSIZE)
70003248:	d013      	beq.n	70003272 <memset+0x92>
7000324a:	f1ac 0304 	sub.w	r3, ip, #4
7000324e:	f023 0303 	bic.w	r3, r3, #3
70003252:	3304      	adds	r3, #4
70003254:	4413      	add	r3, r2
        {
          *aligned_addr++ = buffer;
70003256:	f842 5b04 	str.w	r5, [r2], #4
      while (n >= LBLOCKSIZE)
7000325a:	429a      	cmp	r2, r3
7000325c:	d1fb      	bne.n	70003256 <memset+0x76>
          n -= LBLOCKSIZE;
7000325e:	f00c 0403 	and.w	r4, ip, #3
      s = (char*)aligned_addr;
    }

#endif /* not PREFER_SIZE_OVER_SPEED */

  while (n--)
70003262:	b12c      	cbz	r4, 70003270 <memset+0x90>
        *s++ = (char) c;
70003264:	b2c9      	uxtb	r1, r1
70003266:	441c      	add	r4, r3
    *s++ = (char) c;
70003268:	f803 1b01 	strb.w	r1, [r3], #1
  while (n--)
7000326c:	429c      	cmp	r4, r3
7000326e:	d1fb      	bne.n	70003268 <memset+0x88>

  return m;
}
70003270:	bd30      	pop	{r4, r5, pc}
          n -= 4*LBLOCKSIZE;
70003272:	4664      	mov	r4, ip
          *aligned_addr++ = buffer;
70003274:	4613      	mov	r3, r2
  while (n--)
70003276:	2c00      	cmp	r4, #0
70003278:	d1f4      	bne.n	70003264 <memset+0x84>
7000327a:	e7f9      	b.n	70003270 <memset+0x90>
  char *s = (char *) m;
7000327c:	4603      	mov	r3, r0
  while (UNALIGNED (s))
7000327e:	4614      	mov	r4, r2
70003280:	e7bd      	b.n	700031fe <memset+0x1e>
      while (n >= LBLOCKSIZE*4)
70003282:	461a      	mov	r2, r3
70003284:	46a4      	mov	ip, r4
70003286:	e7e0      	b.n	7000324a <memset+0x6a>

70003288 <strnlen>:
strnlen (const char *str,
	size_t n)
{
  const char *start = str;

  while (n-- > 0 && *str)
70003288:	4603      	mov	r3, r0
7000328a:	eb00 0c01 	add.w	ip, r0, r1
7000328e:	b911      	cbnz	r1, 70003296 <strnlen+0xe>
70003290:	e00a      	b.n	700032a8 <strnlen+0x20>
70003292:	4563      	cmp	r3, ip
70003294:	d006      	beq.n	700032a4 <strnlen+0x1c>
    str++;
70003296:	461a      	mov	r2, r3
70003298:	3301      	adds	r3, #1
  while (n-- > 0 && *str)
7000329a:	7811      	ldrb	r1, [r2, #0]
7000329c:	2900      	cmp	r1, #0
7000329e:	d1f8      	bne.n	70003292 <strnlen+0xa>

  return str - start;
700032a0:	1a10      	subs	r0, r2, r0
}
700032a2:	4770      	bx	lr
  return str - start;
700032a4:	1a18      	subs	r0, r3, r0
700032a6:	4770      	bx	lr
  while (n-- > 0 && *str)
700032a8:	4608      	mov	r0, r1
700032aa:	4770      	bx	lr

700032ac <snprintf>:

#include "stdio_private.h"

int
snprintf(char *s, size_t n, const char *fmt, ...)
{
700032ac:	b40c      	push	{r2, r3}
	   that f.size will be a max number of nonzero symbols.	*/

	if ((int) n < 0)
		n = (unsigned)INT_MAX + 1;

	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
700032ae:	f643 42bd 	movw	r2, #15549	; 0x3cbd
{
700032b2:	4603      	mov	r3, r0
700032b4:	b510      	push	{r4, lr}
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
700032b6:	2002      	movs	r0, #2
{
700032b8:	b088      	sub	sp, #32
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
700032ba:	2400      	movs	r4, #0
700032bc:	f2c7 0200 	movt	r2, #28672	; 0x7000
700032c0:	9305      	str	r3, [sp, #20]
700032c2:	e9cd 4201 	strd	r4, r2, [sp, #4]
700032c6:	e9cd 4403 	strd	r4, r4, [sp, #12]
700032ca:	f88d 0006 	strb.w	r0, [sp, #6]
700032ce:	9407      	str	r4, [sp, #28]
700032d0:	b1a1      	cbz	r1, 700032fc <snprintf+0x50>
700032d2:	f1b1 4f00 	cmp.w	r1, #2147483648	; 0x80000000
700032d6:	bf28      	it	cs
700032d8:	f04f 4100 	movcs.w	r1, #2147483648	; 0x80000000

	va_start(ap, fmt);
700032dc:	aa0b      	add	r2, sp, #44	; 0x2c
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
700032de:	3901      	subs	r1, #1
700032e0:	440b      	add	r3, r1
	i = vfprintf(&f.file, fmt, ap);
700032e2:	990a      	ldr	r1, [sp, #40]	; 0x28
700032e4:	a801      	add	r0, sp, #4
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
700032e6:	9306      	str	r3, [sp, #24]
	va_start(ap, fmt);
700032e8:	9200      	str	r2, [sp, #0]
	i = vfprintf(&f.file, fmt, ap);
700032ea:	f000 f951 	bl	70003590 <__l_vfprintf>
	va_end(ap);

	if (n)
            *f.pos = '\0';
700032ee:	9b05      	ldr	r3, [sp, #20]
700032f0:	701c      	strb	r4, [r3, #0]

	return i;
}
700032f2:	b008      	add	sp, #32
700032f4:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
700032f8:	b002      	add	sp, #8
700032fa:	4770      	bx	lr
	i = vfprintf(&f.file, fmt, ap);
700032fc:	990a      	ldr	r1, [sp, #40]	; 0x28
	va_start(ap, fmt);
700032fe:	aa0b      	add	r2, sp, #44	; 0x2c
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
70003300:	9306      	str	r3, [sp, #24]
	i = vfprintf(&f.file, fmt, ap);
70003302:	a801      	add	r0, sp, #4
	va_start(ap, fmt);
70003304:	9200      	str	r2, [sp, #0]
	i = vfprintf(&f.file, fmt, ap);
70003306:	f000 f943 	bl	70003590 <__l_vfprintf>
}
7000330a:	b008      	add	sp, #32
7000330c:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
70003310:	b002      	add	sp, #8
70003312:	4770      	bx	lr

70003314 <__ultoa_invert>:
#endif
#endif

static __noinline char *
__ultoa_invert(ultoa_unsigned_t val, char *str, int base)
{
70003314:	b570      	push	{r4, r5, r6, lr}
70003316:	4684      	mov	ip, r0
	char hex = ('a' - '0' - 10 + 16) - base;
70003318:	f1c3 0437 	rsb	r4, r3, #55	; 0x37
{
7000331c:	4610      	mov	r0, r2
	char hex = ('a' - '0' - 10 + 16) - base;
7000331e:	b2e2      	uxtb	r2, r4

        base &= 31;
70003320:	f003 041f 	and.w	r4, r3, #31
    switch(base) {
70003324:	2c08      	cmp	r4, #8
        *dig = val & 1;
70003326:	fa5f fe8c 	uxtb.w	lr, ip
    switch(base) {
7000332a:	d042      	beq.n	700033b2 <__ultoa_invert+0x9e>
7000332c:	2c10      	cmp	r4, #16
	q = (n >> 1) + (n >> 2);
7000332e:	ea4f 035c 	mov.w	r3, ip, lsr #1
70003332:	ea4f 069c 	mov.w	r6, ip, lsr #2
70003336:	ea43 73c1 	orr.w	r3, r3, r1, lsl #31
7000333a:	ea46 7681 	orr.w	r6, r6, r1, lsl #30
7000333e:	ea4f 0591 	mov.w	r5, r1, lsr #2
    switch(base) {
70003342:	d04c      	beq.n	700033de <__ultoa_invert+0xca>
70003344:	2c02      	cmp	r4, #2
70003346:	d042      	beq.n	700033ce <__ultoa_invert+0xba>
	q = (n >> 1) + (n >> 2);
70003348:	199b      	adds	r3, r3, r6
7000334a:	eb45 0551 	adc.w	r5, r5, r1, lsr #1
	q = q + (q >> 4);
7000334e:	0919      	lsrs	r1, r3, #4
70003350:	ea41 7105 	orr.w	r1, r1, r5, lsl #28
70003354:	185b      	adds	r3, r3, r1
70003356:	eb45 1515 	adc.w	r5, r5, r5, lsr #4
	q = q + (q >> 8);
7000335a:	0a19      	lsrs	r1, r3, #8
7000335c:	ea41 6105 	orr.w	r1, r1, r5, lsl #24
70003360:	185b      	adds	r3, r3, r1
70003362:	eb45 2515 	adc.w	r5, r5, r5, lsr #8
	q = q + (q >> 16);
70003366:	0c19      	lsrs	r1, r3, #16
70003368:	ea41 4105 	orr.w	r1, r1, r5, lsl #16
7000336c:	185b      	adds	r3, r3, r1
7000336e:	eb45 4515 	adc.w	r5, r5, r5, lsr #16
        q = q + (q >> 32);
70003372:	195b      	adds	r3, r3, r5
70003374:	f145 0500 	adc.w	r5, r5, #0
	q = q >> 3;
70003378:	ea4f 0cd3 	mov.w	ip, r3, lsr #3
7000337c:	ea4c 7c45 	orr.w	ip, ip, r5, lsl #29
70003380:	08e9      	lsrs	r1, r5, #3
	r = (char) (n - (((q << 2) + q) << 1));
70003382:	eb0c 038c 	add.w	r3, ip, ip, lsl #2
70003386:	ebae 0343 	sub.w	r3, lr, r3, lsl #1
7000338a:	b2db      	uxtb	r3, r3
            r -= 10;
7000338c:	f1a3 050a 	sub.w	r5, r3, #10
        if (r > 9) {
70003390:	2b09      	cmp	r3, #9
            r -= 10;
70003392:	b2ed      	uxtb	r5, r5
        if (r > 9) {
70003394:	d914      	bls.n	700033c0 <__ultoa_invert+0xac>
            q++;
70003396:	f11c 0c01 	adds.w	ip, ip, #1
7000339a:	f141 0100 	adc.w	r1, r1, #0
                val = udivmod(val, base, &v);
#else
                v = val % base;
                val /= base;
#endif
		if (v > 9)
7000339e:	2d09      	cmp	r5, #9
700033a0:	d92a      	bls.n	700033f8 <__ultoa_invert+0xe4>
                        v += hex;
700033a2:	4415      	add	r5, r2
                v += '0';
700033a4:	3530      	adds	r5, #48	; 0x30
    switch(base) {
700033a6:	2c08      	cmp	r4, #8
		*str++ = v;
700033a8:	f800 5b01 	strb.w	r5, [r0], #1
        *dig = val & 1;
700033ac:	fa5f fe8c 	uxtb.w	lr, ip
    switch(base) {
700033b0:	d1bc      	bne.n	7000332c <__ultoa_invert+0x18>
        return val >> 3;
700033b2:	ea4f 0cdc 	mov.w	ip, ip, lsr #3
700033b6:	ea4c 7c41 	orr.w	ip, ip, r1, lsl #29
        *dig = val & 7;
700033ba:	f00e 0307 	and.w	r3, lr, #7
        return val >> 3;
700033be:	08c9      	lsrs	r1, r1, #3
                v += '0';
700033c0:	3330      	adds	r3, #48	; 0x30
		*str++ = v;
700033c2:	f800 3b01 	strb.w	r3, [r0], #1
	} while (val);
700033c6:	ea5c 0301 	orrs.w	r3, ip, r1
700033ca:	d1ab      	bne.n	70003324 <__ultoa_invert+0x10>
	return str;
}
700033cc:	bd70      	pop	{r4, r5, r6, pc}
        return val >> 1;
700033ce:	ea4f 0c5c 	mov.w	ip, ip, lsr #1
700033d2:	ea4c 7cc1 	orr.w	ip, ip, r1, lsl #31
        *dig = val & 1;
700033d6:	f00e 0301 	and.w	r3, lr, #1
        return val >> 1;
700033da:	0849      	lsrs	r1, r1, #1
		if (v > 9)
700033dc:	e7f0      	b.n	700033c0 <__ultoa_invert+0xac>
        *dig = val & 15;
700033de:	f00e 030f 	and.w	r3, lr, #15
		if (v > 9)
700033e2:	2b09      	cmp	r3, #9
                        v += hex;
700033e4:	bf88      	it	hi
700033e6:	189b      	addhi	r3, r3, r2
        return val >> 4;
700033e8:	ea4f 1c1c 	mov.w	ip, ip, lsr #4
700033ec:	ea4c 7c01 	orr.w	ip, ip, r1, lsl #28
                        v += hex;
700033f0:	bf88      	it	hi
700033f2:	b2db      	uxtbhi	r3, r3
        return val >> 4;
700033f4:	0909      	lsrs	r1, r1, #4
		if (v > 9)
700033f6:	e7e3      	b.n	700033c0 <__ultoa_invert+0xac>
                v += '0';
700033f8:	3326      	adds	r3, #38	; 0x26
        *dig = val & 1;
700033fa:	fa5f fe8c 	uxtb.w	lr, ip
		*str++ = v;
700033fe:	f800 3b01 	strb.w	r3, [r0], #1
    switch(base) {
70003402:	e793      	b.n	7000332c <__ultoa_invert+0x18>

70003404 <skip_to_arg>:
 * and types to slowly walk the argument vector until it points at the
 * target_argno so that the outer printf code can then extract it.
 */
static void
skip_to_arg(const CHAR *fmt_orig, my_va_list *ap, int target_argno)
{
70003404:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
    unsigned c;		/* holds a char from the format string */
    uint16_t flags;
    int current_argno = 1;
70003408:	f04f 0e01 	mov.w	lr, #1
7000340c:	4603      	mov	r3, r0
    int argno;
    int width;
    const CHAR *fmt = fmt_orig;

    while (current_argno < target_argno) {
7000340e:	4572      	cmp	r2, lr
70003410:	dc02      	bgt.n	70003418 <skip_to_arg+0x14>
70003412:	e006      	b.n	70003422 <skip_to_arg+0x1e>
        for (;;) {
            c = *fmt++;
            if (!c) return;
            if (c == '%') {
70003414:	2c25      	cmp	r4, #37	; 0x25
70003416:	d006      	beq.n	70003426 <skip_to_arg+0x22>
70003418:	469c      	mov	ip, r3
            c = *fmt++;
7000341a:	f813 4b01 	ldrb.w	r4, [r3], #1
            if (!c) return;
7000341e:	2c00      	cmp	r4, #0
70003420:	d1f8      	bne.n	70003414 <skip_to_arg+0x10>
            }
            ++current_argno;
            fmt = fmt_orig;
        }
    }
}
70003422:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
                c = *fmt++;
70003426:	781c      	ldrb	r4, [r3, #0]
                if (c != '%') break;
70003428:	2c25      	cmp	r4, #37	; 0x25
                c = *fmt++;
7000342a:	f10c 0c02 	add.w	ip, ip, #2
7000342e:	4663      	mov	r3, ip
                if (c != '%') break;
70003430:	d0f2      	beq.n	70003418 <skip_to_arg+0x14>
        width = 0;
70003432:	2600      	movs	r6, #0
		switch (c) {
70003434:	f642 0789 	movw	r7, #10377	; 0x2889
        argno = 0;
70003438:	46b0      	mov	r8, r6
		switch (c) {
7000343a:	f2c0 0701 	movt	r7, #1
        flags = 0;
7000343e:	4633      	mov	r3, r6
	    if (flags < FL_WIDTH) {
70003440:	2b1f      	cmp	r3, #31
70003442:	d847      	bhi.n	700034d4 <skip_to_arg+0xd0>
		switch (c) {
70003444:	f1a4 0520 	sub.w	r5, r4, #32
70003448:	2d10      	cmp	r5, #16
7000344a:	d856      	bhi.n	700034fa <skip_to_arg+0xf6>
7000344c:	fa27 f505 	lsr.w	r5, r7, r5
70003450:	07ed      	lsls	r5, r5, #31
70003452:	d434      	bmi.n	700034be <skip_to_arg+0xba>
		if (c >= '0' && c <= '9') {
70003454:	f1a4 0530 	sub.w	r5, r4, #48	; 0x30
70003458:	2d09      	cmp	r5, #9
7000345a:	d952      	bls.n	70003502 <skip_to_arg+0xfe>
                if (c == '$') {
7000345c:	2c24      	cmp	r4, #36	; 0x24
7000345e:	d10a      	bne.n	70003476 <skip_to_arg+0x72>
                    if (argno) {
70003460:	f1b8 0f00 	cmp.w	r8, #0
70003464:	d053      	beq.n	7000350e <skip_to_arg+0x10a>
                        if (width == current_argno) {
70003466:	4576      	cmp	r6, lr
70003468:	d137      	bne.n	700034da <skip_to_arg+0xd6>
                SKIP_FLOAT_ARG(flags, ap->ap);
7000346a:	680d      	ldr	r5, [r1, #0]
                arg_to_unsigned(ap->ap, flags, x);
7000346c:	3504      	adds	r5, #4
                SKIP_FLOAT_ARG(flags, ap->ap);
7000346e:	600d      	str	r5, [r1, #0]
            ++current_argno;
70003470:	f10e 0e01 	add.w	lr, lr, #1
            fmt = fmt_orig;
70003474:	e7ca      	b.n	7000340c <skip_to_arg+0x8>
		if (c == '*') {
70003476:	f024 0504 	bic.w	r5, r4, #4
		if (c == '.') {
7000347a:	2d2a      	cmp	r5, #42	; 0x2a
7000347c:	d02d      	beq.n	700034da <skip_to_arg+0xd6>
            CHECK_INT_SIZES(c, flags);
7000347e:	f1a4 054c 	sub.w	r5, r4, #76	; 0x4c
70003482:	2d2e      	cmp	r5, #46	; 0x2e
70003484:	d81f      	bhi.n	700034c6 <skip_to_arg+0xc2>
70003486:	e8df f005 	tbb	[pc, r5]
7000348a:	1e18      	.short	0x1e18
7000348c:	1e1e1e1e 	.word	0x1e1e1e1e
70003490:	1e1e1e1e 	.word	0x1e1e1e1e
70003494:	1e1e1e1e 	.word	0x1e1e1e1e
70003498:	1e1e1e1e 	.word	0x1e1e1e1e
7000349c:	1e1e1e1e 	.word	0x1e1e1e1e
700034a0:	1e1e1e1e 	.word	0x1e1e1e1e
700034a4:	1e2a1e1e 	.word	0x1e2a1e1e
700034a8:	1e311e18 	.word	0x1e311e18
700034ac:	1e1e1e1e 	.word	0x1e1e1e1e
700034b0:	1e1a1e1e 	.word	0x1e1a1e1e
700034b4:	1e1e1e1e 	.word	0x1e1e1e1e
700034b8:	1a          	.byte	0x1a
700034b9:	00          	.byte	0x00
700034ba:	f443 7320 	orr.w	r3, r3, #640	; 0x280
	} while ( (c = *fmt++) != 0);
700034be:	f81c 4b01 	ldrb.w	r4, [ip], #1
700034c2:	2c00      	cmp	r4, #0
700034c4:	d1bc      	bne.n	70003440 <skip_to_arg+0x3c>
        if (argno == 0)
700034c6:	f1b8 0f00 	cmp.w	r8, #0
700034ca:	d0aa      	beq.n	70003422 <skip_to_arg+0x1e>
        if (argno == current_argno) {
700034cc:	45f0      	cmp	r8, lr
700034ce:	d021      	beq.n	70003514 <skip_to_arg+0x110>
700034d0:	4663      	mov	r3, ip
700034d2:	e79c      	b.n	7000340e <skip_to_arg+0xa>
	    if (flags < FL_LONG) {
700034d4:	2b7f      	cmp	r3, #127	; 0x7f
700034d6:	d8d2      	bhi.n	7000347e <skip_to_arg+0x7a>
700034d8:	e7bc      	b.n	70003454 <skip_to_arg+0x50>
                    width = 0;
700034da:	2600      	movs	r6, #0
700034dc:	e7ef      	b.n	700034be <skip_to_arg+0xba>
            CHECK_INT_SIZES(c, flags);
700034de:	05dd      	lsls	r5, r3, #23
700034e0:	bf48      	it	mi
700034e2:	f443 7300 	orrmi.w	r3, r3, #512	; 0x200
700034e6:	f443 7380 	orr.w	r3, r3, #256	; 0x100
700034ea:	e7e8      	b.n	700034be <skip_to_arg+0xba>
700034ec:	061c      	lsls	r4, r3, #24
700034ee:	bf48      	it	mi
700034f0:	f443 7300 	orrmi.w	r3, r3, #512	; 0x200
700034f4:	f043 0380 	orr.w	r3, r3, #128	; 0x80
700034f8:	e7e1      	b.n	700034be <skip_to_arg+0xba>
		if (c >= '0' && c <= '9') {
700034fa:	f1a4 0530 	sub.w	r5, r4, #48	; 0x30
700034fe:	2d09      	cmp	r5, #9
70003500:	d8b9      	bhi.n	70003476 <skip_to_arg+0x72>
                    flags |= FL_WIDTH;
70003502:	2320      	movs	r3, #32
                    width = 10 * width + c;
70003504:	eb06 0686 	add.w	r6, r6, r6, lsl #2
70003508:	eb05 0646 	add.w	r6, r5, r6, lsl #1
		    continue;
7000350c:	e7d7      	b.n	700034be <skip_to_arg+0xba>
7000350e:	46b0      	mov	r8, r6
                    width = 0;
70003510:	2600      	movs	r6, #0
70003512:	e7d4      	b.n	700034be <skip_to_arg+0xba>
                SKIP_FLOAT_ARG(flags, ap->ap);
70003514:	680d      	ldr	r5, [r1, #0]
            if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
70003516:	f044 0620 	orr.w	r6, r4, #32
                || TOLOWER(c) == 'a'
7000351a:	f1a6 0765 	sub.w	r7, r6, #101	; 0x65
            if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
7000351e:	2e61      	cmp	r6, #97	; 0x61
70003520:	bf18      	it	ne
70003522:	2f02      	cmpne	r7, #2
70003524:	d92e      	bls.n	70003584 <skip_to_arg+0x180>
            } else if (c == 'c') {
70003526:	3c63      	subs	r4, #99	; 0x63
70003528:	2c10      	cmp	r4, #16
7000352a:	d825      	bhi.n	70003578 <skip_to_arg+0x174>
7000352c:	a601      	add	r6, pc, #4	; (adr r6, 70003534 <skip_to_arg+0x130>)
7000352e:	f856 f024 	ldr.w	pc, [r6, r4, lsl #2]
70003532:	bf00      	nop
70003534:	7000346d 	.word	0x7000346d
70003538:	70003579 	.word	0x70003579
7000353c:	70003579 	.word	0x70003579
70003540:	70003579 	.word	0x70003579
70003544:	70003579 	.word	0x70003579
70003548:	70003579 	.word	0x70003579
7000354c:	70003579 	.word	0x70003579
70003550:	70003579 	.word	0x70003579
70003554:	70003579 	.word	0x70003579
70003558:	70003579 	.word	0x70003579
7000355c:	70003579 	.word	0x70003579
70003560:	70003579 	.word	0x70003579
70003564:	70003579 	.word	0x70003579
70003568:	70003579 	.word	0x70003579
7000356c:	70003579 	.word	0x70003579
70003570:	70003579 	.word	0x70003579
70003574:	7000346d 	.word	0x7000346d
                arg_to_unsigned(ap->ap, flags, x);
70003578:	061c      	lsls	r4, r3, #24
7000357a:	f57f af77 	bpl.w	7000346c <skip_to_arg+0x68>
7000357e:	059b      	lsls	r3, r3, #22
70003580:	f57f af74 	bpl.w	7000346c <skip_to_arg+0x68>
70003584:	3507      	adds	r5, #7
70003586:	f025 0507 	bic.w	r5, r5, #7
7000358a:	3508      	adds	r5, #8
7000358c:	e76f      	b.n	7000346e <skip_to_arg+0x6a>
7000358e:	bf00      	nop

70003590 <__l_vfprintf>:
    return len;
}
#endif

int vfprintf (FILE * stream, const CHAR *fmt, va_list ap_orig)
{
70003590:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    int (*put)(char, FILE *) = stream->put;
#define my_putc(c, stream) do { ++stream_len; if (put(c, stream) < 0) goto fail; } while(0)
#endif
#endif

    if ((stream->flags & __SWR) == 0)
70003594:	7883      	ldrb	r3, [r0, #2]
    int (*put)(char, FILE *) = stream->put;
70003596:	f8d0 b004 	ldr.w	fp, [r0, #4]
    if ((stream->flags & __SWR) == 0)
7000359a:	079e      	lsls	r6, r3, #30
{
7000359c:	b09b      	sub	sp, #108	; 0x6c
    if ((stream->flags & __SWR) == 0)
7000359e:	f140 836c 	bpl.w	70003c7a <__l_vfprintf+0x6ea>
700035a2:	4607      	mov	r7, r0
#endif

    for (;;) {

	for (;;) {
	    c = *fmt++;
700035a4:	460b      	mov	r3, r1
    va_copy(ap, ap_orig);
700035a6:	9209      	str	r2, [sp, #36]	; 0x24
	    c = *fmt++;
700035a8:	4696      	mov	lr, r2
700035aa:	f813 0b01 	ldrb.w	r0, [r3], #1
	    if (!c) goto ret;
700035ae:	2800      	cmp	r0, #0
700035b0:	f000 835a 	beq.w	70003c68 <__l_vfprintf+0x6d8>
700035b4:	460d      	mov	r5, r1
    int stream_len = 0;
700035b6:	2400      	movs	r4, #0
700035b8:	e9cd 1203 	strd	r1, r2, [sp, #12]
700035bc:	e00a      	b.n	700035d4 <__l_vfprintf+0x44>
	    if (c == '%') {
		c = *fmt++;
		if (c != '%') break;
	    }
	    my_putc (c, stream);
700035be:	4639      	mov	r1, r7
700035c0:	b2c0      	uxtb	r0, r0
700035c2:	461d      	mov	r5, r3
700035c4:	47d8      	blx	fp
700035c6:	3401      	adds	r4, #1
700035c8:	2800      	cmp	r0, #0
700035ca:	db10      	blt.n	700035ee <__l_vfprintf+0x5e>
	    c = *fmt++;
700035cc:	462b      	mov	r3, r5
700035ce:	f813 0b01 	ldrb.w	r0, [r3], #1
	    if (!c) goto ret;
700035d2:	b190      	cbz	r0, 700035fa <__l_vfprintf+0x6a>
	    if (c == '%') {
700035d4:	2825      	cmp	r0, #37	; 0x25
700035d6:	d1f2      	bne.n	700035be <__l_vfprintf+0x2e>
		c = *fmt++;
700035d8:	f105 0802 	add.w	r8, r5, #2
700035dc:	786d      	ldrb	r5, [r5, #1]
		if (c != '%') break;
700035de:	2d25      	cmp	r5, #37	; 0x25
700035e0:	d10f      	bne.n	70003602 <__l_vfprintf+0x72>
	    my_putc (c, stream);
700035e2:	4639      	mov	r1, r7
		c = *fmt++;
700035e4:	4645      	mov	r5, r8
	    my_putc (c, stream);
700035e6:	47d8      	blx	fp
700035e8:	3401      	adds	r4, #1
700035ea:	2800      	cmp	r0, #0
700035ec:	daee      	bge.n	700035cc <__l_vfprintf+0x3c>
#endif
    return stream_len;
#undef my_putc
#undef ap
  fail:
    stream->flags |= __SERR;
700035ee:	78bb      	ldrb	r3, [r7, #2]
    stream_len = -1;
700035f0:	f04f 34ff 	mov.w	r4, #4294967295	; 0xffffffff
    stream->flags |= __SERR;
700035f4:	f043 0304 	orr.w	r3, r3, #4
700035f8:	70bb      	strb	r3, [r7, #2]
    goto ret;
}
700035fa:	4620      	mov	r0, r4
700035fc:	b01b      	add	sp, #108	; 0x6c
700035fe:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
        argno = 0;
70003602:	f04f 0a00 	mov.w	sl, #0
	width = 0;
70003606:	46d1      	mov	r9, sl
	flags = 0;
70003608:	4656      	mov	r6, sl
	prec = 0;
7000360a:	f8cd a004 	str.w	sl, [sp, #4]
	    if (flags < FL_WIDTH) {
7000360e:	2e1f      	cmp	r6, #31
70003610:	d857      	bhi.n	700036c2 <__l_vfprintf+0x132>
		switch (c) {
70003612:	f1a5 0320 	sub.w	r3, r5, #32
70003616:	2b10      	cmp	r3, #16
70003618:	d80a      	bhi.n	70003630 <__l_vfprintf+0xa0>
7000361a:	e8df f003 	tbb	[pc, r3]
7000361e:	0946      	.short	0x0946
70003620:	09094909 	.word	0x09094909
70003624:	09091409 	.word	0x09091409
70003628:	4f094409 	.word	0x4f094409
7000362c:	0909      	.short	0x0909
7000362e:	4c          	.byte	0x4c
7000362f:	00          	.byte	0x00
		if (c >= '0' && c <= '9') {
70003630:	f1a5 0330 	sub.w	r3, r5, #48	; 0x30
70003634:	2b09      	cmp	r3, #9
70003636:	f200 80b0 	bhi.w	7000379a <__l_vfprintf+0x20a>
		    width = 10*width + c;
7000363a:	eb09 0989 	add.w	r9, r9, r9, lsl #2
		    flags |= FL_WIDTH;
7000363e:	f046 0620 	orr.w	r6, r6, #32
		    width = 10*width + c;
70003642:	eb03 0949 	add.w	r9, r3, r9, lsl #1
	} while ( (c = *fmt++) != 0);
70003646:	f818 5b01 	ldrb.w	r5, [r8], #1
7000364a:	2d00      	cmp	r5, #0
7000364c:	d1df      	bne.n	7000360e <__l_vfprintf+0x7e>
        if (argno) {
7000364e:	9502      	str	r5, [sp, #8]
70003650:	2320      	movs	r3, #32
70003652:	f1ba 0f00 	cmp.w	sl, #0
70003656:	f040 80c9 	bne.w	700037ec <__l_vfprintf+0x25c>
	if (prec < 0) {
7000365a:	9a01      	ldr	r2, [sp, #4]
7000365c:	2a00      	cmp	r2, #0
	    prec = 0;
7000365e:	bfbf      	itttt	lt
70003660:	2200      	movlt	r2, #0
	    flags &= ~FL_PREC;
70003662:	f026 0640 	biclt.w	r6, r6, #64	; 0x40
	    prec = 0;
70003666:	9201      	strlt	r2, [sp, #4]
	    flags &= ~FL_PREC;
70003668:	b2b6      	uxthlt	r6, r6
	if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
7000366a:	9a02      	ldr	r2, [sp, #8]
7000366c:	2a00      	cmp	r2, #0
7000366e:	f040 80f1 	bne.w	70003854 <__l_vfprintf+0x2c4>
            if (c == 'c') {
70003672:	f1a5 0263 	sub.w	r2, r5, #99	; 0x63
70003676:	2a12      	cmp	r2, #18
70003678:	f200 8141 	bhi.w	700038fe <__l_vfprintf+0x36e>
7000367c:	e8df f012 	tbh	[pc, r2, lsl #1]
70003680:	0158018e 	.word	0x0158018e
70003684:	013f013f 	.word	0x013f013f
70003688:	013f013f 	.word	0x013f013f
7000368c:	013f0158 	.word	0x013f0158
70003690:	013f013f 	.word	0x013f013f
70003694:	013f013f 	.word	0x013f013f
70003698:	019802cb 	.word	0x019802cb
7000369c:	013f013f 	.word	0x013f013f
700036a0:	013f01e5 	.word	0x013f01e5
700036a4:	01e0      	.short	0x01e0
		    flags |= FL_PLUS;
700036a6:	f046 0602 	orr.w	r6, r6, #2
		    flags |= FL_SPACE;
700036aa:	f046 0604 	orr.w	r6, r6, #4
		    continue;
700036ae:	e7ca      	b.n	70003646 <__l_vfprintf+0xb6>
		    flags |= FL_ALT;
700036b0:	f046 0610 	orr.w	r6, r6, #16
		    continue;
700036b4:	e7c7      	b.n	70003646 <__l_vfprintf+0xb6>
		    flags |= FL_ZFILL;
700036b6:	f046 0601 	orr.w	r6, r6, #1
		    continue;
700036ba:	e7c4      	b.n	70003646 <__l_vfprintf+0xb6>
		    flags |= FL_LPAD;
700036bc:	f046 0608 	orr.w	r6, r6, #8
		    continue;
700036c0:	e7c1      	b.n	70003646 <__l_vfprintf+0xb6>
	    if (flags < FL_LONG) {
700036c2:	2e7f      	cmp	r6, #127	; 0x7f
700036c4:	f240 82eb 	bls.w	70003c9e <__l_vfprintf+0x70e>
            CHECK_INT_SIZES(c, flags);
700036c8:	f1a5 034c 	sub.w	r3, r5, #76	; 0x4c
700036cc:	2b2e      	cmp	r3, #46	; 0x2e
700036ce:	d87e      	bhi.n	700037ce <__l_vfprintf+0x23e>
700036d0:	a201      	add	r2, pc, #4	; (adr r2, 700036d8 <__l_vfprintf+0x148>)
700036d2:	f852 f023 	ldr.w	pc, [r2, r3, lsl #2]
700036d6:	bf00      	nop
700036d8:	70003795 	.word	0x70003795
700036dc:	700037cf 	.word	0x700037cf
700036e0:	700037cf 	.word	0x700037cf
700036e4:	700037cf 	.word	0x700037cf
700036e8:	700037cf 	.word	0x700037cf
700036ec:	700037cf 	.word	0x700037cf
700036f0:	700037cf 	.word	0x700037cf
700036f4:	700037cf 	.word	0x700037cf
700036f8:	700037cf 	.word	0x700037cf
700036fc:	700037cf 	.word	0x700037cf
70003700:	700037cf 	.word	0x700037cf
70003704:	700037cf 	.word	0x700037cf
70003708:	700037cf 	.word	0x700037cf
7000370c:	700037cf 	.word	0x700037cf
70003710:	700037cf 	.word	0x700037cf
70003714:	700037cf 	.word	0x700037cf
70003718:	700037cf 	.word	0x700037cf
7000371c:	700037cf 	.word	0x700037cf
70003720:	700037cf 	.word	0x700037cf
70003724:	700037cf 	.word	0x700037cf
70003728:	700037cf 	.word	0x700037cf
7000372c:	700037cf 	.word	0x700037cf
70003730:	700037cf 	.word	0x700037cf
70003734:	700037cf 	.word	0x700037cf
70003738:	700037cf 	.word	0x700037cf
7000373c:	700037cf 	.word	0x700037cf
70003740:	700037cf 	.word	0x700037cf
70003744:	700037cf 	.word	0x700037cf
70003748:	7000380f 	.word	0x7000380f
7000374c:	700037cf 	.word	0x700037cf
70003750:	70003795 	.word	0x70003795
70003754:	700037cf 	.word	0x700037cf
70003758:	70003801 	.word	0x70003801
7000375c:	700037cf 	.word	0x700037cf
70003760:	700037cf 	.word	0x700037cf
70003764:	700037cf 	.word	0x700037cf
70003768:	700037cf 	.word	0x700037cf
7000376c:	700037cf 	.word	0x700037cf
70003770:	700037cf 	.word	0x700037cf
70003774:	700037cf 	.word	0x700037cf
70003778:	70003647 	.word	0x70003647
7000377c:	700037cf 	.word	0x700037cf
70003780:	700037cf 	.word	0x700037cf
70003784:	700037cf 	.word	0x700037cf
70003788:	700037cf 	.word	0x700037cf
7000378c:	700037cf 	.word	0x700037cf
70003790:	70003647 	.word	0x70003647
70003794:	f446 7620 	orr.w	r6, r6, #640	; 0x280
70003798:	e755      	b.n	70003646 <__l_vfprintf+0xb6>
		if (c == '*') {
7000379a:	2d2a      	cmp	r5, #42	; 0x2a
7000379c:	d03e      	beq.n	7000381c <__l_vfprintf+0x28c>
		if (c == '.') {
7000379e:	2d2e      	cmp	r5, #46	; 0x2e
700037a0:	d052      	beq.n	70003848 <__l_vfprintf+0x2b8>
                if (c == '$') {
700037a2:	2d24      	cmp	r5, #36	; 0x24
700037a4:	d190      	bne.n	700036c8 <__l_vfprintf+0x138>
                    if (argno) {
700037a6:	f1ba 0f00 	cmp.w	sl, #0
700037aa:	f000 821c 	beq.w	70003be6 <__l_vfprintf+0x656>
                        va_copy(ap, ap_orig);
700037ae:	9b04      	ldr	r3, [sp, #16]
                        skip_to_arg(fmt_orig, &my_ap, (flags & FL_PREC) ? prec : width);
700037b0:	0672      	lsls	r2, r6, #25
                        va_copy(ap, ap_orig);
700037b2:	9309      	str	r3, [sp, #36]	; 0x24
                        skip_to_arg(fmt_orig, &my_ap, (flags & FL_PREC) ? prec : width);
700037b4:	f140 823d 	bpl.w	70003c32 <__l_vfprintf+0x6a2>
700037b8:	9a01      	ldr	r2, [sp, #4]
700037ba:	a909      	add	r1, sp, #36	; 0x24
700037bc:	9803      	ldr	r0, [sp, #12]
700037be:	f7ff fe21 	bl	70003404 <skip_to_arg>
                            prec = va_arg(ap, int);
700037c2:	9b09      	ldr	r3, [sp, #36]	; 0x24
700037c4:	1d1a      	adds	r2, r3, #4
700037c6:	9209      	str	r2, [sp, #36]	; 0x24
700037c8:	681b      	ldr	r3, [r3, #0]
700037ca:	9301      	str	r3, [sp, #4]
700037cc:	e73b      	b.n	70003646 <__l_vfprintf+0xb6>
	if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
700037ce:	f045 0320 	orr.w	r3, r5, #32
            || TOLOWER(c) == 'a'
700037d2:	f1a3 0265 	sub.w	r2, r3, #101	; 0x65
700037d6:	2b61      	cmp	r3, #97	; 0x61
700037d8:	bf18      	it	ne
700037da:	2a02      	cmpne	r2, #2
700037dc:	bf94      	ite	ls
700037de:	2201      	movls	r2, #1
700037e0:	2200      	movhi	r2, #0
700037e2:	9202      	str	r2, [sp, #8]
        if (argno) {
700037e4:	f1ba 0f00 	cmp.w	sl, #0
700037e8:	f43f af37 	beq.w	7000365a <__l_vfprintf+0xca>
            va_copy(ap, ap_orig);
700037ec:	9305      	str	r3, [sp, #20]
            skip_to_arg(fmt_orig, &my_ap, argno);
700037ee:	4652      	mov	r2, sl
            va_copy(ap, ap_orig);
700037f0:	9b04      	ldr	r3, [sp, #16]
            skip_to_arg(fmt_orig, &my_ap, argno);
700037f2:	a909      	add	r1, sp, #36	; 0x24
700037f4:	9803      	ldr	r0, [sp, #12]
            va_copy(ap, ap_orig);
700037f6:	9309      	str	r3, [sp, #36]	; 0x24
            skip_to_arg(fmt_orig, &my_ap, argno);
700037f8:	f7ff fe04 	bl	70003404 <skip_to_arg>
700037fc:	9b05      	ldr	r3, [sp, #20]
700037fe:	e72c      	b.n	7000365a <__l_vfprintf+0xca>
            CHECK_INT_SIZES(c, flags);
70003800:	0633      	lsls	r3, r6, #24
70003802:	bf48      	it	mi
70003804:	f446 7600 	orrmi.w	r6, r6, #512	; 0x200
70003808:	f046 0680 	orr.w	r6, r6, #128	; 0x80
7000380c:	e71b      	b.n	70003646 <__l_vfprintf+0xb6>
7000380e:	05f5      	lsls	r5, r6, #23
70003810:	bf48      	it	mi
70003812:	f446 7600 	orrmi.w	r6, r6, #512	; 0x200
70003816:	f446 7680 	orr.w	r6, r6, #256	; 0x100
7000381a:	e714      	b.n	70003646 <__l_vfprintf+0xb6>
                    if (argno)
7000381c:	f1ba 0f00 	cmp.w	sl, #0
70003820:	f47f af11 	bne.w	70003646 <__l_vfprintf+0xb6>
			prec = va_arg(ap, int);
70003824:	9b09      	ldr	r3, [sp, #36]	; 0x24
		    if (flags & FL_PREC) {
70003826:	0670      	lsls	r0, r6, #25
			prec = va_arg(ap, int);
70003828:	f103 0204 	add.w	r2, r3, #4
7000382c:	9209      	str	r2, [sp, #36]	; 0x24
		    if (flags & FL_PREC) {
7000382e:	d4cb      	bmi.n	700037c8 <__l_vfprintf+0x238>
			width = va_arg(ap, int);
70003830:	f8d3 9000 	ldr.w	r9, [r3]
			if (width < 0) {
70003834:	f1b9 0f00 	cmp.w	r9, #0
			flags |= FL_WIDTH;
70003838:	bfae      	itee	ge
7000383a:	f046 0620 	orrge.w	r6, r6, #32
			    width = -width;
7000383e:	f1c9 0900 	rsblt	r9, r9, #0
			    flags |= FL_LPAD;
70003842:	f046 0628 	orrlt.w	r6, r6, #40	; 0x28
70003846:	e6fe      	b.n	70003646 <__l_vfprintf+0xb6>
		    if (flags & FL_PREC)
70003848:	0671      	lsls	r1, r6, #25
7000384a:	f53f aed6 	bmi.w	700035fa <__l_vfprintf+0x6a>
		    flags |= FL_PREC;
7000384e:	f046 0640 	orr.w	r6, r6, #64	; 0x40
		    continue;
70003852:	e6f8      	b.n	70003646 <__l_vfprintf+0xb6>
            SKIP_FLOAT_ARG(flags, ap);
70003854:	9b09      	ldr	r3, [sp, #36]	; 0x24
	    pnt = "*float*";
70003856:	f245 0258 	movw	r2, #20568	; 0x5058
	    size = sizeof ("*float*") - 1;
7000385a:	f04f 0a07 	mov.w	sl, #7
	    pnt = "*float*";
7000385e:	f2c7 0200 	movt	r2, #28672	; 0x7000
            SKIP_FLOAT_ARG(flags, ap);
70003862:	3307      	adds	r3, #7
70003864:	f023 0307 	bic.w	r3, r3, #7
70003868:	3308      	adds	r3, #8
7000386a:	9309      	str	r3, [sp, #36]	; 0x24
                    while ((size_t) width > size) {
7000386c:	4649      	mov	r1, r9
                if (!(flags & FL_LPAD)) {
7000386e:	0730      	lsls	r0, r6, #28
70003870:	d419      	bmi.n	700038a6 <__l_vfprintf+0x316>
                    while ((size_t) width > size) {
70003872:	45ca      	cmp	sl, r9
70003874:	bf3e      	ittt	cc
70003876:	465d      	movcc	r5, fp
70003878:	4616      	movcc	r6, r2
7000387a:	46cb      	movcc	fp, r9
7000387c:	d303      	bcc.n	70003886 <__l_vfprintf+0x2f6>
7000387e:	e012      	b.n	700038a6 <__l_vfprintf+0x316>
70003880:	459a      	cmp	sl, r3
70003882:	d208      	bcs.n	70003896 <__l_vfprintf+0x306>
                        width--;
70003884:	4699      	mov	r9, r3
                        my_putc (' ', stream);
70003886:	4639      	mov	r1, r7
70003888:	2020      	movs	r0, #32
7000388a:	47a8      	blx	r5
                        width--;
7000388c:	f109 33ff 	add.w	r3, r9, #4294967295	; 0xffffffff
                        my_putc (' ', stream);
70003890:	2800      	cmp	r0, #0
70003892:	daf5      	bge.n	70003880 <__l_vfprintf+0x2f0>
70003894:	e6ab      	b.n	700035ee <__l_vfprintf+0x5e>
70003896:	4659      	mov	r1, fp
70003898:	3401      	adds	r4, #1
7000389a:	4632      	mov	r2, r6
7000389c:	440c      	add	r4, r1
7000389e:	46ab      	mov	fp, r5
700038a0:	eba4 0409 	sub.w	r4, r4, r9
                    while ((size_t) width > size) {
700038a4:	4619      	mov	r1, r3
                    while (size--)
700038a6:	4623      	mov	r3, r4
700038a8:	465e      	mov	r6, fp
700038aa:	4614      	mov	r4, r2
700038ac:	eb02 050a 	add.w	r5, r2, sl
700038b0:	4693      	mov	fp, r2
700038b2:	4699      	mov	r9, r3
700038b4:	9101      	str	r1, [sp, #4]
700038b6:	e005      	b.n	700038c4 <__l_vfprintf+0x334>
                        my_putc (*pnt++, stream);
700038b8:	f814 0b01 	ldrb.w	r0, [r4], #1
700038bc:	47b0      	blx	r6
700038be:	2800      	cmp	r0, #0
700038c0:	f6ff ae95 	blt.w	700035ee <__l_vfprintf+0x5e>
700038c4:	4639      	mov	r1, r7
                    while (size--)
700038c6:	42ac      	cmp	r4, r5
700038c8:	d1f6      	bne.n	700038b8 <__l_vfprintf+0x328>
700038ca:	465a      	mov	r2, fp
700038cc:	464b      	mov	r3, r9
700038ce:	9901      	ldr	r1, [sp, #4]
700038d0:	46a1      	mov	r9, r4
700038d2:	46b3      	mov	fp, r6
700038d4:	1a9b      	subs	r3, r3, r2
                width -= size;
700038d6:	eba1 060a 	sub.w	r6, r1, sl
700038da:	4499      	add	r9, r3
                while (prec > buf_len) {
700038dc:	464c      	mov	r4, r9
700038de:	444e      	add	r6, r9
700038e0:	465d      	mov	r5, fp
700038e2:	e004      	b.n	700038ee <__l_vfprintf+0x35e>
	    my_putc (' ', stream);
700038e4:	47a8      	blx	r5
700038e6:	3401      	adds	r4, #1
700038e8:	2800      	cmp	r0, #0
700038ea:	f6ff ae80 	blt.w	700035ee <__l_vfprintf+0x5e>
700038ee:	4639      	mov	r1, r7
700038f0:	1b33      	subs	r3, r6, r4
700038f2:	2020      	movs	r0, #32
	while (width-- > 0) {
700038f4:	2b00      	cmp	r3, #0
700038f6:	dcf5      	bgt.n	700038e4 <__l_vfprintf+0x354>
700038f8:	46ab      	mov	fp, r5
700038fa:	4645      	mov	r5, r8
700038fc:	e666      	b.n	700035cc <__l_vfprintf+0x3c>
                    } else if (TOLOWER(c) == 'x') {
700038fe:	2b78      	cmp	r3, #120	; 0x78
                        base = ('x' - c) | 16;
70003900:	bf04      	itt	eq
70003902:	f1c5 0378 	rsbeq	r3, r5, #120	; 0x78
70003906:	f043 0310 	orreq.w	r3, r3, #16
                    } else if (TOLOWER(c) == 'x') {
7000390a:	d055      	beq.n	700039b8 <__l_vfprintf+0x428>
                    } else if (TOLOWER(c) == 'b') {
7000390c:	2b62      	cmp	r3, #98	; 0x62
7000390e:	f000 81b2 	beq.w	70003c76 <__l_vfprintf+0x6e6>
                        my_putc('%', stream);
70003912:	4639      	mov	r1, r7
70003914:	2025      	movs	r0, #37	; 0x25
70003916:	47d8      	blx	fp
70003918:	2800      	cmp	r0, #0
7000391a:	f6ff ae68 	blt.w	700035ee <__l_vfprintf+0x5e>
                        my_putc(c, stream);
7000391e:	4628      	mov	r0, r5
70003920:	4639      	mov	r1, r7
70003922:	47d8      	blx	fp
70003924:	2800      	cmp	r0, #0
70003926:	f6ff ae62 	blt.w	700035ee <__l_vfprintf+0x5e>
7000392a:	4645      	mov	r5, r8
7000392c:	3402      	adds	r4, #2
7000392e:	e64d      	b.n	700035cc <__l_vfprintf+0x3c>
            SKIP_FLOAT_ARG(flags, ap);
70003930:	9b09      	ldr	r3, [sp, #36]	; 0x24
                    arg_to_signed(ap, flags, x_s);
70003932:	0632      	lsls	r2, r6, #24
70003934:	f100 8172 	bmi.w	70003c1c <__l_vfprintf+0x68c>
70003938:	1d1a      	adds	r2, r3, #4
7000393a:	05f1      	lsls	r1, r6, #23
7000393c:	9209      	str	r2, [sp, #36]	; 0x24
7000393e:	681a      	ldr	r2, [r3, #0]
70003940:	bf5c      	itt	pl
70003942:	4610      	movpl	r0, r2
70003944:	17c2      	asrpl	r2, r0, #31
70003946:	d507      	bpl.n	70003958 <__l_vfprintf+0x3c8>
70003948:	05b3      	lsls	r3, r6, #22
7000394a:	bf4b      	itete	mi
7000394c:	b250      	sxtbmi	r0, r2
7000394e:	b210      	sxthpl	r0, r2
70003950:	f342 12c0 	sbfxmi	r2, r2, #7, #1
70003954:	f342 32c0 	sbfxpl	r2, r2, #15, #1
                    if (x_s < 0) {
70003958:	f026 0110 	bic.w	r1, r6, #16
7000395c:	2a00      	cmp	r2, #0
7000395e:	fa1f fa81 	uxth.w	sl, r1
70003962:	f2c0 8171 	blt.w	70003c48 <__l_vfprintf+0x6b8>
                    if (x_s == 0 && (flags & FL_PREC) && prec == 0)
70003966:	ea50 0102 	orrs.w	r1, r0, r2
7000396a:	f040 8190 	bne.w	70003c8e <__l_vfprintf+0x6fe>
7000396e:	9a01      	ldr	r2, [sp, #4]
70003970:	f3c6 1380 	ubfx	r3, r6, #6, #1
70003974:	2a00      	cmp	r2, #0
70003976:	bf14      	ite	ne
70003978:	2300      	movne	r3, #0
7000397a:	f003 0301 	andeq.w	r3, r3, #1
7000397e:	f006 0240 	and.w	r2, r6, #64	; 0x40
70003982:	9202      	str	r2, [sp, #8]
70003984:	2b00      	cmp	r3, #0
70003986:	f040 817b 	bne.w	70003c80 <__l_vfprintf+0x6f0>
7000398a:	4618      	mov	r0, r3
7000398c:	4619      	mov	r1, r3
                        buf_len = __ultoa_invert (x_s, buf, 10) - buf;
7000398e:	230a      	movs	r3, #10
70003990:	ae0a      	add	r6, sp, #40	; 0x28
70003992:	4632      	mov	r2, r6
70003994:	f7ff fcbe 	bl	70003314 <__ultoa_invert>
70003998:	1b83      	subs	r3, r0, r6
7000399a:	e03a      	b.n	70003a12 <__l_vfprintf+0x482>
                buf[0] = va_arg (ap, int);
7000399c:	9b09      	ldr	r3, [sp, #36]	; 0x24
                size = 1;
7000399e:	f04f 0a01 	mov.w	sl, #1
                pnt = buf;
700039a2:	aa0a      	add	r2, sp, #40	; 0x28
                buf[0] = va_arg (ap, int);
700039a4:	1d19      	adds	r1, r3, #4
700039a6:	9109      	str	r1, [sp, #36]	; 0x24
700039a8:	681b      	ldr	r3, [r3, #0]
700039aa:	f88d 3028 	strb.w	r3, [sp, #40]	; 0x28
                goto str_lpad;
700039ae:	e75d      	b.n	7000386c <__l_vfprintf+0x2dc>
                        base = 16;
700039b0:	2310      	movs	r3, #16
                        flags |= FL_ALT;
700039b2:	f046 0610 	orr.w	r6, r6, #16
                        c = 'x';
700039b6:	2578      	movs	r5, #120	; 0x78
            SKIP_FLOAT_ARG(flags, ap);
700039b8:	9a09      	ldr	r2, [sp, #36]	; 0x24
                    arg_to_unsigned(ap, flags, x);
700039ba:	f016 0c80 	ands.w	ip, r6, #128	; 0x80
700039be:	f000 80a2 	beq.w	70003b06 <__l_vfprintf+0x576>
700039c2:	f416 7100 	ands.w	r1, r6, #512	; 0x200
700039c6:	bf1d      	ittte	ne
700039c8:	3207      	addne	r2, #7
700039ca:	f022 0207 	bicne.w	r2, r2, #7
700039ce:	f102 0108 	addne.w	r1, r2, #8
700039d2:	1d10      	addeq	r0, r2, #4
700039d4:	bf15      	itete	ne
700039d6:	9109      	strne	r1, [sp, #36]	; 0x24
700039d8:	9009      	streq	r0, [sp, #36]	; 0x24
700039da:	e9d2 0100 	ldrdne	r0, r1, [r2]
700039de:	6810      	ldreq	r0, [r2, #0]
                    if (x == 0)
700039e0:	ea50 0201 	orrs.w	r2, r0, r1
700039e4:	f040 80c5 	bne.w	70003b72 <__l_vfprintf+0x5e2>
                    if (x == 0 && (flags & FL_PREC) && prec == 0)
700039e8:	9a01      	ldr	r2, [sp, #4]
                        flags &= ~FL_ALT;
700039ea:	f026 0c16 	bic.w	ip, r6, #22
                    if (x == 0 && (flags & FL_PREC) && prec == 0)
700039ee:	fab2 f282 	clz	r2, r2
                        flags &= ~FL_ALT;
700039f2:	fa1f fa8c 	uxth.w	sl, ip
                    if (x == 0 && (flags & FL_PREC) && prec == 0)
700039f6:	0952      	lsrs	r2, r2, #5
700039f8:	f006 0c40 	and.w	ip, r6, #64	; 0x40
700039fc:	ea12 1296 	ands.w	r2, r2, r6, lsr #6
70003a00:	f8cd c008 	str.w	ip, [sp, #8]
70003a04:	f040 8129 	bne.w	70003c5a <__l_vfprintf+0x6ca>
                        buf_len = __ultoa_invert (x, buf, base) - buf;
70003a08:	ae0a      	add	r6, sp, #40	; 0x28
70003a0a:	4632      	mov	r2, r6
70003a0c:	f7ff fc82 	bl	70003314 <__ultoa_invert>
70003a10:	1b83      	subs	r3, r0, r6
                if (flags & FL_PREC) {
70003a12:	9a02      	ldr	r2, [sp, #8]
70003a14:	f00a 0c10 	and.w	ip, sl, #16
70003a18:	b37a      	cbz	r2, 70003a7a <__l_vfprintf+0x4ea>
                    if (len < prec) {
70003a1a:	9901      	ldr	r1, [sp, #4]
                    flags &= ~FL_ZFILL;
70003a1c:	f02a 0201 	bic.w	r2, sl, #1
                    if (len < prec) {
70003a20:	4299      	cmp	r1, r3
                    flags &= ~FL_ZFILL;
70003a22:	b292      	uxth	r2, r2
                    if (len < prec) {
70003a24:	bfdc      	itt	le
70003a26:	f00a 0c10 	andle.w	ip, sl, #16
                    flags &= ~FL_ZFILL;
70003a2a:	4692      	movle	sl, r2
                    if (len < prec) {
70003a2c:	dd25      	ble.n	70003a7a <__l_vfprintf+0x4ea>
                        if (c == '\0')
70003a2e:	2d00      	cmp	r5, #0
70003a30:	f040 80ea 	bne.w	70003c08 <__l_vfprintf+0x678>
                            flags &= ~FL_ALT;
70003a34:	f02a 0211 	bic.w	r2, sl, #17
70003a38:	fa1f fa82 	uxth.w	sl, r2
70003a3c:	9a01      	ldr	r2, [sp, #4]
70003a3e:	e071      	b.n	70003b24 <__l_vfprintf+0x594>
                        base = 10;
70003a40:	230a      	movs	r3, #10
                        flags &= ~FL_ALT;
70003a42:	f026 0610 	bic.w	r6, r6, #16
70003a46:	b2b6      	uxth	r6, r6
                        base = 10;
70003a48:	e7b6      	b.n	700039b8 <__l_vfprintf+0x428>
                    pnt = va_arg (ap, char *);
70003a4a:	9a09      	ldr	r2, [sp, #36]	; 0x24
                    pnt = "(null)";
70003a4c:	f245 0350 	movw	r3, #20560	; 0x5050
70003a50:	f2c7 0300 	movt	r3, #28672	; 0x7000
                    pnt = va_arg (ap, char *);
70003a54:	1d11      	adds	r1, r2, #4
70003a56:	9109      	str	r1, [sp, #36]	; 0x24
70003a58:	6812      	ldr	r2, [r2, #0]
                size = strnlen (pnt, size);
70003a5a:	9901      	ldr	r1, [sp, #4]
                    pnt = "(null)";
70003a5c:	2a00      	cmp	r2, #0
70003a5e:	bf08      	it	eq
70003a60:	461a      	moveq	r2, r3
                size = strnlen (pnt, size);
70003a62:	4610      	mov	r0, r2
                size = (flags & FL_PREC) ? (size_t) prec : SIZE_MAX;
70003a64:	f016 0f40 	tst.w	r6, #64	; 0x40
                size = strnlen (pnt, size);
70003a68:	9201      	str	r2, [sp, #4]
70003a6a:	bf08      	it	eq
70003a6c:	f04f 31ff 	moveq.w	r1, #4294967295	; 0xffffffff
70003a70:	f7ff fc0a 	bl	70003288 <strnlen>
70003a74:	9a01      	ldr	r2, [sp, #4]
70003a76:	4682      	mov	sl, r0
70003a78:	e6f8      	b.n	7000386c <__l_vfprintf+0x2dc>
                if (flags & FL_ALT) {
70003a7a:	f1bc 0f00 	cmp.w	ip, #0
70003a7e:	d050      	beq.n	70003b22 <__l_vfprintf+0x592>
                    len += 1;
70003a80:	1c5a      	adds	r2, r3, #1
                    if (c != '\0')
70003a82:	b10d      	cbz	r5, 70003a88 <__l_vfprintf+0x4f8>
70003a84:	461a      	mov	r2, r3
                        len += 1;
70003a86:	3202      	adds	r2, #2
                if (!(flags & FL_LPAD)) {
70003a88:	f01a 0f08 	tst.w	sl, #8
                width -= len;
70003a8c:	bf18      	it	ne
70003a8e:	eba9 0602 	subne.w	r6, r9, r2
                if (!(flags & FL_LPAD)) {
70003a92:	d053      	beq.n	70003b3c <__l_vfprintf+0x5ac>
                    my_putc ('0', stream);
70003a94:	4639      	mov	r1, r7
70003a96:	2030      	movs	r0, #48	; 0x30
70003a98:	9302      	str	r3, [sp, #8]
70003a9a:	47d8      	blx	fp
70003a9c:	2800      	cmp	r0, #0
70003a9e:	f6ff ada6 	blt.w	700035ee <__l_vfprintf+0x5e>
                    if (c != '\0')
70003aa2:	9b02      	ldr	r3, [sp, #8]
70003aa4:	2d00      	cmp	r5, #0
70003aa6:	f040 8094 	bne.w	70003bd2 <__l_vfprintf+0x642>
                    my_putc ('0', stream);
70003aaa:	3401      	adds	r4, #1
                while (prec > buf_len) {
70003aac:	9a01      	ldr	r2, [sp, #4]
70003aae:	4293      	cmp	r3, r2
70003ab0:	bfa8      	it	ge
70003ab2:	4625      	movge	r5, r4
70003ab4:	da12      	bge.n	70003adc <__l_vfprintf+0x54c>
70003ab6:	9d01      	ldr	r5, [sp, #4]
70003ab8:	469a      	mov	sl, r3
70003aba:	4425      	add	r5, r4
70003abc:	1aed      	subs	r5, r5, r3
70003abe:	46a9      	mov	r9, r5
70003ac0:	465d      	mov	r5, fp
70003ac2:	e001      	b.n	70003ac8 <__l_vfprintf+0x538>
70003ac4:	45a1      	cmp	r9, r4
70003ac6:	d006      	beq.n	70003ad6 <__l_vfprintf+0x546>
                    my_putc ('0', stream);
70003ac8:	4639      	mov	r1, r7
70003aca:	2030      	movs	r0, #48	; 0x30
70003acc:	47a8      	blx	r5
70003ace:	3401      	adds	r4, #1
70003ad0:	2800      	cmp	r0, #0
70003ad2:	daf7      	bge.n	70003ac4 <__l_vfprintf+0x534>
70003ad4:	e58b      	b.n	700035ee <__l_vfprintf+0x5e>
70003ad6:	46ab      	mov	fp, r5
70003ad8:	4653      	mov	r3, sl
70003ada:	464d      	mov	r5, r9
70003adc:	46aa      	mov	sl, r5
70003ade:	ac0a      	add	r4, sp, #40	; 0x28
70003ae0:	465d      	mov	r5, fp
70003ae2:	eb04 0903 	add.w	r9, r4, r3
70003ae6:	469b      	mov	fp, r3
70003ae8:	e005      	b.n	70003af6 <__l_vfprintf+0x566>
                    my_putc (buf[--buf_len], stream);
70003aea:	f819 0d01 	ldrb.w	r0, [r9, #-1]!
70003aee:	47a8      	blx	r5
70003af0:	2800      	cmp	r0, #0
70003af2:	f6ff ad7c 	blt.w	700035ee <__l_vfprintf+0x5e>
70003af6:	4639      	mov	r1, r7
                while (buf_len)
70003af8:	45a1      	cmp	r9, r4
70003afa:	d1f6      	bne.n	70003aea <__l_vfprintf+0x55a>
70003afc:	465b      	mov	r3, fp
70003afe:	46ab      	mov	fp, r5
70003b00:	eb0a 0903 	add.w	r9, sl, r3
70003b04:	e6ea      	b.n	700038dc <__l_vfprintf+0x34c>
                    arg_to_unsigned(ap, flags, x);
70003b06:	1d11      	adds	r1, r2, #4
70003b08:	9109      	str	r1, [sp, #36]	; 0x24
70003b0a:	f416 7180 	ands.w	r1, r6, #256	; 0x100
70003b0e:	6810      	ldr	r0, [r2, #0]
70003b10:	f43f af66 	beq.w	700039e0 <__l_vfprintf+0x450>
70003b14:	f416 7100 	ands.w	r1, r6, #512	; 0x200
70003b18:	bf1a      	itte	ne
70003b1a:	4661      	movne	r1, ip
70003b1c:	b2c0      	uxtbne	r0, r0
70003b1e:	b280      	uxtheq	r0, r0
70003b20:	e75e      	b.n	700039e0 <__l_vfprintf+0x450>
70003b22:	461a      	mov	r2, r3
                if (!(flags & FL_LPAD)) {
70003b24:	f240 4106 	movw	r1, #1030	; 0x406
                } else if (flags & (FL_NEGATIVE | FL_PLUS | FL_SPACE)) {
70003b28:	ea1a 0101 	ands.w	r1, sl, r1
                    len += 1;
70003b2c:	bf18      	it	ne
70003b2e:	3201      	addne	r2, #1
                if (!(flags & FL_LPAD)) {
70003b30:	f01a 0c08 	ands.w	ip, sl, #8
                width -= len;
70003b34:	bf18      	it	ne
70003b36:	eba9 0602 	subne.w	r6, r9, r2
                if (!(flags & FL_LPAD)) {
70003b3a:	d135      	bne.n	70003ba8 <__l_vfprintf+0x618>
                    if (flags & FL_ZFILL) {
70003b3c:	f01a 0f01 	tst.w	sl, #1
70003b40:	d158      	bne.n	70003bf4 <__l_vfprintf+0x664>
                    while (len < width) {
70003b42:	4591      	cmp	r9, r2
70003b44:	f340 80a8 	ble.w	70003c98 <__l_vfprintf+0x708>
70003b48:	f8cd 8008 	str.w	r8, [sp, #8]
70003b4c:	eb09 0604 	add.w	r6, r9, r4
70003b50:	e9cd 3205 	strd	r3, r2, [sp, #20]
70003b54:	1ab6      	subs	r6, r6, r2
70003b56:	9407      	str	r4, [sp, #28]
70003b58:	46b0      	mov	r8, r6
70003b5a:	465e      	mov	r6, fp
70003b5c:	46e3      	mov	fp, ip
70003b5e:	e001      	b.n	70003b64 <__l_vfprintf+0x5d4>
70003b60:	45a0      	cmp	r8, r4
70003b62:	d00e      	beq.n	70003b82 <__l_vfprintf+0x5f2>
                        my_putc (' ', stream);
70003b64:	4639      	mov	r1, r7
70003b66:	2020      	movs	r0, #32
70003b68:	47b0      	blx	r6
70003b6a:	3401      	adds	r4, #1
70003b6c:	2800      	cmp	r0, #0
70003b6e:	daf7      	bge.n	70003b60 <__l_vfprintf+0x5d0>
70003b70:	e53d      	b.n	700035ee <__l_vfprintf+0x5e>
                    flags &= ~(FL_PLUS | FL_SPACE);
70003b72:	f026 0206 	bic.w	r2, r6, #6
70003b76:	f006 0640 	and.w	r6, r6, #64	; 0x40
70003b7a:	fa1f fa82 	uxth.w	sl, r2
70003b7e:	9602      	str	r6, [sp, #8]
70003b80:	e742      	b.n	70003a08 <__l_vfprintf+0x478>
                        len++;
70003b82:	e9dd 3205 	ldrd	r3, r2, [sp, #20]
70003b86:	46dc      	mov	ip, fp
70003b88:	9907      	ldr	r1, [sp, #28]
70003b8a:	46b3      	mov	fp, r6
70003b8c:	f8dd 8008 	ldr.w	r8, [sp, #8]
70003b90:	1a56      	subs	r6, r2, r1
70003b92:	4426      	add	r6, r4
                width -= len;
70003b94:	eba9 0606 	sub.w	r6, r9, r6
                if (flags & FL_ALT) {
70003b98:	f1bc 0f00 	cmp.w	ip, #0
70003b9c:	f47f af7a 	bne.w	70003a94 <__l_vfprintf+0x504>
70003ba0:	f240 4106 	movw	r1, #1030	; 0x406
70003ba4:	ea0a 0101 	and.w	r1, sl, r1
                } else if (flags & (FL_NEGATIVE | FL_PLUS | FL_SPACE)) {
70003ba8:	2900      	cmp	r1, #0
70003baa:	f43f af7f 	beq.w	70003aac <__l_vfprintf+0x51c>
                    my_putc (z, stream);
70003bae:	4639      	mov	r1, r7
                    if (flags & FL_PLUS) z = '+';
70003bb0:	f01a 0f02 	tst.w	sl, #2
70003bb4:	bf14      	ite	ne
70003bb6:	202b      	movne	r0, #43	; 0x2b
70003bb8:	2020      	moveq	r0, #32
                    if (flags & FL_NEGATIVE) z = '-';
70003bba:	9302      	str	r3, [sp, #8]
70003bbc:	f41a 6f80 	tst.w	sl, #1024	; 0x400
                    my_putc (z, stream);
70003bc0:	bf18      	it	ne
70003bc2:	202d      	movne	r0, #45	; 0x2d
70003bc4:	3401      	adds	r4, #1
70003bc6:	47d8      	blx	fp
70003bc8:	9b02      	ldr	r3, [sp, #8]
70003bca:	2800      	cmp	r0, #0
70003bcc:	f6bf af6e 	bge.w	70003aac <__l_vfprintf+0x51c>
70003bd0:	e50d      	b.n	700035ee <__l_vfprintf+0x5e>
                        my_putc (c, stream);
70003bd2:	4628      	mov	r0, r5
70003bd4:	4639      	mov	r1, r7
70003bd6:	9302      	str	r3, [sp, #8]
70003bd8:	47d8      	blx	fp
70003bda:	9b02      	ldr	r3, [sp, #8]
70003bdc:	3402      	adds	r4, #2
70003bde:	2800      	cmp	r0, #0
70003be0:	f6bf af64 	bge.w	70003aac <__l_vfprintf+0x51c>
70003be4:	e503      	b.n	700035ee <__l_vfprintf+0x5e>
70003be6:	464b      	mov	r3, r9
                        prec = 0;
70003be8:	4656      	mov	r6, sl
70003bea:	f8cd a004 	str.w	sl, [sp, #4]
                        width = 0;
70003bee:	46d1      	mov	r9, sl
70003bf0:	469a      	mov	sl, r3
70003bf2:	e528      	b.n	70003646 <__l_vfprintf+0xb6>
                        if (len < width) {
70003bf4:	4591      	cmp	r9, r2
                            prec += width - len;
70003bf6:	eba9 0602 	sub.w	r6, r9, r2
70003bfa:	bfd8      	it	le
70003bfc:	9301      	strle	r3, [sp, #4]
                        if (len < width) {
70003bfe:	ddcb      	ble.n	70003b98 <__l_vfprintf+0x608>
                            prec += width - len;
70003c00:	199a      	adds	r2, r3, r6
70003c02:	2600      	movs	r6, #0
70003c04:	9201      	str	r2, [sp, #4]
                            len = width;
70003c06:	e7c7      	b.n	70003b98 <__l_vfprintf+0x608>
                if (flags & FL_ALT) {
70003c08:	f01a 0c10 	ands.w	ip, sl, #16
70003c0c:	4692      	mov	sl, r2
                        len = prec;
70003c0e:	9a01      	ldr	r2, [sp, #4]
                if (flags & FL_ALT) {
70003c10:	f47f af39 	bne.w	70003a86 <__l_vfprintf+0x4f6>
70003c14:	e786      	b.n	70003b24 <__l_vfprintf+0x594>
	if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
70003c16:	2308      	movs	r3, #8
70003c18:	2500      	movs	r5, #0
70003c1a:	e6cd      	b.n	700039b8 <__l_vfprintf+0x428>
                    arg_to_signed(ap, flags, x_s);
70003c1c:	05b0      	lsls	r0, r6, #22
70003c1e:	d525      	bpl.n	70003c6c <__l_vfprintf+0x6dc>
70003c20:	3307      	adds	r3, #7
70003c22:	f023 0307 	bic.w	r3, r3, #7
70003c26:	f103 0208 	add.w	r2, r3, #8
70003c2a:	9209      	str	r2, [sp, #36]	; 0x24
70003c2c:	e9d3 0200 	ldrd	r0, r2, [r3]
70003c30:	e692      	b.n	70003958 <__l_vfprintf+0x3c8>
                        skip_to_arg(fmt_orig, &my_ap, (flags & FL_PREC) ? prec : width);
70003c32:	464a      	mov	r2, r9
70003c34:	a909      	add	r1, sp, #36	; 0x24
70003c36:	9803      	ldr	r0, [sp, #12]
70003c38:	f7ff fbe4 	bl	70003404 <skip_to_arg>
                            width = va_arg(ap, int);
70003c3c:	9b09      	ldr	r3, [sp, #36]	; 0x24
70003c3e:	1d1a      	adds	r2, r3, #4
70003c40:	9209      	str	r2, [sp, #36]	; 0x24
70003c42:	f8d3 9000 	ldr.w	r9, [r3]
70003c46:	e4fe      	b.n	70003646 <__l_vfprintf+0xb6>
                    flags &= ~FL_ALT;
70003c48:	f006 0340 	and.w	r3, r6, #64	; 0x40
                        x_s = -x_s;
70003c4c:	4240      	negs	r0, r0
                    flags &= ~FL_ALT;
70003c4e:	f44a 6a80 	orr.w	sl, sl, #1024	; 0x400
                    if (x_s == 0 && (flags & FL_PREC) && prec == 0)
70003c52:	9302      	str	r3, [sp, #8]
                        x_s = -x_s;
70003c54:	eb62 0142 	sbc.w	r1, r2, r2, lsl #1
70003c58:	e699      	b.n	7000398e <__l_vfprintf+0x3fe>
                        buf_len = 0;
70003c5a:	2200      	movs	r2, #0
                    flags &= ~FL_ZFILL;
70003c5c:	f026 0617 	bic.w	r6, r6, #23
                        buf_len = 0;
70003c60:	4613      	mov	r3, r2
                    flags &= ~FL_ZFILL;
70003c62:	fa1f fa86 	uxth.w	sl, r6
                if (flags & FL_ALT) {
70003c66:	e75d      	b.n	70003b24 <__l_vfprintf+0x594>
    int stream_len = 0;
70003c68:	4604      	mov	r4, r0
    return stream_len;
70003c6a:	e4c6      	b.n	700035fa <__l_vfprintf+0x6a>
                    arg_to_signed(ap, flags, x_s);
70003c6c:	1d1a      	adds	r2, r3, #4
70003c6e:	9209      	str	r2, [sp, #36]	; 0x24
70003c70:	6818      	ldr	r0, [r3, #0]
70003c72:	17c2      	asrs	r2, r0, #31
70003c74:	e670      	b.n	70003958 <__l_vfprintf+0x3c8>
                        base = 2;
70003c76:	2302      	movs	r3, #2
70003c78:	e69e      	b.n	700039b8 <__l_vfprintf+0x428>
	return EOF;
70003c7a:	f04f 34ff 	mov.w	r4, #4294967295	; 0xffffffff
70003c7e:	e4bc      	b.n	700035fa <__l_vfprintf+0x6a>
                        buf_len = 0;
70003c80:	2200      	movs	r2, #0
                    flags &= ~FL_ZFILL;
70003c82:	f026 0611 	bic.w	r6, r6, #17
                        buf_len = 0;
70003c86:	4613      	mov	r3, r2
                    flags &= ~FL_ZFILL;
70003c88:	fa1f fa86 	uxth.w	sl, r6
                if (flags & FL_ALT) {
70003c8c:	e74a      	b.n	70003b24 <__l_vfprintf+0x594>
                        buf_len = __ultoa_invert (x_s, buf, 10) - buf;
70003c8e:	4611      	mov	r1, r2
70003c90:	f006 0340 	and.w	r3, r6, #64	; 0x40
70003c94:	9302      	str	r3, [sp, #8]
70003c96:	e67a      	b.n	7000398e <__l_vfprintf+0x3fe>
                            prec += width - len;
70003c98:	eba9 0602 	sub.w	r6, r9, r2
70003c9c:	e77c      	b.n	70003b98 <__l_vfprintf+0x608>
		if (c >= '0' && c <= '9') {
70003c9e:	f1a5 0330 	sub.w	r3, r5, #48	; 0x30
70003ca2:	2b09      	cmp	r3, #9
70003ca4:	f63f ad79 	bhi.w	7000379a <__l_vfprintf+0x20a>
		    if (flags & FL_PREC) {
70003ca8:	0675      	lsls	r5, r6, #25
70003caa:	f57f acc6 	bpl.w	7000363a <__l_vfprintf+0xaa>
			prec = 10*prec + c;
70003cae:	9a01      	ldr	r2, [sp, #4]
70003cb0:	eb02 0282 	add.w	r2, r2, r2, lsl #2
70003cb4:	eb03 0342 	add.w	r3, r3, r2, lsl #1
70003cb8:	9301      	str	r3, [sp, #4]
			continue;
70003cba:	e4c4      	b.n	70003646 <__l_vfprintf+0xb6>

70003cbc <__file_str_put>:
         * overflow, instead it returns the total number of characters
         * processed but truncates the result to fit within the target
         * buffer. As a result, this function simply stops writing
         * when it reaches the end of the buffer
         */
	if (sstream->pos != sstream->end)
70003cbc:	e9d1 3204 	ldrd	r3, r2, [r1, #16]
70003cc0:	4293      	cmp	r3, r2
            *sstream->pos++ = c;
70003cc2:	bf1e      	ittt	ne
70003cc4:	1c5a      	addne	r2, r3, #1
70003cc6:	610a      	strne	r2, [r1, #16]
70003cc8:	7018      	strbne	r0, [r3, #0]
	return (unsigned char) c;
}
70003cca:	4770      	bx	lr
70003ccc:	0000      	movs	r0, r0
	...

70003cd0 <__z_arm_int_exit_from_thumb>:
70003cd0:	4778      	bx	pc
70003cd2:	e7fd      	b.n	70003cd0 <__z_arm_int_exit_from_thumb>
70003cd4:	eafff4e9 	b	70001080 <z_arm_int_exit>

Disassembly of section .boot_section:

00000000 <__boot_spring>:
 * @brief Initialisation of fault handling
 */
void z_arm_fault_init(void)
{
	/* Nothing to do for now */
}
   0:	e59fd004 	ldr	sp, [pc, #4]	; c <___thread_base_t_user_options_OFFSET>
	arch_system_halt(reason);
   4:	fa000024 	blx	9c <MpuP_init>
	handler = pHandler;
   8:	ea000056 	b	168 <____start_veneer>
};

void rsc_table_get(struct fw_resource_table **table_ptr, int *length)
{
	*table_ptr = &resource_table;
	*length = sizeof(resource_table);
   c:	70009d80 	.word	0x70009d80

00000010 <MpuP_setRegion>:
	cmp	r0, #0
	bne	_irq_disabled
	cpsie	i
_irq_disabled:

	bx	lr
  10:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
  12:	f893 c004 	ldrb.w	ip, [r3, #4]
{
	uint32_t *ssf_contents = ssf_ptr;
	struct arch_esf oops_esf = { 0 };

	/* TODO: Copy the rest of the register set out of ssf_ptr */
	oops_esf.basic.pc = ssf_contents[3];
  16:	f893 e000 	ldrb.w	lr, [r3]
	z_fatal_error(reason, esf);
  1a:	79de      	ldrb	r6, [r3, #7]
}
  1c:	4604      	mov	r4, r0
  1e:	ea4f 3c0c 	mov.w	ip, ip, lsl #12
   z_vim_irq_enable(irq);
  22:	7998      	ldrb	r0, [r3, #6]
  24:	0200      	lsls	r0, r0, #8
		(void) vfprintf(&console, fmt, ap);
  26:	f400 60e0 	and.w	r0, r0, #1792	; 0x700
}
  2a:	f40c 5c80 	and.w	ip, ip, #4096	; 0x1000
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	sys_write32(BIT(irq_bit_num), VIM_RAW(irq_group_num));
  2e:	ea4c 0c00 	orr.w	ip, ip, r0
  32:	7898      	ldrb	r0, [r3, #2]
  34:	f000 0001 	and.w	r0, r0, #1
  38:	ea4c 0c00 	orr.w	ip, ip, r0
}
  3c:	7958      	ldrb	r0, [r3, #5]
	return dev->state->initialized && (dev->state->init_res == 0U);
  3e:	00c0      	lsls	r0, r0, #3
		return NULL;
  40:	f000 0038 	and.w	r0, r0, #56	; 0x38
  44:	ea4c 0c00 	orr.w	ip, ip, r0
}
  48:	78d8      	ldrb	r0, [r3, #3]
		return NULL;
  4a:	0080      	lsls	r0, r0, #2
}
  4c:	f000 0004 	and.w	r0, r0, #4
	void *ret = sys_heap_aligned_realloc(&z_malloc_heap, ptr,
					     __alignof__(z_max_align_t),
					     requested_size);

	if (ret == NULL && requested_size != 0) {
		errno = ENOMEM;
  50:	f002 021f 	and.w	r2, r2, #31
  54:	ea4c 0c00 	orr.w	ip, ip, r0
	return z_impl_k_mutex_unlock(mutex);
  58:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
  5c:	1c55      	adds	r5, r2, #1
  5e:	f00e 0e01 	and.w	lr, lr, #1
	}

	malloc_unlock();

	return ret;
}
  62:	40a8      	lsls	r0, r5
  64:	ea01 0500 	and.w	r5, r1, r0
	slab->info.num_used--;

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_mem_slab, free, slab);

	k_spin_unlock(&slab->lock, key);
}
  68:	7858      	ldrb	r0, [r3, #1]
  6a:	0040      	lsls	r0, r0, #1
			z_reschedule(&slab->lock, key);
  6c:	ea4e 2e06 	orr.w	lr, lr, r6, lsl #8
	return list->head == list;
  70:	f000 0002 	and.w	r0, r0, #2
		if (unlikely(thread != NULL)) {
  74:	ea4c 0600 	orr.w	r6, ip, r0
  78:	ea4e 0742 	orr.w	r7, lr, r2, lsl #1

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_heap, realloc, heap, ptr, bytes, timeout, ret);

	k_spin_unlock(&heap->lock, key);
	return ret;
}
  7c:	f000 e85c 	blx	138 <MpuP_isEnableAsm>
  80:	4633      	mov	r3, r6
  82:	463a      	mov	r2, r7
}
  84:	4629      	mov	r1, r5
      {
         printk("Event %s Count: %u\r\n", p->events[j].name, p->events[j].value);
      }
      printk("\r\n");
   }
}
  86:	4606      	mov	r6, r0
  88:	4620      	mov	r0, r4
		wfe();
	}

	cpu_map[cpu_num] = cpu_mpid;

	printk("Secondary CPU core %d (MPID:%#x) is up\n", cpu_num, cpu_mpid);
  8a:	f000 e860 	blx	14c <MpuP_setRegionAsm>
  8e:	b906      	cbnz	r6, 92 <CONFIG_CONSOLE_INPUT_MAX_LINE_LEN+0x12>
}
  90:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
	node->prev = prev;
  92:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
	prev->next = node;
  96:	f000 b863 	b.w	160 <__MpuP_enableAsm_from_thumb>
}
  9a:	bf00      	nop

0000009c <MpuP_init>:
   /* Print PMU results for measurements */
   for (i = 0; i < ITERATION_COUNT; i++)
   {
      // printf("Receive Latency: ");
      // tm_pmu_profile_print(pmu_recv_names[i]);
      printf("Send Latency: ");
  9c:	b570      	push	{r4, r5, r6, lr}
   printf("Total interrupts processed: %lu\r\n", tm_isr_counter);
  9e:	f000 e830 	blx	100 <MpuP_disableBRAsm>
  a2:	f24b 36ec 	movw	r6, #46060	; 0xb3ec
      printf("Send Latency: ");
  a6:	f2c7 0600 	movt	r6, #28672	; 0x7000
      tm_pmu_profile_print(pmu_send_names[i]);
  aa:	6833      	ldr	r3, [r6, #0]
   for (i = 0; i < ITERATION_COUNT; i++)
  ac:	b163      	cbz	r3, c8 <MpuP_init+0x2c>
      tm_pmu_profile_print(pmu_send_names[i]);
  ae:	4c0d      	ldr	r4, [pc, #52]	; (e4 <__data_size+0xc>)
  b0:	2500      	movs	r5, #0
   for (i = 0; i < ITERATION_COUNT; i++)
  b2:	4623      	mov	r3, r4
  b4:	4628      	mov	r0, r5
   }

   tm_thread_suspend(0);
}
  b6:	e954 1202 	ldrd	r1, r2, [r4, #-8]
   tm_thread_suspend(0);
  ba:	3501      	adds	r5, #1
  bc:	f7ff ffa8 	bl	10 <MpuP_setRegion>
  c0:	6833      	ldr	r3, [r6, #0]
  c2:	3410      	adds	r4, #16
  c4:	42ab      	cmp	r3, r5
  c6:	d8f4      	bhi.n	b2 <MpuP_init+0x16>
                gMpuRegionConfig[i].size,
                &gMpuRegionConfig[i].attrs
        );
    }

    if (gMpuConfig.enableBackgroundRegion) {
  c8:	6873      	ldr	r3, [r6, #4]
  ca:	b913      	cbnz	r3, d2 <MpuP_init+0x36>
        MpuP_enableBRAsm();
    }

    if (gMpuConfig.enableMpu) {
  cc:	68b3      	ldr	r3, [r6, #8]
  ce:	b92b      	cbnz	r3, dc <__data_size+0x4>
	    MpuP_enableAsm();
    }
}
  d0:	bd70      	pop	{r4, r5, r6, pc}
        MpuP_enableBRAsm();
  d2:	f000 e82a 	blx	128 <MpuP_enableBRAsm>
    if (gMpuConfig.enableMpu) {
  d6:	68b3      	ldr	r3, [r6, #8]
  d8:	2b00      	cmp	r3, #0
  da:	d0f9      	beq.n	d0 <MpuP_init+0x34>
}
  dc:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	    MpuP_enableAsm();
  e0:	f000 b83e 	b.w	160 <__MpuP_enableAsm_from_thumb>
  e4:	7000b3a4 	.word	0x7000b3a4

000000e8 <MpuP_disableAsm>:
_ASM_FILE_PROLOGUE

/* FUNCTION DEF: void MpuP_disableAsm(void) */
GTEXT(MpuP_disableAsm)
SECTION_FUNC(boot_section, MpuP_disableAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
  e8:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        bic     r0, r0, #0x1             // clear bit 0 in r0
  ec:	e3c00001 	bic	r0, r0, #1
        dsb
  f0:	f57ff04f 	dsb	sy
        mcr     p15, #0, r0, c1, c0, #0  // MPU disabled (bit 0 = 0)
  f4:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        isb                              // flush instruction pipeline
  f8:	f57ff06f 	isb	sy
        bx      LR
  fc:	e12fff1e 	bx	lr

00000100 <MpuP_disableBRAsm>:

/* FUNCTION DEF: void MpuP_disableBRAsm(void) */
GTEXT(MpuP_disableBRAsm)
SECTION_FUNC(boot_section, MpuP_disableBRAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 100:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        bic     r0, r0, #0x20000         // clear bit 17 in r0
 104:	e3c00802 	bic	r0, r0, #131072	; 0x20000
        mcr     p15, #0, r0, c1, c0, #0  // disable background region
 108:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        bx      LR
 10c:	e12fff1e 	bx	lr

00000110 <MpuP_enableAsm>:

/* FUNCTION DEF: void MpuP_enableAsm(void) */
GTEXT(MpuP_enableAsm)
SECTION_FUNC(boot_section, MpuP_enableAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 110:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        orr     r0, r0, #0x1             // set bit 0 in r0
 114:	e3800001 	orr	r0, r0, #1
        dsb
 118:	f57ff04f 	dsb	sy
        mcr     p15, #0, r0, c1, c0, #0  // MPU enabled (bit 0 = 1)
 11c:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        isb                              // flush instruction pipeline
 120:	f57ff06f 	isb	sy
        bx      LR
 124:	e12fff1e 	bx	lr

00000128 <MpuP_enableBRAsm>:

/* FUNCTION DEF: void MpuP_enableBRAsm(void) */
GTEXT(MpuP_enableBRAsm)
SECTION_FUNC(boot_section, MpuP_enableBRAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 128:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        orr     r0, r0, #0x20000         // set bit 17 in r0
 12c:	e3800802 	orr	r0, r0, #131072	; 0x20000
        mcr     p15, #0, r0, c1, c0, #0  // background region enabled
 130:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        bx      LR
 134:	e12fff1e 	bx	lr

00000138 <MpuP_isEnableAsm>:

/* FUNCTION DEF: uint32_t MpuP_isEnableAsm(void) */
GTEXT(MpuP_isEnableAsm)
SECTION_FUNC(boot_section, MpuP_isEnableAsm)
        mov     r0, #0
 138:	e3a00000 	mov	r0, #0
        mrc     p15, #0, r1, c1, c0, #0  // read SCTLR register to r1
 13c:	ee111f10 	mrc	15, 0, r1, cr1, cr0, {0}
        tst     r1, #0x1                 // test bit 0
 140:	e3110001 	tst	r1, #1
        movne   r0, #1                   // if not 0, MPU is enabled
 144:	13a00001 	movne	r0, #1
        bx      LR
 148:	e12fff1e 	bx	lr

0000014c <MpuP_setRegionAsm>:
 * r2 = sizeAndEnable
 * r3 = regionAttrs
 */
GTEXT(MpuP_setRegionAsm)
SECTION_FUNC(boot_section, MpuP_setRegionAsm)
        mcr     p15, #0, r0, c6, c2, #0  // select MPU region
 14c:	ee060f12 	mcr	15, 0, r0, cr6, cr2, {0}
        mcr     p15, #0, r1, c6, c1, #0  // set region base address
 150:	ee061f11 	mcr	15, 0, r1, cr6, cr1, {0}
        mcr     p15, #0, r2, c6, c1, #2  // set region size and enable it
 154:	ee062f51 	mcr	15, 0, r2, cr6, cr1, {2}
        mcr     p15, #0, r3, c6, c1, #4  // set protection attributes
 158:	ee063f91 	mcr	15, 0, r3, cr6, cr1, {4}
        bx      LR
 15c:	e12fff1e 	bx	lr

00000160 <__MpuP_enableAsm_from_thumb>:
		split_chunks(h, c, c + chunks_need);
 160:	4778      	bx	pc
 162:	e7fd      	b.n	160 <__MpuP_enableAsm_from_thumb>
 164:	eaffffe9 	b	110 <MpuP_enableAsm>

00000168 <____start_veneer>:
		free_chunk(h, c + chunks_need);
 168:	e51ff004 	ldr	pc, [pc, #-4]	; 16c <____start_veneer+0x4>
 16c:	70000d5c 	.word	0x70000d5c
