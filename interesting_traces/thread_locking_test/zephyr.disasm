
files/zephyr.elf:     file format elf32-littlearm


Disassembly of section rom_start:

70000000 <_vector_table>:
#include "macro_priv.inc"

_ASM_FILE_PROLOGUE

SECTION_SUBSEC_FUNC(exc_vector_table,_vector_table_section,_vector_table)
	ldr pc, =z_arm_reset             /*                   offset 0 */
70000000:	18 f0 9f e5 18 f0 9f e5 18 f0 9f e5 18 f0 9f e5     ................
	ldr pc, =z_arm_undef_instruction /* undef instruction offset 4 */
	ldr pc, =z_arm_svc               /* svc               offset 8 */
	ldr pc, =z_arm_prefetch_abort    /* prefetch abort offset  0xc */
	ldr pc, =z_arm_data_abort        /* data abort     offset 0x10 */
70000010:	18 f0 9f e5 00 f0 20 e3 14 f0 9f e5 14 f0 9f e5     ...... .........
	ldr pc, =z_arm_reset             /*                   offset 0 */
70000020:	48 0c 00 70 30 0a 00 70 dc 0e 00 70 74 0a 00 70     H..p0..p...pt..p
	ldr pc, =z_arm_data_abort        /* data abort     offset 0x10 */
70000030:	a4 0a 00 70 34 0d 00 70 11 0a 00 70                 ...p4..p...p

Disassembly of section text:

70000040 <strcmp>:
	.fnstart
	.cfi_sections .debug_frame
	.cfi_startproc
	prologue push_ip=HAVE_PAC_LEAF
#ifndef STRCMP_NO_PRECHECK
	ldrb	r2, [src1]
70000040:	7802      	ldrb	r2, [r0, #0]
	ldrb	r3, [src2]
70000042:	780b      	ldrb	r3, [r1, #0]
	cmp	r2, #1
70000044:	2a01      	cmp	r2, #1
	it	cs
70000046:	bf28      	it	cs
	cmpcs	r2, r3
70000048:	429a      	cmpcs	r2, r3
	bne	.Lfastpath_exit
7000004a:	f040 80d8 	bne.w	700001fe <strcmp+0x1be>
#endif
	strd	r4, r5, [sp, #-16]!
7000004e:	e96d 4504 	strd	r4, r5, [sp, #-16]!
	.cfi_adjust_cfa_offset 16
	.cfi_rel_offset 4, 0
	.cfi_rel_offset 5, 4
	orr	tmp1, src1, src2
70000052:	ea40 0401 	orr.w	r4, r0, r1
	strd	r6, r7, [sp, #8]
70000056:	e9cd 6702 	strd	r6, r7, [sp, #8]
	.cfi_rel_offset 6, 8
	.cfi_rel_offset 7, 12
	mvn	const_m1, #0
7000005a:	f06f 0c00 	mvn.w	ip, #0
	lsl	r2, tmp1, #29
7000005e:	ea4f 7244 	mov.w	r2, r4, lsl #29
	cbz	r2, .Lloop_aligned8
70000062:	b31a      	cbz	r2, 700000ac <strcmp+0x6c>

.Lnot_aligned:
	eor	tmp1, src1, src2
70000064:	ea80 0401 	eor.w	r4, r0, r1
	tst	tmp1, #7
70000068:	f014 0f07 	tst.w	r4, #7
	bne	.Lmisaligned8
7000006c:	d16b      	bne.n	70000146 <strcmp+0x106>

	/* Deal with mutual misalignment by aligning downwards and then
	   masking off the unwanted loaded data to prevent a difference.  */
	and	tmp1, src1, #7
7000006e:	f000 0407 	and.w	r4, r0, #7
	bic	src1, src1, #7
70000072:	f020 0007 	bic.w	r0, r0, #7
	and	tmp2, tmp1, #3
70000076:	f004 0503 	and.w	r5, r4, #3
	bic	src2, src2, #7
7000007a:	f021 0107 	bic.w	r1, r1, #7
	lsl	tmp2, tmp2, #3	/* Bytes -> bits.  */
7000007e:	ea4f 05c5 	mov.w	r5, r5, lsl #3
	ldrd	data1a, data1b, [src1], #16
70000082:	e8f0 2304 	ldrd	r2, r3, [r0], #16
	tst	tmp1, #4
70000086:	f014 0f04 	tst.w	r4, #4
	ldrd	data2a, data2b, [src2], #16
7000008a:	e8f1 6704 	ldrd	r6, r7, [r1], #16
	/* In thumb code we can't use MVN with a register shift, but
	   we do have ORN.  */
	S2HI	tmp1, const_m1, tmp2
7000008e:	fa0c f405 	lsl.w	r4, ip, r5
	orn	data1a, data1a, tmp1
70000092:	ea62 0204 	orn	r2, r2, r4
	orn	data2a, data2a, tmp1
70000096:	ea66 0604 	orn	r6, r6, r4
	beq	.Lstart_realigned8
7000009a:	d00b      	beq.n	700000b4 <strcmp+0x74>
	orn	data1b, data1b, tmp1
7000009c:	ea63 0304 	orn	r3, r3, r4
	mov	data1a, const_m1
700000a0:	4662      	mov	r2, ip
	orn	data2b, data2b, tmp1
700000a2:	ea67 0704 	orn	r7, r7, r4
	mov	data2a, const_m1
700000a6:	4666      	mov	r6, ip
	b	.Lstart_realigned8
700000a8:	e004      	b.n	700000b4 <strcmp+0x74>
700000aa:	bf00      	nop
	/* Unwind the inner loop by a factor of 2, giving 16 bytes per
	   pass.  */
	.p2align 5,,12  /* Don't start in the tail bytes of a cache line.  */
	.p2align 2	/* Always word aligned.  */
.Lloop_aligned8:
	ldrd	data1a, data1b, [src1], #16
700000ac:	e8f0 2304 	ldrd	r2, r3, [r0], #16
	ldrd	data2a, data2b, [src2], #16
700000b0:	e8f1 6704 	ldrd	r6, r7, [r1], #16
.Lstart_realigned8:
	uadd8	syndrome_b, data1a, const_m1	/* Only want GE bits,  */
700000b4:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome_a, data1a, data2a
700000b8:	ea82 0406 	eor.w	r4, r2, r6
	sel	syndrome_a, syndrome_a, const_m1
700000bc:	faa4 f48c 	sel	r4, r4, ip
	cbnz	syndrome_a, .Ldiff_in_a
700000c0:	bb6c      	cbnz	r4, 7000011e <strcmp+0xde>
	uadd8	syndrome_b, data1b, const_m1	/* Only want GE bits.  */
700000c2:	fa83 f54c 	uadd8	r5, r3, ip
	eor	syndrome_b, data1b, data2b
700000c6:	ea83 0507 	eor.w	r5, r3, r7
	sel	syndrome_b, syndrome_b, const_m1
700000ca:	faa5 f58c 	sel	r5, r5, ip
	cbnz	syndrome_b, .Ldiff_in_b
700000ce:	b995      	cbnz	r5, 700000f6 <strcmp+0xb6>

	ldrd	data1a, data1b, [src1, #-8]
700000d0:	e950 2302 	ldrd	r2, r3, [r0, #-8]
	ldrd	data2a, data2b, [src2, #-8]
700000d4:	e951 6702 	ldrd	r6, r7, [r1, #-8]
	uadd8	syndrome_b, data1a, const_m1	/* Only want GE bits,  */
700000d8:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome_a, data1a, data2a
700000dc:	ea82 0406 	eor.w	r4, r2, r6
	sel	syndrome_a, syndrome_a, const_m1
700000e0:	faa4 f48c 	sel	r4, r4, ip
	uadd8	syndrome_b, data1b, const_m1	/* Only want GE bits.  */
700000e4:	fa83 f54c 	uadd8	r5, r3, ip
	eor	syndrome_b, data1b, data2b
700000e8:	ea83 0507 	eor.w	r5, r3, r7
	sel	syndrome_b, syndrome_b, const_m1
700000ec:	faa5 f58c 	sel	r5, r5, ip
	/* Can't use CBZ for backwards branch.  */
	orrs	syndrome_b, syndrome_b, syndrome_a /* Only need if s_a == 0 */
700000f0:	4325      	orrs	r5, r4
	beq	.Lloop_aligned8
700000f2:	d0db      	beq.n	700000ac <strcmp+0x6c>

.Ldiff_found:
	cbnz	syndrome_a, .Ldiff_in_a
700000f4:	b99c      	cbnz	r4, 7000011e <strcmp+0xde>

.Ldiff_in_b:
	strcmp_epilogue_aligned syndrome_b, data1b, data2b 1
700000f6:	ba2d      	rev	r5, r5
700000f8:	fab5 f485 	clz	r4, r5
700000fc:	f024 0407 	bic.w	r4, r4, #7
70000100:	fa27 f104 	lsr.w	r1, r7, r4
70000104:	e9dd 6702 	ldrd	r6, r7, [sp, #8]
70000108:	fa23 f304 	lsr.w	r3, r3, r4
7000010c:	f003 00ff 	and.w	r0, r3, #255	; 0xff
70000110:	f001 01ff 	and.w	r1, r1, #255	; 0xff
70000114:	e8fd 4504 	ldrd	r4, r5, [sp], #16
70000118:	eba0 0001 	sub.w	r0, r0, r1
7000011c:	4770      	bx	lr

.Ldiff_in_a:
	.cfi_restore_state
	strcmp_epilogue_aligned syndrome_a, data1a, data2a 1
7000011e:	ba24      	rev	r4, r4
70000120:	fab4 f484 	clz	r4, r4
70000124:	f024 0407 	bic.w	r4, r4, #7
70000128:	fa26 f104 	lsr.w	r1, r6, r4
7000012c:	e9dd 6702 	ldrd	r6, r7, [sp, #8]
70000130:	fa22 f204 	lsr.w	r2, r2, r4
70000134:	f002 00ff 	and.w	r0, r2, #255	; 0xff
70000138:	f001 01ff 	and.w	r1, r1, #255	; 0xff
7000013c:	e8fd 4504 	ldrd	r4, r5, [sp], #16
70000140:	eba0 0001 	sub.w	r0, r0, r1
70000144:	4770      	bx	lr

	.cfi_restore_state
.Lmisaligned8:
	tst	tmp1, #3
70000146:	f014 0f03 	tst.w	r4, #3
	bne	.Lmisaligned4
7000014a:	d13c      	bne.n	700001c6 <strcmp+0x186>
	ands	tmp1, src1, #3
7000014c:	f010 0403 	ands.w	r4, r0, #3
	bne	.Lmutual_align4
70000150:	d128      	bne.n	700001a4 <strcmp+0x164>

	/* Unrolled by a factor of 2, to reduce the number of post-increment
	   operations.  */
.Lloop_aligned4:
	ldr	data1, [src1], #8
70000152:	f850 2b08 	ldr.w	r2, [r0], #8
	ldr	data2, [src2], #8
70000156:	f851 3b08 	ldr.w	r3, [r1], #8
.Lstart_realigned4:
	uadd8	syndrome, data1, const_m1	/* Only need GE bits.  */
7000015a:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome, data1, data2
7000015e:	ea82 0503 	eor.w	r5, r2, r3
	sel	syndrome, syndrome, const_m1
70000162:	faa5 f58c 	sel	r5, r5, ip
	cbnz	syndrome, .Laligned4_done
70000166:	b95d      	cbnz	r5, 70000180 <strcmp+0x140>
	ldr	data1, [src1, #-4]
70000168:	f850 2c04 	ldr.w	r2, [r0, #-4]
	ldr	data2, [src2, #-4]
7000016c:	f851 3c04 	ldr.w	r3, [r1, #-4]
	uadd8	syndrome, data1, const_m1
70000170:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome, data1, data2
70000174:	ea82 0503 	eor.w	r5, r2, r3
	sel	syndrome, syndrome, const_m1
70000178:	faa5 f58c 	sel	r5, r5, ip
	cmp	syndrome, #0
7000017c:	2d00      	cmp	r5, #0
	beq	.Lloop_aligned4
7000017e:	d0e8      	beq.n	70000152 <strcmp+0x112>

.Laligned4_done:
	strcmp_epilogue_aligned syndrome, data1, data2, 0
70000180:	ba2d      	rev	r5, r5
70000182:	fab5 f485 	clz	r4, r5
70000186:	f024 0407 	bic.w	r4, r4, #7
7000018a:	fa23 f104 	lsr.w	r1, r3, r4
7000018e:	fa22 f204 	lsr.w	r2, r2, r4
70000192:	f002 00ff 	and.w	r0, r2, #255	; 0xff
70000196:	f001 01ff 	and.w	r1, r1, #255	; 0xff
7000019a:	e8fd 4504 	ldrd	r4, r5, [sp], #16
7000019e:	eba0 0001 	sub.w	r0, r0, r1
700001a2:	4770      	bx	lr

.Lmutual_align4:
	.cfi_restore_state
	/* Deal with mutual misalignment by aligning downwards and then
	   masking off the unwanted loaded data to prevent a difference.  */
	lsl	tmp1, tmp1, #3	/* Bytes -> bits.  */
700001a4:	ea4f 04c4 	mov.w	r4, r4, lsl #3
	bic	src1, src1, #3
700001a8:	f020 0003 	bic.w	r0, r0, #3
	ldr	data1, [src1], #8
700001ac:	f850 2b08 	ldr.w	r2, [r0], #8
	bic	src2, src2, #3
700001b0:	f021 0103 	bic.w	r1, r1, #3
	ldr	data2, [src2], #8
700001b4:	f851 3b08 	ldr.w	r3, [r1], #8

	/* In thumb code we can't use MVN with a register shift, but
	   we do have ORN.  */
	S2HI	tmp1, const_m1, tmp1
700001b8:	fa0c f404 	lsl.w	r4, ip, r4
	orn	data1, data1, tmp1
700001bc:	ea62 0204 	orn	r2, r2, r4
	orn	data2, data2, tmp1
700001c0:	ea63 0304 	orn	r3, r3, r4
	b	.Lstart_realigned4
700001c4:	e7c9      	b.n	7000015a <strcmp+0x11a>

.Lmisaligned4:
	ands	tmp1, src1, #3
700001c6:	f010 0403 	ands.w	r4, r0, #3
	beq	.Lsrc1_aligned
700001ca:	d01d      	beq.n	70000208 <strcmp+0x1c8>
	sub	src2, src2, tmp1
700001cc:	eba1 0104 	sub.w	r1, r1, r4
	bic	src1, src1, #3
700001d0:	f020 0003 	bic.w	r0, r0, #3
	lsls	tmp1, tmp1, #31
700001d4:	07e4      	lsls	r4, r4, #31
	ldr	data1, [src1], #4
700001d6:	f850 2b04 	ldr.w	r2, [r0], #4
	beq	.Laligned_m2
700001da:	d006      	beq.n	700001ea <strcmp+0x1aa>
	bcs	.Laligned_m1
700001dc:	d212      	bcs.n	70000204 <strcmp+0x1c4>
	add	src2, src2, #4
	cbnz	data2, .Lsrc1_aligned
#else  /* STRCMP_NO_PRECHECK */
	/* If we've done the pre-check, then we don't need to check the
	   first byte again here.  */
	ldrb	data2, [src2, #2]
700001de:	788b      	ldrb	r3, [r1, #2]
	uxtb	tmp1, data1, ror #BYTE2_OFFSET
700001e0:	fa5f f4a2 	uxtb.w	r4, r2, ror #16
	subs	tmp1, tmp1, data2
700001e4:	1ae4      	subs	r4, r4, r3
	bne	.Lmisaligned_exit
700001e6:	d106      	bne.n	700001f6 <strcmp+0x1b6>
	cbz	data2, .Lmisaligned_exit
700001e8:	b12b      	cbz	r3, 700001f6 <strcmp+0x1b6>

.Laligned_m2:
	ldrb	data2, [src2, #3]
700001ea:	78cb      	ldrb	r3, [r1, #3]
	uxtb	tmp1, data1, ror #BYTE3_OFFSET
700001ec:	fa5f f4b2 	uxtb.w	r4, r2, ror #24
	subs	tmp1, tmp1, data2
700001f0:	1ae4      	subs	r4, r4, r3
	bne	.Lmisaligned_exit
700001f2:	d100      	bne.n	700001f6 <strcmp+0x1b6>
	cbnz	data2, .Laligned_m1
700001f4:	b933      	cbnz	r3, 70000204 <strcmp+0x1c4>
#endif

.Lmisaligned_exit:
	.cfi_remember_state
	mov	result, tmp1
700001f6:	4620      	mov	r0, r4
	ldr	r4, [sp], #16
700001f8:	f85d 4b10 	ldr.w	r4, [sp], #16
	.cfi_restore 4
	.cfi_adjust_cfa_offset -16
	epilogue push_ip=HAVE_PAC_LEAF
700001fc:	4770      	bx	lr

#ifndef STRCMP_NO_PRECHECK
.Lfastpath_exit:
	.cfi_restore_state
	.cfi_remember_state
	sub	r0, r2, r3
700001fe:	eba2 0003 	sub.w	r0, r2, r3
	epilogue push_ip=HAVE_PAC_LEAF
70000202:	4770      	bx	lr

.Laligned_m1:
	.cfi_restore_state
	.cfi_remember_state
	add	src2, src2, #4
70000204:	f101 0104 	add.w	r1, r1, #4
#endif
.Lsrc1_aligned:
	.cfi_restore_state
	/* src1 is word aligned, but src2 has no common alignment
	   with it.  */
	ldr	data1, [src1], #4
70000208:	f850 2b04 	ldr.w	r2, [r0], #4
	lsls	tmp1, src2, #31		/* C=src2[1], Z=src2[0].  */
7000020c:	07cc      	lsls	r4, r1, #31

	bic	src2, src2, #3
7000020e:	f021 0103 	bic.w	r1, r1, #3
	ldr	data2, [src2], #4
70000212:	f851 3b04 	ldr.w	r3, [r1], #4
	bhi	.Loverlap1		/* C=1, Z=0 => src2[1:0] = 0b11.  */
70000216:	d848      	bhi.n	700002aa <strcmp+0x26a>
	bcs	.Loverlap2		/* C=1, Z=1 => src2[1:0] = 0b10.  */
70000218:	d224      	bcs.n	70000264 <strcmp+0x224>

	/* (overlap3) C=0, Z=0 => src2[1:0] = 0b01.  */
.Loverlap3:
	bic	tmp1, data1, #MSB
7000021a:	f022 447f 	bic.w	r4, r2, #4278190080	; 0xff000000
	uadd8	syndrome, data1, const_m1
7000021e:	fa82 f54c 	uadd8	r5, r2, ip
	eors	syndrome, tmp1, data2, S2LO #8
70000222:	ea94 2513 	eors.w	r5, r4, r3, lsr #8
	sel	syndrome, syndrome, const_m1
70000226:	faa5 f58c 	sel	r5, r5, ip
	bne	4f
7000022a:	d10a      	bne.n	70000242 <strcmp+0x202>
	cbnz	syndrome, 5f
7000022c:	b965      	cbnz	r5, 70000248 <strcmp+0x208>
	ldr	data2, [src2], #4
7000022e:	f851 3b04 	ldr.w	r3, [r1], #4
	eor	tmp1, tmp1, data1
70000232:	ea84 0402 	eor.w	r4, r4, r2
	cmp	tmp1, data2, S2HI #24
70000236:	ebb4 6f03 	cmp.w	r4, r3, lsl #24
	bne	6f
7000023a:	d10e      	bne.n	7000025a <strcmp+0x21a>
	ldr	data1, [src1], #4
7000023c:	f850 2b04 	ldr.w	r2, [r0], #4
	b	.Loverlap3
70000240:	e7eb      	b.n	7000021a <strcmp+0x1da>
4:
	S2LO	data2, data2, #8
70000242:	ea4f 2313 	mov.w	r3, r3, lsr #8
	b	.Lstrcmp_tail
70000246:	e055      	b.n	700002f4 <strcmp+0x2b4>

5:
	bics	syndrome, syndrome, #MSB
70000248:	f035 457f 	bics.w	r5, r5, #4278190080	; 0xff000000
	bne	.Lstrcmp_done_equal
7000024c:	d14d      	bne.n	700002ea <strcmp+0x2aa>

	/* We can only get here if the MSB of data1 contains 0, so
	   fast-path the exit.  */
	ldrb	result, [src2]
7000024e:	7808      	ldrb	r0, [r1, #0]
	.cfi_remember_state
	ldrd	r4, r5, [sp], #16
70000250:	e8fd 4504 	ldrd	r4, r5, [sp], #16
	.cfi_restore 5
	/* R6/7 Not used in this sequence.  */
	.cfi_restore 6
	.cfi_restore 7
	.cfi_adjust_cfa_offset -16
	neg	result, result
70000254:	f1c0 0000 	rsb	r0, r0, #0
	epilogue push_ip=HAVE_PAC_LEAF
70000258:	4770      	bx	lr

6:
	.cfi_restore_state
	S2LO	data1, data1, #24
7000025a:	ea4f 6212 	mov.w	r2, r2, lsr #24
	and	data2, data2, #LSB
7000025e:	f003 03ff 	and.w	r3, r3, #255	; 0xff
	b	.Lstrcmp_tail
70000262:	e047      	b.n	700002f4 <strcmp+0x2b4>

	.p2align 5,,12	/* Ensure at least 3 instructions in cache line.  */
.Loverlap2:
	and	tmp1, data1, const_m1, S2LO #16
70000264:	ea02 441c 	and.w	r4, r2, ip, lsr #16
	uadd8	syndrome, data1, const_m1
70000268:	fa82 f54c 	uadd8	r5, r2, ip
	eors	syndrome, tmp1, data2, S2LO #16
7000026c:	ea94 4513 	eors.w	r5, r4, r3, lsr #16
	sel	syndrome, syndrome, const_m1
70000270:	faa5 f58c 	sel	r5, r5, ip
	bne	4f
70000274:	d10a      	bne.n	7000028c <strcmp+0x24c>
	cbnz	syndrome, 5f
70000276:	b965      	cbnz	r5, 70000292 <strcmp+0x252>
	ldr	data2, [src2], #4
70000278:	f851 3b04 	ldr.w	r3, [r1], #4
	eor	tmp1, tmp1, data1
7000027c:	ea84 0402 	eor.w	r4, r4, r2
	cmp	tmp1, data2, S2HI #16
70000280:	ebb4 4f03 	cmp.w	r4, r3, lsl #16
	bne	6f
70000284:	d10c      	bne.n	700002a0 <strcmp+0x260>
	ldr	data1, [src1], #4
70000286:	f850 2b04 	ldr.w	r2, [r0], #4
	b	.Loverlap2
7000028a:	e7eb      	b.n	70000264 <strcmp+0x224>
4:
	S2LO	data2, data2, #16
7000028c:	ea4f 4313 	mov.w	r3, r3, lsr #16
	b	.Lstrcmp_tail
70000290:	e030      	b.n	700002f4 <strcmp+0x2b4>
5:
	ands	syndrome, syndrome, const_m1, S2LO #16
70000292:	ea15 451c 	ands.w	r5, r5, ip, lsr #16
	bne	.Lstrcmp_done_equal
70000296:	d128      	bne.n	700002ea <strcmp+0x2aa>

	ldrh	data2, [src2]
70000298:	880b      	ldrh	r3, [r1, #0]
	S2LO	data1, data1, #16
7000029a:	ea4f 4212 	mov.w	r2, r2, lsr #16
#ifdef __ARM_BIG_ENDIAN
	lsl	data2, data2, #16
#endif
	b	.Lstrcmp_tail
7000029e:	e029      	b.n	700002f4 <strcmp+0x2b4>

6:
	S2LO	data1, data1, #16
700002a0:	ea4f 4212 	mov.w	r2, r2, lsr #16
	and	data2, data2, const_m1, S2LO #16
700002a4:	ea03 431c 	and.w	r3, r3, ip, lsr #16
	b	.Lstrcmp_tail
700002a8:	e024      	b.n	700002f4 <strcmp+0x2b4>

	.p2align 5,,12	/* Ensure at least 3 instructions in cache line.  */
.Loverlap1:
	and	tmp1, data1, #LSB
700002aa:	f002 04ff 	and.w	r4, r2, #255	; 0xff
	uadd8	syndrome, data1, const_m1
700002ae:	fa82 f54c 	uadd8	r5, r2, ip
	eors	syndrome, tmp1, data2, S2LO #24
700002b2:	ea94 6513 	eors.w	r5, r4, r3, lsr #24
	sel	syndrome, syndrome, const_m1
700002b6:	faa5 f58c 	sel	r5, r5, ip
	bne	4f
700002ba:	d10a      	bne.n	700002d2 <strcmp+0x292>
	cbnz	syndrome, 5f
700002bc:	b965      	cbnz	r5, 700002d8 <strcmp+0x298>
	ldr	data2, [src2], #4
700002be:	f851 3b04 	ldr.w	r3, [r1], #4
	eor	tmp1, tmp1, data1
700002c2:	ea84 0402 	eor.w	r4, r4, r2
	cmp	tmp1, data2, S2HI #8
700002c6:	ebb4 2f03 	cmp.w	r4, r3, lsl #8
	bne	6f
700002ca:	d109      	bne.n	700002e0 <strcmp+0x2a0>
	ldr	data1, [src1], #4
700002cc:	f850 2b04 	ldr.w	r2, [r0], #4
	b	.Loverlap1
700002d0:	e7eb      	b.n	700002aa <strcmp+0x26a>
4:
	S2LO	data2, data2, #24
700002d2:	ea4f 6313 	mov.w	r3, r3, lsr #24
	b	.Lstrcmp_tail
700002d6:	e00d      	b.n	700002f4 <strcmp+0x2b4>
5:
	tst	syndrome, #LSB
700002d8:	f015 0fff 	tst.w	r5, #255	; 0xff
	bne	.Lstrcmp_done_equal
700002dc:	d105      	bne.n	700002ea <strcmp+0x2aa>
	ldr	data2, [src2]
700002de:	680b      	ldr	r3, [r1, #0]
6:
	S2LO	data1, data1, #8
700002e0:	ea4f 2212 	mov.w	r2, r2, lsr #8
	bic	data2, data2, #MSB
700002e4:	f023 437f 	bic.w	r3, r3, #4278190080	; 0xff000000
	b	.Lstrcmp_tail
700002e8:	e004      	b.n	700002f4 <strcmp+0x2b4>

.Lstrcmp_done_equal:
	mov	result, #0
700002ea:	f04f 0000 	mov.w	r0, #0
	.cfi_remember_state
	ldrd	r4, r5, [sp], #16
700002ee:	e8fd 4504 	ldrd	r4, r5, [sp], #16
	.cfi_restore 5
	/* R6/7 not used in this sequence.  */
	.cfi_restore 6
	.cfi_restore 7
	.cfi_adjust_cfa_offset -16
	epilogue push_ip=HAVE_PAC_LEAF
700002f2:	4770      	bx	lr

.Lstrcmp_tail:
	.cfi_restore_state
#ifndef __ARM_BIG_ENDIAN
	rev	data1, data1
700002f4:	ba12      	rev	r2, r2
	rev	data2, data2
700002f6:	ba1b      	rev	r3, r3
	/* Now everything looks big-endian...  */
#endif
	uadd8	tmp1, data1, const_m1
700002f8:	fa82 f44c 	uadd8	r4, r2, ip
	eor	tmp1, data1, data2
700002fc:	ea82 0403 	eor.w	r4, r2, r3
	sel	syndrome, tmp1, const_m1
70000300:	faa4 f58c 	sel	r5, r4, ip
	clz	tmp1, syndrome
70000304:	fab5 f485 	clz	r4, r5
	lsl	data1, data1, tmp1
70000308:	fa02 f204 	lsl.w	r2, r2, r4
	lsl	data2, data2, tmp1
7000030c:	fa03 f304 	lsl.w	r3, r3, r4
	lsr	result, data1, #24
70000310:	ea4f 6012 	mov.w	r0, r2, lsr #24
	ldrd	r4, r5, [sp], #16
70000314:	e8fd 4504 	ldrd	r4, r5, [sp], #16
	.cfi_restore 5
	/* R6/7 not used in this sequence.  */
	.cfi_restore 6
	.cfi_restore 7
	.cfi_adjust_cfa_offset -16
	sub	result, result, data2, lsr #24
70000318:	eba0 6013 	sub.w	r0, r0, r3, lsr #24
	epilogue push_ip=HAVE_PAC_LEAF
7000031c:	4770      	bx	lr
7000031e:	bf00      	nop

70000320 <_OffsetAbsSyms>:

#include <gen_offset.h>

#include "offsets_aarch32.c"

GEN_ABS_SYM_END
70000320:	4770      	bx	lr
70000322:	bf00      	nop

70000324 <tm_thread_locking_test_initialize>:
void tm_thread_locking_reporting_thread(void* p1, void* p2, void* p3);
void tm_thread_locking_test_initialize(void);

/* Initialization function */
void tm_thread_locking_test_initialize(void)
{
70000324:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
   int i;
   tm_setup_pmu();
70000326:	f000 f929 	bl	7000057c <tm_setup_pmu>

   /* Precompute PMU names for each iteration to avoid runtime formatting overhead */
   for (i = 0; i < ITERATION_COUNT; i++)
7000032a:	f245 4428 	movw	r4, #21544	; 0x5428
   {
      snprintf(pmu_lock_numbers[i], sizeof(pmu_lock_numbers[i]), "L%02d", i);
7000032e:	f644 265c 	movw	r6, #19036	; 0x4a5c
   for (i = 0; i < ITERATION_COUNT; i++)
70000332:	2500      	movs	r5, #0
70000334:	f2c7 0400 	movt	r4, #28672	; 0x7000
70000338:	f504 7700 	add.w	r7, r4, #512	; 0x200
      snprintf(pmu_lock_numbers[i], sizeof(pmu_lock_numbers[i]), "L%02d", i);
7000033c:	f2c7 0600 	movt	r6, #28672	; 0x7000
70000340:	2110      	movs	r1, #16
70000342:	462b      	mov	r3, r5
70000344:	4620      	mov	r0, r4
70000346:	4632      	mov	r2, r6
   for (i = 0; i < ITERATION_COUNT; i++)
70000348:	440c      	add	r4, r1
      snprintf(pmu_lock_numbers[i], sizeof(pmu_lock_numbers[i]), "L%02d", i);
7000034a:	f002 fdf5 	bl	70002f38 <snprintf>
   for (i = 0; i < ITERATION_COUNT; i++)
7000034e:	42bc      	cmp	r4, r7
70000350:	f105 0501 	add.w	r5, r5, #1
70000354:	d1f4      	bne.n	70000340 <tm_thread_locking_test_initialize+0x1c>
   }

   /* Create the benchmark thread that drives the locking test */
   tm_thread_create(0, 5, tm_thread_locking_benchmark_thread);
70000356:	f240 3289 	movw	r2, #905	; 0x389
7000035a:	2105      	movs	r1, #5
7000035c:	2000      	movs	r0, #0
7000035e:	f2c7 0200 	movt	r2, #28672	; 0x7000
70000362:	f000 f967 	bl	70000634 <tm_thread_create>
   tm_thread_resume(0);
70000366:	2000      	movs	r0, #0
70000368:	f000 f992 	bl	70000690 <tm_thread_resume>

   /* Create a reporting thread to output benchmark results */
   tm_thread_create(1, 1, tm_thread_locking_reporting_thread);
7000036c:	2101      	movs	r1, #1
7000036e:	f240 32dd 	movw	r2, #989	; 0x3dd
70000372:	4608      	mov	r0, r1
70000374:	f2c7 0200 	movt	r2, #28672	; 0x7000
70000378:	f000 f95c 	bl	70000634 <tm_thread_create>
   tm_thread_resume(1);
}
7000037c:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
   tm_thread_resume(1);
70000380:	2001      	movs	r0, #1
70000382:	f000 b985 	b.w	70000690 <tm_thread_resume>
70000386:	bf00      	nop

70000388 <tm_thread_locking_benchmark_thread>:

/* Benchmark thread that tests thread locking */
void tm_thread_locking_benchmark_thread(void* p1, void* p2, void* p3)
{
70000388:	b538      	push	{r3, r4, r5, lr}
7000038a:	f245 6428 	movw	r4, #22056	; 0x5628
7000038e:	f245 4528 	movw	r5, #21544	; 0x5428
70000392:	f2c7 0400 	movt	r4, #28672	; 0x7000
70000396:	f2c7 0500 	movt	r5, #28672	; 0x7000
   (void) p2;
   (void) p3;

   while (1)
   {
      if (thread_locking_counter < ITERATION_COUNT)
7000039a:	6823      	ldr	r3, [r4, #0]
7000039c:	2b1f      	cmp	r3, #31
7000039e:	d917      	bls.n	700003d0 <tm_thread_locking_benchmark_thread+0x48>
      {
         tm_pmu_profile_start(pmu_lock_numbers[thread_locking_counter]);
      }

      /* Lock the thread by stopping the scheduler */
      tm_suspend_scheduler();
700003a0:	f000 f99a 	bl	700006d8 <tm_suspend_scheduler>
      thread_locking_counter++;
700003a4:	6822      	ldr	r2, [r4, #0]
700003a6:	f44f 737a 	mov.w	r3, #1000	; 0x3e8
700003aa:	3201      	adds	r2, #1
700003ac:	6022      	str	r2, [r4, #0]
      /* busy work loop to have some blocked time*/
      for (int i = 0; i < 1000; i++)
      {
         __asm__ volatile("nop");
700003ae:	bf00      	nop
      for (int i = 0; i < 1000; i++)
700003b0:	3b01      	subs	r3, #1
700003b2:	d1fc      	bne.n	700003ae <tm_thread_locking_benchmark_thread+0x26>
      }
      /* Unlock the thread by restarting the scheduler */
      tm_resume_scheduler();
700003b4:	f000 f992 	bl	700006dc <tm_resume_scheduler>

      if (thread_locking_counter < ITERATION_COUNT + 1)
700003b8:	6823      	ldr	r3, [r4, #0]
700003ba:	2b20      	cmp	r3, #32
700003bc:	d8ed      	bhi.n	7000039a <tm_thread_locking_benchmark_thread+0x12>
      {
         tm_pmu_profile_end(pmu_lock_numbers[thread_locking_counter - 1]);
700003be:	6820      	ldr	r0, [r4, #0]
700003c0:	3801      	subs	r0, #1
700003c2:	eb05 1000 	add.w	r0, r5, r0, lsl #4
700003c6:	f000 f9cb 	bl	70000760 <tm_pmu_profile_end>
      if (thread_locking_counter < ITERATION_COUNT)
700003ca:	6823      	ldr	r3, [r4, #0]
700003cc:	2b1f      	cmp	r3, #31
700003ce:	d8e7      	bhi.n	700003a0 <tm_thread_locking_benchmark_thread+0x18>
         tm_pmu_profile_start(pmu_lock_numbers[thread_locking_counter]);
700003d0:	6820      	ldr	r0, [r4, #0]
700003d2:	eb05 1000 	add.w	r0, r5, r0, lsl #4
700003d6:	f000 f983 	bl	700006e0 <tm_pmu_profile_start>
700003da:	e7e1      	b.n	700003a0 <tm_thread_locking_benchmark_thread+0x18>

700003dc <tm_thread_locking_reporting_thread>:
   }
}

/* Reporting thread to display PMU measurements and counter progress */
void tm_thread_locking_reporting_thread(void* p1, void* p2, void* p3)
{
700003dc:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   (void) p1;
   (void) p2;
   (void) p3;
   unsigned long last_counter = 0;
   unsigned long relative_time = 0;
700003e0:	2600      	movs	r6, #0
700003e2:	f245 6728 	movw	r7, #22056	; 0x5628

   while (1)
   {
      tm_thread_sleep(TM_TEST_DURATION);
      relative_time += TM_TEST_DURATION;
      printf("**** Thread Locking Benchmark **** Relative Time: %lu\r\n", relative_time);
700003e6:	f644 2864 	movw	r8, #19044	; 0x4a64
      {
         printf("ERROR: No progress in thread locking counter!\r\n");
      }
      else
      {
         printf("Locking Operations in Period: %lu\r\n", thread_locking_counter - last_counter);
700003ea:	f644 29cc 	movw	r9, #19148	; 0x4acc
         printf("ERROR: No progress in thread locking counter!\r\n");
700003ee:	f644 2a9c 	movw	sl, #19100	; 0x4a9c
   unsigned long last_counter = 0;
700003f2:	4634      	mov	r4, r6
700003f4:	4d14      	ldr	r5, [pc, #80]	; (70000448 <tm_thread_locking_reporting_thread+0x6c>)
700003f6:	f2c7 0700 	movt	r7, #28672	; 0x7000
      printf("**** Thread Locking Benchmark **** Relative Time: %lu\r\n", relative_time);
700003fa:	f2c7 0800 	movt	r8, #28672	; 0x7000
         printf("Locking Operations in Period: %lu\r\n", thread_locking_counter - last_counter);
700003fe:	f2c7 0900 	movt	r9, #28672	; 0x7000
         printf("ERROR: No progress in thread locking counter!\r\n");
70000402:	f2c7 0a00 	movt	sl, #28672	; 0x7000
      tm_thread_sleep(TM_TEST_DURATION);
70000406:	201e      	movs	r0, #30
      relative_time += TM_TEST_DURATION;
70000408:	4406      	add	r6, r0
      tm_thread_sleep(TM_TEST_DURATION);
7000040a:	f000 f94f 	bl	700006ac <tm_thread_sleep>
      printf("**** Thread Locking Benchmark **** Relative Time: %lu\r\n", relative_time);
7000040e:	4631      	mov	r1, r6
70000410:	4640      	mov	r0, r8
70000412:	f000 fabb 	bl	7000098c <printk>
      if (thread_locking_counter == last_counter)
70000416:	683b      	ldr	r3, [r7, #0]
70000418:	42a3      	cmp	r3, r4
7000041a:	d011      	beq.n	70000440 <tm_thread_locking_reporting_thread+0x64>
         printf("Locking Operations in Period: %lu\r\n", thread_locking_counter - last_counter);
7000041c:	6839      	ldr	r1, [r7, #0]
7000041e:	4648      	mov	r0, r9
70000420:	1b09      	subs	r1, r1, r4
70000422:	f000 fab3 	bl	7000098c <printk>
      }

      /* Print PMU profile results on the first reporting interval */
      if (last_counter == 0)
70000426:	b94c      	cbnz	r4, 7000043c <tm_thread_locking_reporting_thread+0x60>
70000428:	f245 4428 	movw	r4, #21544	; 0x5428
7000042c:	f2c7 0400 	movt	r4, #28672	; 0x7000
      {
         for (int i = 0; i < ITERATION_COUNT; i++)
         {
            tm_pmu_profile_print(pmu_lock_numbers[i]);
70000430:	4620      	mov	r0, r4
         for (int i = 0; i < ITERATION_COUNT; i++)
70000432:	3410      	adds	r4, #16
            tm_pmu_profile_print(pmu_lock_numbers[i]);
70000434:	f000 f9e0 	bl	700007f8 <tm_pmu_profile_print>
         for (int i = 0; i < ITERATION_COUNT; i++)
70000438:	42ac      	cmp	r4, r5
7000043a:	d1f9      	bne.n	70000430 <tm_thread_locking_reporting_thread+0x54>
         }
      }
      last_counter = thread_locking_counter;
7000043c:	683c      	ldr	r4, [r7, #0]
      tm_thread_sleep(TM_TEST_DURATION);
7000043e:	e7e2      	b.n	70000406 <tm_thread_locking_reporting_thread+0x2a>
         printf("ERROR: No progress in thread locking counter!\r\n");
70000440:	4650      	mov	r0, sl
70000442:	f000 faa3 	bl	7000098c <printk>
70000446:	e7ee      	b.n	70000426 <tm_thread_locking_reporting_thread+0x4a>
70000448:	70005628 	.word	0x70005628

7000044c <main_thread_locking_test>:
}

/* Main entry point for the thread locking test */
int main_thread_locking_test(void)
{
   tm_initialize(tm_thread_locking_test_initialize);
7000044c:	f240 3025 	movw	r0, #805	; 0x325
70000450:	f2c7 0000 	movt	r0, #28672	; 0x7000
{
70000454:	b508      	push	{r3, lr}
   tm_initialize(tm_thread_locking_test_initialize);
70000456:	f000 f8eb 	bl	70000630 <tm_initialize>
   return 0;
}
7000045a:	2000      	movs	r0, #0
7000045c:	bd08      	pop	{r3, pc}
7000045e:	bf00      	nop

70000460 <main>:

int main(void)
{
#ifdef USING_ZEPHYR
   extern int rtos_main_zephyr(void);
   return rtos_main_zephyr();
70000460:	f000 b830 	b.w	700004c4 <rtos_main_zephyr>

70000464 <tm_interrupt_handler>:
void* test_interrupt_handler = NULL;

/* Define the interrupt handler */
void tm_interrupt_handler(void* args)
{
   if (test_interrupt_handler != NULL)
70000464:	f245 632c 	movw	r3, #22060	; 0x562c
70000468:	f2c7 0300 	movt	r3, #28672	; 0x7000
7000046c:	681b      	ldr	r3, [r3, #0]
7000046e:	b103      	cbz	r3, 70000472 <tm_interrupt_handler+0xe>
   {
      /* Call the assigned handler function */
      ((void (*)(void)) test_interrupt_handler)();
70000470:	4718      	bx	r3
   }
}
70000472:	4770      	bx	lr

70000474 <main_task>:
}

void main_task(void* pvParameters)
{
   /* Start Thread-Metric tests */
   printk("Starting Thread-Metric tests...\r\n");
70000474:	f644 20f0 	movw	r0, #19184	; 0x4af0
{
70000478:	b510      	push	{r4, lr}

   /* Initialize custom interrupts*/
   test_interrupt_handler = tm_isr_message_handler;
7000047a:	f240 44f1 	movw	r4, #1265	; 0x4f1
   printk("Starting Thread-Metric tests...\r\n");
7000047e:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000482:	f000 fa83 	bl	7000098c <printk>
   test_interrupt_handler = tm_isr_message_handler;
70000486:	f245 632c 	movw	r3, #22060	; 0x562c
7000048a:	f2c7 0300 	movt	r3, #28672	; 0x7000
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
7000048e:	2204      	movs	r2, #4
   test_interrupt_handler = tm_isr_message_handler;
70000490:	f2c7 0400 	movt	r4, #28672	; 0x7000
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
70000494:	2101      	movs	r1, #1
70000496:	200a      	movs	r0, #10
   test_interrupt_handler = tm_isr_message_handler;
70000498:	601c      	str	r4, [r3, #0]
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
7000049a:	f000 fe55 	bl	70001148 <z_vim_irq_priority_set>
   IRQ_CONNECT(SOFTWARE_INTERRUPT_ID, 1, tm_interrupt_handler, NULL, 0);
7000049e:	2200      	movs	r2, #0
700004a0:	2101      	movs	r1, #1
700004a2:	200a      	movs	r0, #10
700004a4:	f000 faa2 	bl	700009ec <z_soc_irq_priority_set>
   irq_enable(SOFTWARE_INTERRUPT_ID);
700004a8:	200a      	movs	r0, #10
700004aa:	f000 faa1 	bl	700009f0 <z_soc_irq_enable>
   z_vim_irq_enable(irq);
700004ae:	200a      	movs	r0, #10
700004b0:	f000 fe76 	bl	700011a0 <z_vim_irq_enable>
   setup_interrupt();

   /* Call the main Thread-Metric function */
   main_thread_locking_test();
700004b4:	f7ff ffca 	bl	7000044c <main_thread_locking_test>
	if (z_syscall_trap()) {
		return (k_tid_t) arch_syscall_invoke0(K_SYSCALL_K_SCHED_CURRENT_THREAD_QUERY);
	}
#endif
	compiler_barrier();
	return z_impl_k_sched_current_thread_query();
700004b8:	f002 f8a8 	bl	7000260c <z_impl_k_sched_current_thread_query>

   /* Delete thread after completion */
   k_thread_abort(k_current_get());
}
700004bc:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_ABORT);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_abort(thread);
700004c0:	f002 b8aa 	b.w	70002618 <z_impl_k_thread_abort>

700004c4 <rtos_main_zephyr>:
/* Thread definition */
K_THREAD_DEFINE(main_thread, 512 /* STACKSIZE */, main_task, NULL, NULL, NULL, MAIN_TASK_PRI, K_USER, -1);

int rtos_main_zephyr(void)
{
   printk("Initializing Zephyr system...\r\n");
700004c4:	f644 3014 	movw	r0, #19220	; 0x4b14
{
700004c8:	b508      	push	{r3, lr}
   printk("Initializing Zephyr system...\r\n");
700004ca:	f2c7 0000 	movt	r0, #28672	; 0x7000
700004ce:	f000 fa5d 	bl	7000098c <printk>
	z_impl_k_wakeup(thread);
700004d2:	f644 40f0 	movw	r0, #19696	; 0x4cf0
700004d6:	f2c7 0000 	movt	r0, #28672	; 0x7000
700004da:	f002 f871 	bl	700025c0 <z_impl_k_wakeup>

   /* Create main task */
   k_thread_start(main_thread);

   printk("Main task created and running...\r\n");
700004de:	f644 3034 	movw	r0, #19252	; 0x4b34
700004e2:	f2c7 0000 	movt	r0, #28672	; 0x7000
700004e6:	f000 fa51 	bl	7000098c <printk>

   return 0;
}
700004ea:	2000      	movs	r0, #0
700004ec:	bd08      	pop	{r3, pc}
700004ee:	bf00      	nop

700004f0 <tm_isr_message_handler>:

/* Minimal ISR: No prints, no dynamic formatting */
void tm_isr_message_handler(void)
{
   int i;
   tm_isr_counter++;
700004f0:	f645 03b4 	movw	r3, #22708	; 0x58b4
   /* Generate message:
      [0] : Producer ID (1)
      [1] : Message counter (isr_message_counter)
      [2..MESSAGE_SIZE-2] : Pattern = 1000 + (isr_message_counter * 10) + index
      [MESSAGE_SIZE-1] : Checksum over first (MESSAGE_SIZE-1) words */
   message[0] = 1;
700004f4:	2001      	movs	r0, #1
   tm_isr_counter++;
700004f6:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
700004fa:	b510      	push	{r4, lr}
   tm_isr_counter++;
700004fc:	681a      	ldr	r2, [r3, #0]
   message[1] = isr_message_counter;
700004fe:	f645 04b0 	movw	r4, #22704	; 0x58b0
   message[0] = 1;
70000502:	f645 0c30 	movw	ip, #22576	; 0x5830
   message[1] = isr_message_counter;
70000506:	f2c7 0400 	movt	r4, #28672	; 0x7000
   tm_isr_counter++;
7000050a:	4402      	add	r2, r0
   message[0] = 1;
7000050c:	f2c7 0c00 	movt	ip, #28672	; 0x7000
   tm_isr_counter++;
70000510:	601a      	str	r2, [r3, #0]
   message[1] = isr_message_counter;
70000512:	4661      	mov	r1, ip
70000514:	6823      	ldr	r3, [r4, #0]
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
70000516:	2202      	movs	r2, #2
   message[0] = 1;
70000518:	f8cc 0000 	str.w	r0, [ip]
   message[1] = isr_message_counter;
7000051c:	f841 3f04 	str.w	r3, [r1, #4]!
   {
      message[i] = 1000 + (isr_message_counter * 10) + i;
70000520:	6823      	ldr	r3, [r4, #0]
70000522:	eb03 0383 	add.w	r3, r3, r3, lsl #2
70000526:	eb02 0343 	add.w	r3, r2, r3, lsl #1
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
7000052a:	3201      	adds	r2, #1
      message[i] = 1000 + (isr_message_counter * 10) + i;
7000052c:	f503 737a 	add.w	r3, r3, #1000	; 0x3e8
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
70000530:	2a1f      	cmp	r2, #31
      message[i] = 1000 + (isr_message_counter * 10) + i;
70000532:	f841 3f04 	str.w	r3, [r1, #4]!
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
70000536:	d1f3      	bne.n	70000520 <tm_isr_message_handler+0x30>
70000538:	4b0f      	ldr	r3, [pc, #60]	; (70000578 <tm_isr_message_handler+0x88>)
   unsigned long checksum = 0;
7000053a:	2200      	movs	r2, #0
7000053c:	f103 007c 	add.w	r0, r3, #124	; 0x7c
      checksum += msg[i];
70000540:	f853 1f04 	ldr.w	r1, [r3, #4]!
   for (int i = 0; i < size; i++)
70000544:	4283      	cmp	r3, r0
      checksum += msg[i];
70000546:	440a      	add	r2, r1
   for (int i = 0; i < size; i++)
70000548:	d1fa      	bne.n	70000540 <tm_isr_message_handler+0x50>
   }
   message[MESSAGE_SIZE - 1] = compute_checksum(message, MESSAGE_SIZE - 1);

   /* Measure send latency using a precomputed PMU name */
   tm_pmu_profile_start(pmu_send_names[isr_message_counter]);
7000054a:	6820      	ldr	r0, [r4, #0]
7000054c:	f245 6330 	movw	r3, #22064	; 0x5630
   message[MESSAGE_SIZE - 1] = compute_checksum(message, MESSAGE_SIZE - 1);
70000550:	f8cc 207c 	str.w	r2, [ip, #124]	; 0x7c
   tm_pmu_profile_start(pmu_send_names[isr_message_counter]);
70000554:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000558:	eb03 1000 	add.w	r0, r3, r0, lsl #4
7000055c:	f000 f8c0 	bl	700006e0 <tm_pmu_profile_start>
   tm_queue_send_from_isr(0, message);
70000560:	f645 0130 	movw	r1, #22576	; 0x5830
70000564:	2000      	movs	r0, #0
70000566:	f2c7 0100 	movt	r1, #28672	; 0x7000
7000056a:	f000 f8a7 	bl	700006bc <tm_queue_send_from_isr>
   // tm_pmu_profile_end(pmu_send_names[isr_message_counter]);

   isr_message_counter++; /* Prepare for next iteration */
7000056e:	6823      	ldr	r3, [r4, #0]
70000570:	3301      	adds	r3, #1
70000572:	6023      	str	r3, [r4, #0]
}
70000574:	bd10      	pop	{r4, pc}
70000576:	bf00      	nop
70000578:	7000582c 	.word	0x7000582c

7000057c <tm_setup_pmu>:
/* --------------------------------------------------------------------------
 * PMU Initialization (called at system boot)
 * -------------------------------------------------------------------------- */
int tm_setup_pmu(void)
{
   printk("Initializing PMU...\r\n");
7000057c:	f644 3064 	movw	r0, #19300	; 0x4b64
{
70000580:	b538      	push	{r3, r4, r5, lr}
   printk("Initializing PMU...\r\n");
70000582:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000586:	f000 fa01 	bl	7000098c <printk>

/* Performance Monitor Control Register (PMCR) */
__STATIC_FORCEINLINE uint32_t pmu_read_pmcr(void)
{
    uint32_t val;
    __asm__ volatile ("mrc p15, 0, %0, c9, c12, 0" : "=r" (val));
7000058a:	ee19 3f1c 	mrc	15, 0, r3, cr9, cr12, {0}

   /* Disable all counters (PMCR.E=0) */
   uint32_t pmcr = pmu_read_pmcr();
   pmcr &= ~0x1;
7000058e:	f023 0301 	bic.w	r3, r3, #1
    return val;
}

__STATIC_FORCEINLINE void pmu_write_pmcr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
70000592:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}
}

/* Performance Monitor Count Enable Clear Register (PMCNTENCLR) */
__STATIC_FORCEINLINE void pmu_write_cntenclr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 2" : : "r" (val));
70000596:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
7000059a:	ee09 3f5c 	mcr	15, 0, r3, cr9, cr12, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
7000059e:	2306      	movs	r3, #6
700005a0:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}
    return val;
}

__STATIC_FORCEINLINE void pmu_write_pmccntr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 0" : : "r" (val));
700005a4:	2400      	movs	r4, #0
700005a6:	ee09 4f1d 	mcr	15, 0, r4, cr9, cr13, {0}
}

/* Event Counter Selection Register (PMSELR) */
__STATIC_FORCEINLINE void pmu_select_event_counter(uint32_t counter_idx)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
700005aa:	ee09 4fbc 	mcr	15, 0, r4, cr9, cr12, {5}

   /* Configure event counters */
   for (uint32_t i = 0; i < gPmuConfig.numEventCounters; i++)
   {
      pmu_select_event_counter(i);
      pmu_write_evtyper(gPmuConfig.eventCounters[i].type);
700005ae:	f24b 03c0 	movw	r3, #45248	; 0xb0c0
700005b2:	f2c7 0300 	movt	r3, #28672	; 0x7000
}

/* Event Type Register (PMXEVTYPER) */
__STATIC_FORCEINLINE void pmu_write_evtyper(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
700005b6:	685a      	ldr	r2, [r3, #4]
700005b8:	ee09 2f3d 	mcr	15, 0, r2, cr9, cr13, {1}
    return val;
}

__STATIC_FORCEINLINE void pmu_write_evcounter(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
700005bc:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
700005c0:	2501      	movs	r5, #1
700005c2:	ee09 5fbc 	mcr	15, 0, r5, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
700005c6:	68da      	ldr	r2, [r3, #12]
700005c8:	ee09 2f3d 	mcr	15, 0, r2, cr9, cr13, {1}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
700005cc:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
700005d0:	2202      	movs	r2, #2
700005d2:	ee09 2fbc 	mcr	15, 0, r2, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
700005d6:	695b      	ldr	r3, [r3, #20]
700005d8:	ee09 3f3d 	mcr	15, 0, r3, cr9, cr13, {1}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
700005dc:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 1" : : "r" (val));
700005e0:	2307      	movs	r3, #7
700005e2:	f2c8 0300 	movt	r3, #32768	; 0x8000
700005e6:	ee09 3f3c 	mcr	15, 0, r3, cr9, cr12, {1}
    __asm__ volatile ("mrc p15, 0, %0, c9, c12, 0" : "=r" (val));
700005ea:	ee19 3f1c 	mrc	15, 0, r3, cr9, cr12, {0}
   /*    bit31 => cycle counter, plus bits [0..(numEventCounters-1)] => event counters */
   pmu_write_cntenset((1 << 31) | ((1 << gPmuConfig.numEventCounters) - 1));

   /* Enable counters in PMCR (bit[0] = E=1) */
   pmcr = pmu_read_pmcr();
   pmcr |= 0x1;
700005ee:	432b      	orrs	r3, r5
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
700005f0:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}

/* PMU User Access Enable Register (PMUSERENR) */
__STATIC_FORCEINLINE void pmu_enable_user_access(void)
{
    uint32_t val;
    __asm__ volatile ("mrc p15, 0, %0, c9, c14, 0" : "=r" (val));
700005f4:	ee19 3f1e 	mrc	15, 0, r3, cr9, cr14, {0}
    val |= 1;  // Enable user mode access
700005f8:	432b      	orrs	r3, r5
    __asm__ volatile ("mcr p15, 0, %0, c9, c14, 0" : : "r" (val));
700005fa:	ee09 3f1e 	mcr	15, 0, r3, cr9, cr14, {0}
/* --------------------------------------------------------------------------
 * Init for the Chache Hits/Misses profile structure
 * -------------------------------------------------------------------------- */
void pmu_init_profile(void)
{
   memset(&gProfileObject, 0, sizeof(gProfileObject));
700005fe:	f645 03b8 	movw	r3, #22712	; 0x58b8
70000602:	4621      	mov	r1, r4
70000604:	f241 320c 	movw	r2, #4876	; 0x130c
70000608:	f2c7 0300 	movt	r3, #28672	; 0x7000
7000060c:	4618      	mov	r0, r3
7000060e:	f002 fc2d 	bl	70002e6c <memset>
   gProfileObject.logIndex = 0;
   gProfileObject.numEvents = PMU_MAX_EVENT_COUNTERS;
70000612:	2203      	movs	r2, #3
70000614:	f500 5380 	add.w	r3, r0, #4096	; 0x1000
   printk("PMU Initialized.\r\n");
70000618:	f644 307c 	movw	r0, #19324	; 0x4b7c
   gProfileObject.bCycleCounter = 1; /* We use cycle counter */
7000061c:	f883 5308 	strb.w	r5, [r3, #776]	; 0x308
   printk("PMU Initialized.\r\n");
70000620:	f2c7 0000 	movt	r0, #28672	; 0x7000
   gProfileObject.numEvents = PMU_MAX_EVENT_COUNTERS;
70000624:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
   printk("PMU Initialized.\r\n");
70000628:	f000 f9b0 	bl	7000098c <printk>
}
7000062c:	4620      	mov	r0, r4
7000062e:	bd38      	pop	{r3, r4, r5, pc}

70000630 <tm_initialize>:
   test_initialization_function();
70000630:	4700      	bx	r0
70000632:	bf00      	nop

70000634 <tm_thread_create>:
{
70000634:	b5f0      	push	{r4, r5, r6, r7, lr}
   tid = k_thread_create(&test_thread[thread_id], test_stack[thread_id], TM_TEST_STACK_SIZE, entry_function, NULL, NULL,
70000636:	f644 5468 	movw	r4, #19816	; 0x4d68
7000063a:	ebc0 1500 	rsb	r5, r0, r0, lsl #4
7000063e:	f2c7 0400 	movt	r4, #28672	; 0x7000
{
70000642:	4613      	mov	r3, r2
70000644:	b089      	sub	sp, #36	; 0x24
70000646:	f04f 36ff 	mov.w	r6, #4294967295	; 0xffffffff
   tid = k_thread_create(&test_thread[thread_id], test_stack[thread_id], TM_TEST_STACK_SIZE, entry_function, NULL, NULL,
7000064a:	eb04 04c5 	add.w	r4, r4, r5, lsl #3
7000064e:	f04f 37ff 	mov.w	r7, #4294967295	; 0xffffffff
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
70000652:	2500      	movs	r5, #0
70000654:	f44f 6280 	mov.w	r2, #1024	; 0x400
70000658:	9103      	str	r1, [sp, #12]
7000065a:	f646 61c0 	movw	r1, #28352	; 0x6ec0
7000065e:	9504      	str	r5, [sp, #16]
70000660:	f2c7 0100 	movt	r1, #28672	; 0x7000
70000664:	e9cd 5501 	strd	r5, r5, [sp, #4]
70000668:	eb01 2180 	add.w	r1, r1, r0, lsl #10
7000066c:	9500      	str	r5, [sp, #0]
7000066e:	4620      	mov	r0, r4
70000670:	e9cd 6706 	strd	r6, r7, [sp, #24]
70000674:	f001 fc14 	bl	70001ea0 <z_impl_k_thread_create>
70000678:	4605      	mov	r5, r0
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_SUSPEND);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_suspend(thread);
7000067a:	4620      	mov	r0, r4
7000067c:	f001 fdba 	bl	700021f4 <z_impl_k_thread_suspend>
	z_impl_k_wakeup(thread);
70000680:	4620      	mov	r0, r4
70000682:	f001 ff9d 	bl	700025c0 <z_impl_k_wakeup>
}
70000686:	1b60      	subs	r0, r4, r5
70000688:	bf18      	it	ne
7000068a:	2001      	movne	r0, #1
7000068c:	b009      	add	sp, #36	; 0x24
7000068e:	bdf0      	pop	{r4, r5, r6, r7, pc}

70000690 <tm_thread_resume>:
{
70000690:	b508      	push	{r3, lr}
   k_thread_resume(&test_thread[thread_id]);
70000692:	f644 5368 	movw	r3, #19816	; 0x4d68
70000696:	ebc0 1000 	rsb	r0, r0, r0, lsl #4
7000069a:	f2c7 0300 	movt	r3, #28672	; 0x7000
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_RESUME);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_resume(thread);
7000069e:	eb03 00c0 	add.w	r0, r3, r0, lsl #3
700006a2:	f001 fe7b 	bl	7000239c <z_impl_k_thread_resume>
}
700006a6:	2000      	movs	r0, #0
700006a8:	bd08      	pop	{r3, pc}
700006aa:	bf00      	nop

700006ac <tm_thread_sleep>:
   k_sleep(K_SECONDS(seconds));
700006ac:	2100      	movs	r1, #0
700006ae:	ebc0 1340 	rsb	r3, r0, r0, lsl #5
700006b2:	eb00 0083 	add.w	r0, r0, r3, lsl #2
700006b6:	00c0      	lsls	r0, r0, #3
	return z_impl_k_sleep(timeout);
700006b8:	f001 bf74 	b.w	700025a4 <z_impl_k_sleep>

700006bc <tm_queue_send_from_isr>:
{
700006bc:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
700006c0:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
   return k_msgq_put(&test_msgq[queue_id], message_ptr, K_FOREVER);
700006c4:	f646 3cc4 	movw	ip, #27588	; 0x6bc4
700006c8:	eb00 0040 	add.w	r0, r0, r0, lsl #1
700006cc:	f2c7 0c00 	movt	ip, #28672	; 0x7000
		union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm2 = { .val = timeout };
		return (int) arch_syscall_invoke4(parm0.x, parm1.x, parm2.split.lo, parm2.split.hi, K_SYSCALL_K_MSGQ_PUT);
	}
#endif
	compiler_barrier();
	return z_impl_k_msgq_put(msgq, data, timeout);
700006d0:	eb0c 1000 	add.w	r0, ip, r0, lsl #4
700006d4:	f001 bafa 	b.w	70001ccc <z_impl_k_msgq_put>

700006d8 <tm_suspend_scheduler>:
   k_sched_lock();
700006d8:	f001 be7a 	b.w	700023d0 <k_sched_lock>

700006dc <tm_resume_scheduler>:
   k_sched_unlock();
700006dc:	f001 be88 	b.w	700023f0 <k_sched_unlock>

700006e0 <tm_pmu_profile_start>:
 * - Read "start" values
 * - Store them in the next free slot
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_start(const char* name)
{
   uint32_t idx = gProfileObject.logIndex;
700006e0:	f645 0cb8 	movw	ip, #22712	; 0x58b8
700006e4:	f2c7 0c00 	movt	ip, #28672	; 0x7000
{
700006e8:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   uint32_t idx = gProfileObject.logIndex;
700006ec:	f8dc 4000 	ldr.w	r4, [ip]
   if (idx >= PMU_MAX_LOG_ENTRIES)
700006f0:	2c3f      	cmp	r4, #63	; 0x3f
700006f2:	d833      	bhi.n	7000075c <tm_pmu_profile_start+0x7c>
      /* no more space */
      return;
   }

   TM_PMUProfilePoint* p = &gProfileObject.point[idx];
   p->name = name;
700006f4:	eb04 02c4 	add.w	r2, r4, r4, lsl #3

   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700006f8:	f50c 5380 	add.w	r3, ip, #4096	; 0x1000
   p->name = name;
700006fc:	eb04 0242 	add.w	r2, r4, r2, lsl #1
70000700:	ea4f 0ec4 	mov.w	lr, r4, lsl #3
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000704:	f8d3 5304 	ldr.w	r5, [r3, #772]	; 0x304
   p->name = name;
70000708:	eb0c 0182 	add.w	r1, ip, r2, lsl #2
7000070c:	0092      	lsls	r2, r2, #2
7000070e:	6048      	str	r0, [r1, #4]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000710:	b1dd      	cbz	r5, 7000074a <tm_pmu_profile_start+0x6a>
70000712:	f24b 06c0 	movw	r6, #45248	; 0xb0c0
70000716:	3234      	adds	r2, #52	; 0x34
70000718:	2300      	movs	r3, #0
7000071a:	f2c7 0600 	movt	r6, #28672	; 0x7000
7000071e:	4462      	add	r2, ip
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
70000720:	461f      	mov	r7, r3
70000722:	f106 0804 	add.w	r8, r6, #4
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
70000726:	ee09 3fbc 	mcr	15, 0, r3, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
7000072a:	ee09 7f5d 	mcr	15, 0, r7, cr9, cr13, {2}
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 2" : "=r" (val));
7000072e:	ee19 0f5d 	mrc	15, 0, r0, cr9, cr13, {2}
   {
      pmu_select_event_counter(i);
      /* Reset the counters to 0 */
      pmu_write_evcounter(0);
      p->eventStart[i] = pmu_read_evcounter();
70000732:	f842 0f04 	str.w	r0, [r2, #4]!
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000736:	310c      	adds	r1, #12

      /* Also store name & type */
      p->events[i].name = gPmuEventCfg[i].name;
70000738:	f856 0033 	ldr.w	r0, [r6, r3, lsl #3]
7000073c:	6088      	str	r0, [r1, #8]
      p->events[i].type = gPmuEventCfg[i].type;
7000073e:	f858 0033 	ldr.w	r0, [r8, r3, lsl #3]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000742:	3301      	adds	r3, #1
      p->events[i].type = gPmuEventCfg[i].type;
70000744:	60c8      	str	r0, [r1, #12]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000746:	42ab      	cmp	r3, r5
70000748:	d1ed      	bne.n	70000726 <tm_pmu_profile_start+0x46>
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 0" : "=r" (val));
7000074a:	ee19 3f1d 	mrc	15, 0, r3, cr9, cr13, {0}
   }
   /* Immediately read them as "start" values */
   p->cycleCountStart = pmu_read_pmccntr();
7000074e:	44a6      	add	lr, r4
70000750:	eb04 044e 	add.w	r4, r4, lr, lsl #1
70000754:	eb0c 0c84 	add.w	ip, ip, r4, lsl #2
70000758:	f8cc 3008 	str.w	r3, [ip, #8]
}
7000075c:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

70000760 <tm_pmu_profile_end>:
 * - Read PMU Registers for "end" values
 * - Compute delta
 * - Increase log index
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_end(const char* name)
{
70000760:	b570      	push	{r4, r5, r6, lr}
   uint32_t idx = gProfileObject.logIndex;
70000762:	f645 0eb8 	movw	lr, #22712	; 0x58b8
70000766:	f2c7 0e00 	movt	lr, #28672	; 0x7000
7000076a:	f8de 4000 	ldr.w	r4, [lr]
   if (idx >= PMU_MAX_LOG_ENTRIES)
7000076e:	2c3f      	cmp	r4, #63	; 0x3f
70000770:	d83a      	bhi.n	700007e8 <tm_pmu_profile_end+0x88>
70000772:	ee19 1f1d 	mrc	15, 0, r1, cr9, cr13, {0}
   //    return;
   // }

   /* Read end counters */
   p->cycleCountEnd = pmu_read_pmccntr();
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000776:	f50e 5380 	add.w	r3, lr, #4096	; 0x1000
   p->cycleCountEnd = pmu_read_pmccntr();
7000077a:	eb04 0cc4 	add.w	ip, r4, r4, lsl #3
7000077e:	00e5      	lsls	r5, r4, #3
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000780:	f8d3 6304 	ldr.w	r6, [r3, #772]	; 0x304
   p->cycleCountEnd = pmu_read_pmccntr();
70000784:	eb04 0c4c 	add.w	ip, r4, ip, lsl #1
70000788:	eb0e 038c 	add.w	r3, lr, ip, lsl #2
7000078c:	ea4f 0c8c 	mov.w	ip, ip, lsl #2
70000790:	60d9      	str	r1, [r3, #12]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000792:	b356      	cbz	r6, 700007ea <tm_pmu_profile_end+0x8a>
70000794:	2300      	movs	r3, #0
70000796:	f10c 0240 	add.w	r2, ip, #64	; 0x40
7000079a:	4472      	add	r2, lr
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
7000079c:	ee09 3fbc 	mcr	15, 0, r3, cr9, cr12, {5}
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 2" : "=r" (val));
700007a0:	ee19 0f5d 	mrc	15, 0, r0, cr9, cr13, {2}
   {
      pmu_select_event_counter(i);
      p->eventEnd[i] = pmu_read_evcounter();
700007a4:	f842 0f04 	str.w	r0, [r2, #4]!
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700007a8:	3301      	adds	r3, #1
700007aa:	42b3      	cmp	r3, r6
700007ac:	d1f6      	bne.n	7000079c <tm_pmu_profile_end+0x3c>
   }

   /* Compute deltas */
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
700007ae:	4425      	add	r5, r4
700007b0:	f10c 0034 	add.w	r0, ip, #52	; 0x34
700007b4:	eb04 0545 	add.w	r5, r4, r5, lsl #1
700007b8:	f10c 0c1c 	add.w	ip, ip, #28
700007bc:	eb0e 0585 	add.w	r5, lr, r5, lsl #2
700007c0:	eb03 0343 	add.w	r3, r3, r3, lsl #1
700007c4:	4470      	add	r0, lr
700007c6:	68ae      	ldr	r6, [r5, #8]
700007c8:	44f4      	add	ip, lr
700007ca:	2200      	movs	r2, #0
700007cc:	1b89      	subs	r1, r1, r6
700007ce:	6129      	str	r1, [r5, #16]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
   {
      uint32_t diff = p->eventEnd[i] - p->eventStart[i];
700007d0:	6901      	ldr	r1, [r0, #16]
700007d2:	f850 5f04 	ldr.w	r5, [r0, #4]!
700007d6:	1b49      	subs	r1, r1, r5
      p->events[i].value = diff;
700007d8:	f84c 1022 	str.w	r1, [ip, r2, lsl #2]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700007dc:	3203      	adds	r2, #3
700007de:	429a      	cmp	r2, r3
700007e0:	d1f6      	bne.n	700007d0 <tm_pmu_profile_end+0x70>
   }

   /* Move to next log slot for future profileStart() */
   gProfileObject.logIndex++;
700007e2:	3401      	adds	r4, #1
700007e4:	f8ce 4000 	str.w	r4, [lr]
}
700007e8:	bd70      	pop	{r4, r5, r6, pc}
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
700007ea:	689a      	ldr	r2, [r3, #8]
   gProfileObject.logIndex++;
700007ec:	3401      	adds	r4, #1
700007ee:	f8ce 4000 	str.w	r4, [lr]
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
700007f2:	1a8a      	subs	r2, r1, r2
700007f4:	611a      	str	r2, [r3, #16]
   gProfileObject.logIndex++;
700007f6:	e7f7      	b.n	700007e8 <tm_pmu_profile_end+0x88>

700007f8 <tm_pmu_profile_print>:
 * tm_pmu_profile_print_entry(name)
 * - Search for an entry with the given name
 * - Print results
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_print(const char* name)
{
700007f8:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
700007fc:	f645 09b8 	movw	r9, #22712	; 0x58b8
{
70000800:	4680      	mov	r8, r0
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
70000802:	f2c7 0900 	movt	r9, #28672	; 0x7000
70000806:	f8d9 a000 	ldr.w	sl, [r9]
7000080a:	f1ba 0f00 	cmp.w	sl, #0
7000080e:	d00d      	beq.n	7000082c <tm_pmu_profile_print+0x34>
70000810:	464e      	mov	r6, r9
70000812:	2500      	movs	r5, #0
   {
      TM_PMUProfilePoint* p = &gProfileObject.point[i];
      if (p->name != NULL && strcmp(p->name, name) == 0)
70000814:	6877      	ldr	r7, [r6, #4]
70000816:	4641      	mov	r1, r8
70000818:	4638      	mov	r0, r7
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
7000081a:	364c      	adds	r6, #76	; 0x4c
      if (p->name != NULL && strcmp(p->name, name) == 0)
7000081c:	b11f      	cbz	r7, 70000826 <tm_pmu_profile_print+0x2e>
7000081e:	f7ff fc0f 	bl	70000040 <strcmp>
70000822:	4604      	mov	r4, r0
70000824:	b158      	cbz	r0, 7000083e <tm_pmu_profile_print+0x46>
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
70000826:	3501      	adds	r5, #1
70000828:	4555      	cmp	r5, sl
7000082a:	d1f3      	bne.n	70000814 <tm_pmu_profile_print+0x1c>
         }
         printk("\r\n");
         return;
      }
   }
   printk("No profile entry found for name: %s\r\n", name);
7000082c:	f644 30c8 	movw	r0, #19400	; 0x4bc8
70000830:	4641      	mov	r1, r8
70000832:	f2c7 0000 	movt	r0, #28672	; 0x7000
}
70000836:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   printk("No profile entry found for name: %s\r\n", name);
7000083a:	f000 b8a7 	b.w	7000098c <printk>
         printk("Profile Entry: %s\r\n", p->name);
7000083e:	f644 3090 	movw	r0, #19344	; 0x4b90
70000842:	4639      	mov	r1, r7
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
70000844:	4e17      	ldr	r6, [pc, #92]	; (700008a4 <tm_pmu_profile_print+0xac>)
         printk("Profile Entry: %s\r\n", p->name);
70000846:	f2c7 0000 	movt	r0, #28672	; 0x7000
7000084a:	f000 f89f 	bl	7000098c <printk>
         printk("Cycle Count: %u\r\n", p->cycleCountValue);
7000084e:	f644 30a4 	movw	r0, #19364	; 0x4ba4
70000852:	eb05 03c5 	add.w	r3, r5, r5, lsl #3
70000856:	f2c7 0000 	movt	r0, #28672	; 0x7000
7000085a:	eb05 0543 	add.w	r5, r5, r3, lsl #1
7000085e:	eb09 0985 	add.w	r9, r9, r5, lsl #2
70000862:	f8d9 1010 	ldr.w	r1, [r9, #16]
70000866:	f000 f891 	bl	7000098c <printk>
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
7000086a:	f8d6 3304 	ldr.w	r3, [r6, #772]	; 0x304
7000086e:	b18b      	cbz	r3, 70000894 <tm_pmu_profile_print+0x9c>
            printk("%s Count: %u\r\n", p->events[j].name, p->events[j].value);
70000870:	f644 35b8 	movw	r5, #19384	; 0x4bb8
70000874:	f2c7 0500 	movt	r5, #28672	; 0x7000
70000878:	f8d9 201c 	ldr.w	r2, [r9, #28]
7000087c:	4628      	mov	r0, r5
7000087e:	f8d9 1014 	ldr.w	r1, [r9, #20]
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
70000882:	3401      	adds	r4, #1
            printk("%s Count: %u\r\n", p->events[j].name, p->events[j].value);
70000884:	f000 f882 	bl	7000098c <printk>
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
70000888:	f8d6 3304 	ldr.w	r3, [r6, #772]	; 0x304
7000088c:	f109 090c 	add.w	r9, r9, #12
70000890:	42a3      	cmp	r3, r4
70000892:	d8f1      	bhi.n	70000878 <tm_pmu_profile_print+0x80>
         printk("\r\n");
70000894:	f644 3054 	movw	r0, #19284	; 0x4b54
}
70000898:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
         printk("\r\n");
7000089c:	f2c7 0000 	movt	r0, #28672	; 0x7000
700008a0:	f000 b874 	b.w	7000098c <printk>
700008a4:	700068b8 	.word	0x700068b8

700008a8 <free_list_add>:
	h->free_bytes += chunksz_to_bytes(h, chunk_size(h, c));
#endif
}

static void free_list_add(struct z_heap *h, chunkid_t c)
{
700008a8:	b530      	push	{r4, r5, lr}
	void *cmem = &buf[c];

	if (big_heap(h)) {
		return ((uint32_t *)cmem)[f];
	} else {
		return ((uint16_t *)cmem)[f];
700008aa:	eb00 04c1 	add.w	r4, r0, r1, lsl #3
700008ae:	8863      	ldrh	r3, [r4, #2]
	return chunk_field(h, c, SIZE_AND_USED) & 1U;
}

static inline chunksz_t chunk_size(struct z_heap *h, chunkid_t c)
{
	return chunk_field(h, c, SIZE_AND_USED) >> 1;
700008b0:	085b      	lsrs	r3, r3, #1
}

static inline int bucket_idx(struct z_heap *h, chunksz_t sz)
{
	unsigned int usable_sz = sz - min_chunk_size(h) + 1;
	return 31 - __builtin_clz(usable_sz);
700008b2:	fab3 f383 	clz	r3, r3
700008b6:	f1c3 031f 	rsb	r3, r3, #31
	void *cmem = &buf[c];
700008ba:	ea4f 0cc1 	mov.w	ip, r1, lsl #3
	if (b->next == 0U) {
700008be:	eb00 0583 	add.w	r5, r0, r3, lsl #2
		((uint16_t *)cmem)[f] = val;
700008c2:	f10c 0c04 	add.w	ip, ip, #4
700008c6:	fa1f fe81 	uxth.w	lr, r1
700008ca:	692a      	ldr	r2, [r5, #16]
700008cc:	b962      	cbnz	r2, 700008e8 <free_list_add+0x40>
		h->avail_buckets |= BIT(bidx);
700008ce:	2401      	movs	r4, #1
700008d0:	f36e 020f 	bfi	r2, lr, #0, #16
700008d4:	f36e 421f 	bfi	r2, lr, #16, #16
700008d8:	409c      	lsls	r4, r3
700008da:	68c3      	ldr	r3, [r0, #12]
700008dc:	4323      	orrs	r3, r4
700008de:	60c3      	str	r3, [r0, #12]
		b->next = c;
700008e0:	6129      	str	r1, [r5, #16]
700008e2:	f840 200c 	str.w	r2, [r0, ip]
	if (!solo_free_header(h, c)) {
		int bidx = bucket_idx(h, chunk_size(h, c));
		free_list_add_bidx(h, c, bidx);
	}
}
700008e6:	bd30      	pop	{r4, r5, pc}
	void *cmem = &buf[c];
700008e8:	00d3      	lsls	r3, r2, #3
		return ((uint16_t *)cmem)[f];
700008ea:	3304      	adds	r3, #4
700008ec:	5ac1      	ldrh	r1, [r0, r3]
		((uint16_t *)cmem)[f] = val;
700008ee:	f820 100c 	strh.w	r1, [r0, ip]
700008f2:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
700008f6:	80e2      	strh	r2, [r4, #6]
700008f8:	f8a1 e006 	strh.w	lr, [r1, #6]
700008fc:	f820 e003 	strh.w	lr, [r0, r3]
70000900:	bd30      	pop	{r4, r5, pc}
70000902:	bf00      	nop

70000904 <sys_heap_init>:
		__ASSERT(bytes / CHUNK_UNIT <= 0x7fffffffU, "heap size is too big");
	}

	/* Reserve the end marker chunk's header */
	__ASSERT(bytes > heap_footer_bytes(bytes), "heap size is too small");
	bytes -= heap_footer_bytes(bytes);
70000904:	3a04      	subs	r2, #4
{
70000906:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}

	/* Round the start up, the end down */
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
7000090a:	188d      	adds	r5, r1, r2
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
7000090c:	1dcc      	adds	r4, r1, #7
7000090e:	f024 0407 	bic.w	r4, r4, #7
	__ASSERT(heap_sz > chunksz(sizeof(struct z_heap)), "heap size is too small");

	struct z_heap *h = (struct z_heap *)addr;
	heap->heap = h;
	h->end_chunk = heap_sz;
	h->avail_buckets = 0;
70000912:	f04f 0800 	mov.w	r8, #0
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
70000916:	f025 0507 	bic.w	r5, r5, #7
	heap->heap = h;
7000091a:	6004      	str	r4, [r0, #0]
	chunksz_t heap_sz = (end - addr) / CHUNK_UNIT;
7000091c:	1b2d      	subs	r5, r5, r4
				     nb_buckets * sizeof(struct z_heap_bucket));

	__ASSERT(chunk0_size + min_chunk_size(h) <= heap_sz, "heap size is too small");

	for (int i = 0; i < nb_buckets; i++) {
		h->buckets[i].next = 0;
7000091e:	4641      	mov	r1, r8
70000920:	f104 0010 	add.w	r0, r4, #16
	chunksz_t heap_sz = (end - addr) / CHUNK_UNIT;
70000924:	08ef      	lsrs	r7, r5, #3
	return 31 - __builtin_clz(usable_sz);
70000926:	fab7 f287 	clz	r2, r7
	h->avail_buckets = 0;
7000092a:	e9c4 7802 	strd	r7, r8, [r4, #8]
	chunksz_t chunk0_size = chunksz(sizeof(struct z_heap) +
7000092e:	f1c2 0624 	rsb	r6, r2, #36	; 0x24
	int nb_buckets = bucket_idx(h, heap_sz) + 1;
70000932:	f1c2 0220 	rsb	r2, r2, #32
	chunksz_t chunk0_size = chunksz(sizeof(struct z_heap) +
70000936:	00b6      	lsls	r6, r6, #2
	return (bytes + CHUNK_UNIT - 1U) / CHUNK_UNIT;
70000938:	3607      	adds	r6, #7
		h->buckets[i].next = 0;
7000093a:	0092      	lsls	r2, r2, #2
7000093c:	08f6      	lsrs	r6, r6, #3
7000093e:	f002 fa95 	bl	70002e6c <memset>
		((uint16_t *)cmem)[f] = val;
70000942:	f8a4 8000 	strh.w	r8, [r4]
	set_chunk_size(h, 0, chunk0_size);
	set_left_chunk_size(h, 0, 0);
	set_chunk_used(h, 0, true);

	/* chunk containing the free heap */
	set_chunk_size(h, chunk0_size, heap_sz - chunk0_size);
70000946:	1bbb      	subs	r3, r7, r6
	/* the end marker chunk */
	set_chunk_size(h, heap_sz, 0);
	set_left_chunk_size(h, heap_sz, heap_sz - chunk0_size);
	set_chunk_used(h, heap_sz, true);

	free_list_add(h, chunk0_size);
70000948:	4620      	mov	r0, r4
	chunk_set(h, c, SIZE_AND_USED, size << 1);
7000094a:	0072      	lsls	r2, r6, #1
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
7000094c:	f042 0201 	orr.w	r2, r2, #1
	chunk_set(h, c, SIZE_AND_USED, size << 1);
70000950:	0059      	lsls	r1, r3, #1
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
70000952:	8062      	strh	r2, [r4, #2]
		((uint16_t *)cmem)[f] = val;
70000954:	eb04 02c6 	add.w	r2, r4, r6, lsl #3
70000958:	8051      	strh	r1, [r2, #2]
7000095a:	1962      	adds	r2, r4, r5
7000095c:	f824 6036 	strh.w	r6, [r4, r6, lsl #3]
70000960:	4631      	mov	r1, r6
70000962:	5363      	strh	r3, [r4, r5]
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
70000964:	2301      	movs	r3, #1
70000966:	8053      	strh	r3, [r2, #2]
}
70000968:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
	free_list_add(h, chunk0_size);
7000096c:	f7ff bf9c 	b.w	700008a8 <free_list_add>

70000970 <arch_printk_char_out>:
{
	ARG_UNUSED(c);

	/* do nothing */
	return 0;
}
70000970:	2000      	movs	r0, #0
70000972:	4770      	bx	lr

70000974 <char_out>:
}

static int char_out(int c, void *ctx_p)
{
	ARG_UNUSED(ctx_p);
	return _char_out(c);
70000974:	f24b 03d8 	movw	r3, #45272	; 0xb0d8
70000978:	f2c7 0300 	movt	r3, #28672	; 0x7000
7000097c:	681b      	ldr	r3, [r3, #0]
7000097e:	4718      	bx	r3

70000980 <__printk_hook_install>:
	_char_out = fn;
70000980:	f24b 03d8 	movw	r3, #45272	; 0xb0d8
70000984:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000988:	6018      	str	r0, [r3, #0]
}
7000098a:	4770      	bx	lr

7000098c <printk>:
 *
 * @param fmt formatted string to output
 */

void printk(const char *fmt, ...)
{
7000098c:	b40f      	push	{r0, r1, r2, r3}
7000098e:	b500      	push	{lr}
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000990:	f640 1075 	movw	r0, #2421	; 0x975
{
70000994:	b087      	sub	sp, #28
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000996:	2300      	movs	r3, #0
{
70000998:	aa08      	add	r2, sp, #32
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
7000099a:	f04f 0c02 	mov.w	ip, #2
7000099e:	f2c7 0000 	movt	r0, #28672	; 0x7000
700009a2:	e9cd 3304 	strd	r3, r3, [sp, #16]
700009a6:	e9cd 3002 	strd	r3, r0, [sp, #8]
		(void) vfprintf(&console, fmt, ap);
700009aa:	a802      	add	r0, sp, #8
{
700009ac:	f852 1b04 	ldr.w	r1, [r2], #4
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
700009b0:	f88d c00a 	strb.w	ip, [sp, #10]
	va_list ap;

	va_start(ap, fmt);
700009b4:	9201      	str	r2, [sp, #4]
		(void) vfprintf(&console, fmt, ap);
700009b6:	f002 fc31 	bl	7000321c <__l_vfprintf>

	vprintk(fmt, ap);

	va_end(ap);
}
700009ba:	b007      	add	sp, #28
700009bc:	f85d eb04 	ldr.w	lr, [sp], #4
700009c0:	b004      	add	sp, #16
700009c2:	4770      	bx	lr

700009c4 <z_thread_entry>:
 * This routine does not return, and is marked as such so the compiler won't
 * generate preamble code that is only used by functions that actually return.
 */
FUNC_NORETURN void z_thread_entry(k_thread_entry_t entry,
				 void *p1, void *p2, void *p3)
{
700009c4:	468c      	mov	ip, r1
700009c6:	4604      	mov	r4, r0
700009c8:	4611      	mov	r1, r2

	sys_rand_get((uint8_t *)&stack_guard, sizeof(stack_guard));
	__stack_chk_guard = stack_guard;
	__stack_chk_guard <<= 8;
#endif	/* CONFIG_STACK_CANARIES */
	entry(p1, p2, p3);
700009ca:	4660      	mov	r0, ip
700009cc:	461a      	mov	r2, r3
{
700009ce:	b508      	push	{r3, lr}
	entry(p1, p2, p3);
700009d0:	47a0      	blx	r4
	return z_impl_k_sched_current_thread_query();
700009d2:	f001 fe1b 	bl	7000260c <z_impl_k_sched_current_thread_query>
	z_impl_k_thread_abort(thread);
700009d6:	f001 fe1f 	bl	70002618 <z_impl_k_thread_abort>
700009da:	bf00      	nop

700009dc <_ConfigAbsSyms>:
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_WARN_DEPRECATED, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_ENFORCE_ZEPHYR_STDINT, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_LEGACY_GENERATED_INCLUDE_PATH, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_BENCHMARK_NUM_ITERATIONS, 1000);

GEN_ABS_SYM_END
700009dc:	4770      	bx	lr
700009de:	bf00      	nop

700009e0 <z_soc_irq_get_active>:

#include "soc.h"

unsigned int z_soc_irq_get_active(void)
{
	return z_vim_irq_get_active();
700009e0:	f000 bb4c 	b.w	7000107c <z_vim_irq_get_active>

700009e4 <z_soc_irq_eoi>:
}

void z_soc_irq_eoi(unsigned int irq)
{
	z_vim_irq_eoi(irq);
700009e4:	f000 bb70 	b.w	700010c8 <z_vim_irq_eoi>

700009e8 <z_soc_irq_init>:
}

void z_soc_irq_init(void)
{
	z_vim_irq_init();
700009e8:	f000 bb76 	b.w	700010d8 <z_vim_irq_init>

700009ec <z_soc_irq_priority_set>:
}

void z_soc_irq_priority_set(unsigned int irq, unsigned int prio, uint32_t flags)
{
	/* Configure interrupt type and priority */
	z_vim_irq_priority_set(irq, prio, flags);
700009ec:	f000 bbac 	b.w	70001148 <z_vim_irq_priority_set>

700009f0 <z_soc_irq_enable>:
}

void z_soc_irq_enable(unsigned int irq)
{
	/* Enable interrupt */
	z_vim_irq_enable(irq);
700009f0:	f000 bbd6 	b.w	700011a0 <z_vim_irq_enable>

700009f4 <soc_reset_hook>:
	/* Check if interrupt is enabled */
	return z_vim_irq_is_enabled(irq);
}

void soc_reset_hook(void)
{
700009f4:	b508      	push	{r3, lr}
 *
 */
static ALWAYS_INLINE void sys_cache_instr_enable(void)
{
#if defined(CONFIG_CACHE_MANAGEMENT) && defined(CONFIG_ICACHE)
	cache_instr_enable();
700009f6:	f000 fa35 	bl	70000e64 <arch_icache_enable>
	/*
	 * Enable the caches only if configured to do so.
	 */
	sys_cache_instr_enable();
	sys_cache_data_enable();
700009fa:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	cache_data_enable();
700009fe:	f000 ba23 	b.w	70000e48 <arch_dcache_enable>
70000a02:	bf00      	nop

70000a04 <z_arm_fatal_error>:

		LOG_ERR("Unhandled IRQn: %d", irqn);
	}
#endif

	z_fatal_error(reason, esf);
70000a04:	f000 bff8 	b.w	700019f8 <z_fatal_error>

70000a08 <z_do_kernel_oops>:
 * @param esf exception frame
 * @param callee_regs Callee-saved registers (R4-R11)
 * @param exc_return EXC_RETURN value present in LR after exception entry.
 */
void z_do_kernel_oops(const struct arch_esf *esf, _callee_saved_t *callee_regs, uint32_t exc_return)
{
70000a08:	4601      	mov	r1, r0
	z_fatal_error(reason, esf);
70000a0a:	6800      	ldr	r0, [r0, #0]
70000a0c:	f000 bff4 	b.w	700019f8 <z_fatal_error>

70000a10 <z_arm_nmi>:
 * Simply call what is installed in 'static void(*handler)(void)'.
 *
 */

void z_arm_nmi(void)
{
70000a10:	b508      	push	{r3, lr}
	handler();
70000a12:	f24b 1338 	movw	r3, #45368	; 0xb138
70000a16:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000a1a:	681b      	ldr	r3, [r3, #0]
70000a1c:	4798      	blx	r3
	z_arm_int_exit();
}
70000a1e:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_arm_int_exit();
70000a22:	f002 bf99 	b.w	70003958 <__z_arm_int_exit_from_thumb>
70000a26:	bf00      	nop

70000a28 <z_SysNmiOnReset>:
_ASM_FILE_PROLOGUE

GTEXT(z_SysNmiOnReset)

SECTION_FUNC(TEXT, z_SysNmiOnReset)
    wfi
70000a28:	e320f003 	wfi
    b z_SysNmiOnReset
70000a2c:	eafffffd 	b	70000a28 <z_SysNmiOnReset>

70000a30 <z_arm_undef_instruction>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_undef_instruction)
	/*
	 * The undefined instruction address is offset by 2 if the previous
	 * mode is Thumb; otherwise, it is offset by 4.
	 */
	push {r0}
70000a30:	e52d0004 	push	{r0}		; (str r0, [sp, #-4]!)
	mrs r0, spsr
70000a34:	e14f0000 	mrs	r0, SPSR
	tst r0, #T_BIT
70000a38:	e3100020 	tst	r0, #32
	subeq lr, #4	/* ARM   (!T_BIT) */
70000a3c:	024ee004 	subeq	lr, lr, #4
	subne lr, #2	/* Thumb (T_BIT) */
70000a40:	124ee002 	subne	lr, lr, #2
	pop {r0}
70000a44:	e49d0004 	pop	{r0}		; (ldr r0, [sp], #4)

	/*
	 * Store r0-r3, r12, lr, lr_und and spsr_und into the stack to
	 * construct an exception stack frame.
	 */
	srsdb sp!, #MODE_UND
70000a48:	f96d051b 	srsdb	sp!, #27
	stmfd sp, {r0-r3, r12, lr}^
70000a4c:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
	sub sp, #24
70000a50:	e24dd018 	sub	sp, sp, #24

	/* Increment exception nesting count */
	get_cpu r2
70000a54:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000a58:	e3c22003 	bic	r2, r2, #3
	ldr r1, [r2, #___cpu_t_nested_OFFSET]
70000a5c:	e5921000 	ldr	r1, [r2]
	add r1, r1, #1
70000a60:	e2811001 	add	r1, r1, #1
	str r1, [r2, #___cpu_t_nested_OFFSET]
70000a64:	e5821000 	str	r1, [r2]
	cps #MODE_UND

	mov r0, sp
	mov sp, r1
#else
	mov r0, sp
70000a68:	e1a0000d 	mov	r0, sp
#endif

	bl z_arm_fault_undef_instruction
70000a6c:	fa00001b 	blx	70000ae0 <z_arm_fault_undef_instruction>
	exception_exit

	b z_arm_exc_exit
70000a70:	ea000153 	b	70000fc4 <z_arm_exc_exit>

70000a74 <z_arm_prefetch_abort>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_prefetch_abort)
	/*
	 * The faulting instruction address is always offset by 4 for the
	 * prefetch abort exceptions.
	 */
	sub lr, #4
70000a74:	e24ee004 	sub	lr, lr, #4

	exception_entry MODE_ABT
70000a78:	f96d0517 	srsdb	sp!, #23
70000a7c:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
70000a80:	e24dd018 	sub	sp, sp, #24
70000a84:	e1a0000d 	mov	r0, sp
70000a88:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000a8c:	e3c22003 	bic	r2, r2, #3
70000a90:	e5921000 	ldr	r1, [r2]
70000a94:	e2811001 	add	r1, r1, #1
70000a98:	e5821000 	str	r1, [r2]
	bl z_arm_fault_prefetch
70000a9c:	fa000013 	blx	70000af0 <z_arm_fault_prefetch>
	exception_exit

	b z_arm_exc_exit
70000aa0:	ea000147 	b	70000fc4 <z_arm_exc_exit>

70000aa4 <z_arm_data_abort>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_data_abort)
	/*
	 * The faulting instruction address is always offset by 8 for the data
	 * abort exceptions.
	 */
	sub lr, #8
70000aa4:	e24ee008 	sub	lr, lr, #8

	exception_entry MODE_ABT
70000aa8:	f96d0517 	srsdb	sp!, #23
70000aac:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
70000ab0:	e24dd018 	sub	sp, sp, #24
70000ab4:	e1a0000d 	mov	r0, sp
70000ab8:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000abc:	e3c22003 	bic	r2, r2, #3
70000ac0:	e5921000 	ldr	r1, [r2]
70000ac4:	e2811001 	add	r1, r1, #1
70000ac8:	e5821000 	str	r1, [r2]
	bl z_arm_fault_data
70000acc:	fa00002c 	blx	70000b84 <z_arm_fault_data>
	/*
	 * If z_arm_fault_data returns false, then we recovered from
	 * the error.  It may have updated $pc, so copy $pc back to
	 * the true esf from the one passed to z_arm_fault_data.
	 */
	cmp r0, #0
70000ad0:	e3500000 	cmp	r0, #0
	ldreq r1, [sp, #24 + FPU_SF_SIZE]
70000ad4:	059d1018 	ldreq	r1, [sp, #24]

	exception_exit

	streq r1, [sp, #24 + FPU_SF_SIZE]
70000ad8:	058d1018 	streq	r1, [sp, #24]

	b z_arm_exc_exit
70000adc:	ea000138 	b	70000fc4 <z_arm_exc_exit>

70000ae0 <z_arm_fault_undef_instruction>:
 * @brief Undefined instruction fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_undef_instruction(struct arch_esf *esf)
{
70000ae0:	4601      	mov	r1, r0
	uint32_t reason = IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) ?
			  K_ERR_CPU_EXCEPTION :
			  K_ERR_ARM_UNDEFINED_INSTRUCTION;

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70000ae2:	202d      	movs	r0, #45	; 0x2d
{
70000ae4:	b508      	push	{r3, lr}
	z_arm_fatal_error(reason, esf);
70000ae6:	f7ff ff8d 	bl	70000a04 <z_arm_fatal_error>

	/* All undefined instructions are treated as fatal for now */
	return true;
}
70000aea:	2001      	movs	r0, #1
70000aec:	bd08      	pop	{r3, pc}
70000aee:	bf00      	nop

70000af0 <z_arm_fault_prefetch>:
 * @brief Prefetch abort fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_prefetch(struct arch_esf *esf)
{
70000af0:	4601      	mov	r1, r0
70000af2:	b508      	push	{r3, lr}
    \return               Instruction Fault Status Register value
 */
__STATIC_FORCEINLINE uint32_t __get_IFSR(void)
{
  uint32_t result;
  __get_CP(15, 0, result, 5, 0, 1);
70000af4:	ee15 2f30 	mrc	15, 0, r2, cr5, cr0, {1}
	__get_CP(15, 0, result, 6, 0, 2);
70000af8:	ee16 3f50 	mrc	15, 0, r3, cr6, cr0, {2}
	/* Read and parse Instruction Fault Status Register (IFSR) */
	uint32_t ifsr = __get_IFSR();
#if defined(CONFIG_AARCH32_ARMV8_R)
	uint32_t fs = ifsr & IFSR_STATUS_Msk;
#else
	uint32_t fs = ((ifsr & IFSR_FS1_Msk) >> 6) | (ifsr & IFSR_FS0_Msk);
70000afc:	0993      	lsrs	r3, r2, #6
70000afe:	f003 0310 	and.w	r3, r3, #16
70000b02:	f002 020f 	and.w	r2, r2, #15
70000b06:	4313      	orrs	r3, r2
	switch (status) {
70000b08:	2b19      	cmp	r3, #25
70000b0a:	d80e      	bhi.n	70000b2a <z_arm_fault_prefetch+0x3a>
70000b0c:	e8df f003 	tbb	[pc, r3]
70000b10:	0d1c3717 	.word	0x0d1c3717
70000b14:	0d0d0d0d 	.word	0x0d0d0d0d
70000b18:	0d0d0d23 	.word	0x0d0d0d23
70000b1c:	0d0d280d 	.word	0x0d0d280d
70000b20:	0d0d0d0d 	.word	0x0d0d0d0d
70000b24:	0d2d0d0d 	.word	0x0d2d0d0d
70000b28:	1232      	.short	0x1232
	uint32_t reason = K_ERR_CPU_EXCEPTION;
70000b2a:	2000      	movs	r0, #0
	if (IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) && (reason >= K_ERR_ARCH_START)) {
		reason = K_ERR_CPU_EXCEPTION;
	}

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70000b2c:	f7ff ff6a 	bl	70000a04 <z_arm_fatal_error>

	/* All prefetch aborts are treated as fatal for now */
	return true;
}
70000b30:	2001      	movs	r0, #1
70000b32:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_PARITY_ERROR;
70000b34:	2033      	movs	r0, #51	; 0x33
	z_arm_fatal_error(reason, esf);
70000b36:	f7ff ff65 	bl	70000a04 <z_arm_fatal_error>
}
70000b3a:	2001      	movs	r0, #1
70000b3c:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_BACKGROUND_FAULT;
70000b3e:	202f      	movs	r0, #47	; 0x2f
	z_arm_fatal_error(reason, esf);
70000b40:	f7ff ff60 	bl	70000a04 <z_arm_fatal_error>
}
70000b44:	2001      	movs	r0, #1
70000b46:	bd08      	pop	{r3, pc}
	__get_CP(14, 0, result, 0, 1, 0);
70000b48:	ee10 3e11 	mrc	14, 0, r3, cr0, cr1, {0}
		reason = K_ERR_ARM_DEBUG_EVENT;
70000b4c:	2035      	movs	r0, #53	; 0x35
	z_arm_fatal_error(reason, esf);
70000b4e:	f7ff ff59 	bl	70000a04 <z_arm_fatal_error>
}
70000b52:	2001      	movs	r0, #1
70000b54:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_EXTERNAL_ABORT;
70000b56:	2031      	movs	r0, #49	; 0x31
	z_arm_fatal_error(reason, esf);
70000b58:	f7ff ff54 	bl	70000a04 <z_arm_fatal_error>
}
70000b5c:	2001      	movs	r0, #1
70000b5e:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_PERMISSION_FAULT;
70000b60:	2030      	movs	r0, #48	; 0x30
	z_arm_fatal_error(reason, esf);
70000b62:	f7ff ff4f 	bl	70000a04 <z_arm_fatal_error>
}
70000b66:	2001      	movs	r0, #1
70000b68:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_EXTERNAL_ABORT;
70000b6a:	2032      	movs	r0, #50	; 0x32
	z_arm_fatal_error(reason, esf);
70000b6c:	f7ff ff4a 	bl	70000a04 <z_arm_fatal_error>
}
70000b70:	2001      	movs	r0, #1
70000b72:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_PARITY_ERROR;
70000b74:	2034      	movs	r0, #52	; 0x34
	z_arm_fatal_error(reason, esf);
70000b76:	f7ff ff45 	bl	70000a04 <z_arm_fatal_error>
}
70000b7a:	2001      	movs	r0, #1
70000b7c:	bd08      	pop	{r3, pc}
	switch (status) {
70000b7e:	202e      	movs	r0, #46	; 0x2e
70000b80:	e7d4      	b.n	70000b2c <z_arm_fault_prefetch+0x3c>
70000b82:	bf00      	nop

70000b84 <z_arm_fault_data>:
 * @brief Data abort fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_data(struct arch_esf *esf)
{
70000b84:	4601      	mov	r1, r0
70000b86:	b508      	push	{r3, lr}
  __get_CP(15, 0, result, 5, 0, 0);
70000b88:	ee15 2f10 	mrc	15, 0, r2, cr5, cr0, {0}
	__get_CP(15, 0, result, 6, 0, 0);
70000b8c:	ee16 3f10 	mrc	15, 0, r3, cr6, cr0, {0}
	/* Read and parse Data Fault Status Register (DFSR) */
	uint32_t dfsr = __get_DFSR();
#if defined(CONFIG_AARCH32_ARMV8_R)
	uint32_t fs = dfsr & DFSR_STATUS_Msk;
#else
	uint32_t fs = ((dfsr & DFSR_FS1_Msk) >> 6) | (dfsr & DFSR_FS0_Msk);
70000b90:	0993      	lsrs	r3, r2, #6
70000b92:	f003 0310 	and.w	r3, r3, #16
70000b96:	f002 020f 	and.w	r2, r2, #15
70000b9a:	4313      	orrs	r3, r2
	switch (status) {
70000b9c:	2b19      	cmp	r3, #25
70000b9e:	d80e      	bhi.n	70000bbe <z_arm_fault_data+0x3a>
70000ba0:	e8df f003 	tbb	[pc, r3]
70000ba4:	0d1c3717 	.word	0x0d1c3717
70000ba8:	0d0d0d0d 	.word	0x0d0d0d0d
70000bac:	0d0d0d23 	.word	0x0d0d0d23
70000bb0:	0d0d280d 	.word	0x0d0d280d
70000bb4:	0d0d0d0d 	.word	0x0d0d0d0d
70000bb8:	0d2d0d0d 	.word	0x0d2d0d0d
70000bbc:	1232      	.short	0x1232
	uint32_t reason = K_ERR_CPU_EXCEPTION;
70000bbe:	2000      	movs	r0, #0
	if (IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) && (reason >= K_ERR_ARCH_START)) {
		reason = K_ERR_CPU_EXCEPTION;
	}

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70000bc0:	f7ff ff20 	bl	70000a04 <z_arm_fatal_error>

	/* All data aborts are treated as fatal for now */
	return true;
}
70000bc4:	2001      	movs	r0, #1
70000bc6:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_PARITY_ERROR;
70000bc8:	2033      	movs	r0, #51	; 0x33
	z_arm_fatal_error(reason, esf);
70000bca:	f7ff ff1b 	bl	70000a04 <z_arm_fatal_error>
}
70000bce:	2001      	movs	r0, #1
70000bd0:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_BACKGROUND_FAULT;
70000bd2:	202f      	movs	r0, #47	; 0x2f
	z_arm_fatal_error(reason, esf);
70000bd4:	f7ff ff16 	bl	70000a04 <z_arm_fatal_error>
}
70000bd8:	2001      	movs	r0, #1
70000bda:	bd08      	pop	{r3, pc}
	__get_CP(14, 0, result, 0, 1, 0);
70000bdc:	ee10 3e11 	mrc	14, 0, r3, cr0, cr1, {0}
		reason = K_ERR_ARM_DEBUG_EVENT;
70000be0:	2035      	movs	r0, #53	; 0x35
	z_arm_fatal_error(reason, esf);
70000be2:	f7ff ff0f 	bl	70000a04 <z_arm_fatal_error>
}
70000be6:	2001      	movs	r0, #1
70000be8:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_EXTERNAL_ABORT;
70000bea:	2031      	movs	r0, #49	; 0x31
	z_arm_fatal_error(reason, esf);
70000bec:	f7ff ff0a 	bl	70000a04 <z_arm_fatal_error>
}
70000bf0:	2001      	movs	r0, #1
70000bf2:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_PERMISSION_FAULT;
70000bf4:	2030      	movs	r0, #48	; 0x30
	z_arm_fatal_error(reason, esf);
70000bf6:	f7ff ff05 	bl	70000a04 <z_arm_fatal_error>
}
70000bfa:	2001      	movs	r0, #1
70000bfc:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_EXTERNAL_ABORT;
70000bfe:	2032      	movs	r0, #50	; 0x32
	z_arm_fatal_error(reason, esf);
70000c00:	f7ff ff00 	bl	70000a04 <z_arm_fatal_error>
}
70000c04:	2001      	movs	r0, #1
70000c06:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_PARITY_ERROR;
70000c08:	2034      	movs	r0, #52	; 0x34
	z_arm_fatal_error(reason, esf);
70000c0a:	f7ff fefb 	bl	70000a04 <z_arm_fatal_error>
}
70000c0e:	2001      	movs	r0, #1
70000c10:	bd08      	pop	{r3, pc}
	switch (status) {
70000c12:	202e      	movs	r0, #46	; 0x2e
70000c14:	e7d4      	b.n	70000bc0 <z_arm_fault_data+0x3c>
70000c16:	bf00      	nop

70000c18 <z_arm_interrupt_init>:
	/*
	 * Initialise interrupt controller.
	 */
#ifdef CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER
	/* Invoke SoC-specific interrupt controller initialisation */
	z_soc_irq_init();
70000c18:	f7ff bee6 	b.w	700009e8 <z_soc_irq_init>

70000c1c <relocate_vector_table>:
		write_sysreg64(val, op1, CRm);				\
	}

MAKE_REG_HELPER(mpuir,	     0, 0, 0, 4);
MAKE_REG_HELPER(mpidr,	     0, 0, 0, 5);
MAKE_REG_HELPER(sctlr,	     0, 1, 0, 0);
70000c1c:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}

void __weak relocate_vector_table(void)
{
#if defined(CONFIG_XIP) && (CONFIG_FLASH_BASE_ADDRESS != 0) ||                                     \
	!defined(CONFIG_XIP) && (CONFIG_SRAM_BASE_ADDRESS != 0)
	write_sctlr(read_sctlr() & ~HIVECS);
70000c20:	f423 5300 	bic.w	r3, r3, #8192	; 0x2000
70000c24:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
	size_t vector_size = (size_t)_vector_end - (size_t)_vector_start;
70000c28:	f240 023c 	movw	r2, #60	; 0x3c
70000c2c:	f240 0100 	movw	r1, #0
70000c30:	f2c7 0100 	movt	r1, #28672	; 0x7000
	(void)memcpy(VECTOR_ADDRESS, _vector_start, vector_size);
70000c34:	2000      	movs	r0, #0
	size_t vector_size = (size_t)_vector_end - (size_t)_vector_start;
70000c36:	f2c7 0200 	movt	r2, #28672	; 0x7000
	(void)memcpy(VECTOR_ADDRESS, _vector_start, vector_size);
70000c3a:	1a52      	subs	r2, r2, r1
70000c3c:	f002 b8ae 	b.w	70002d9c <memcpy>

70000c40 <z_arm_relocate_vector_table>:
#endif

#endif /* !CONFIG_AARCH32_ARMV8_R */

void z_arm_relocate_vector_table(void)
{
70000c40:	b508      	push	{r3, lr}
	relocate_vector_table();
70000c42:	f7ff ffeb 	bl	70000c1c <relocate_vector_table>
}
70000c46:	bd08      	pop	{r3, pc}

70000c48 <__start>:
    ldr r0, =IMP_CSCTLR(CONFIG_CPU_CORTEX_R52_ICACHE_FLASH_WAY,
                        CONFIG_CPU_CORTEX_R52_DCACHE_FLASH_WAY)
    mcr p15, 1, r0, c9, c1, 0
#endif

    ldr r0, =arm_cpu_boot_params
70000c48:	e59f0054 	ldr	r0, [pc, #84]	; 70000ca4 <__start+0x5c>
    b 2f

_primary_core:
#endif

    ldr r4, =z_prep_c
70000c4c:	e59f4054 	ldr	r4, [pc, #84]	; 70000ca8 <__start+0x60>
    ldr r5, =(z_arm_fiq_stack + CONFIG_ARMV7_FIQ_STACK_SIZE)
70000c50:	e59f5054 	ldr	r5, [pc, #84]	; 70000cac <__start+0x64>
    ldr r6, =(z_interrupt_stacks + CONFIG_ISR_STACK_SIZE)
70000c54:	e59f6054 	ldr	r6, [pc, #84]	; 70000cb0 <__start+0x68>
    ldr r7, =(z_arm_abort_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000c58:	e59f7054 	ldr	r7, [pc, #84]	; 70000cb4 <__start+0x6c>
    ldr r8, =(z_arm_undef_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000c5c:	e59f8054 	ldr	r8, [pc, #84]	; 70000cb8 <__start+0x70>
    ldr r9, =(z_arm_svc_stack + CONFIG_ARMV7_SVC_STACK_SIZE)
70000c60:	e59f9054 	ldr	r9, [pc, #84]	; 70000cbc <__start+0x74>
    ldr r10, =(z_arm_sys_stack + CONFIG_ARMV7_SYS_STACK_SIZE)
70000c64:	e59fa054 	ldr	sl, [pc, #84]	; 70000cc0 <__start+0x78>
    /*
     * Configure stack.
     */

    /* FIQ mode stack */
    msr CPSR_c, #(MODE_FIQ | I_BIT | F_BIT)
70000c68:	e321f0d1 	msr	CPSR_c, #209	; 0xd1
    mov sp, r5
70000c6c:	e1a0d005 	mov	sp, r5

    /* IRQ mode stack */
    msr CPSR_c, #(MODE_IRQ | I_BIT | F_BIT)
70000c70:	e321f0d2 	msr	CPSR_c, #210	; 0xd2
    mov sp, r6
70000c74:	e1a0d006 	mov	sp, r6

    /* ABT mode stack */
    msr CPSR_c, #(MODE_ABT | I_BIT | F_BIT)
70000c78:	e321f0d7 	msr	CPSR_c, #215	; 0xd7
    mov sp, r7
70000c7c:	e1a0d007 	mov	sp, r7

    /* UND mode stack */
    msr CPSR_c, #(MODE_UND | I_BIT | F_BIT)
70000c80:	e321f0db 	msr	CPSR_c, #219	; 0xdb
    mov sp, r8
70000c84:	e1a0d008 	mov	sp, r8

    /* SVC mode stack */
    msr CPSR_c, #(MODE_SVC | I_BIT | F_BIT)
70000c88:	e321f0d3 	msr	CPSR_c, #211	; 0xd3
    mov sp, r9
70000c8c:	e1a0d009 	mov	sp, r9

    /* SYS mode stack */
    msr CPSR_c, #(MODE_SYS | I_BIT | F_BIT)
70000c90:	e321f0df 	msr	CPSR_c, #223	; 0xdf
    mov sp, r10
70000c94:	e1a0d00a 	mov	sp, sl

#if defined(CONFIG_SOC_RESET_HOOK)
    /* Execute platform-specific initialisation if applicable */
    bl soc_reset_hook
70000c98:	faffff55 	blx	700009f4 <soc_reset_hook>

#if defined(CONFIG_DISABLE_TCM_ECC)
    bl z_arm_tcm_disable_ecc
#endif

    bl z_arm_relocate_vector_table
70000c9c:	faffffe7 	blx	70000c40 <z_arm_relocate_vector_table>

    bx r4
70000ca0:	e12fff14 	bx	r4
    ldr r0, =arm_cpu_boot_params
70000ca4:	7000b13c 	.word	0x7000b13c
    ldr r4, =z_prep_c
70000ca8:	70000ccd 	.word	0x70000ccd
    ldr r5, =(z_arm_fiq_stack + CONFIG_ARMV7_FIQ_STACK_SIZE)
70000cac:	70009fc0 	.word	0x70009fc0
    ldr r6, =(z_interrupt_stacks + CONFIG_ISR_STACK_SIZE)
70000cb0:	7000a7c0 	.word	0x7000a7c0
    ldr r7, =(z_arm_abort_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000cb4:	70009ec0 	.word	0x70009ec0
    ldr r8, =(z_arm_undef_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000cb8:	70009dc0 	.word	0x70009dc0
    ldr r9, =(z_arm_svc_stack + CONFIG_ARMV7_SVC_STACK_SIZE)
70000cbc:	70009cc0 	.word	0x70009cc0
    ldr r10, =(z_arm_sys_stack + CONFIG_ARMV7_SYS_STACK_SIZE)
70000cc0:	70009ac0 	.word	0x70009ac0

70000cc4 <z_irq_spurious>:
 */
void z_irq_spurious(const void *unused)
{
	ARG_UNUSED(unused);

	z_arm_fatal_error(K_ERR_SPURIOUS_IRQ, NULL);
70000cc4:	2100      	movs	r1, #0
70000cc6:	2001      	movs	r0, #1
70000cc8:	f7ff be9c 	b.w	70000a04 <z_arm_fatal_error>

70000ccc <z_prep_c>:
 *
 * This routine prepares for the execution of and runs C code.
 *
 */
void z_prep_c(void)
{
70000ccc:	b508      	push	{r3, lr}
MAKE_REG_HELPER(prlar,	     0, 6, 3, 1);
MAKE_REG_HELPER(mair0,       0, 10, 2, 0);
MAKE_REG_HELPER(vbar,        0, 12, 0, 0);
MAKE_REG_HELPER(cntv_ctl,    0, 14,  3, 1);
MAKE_REG_HELPER(ctr,         0, 0, 0, 1);
MAKE_REG_HELPER(tpidruro,    0, 13, 0, 3);
70000cce:	f646 4398 	movw	r3, #27800	; 0x6c98
70000cd2:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000cd6:	ee0d 3f70 	mcr	15, 0, r3, cr13, cr0, {3}
	write_tpidruro((uintptr_t)&_kernel.cpus[0]);

#if defined(CONFIG_CPU_HAS_FPU)
	z_arm_floating_point_init();
#endif
	z_bss_zero();
70000cda:	f000 ff3f 	bl	70001b5c <z_bss_zero>
	z_data_copy();
#if ((defined(CONFIG_ARMV7_R) || defined(CONFIG_ARMV7_A)) && defined(CONFIG_INIT_STACKS))
	z_arm_init_stacks();
#endif
	z_arm_interrupt_init();
70000cde:	f7ff ff9b 	bl	70000c18 <z_arm_interrupt_init>
#if CONFIG_ARCH_CACHE
	arch_cache_init();
70000ce2:	f000 f8cf 	bl	70000e84 <arch_cache_init>
	z_arm_mpu_init();
	z_arm_configure_static_mpu_regions();
#elif defined(CONFIG_ARM_AARCH32_MMU)
	z_arm_mmu_init();
#endif
	z_cstart();
70000ce6:	f000 ff47 	bl	70001b78 <z_cstart>
70000cea:	bf00      	nop

70000cec <arch_new_thread>:
 * of the ESF.
 */
void arch_new_thread(struct k_thread *thread, k_thread_stack_t *stack,
		     char *stack_ptr, k_thread_entry_t entry,
		     void *p1, void *p2, void *p3)
{
70000cec:	b430      	push	{r4, r5}
	}
#else
	iframe->pc = (uint32_t)z_thread_entry;
#endif

	iframe->a1 = (uint32_t)entry;
70000cee:	f842 3c20 	str.w	r3, [r2, #-32]
#if defined(CONFIG_BIG_ENDIAN)
	iframe->xpsr |= E_BIT;
#endif /* CONFIG_BIG_ENDIAN */

#if defined(CONFIG_COMPILER_ISA_THUMB2)
	iframe->xpsr |= T_BIT;
70000cf2:	f240 153f 	movw	r5, #319	; 0x13f
{
70000cf6:	9b02      	ldr	r3, [sp, #8]
	iframe = Z_STACK_PTR_TO_FRAME(struct __basic_sf, stack_ptr);
70000cf8:	f1a2 0420 	sub.w	r4, r2, #32
	iframe->a2 = (uint32_t)p1;
70000cfc:	f842 3c1c 	str.w	r3, [r2, #-28]
	iframe->pc = (uint32_t)z_thread_entry;
70000d00:	f640 13c5 	movw	r3, #2501	; 0x9c5
		((uintptr_t)iframe - sizeof(struct __fpu_sf));
	memset(iframe, 0, sizeof(struct __fpu_sf));
#endif

	thread->callee_saved.psp = (uint32_t)iframe;
	thread->arch.basepri = 0;
70000d04:	2100      	movs	r1, #0
	iframe->pc = (uint32_t)z_thread_entry;
70000d06:	f2c7 0300 	movt	r3, #28672	; 0x7000
	iframe->xpsr |= T_BIT;
70000d0a:	f842 5c04 	str.w	r5, [r2, #-4]
	iframe->pc = (uint32_t)z_thread_entry;
70000d0e:	f842 3c08 	str.w	r3, [r2, #-8]
{
70000d12:	9b03      	ldr	r3, [sp, #12]
	iframe->a3 = (uint32_t)p2;
70000d14:	f842 3c18 	str.w	r3, [r2, #-24]
{
70000d18:	9b04      	ldr	r3, [sp, #16]
	iframe->a4 = (uint32_t)p3;
70000d1a:	f842 3c14 	str.w	r3, [r2, #-20]
	thread->callee_saved.psp = (uint32_t)iframe;
70000d1e:	6504      	str	r4, [r0, #80]	; 0x50
	thread->arch.basepri = 0;
70000d20:	66c1      	str	r1, [r0, #108]	; 0x6c
	thread->switch_handle = thread;
	/* thread birth happens through the exception return path */
	thread->arch.exception_depth = 1;
	thread->callee_saved.lr = (uint32_t)z_arm_cortex_ar_exit_exc;
#endif
}
70000d22:	bc30      	pop	{r4, r5}
70000d24:	4770      	bx	lr
70000d26:	bf00      	nop

70000d28 <arch_cpu_idle>:

	/*
	 * Clear PRIMASK and flush instruction buffer to immediately service
	 * the wake-up interrupt.
	 */
	cpsie	i
70000d28:	f1080080 	cpsie	i
	isb
70000d2c:	f57ff06f 	isb	sy

	bx	lr
70000d30:	e12fff1e 	bx	lr

70000d34 <_isr_wrapper>:
	 * Save away r0-r3, r12 and lr_irq for the previous context to the
	 * process stack since they are clobbered here.  Also, save away lr
	 * and spsr_irq since we may swap processes and return to a different
	 * thread.
	 */
	sub lr, lr, #4
70000d34:	e24ee004 	sub	lr, lr, #4
	srsdb #MODE_SYS!
70000d38:	f96d051f 	srsdb	sp!, #31
	cps #MODE_SYS
70000d3c:	f102001f 	cps	#31
	push {r0-r3, r12, lr}
70000d40:	e92d500f 	push	{r0, r1, r2, r3, ip, lr}
	 * threads have high stack usage.
	 *
	 * When userspace is enabled, this also prevents leaking privileged
	 * information to the user mode.
	 */
	cps #MODE_SVC
70000d44:	f1020013 	cps	#19
	/*
	 * Preserve lr_svc which may contain the branch return address of the
	 * interrupted context in case of a nested interrupt. This value will
	 * be restored prior to exiting the interrupt in z_arm_int_exit.
	 */
	push {lr}
70000d48:	e52de004 	push	{lr}		; (str lr, [sp, #-4]!)

	/* Align stack at double-word boundary */
	and r3, sp, #4
70000d4c:	e20d3004 	and	r3, sp, #4
	sub sp, sp, r3
70000d50:	e04dd003 	sub	sp, sp, r3
	push {r2, r3}
70000d54:	e92d000c 	push	{r2, r3}

	/* Increment interrupt nesting count */
	get_cpu r2
70000d58:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000d5c:	e3c22003 	bic	r2, r2, #3
	ldr r0, [r2, #___cpu_t_nested_OFFSET]
70000d60:	e5920000 	ldr	r0, [r2]
	add r0, r0, #1
70000d64:	e2800001 	add	r0, r0, #1
	str r0, [r2, #___cpu_t_nested_OFFSET]
70000d68:	e5820000 	str	r0, [r2]

	/* Get active IRQ number from the interrupt controller */
#if !defined(CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER)
	bl arm_gic_get_active
#else
	bl z_soc_irq_get_active
70000d6c:	faffff1b 	blx	700009e0 <z_soc_irq_get_active>
#endif /* !CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER */
	push {r0, r1}
70000d70:	e92d0003 	push	{r0, r1}
	lsl r0, r0, #3	/* table is 8-byte wide */
70000d74:	e1a00180 	lsl	r0, r0, #3
	 * to note that most interrupt controllers require that the nested
	 * interrupts are handled after the active interrupt is acknowledged;
	 * this is be done through the `get_active` interrupt controller
	 * interface function.
	 */
	cpsie i
70000d78:	f1080080 	cpsie	i

	/*
	 * Skip calling the isr if it is a spurious interrupt.
	 */
	mov r1, #CONFIG_NUM_IRQS
70000d7c:	e3a01c02 	mov	r1, #512	; 0x200
	lsl r1, r1, #3
70000d80:	e1a01181 	lsl	r1, r1, #3
	cmp r0, r1
70000d84:	e1500001 	cmp	r0, r1
	bge spurious_continue
70000d88:	aa000003 	bge	70000d9c <spurious_continue>

	ldr r1, =_sw_isr_table
70000d8c:	e59f1018 	ldr	r1, [pc, #24]	; 70000dac <spurious_continue+0x10>
	add r1, r1, r0	/* table entry: ISRs must have their MSB set to stay
70000d90:	e0811000 	add	r1, r1, r0
			 * in thumb mode */

	ldm r1!,{r0,r3}	/* arg in r0, ISR in r3 */
70000d94:	e8b10009 	ldm	r1!, {r0, r3}
	blx r3		/* call ISR */
70000d98:	e12fff33 	blx	r3

70000d9c <spurious_continue>:

spurious_continue:
	/* Signal end-of-interrupt */
	pop {r0, r1}
70000d9c:	e8bd0003 	pop	{r0, r1}
#if !defined(CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER)
	bl arm_gic_eoi
#else
	bl z_soc_irq_eoi
70000da0:	faffff0f 	blx	700009e4 <z_soc_irq_eoi>
#endif

	/* Use 'bx' instead of 'b' because 'bx' can jump further, and use
	 * 'bx' instead of 'blx' because exception return is done in
	 * z_arm_int_exit() */
	ldr r1, =z_arm_int_exit
70000da4:	e59f1004 	ldr	r1, [pc, #4]	; 70000db0 <spurious_continue+0x14>
	bx r1
70000da8:	e12fff11 	bx	r1
	ldr r1, =_sw_isr_table
70000dac:	700039d8 	.word	0x700039d8
	ldr r1, =z_arm_int_exit
70000db0:	70000f6c 	.word	0x70000f6c

70000db4 <arch_dcache_invd_all>:

	return 0;
}

int arch_dcache_invd_all(void)
{
70000db4:	b5f0      	push	{r4, r5, r6, r7, lr}
 */
__STATIC_FORCEINLINE uint32_t __get_CLIDR(void)
{
  uint32_t result;
//  __ASM volatile("MRC p15, 1, %0, c0, c0, 1" : "=r"(result) : : "memory");
  __get_CP(15, 1, result, 0, 0, 1);
70000db6:	ee30 6f30 	mrc	15, 1, r6, cr0, cr0, {1}
*/
__STATIC_FORCEINLINE void L1C_CleanInvalidateCache(uint32_t op) {
  uint32_t clidr;
  uint32_t cache_type;
  clidr =  __get_CLIDR();
  for(uint32_t i = 0U; i<7U; i++)
70000dba:	2400      	movs	r4, #0
  {
    cache_type = (clidr >> i*3U) & 0x7UL;
70000dbc:	eb04 0344 	add.w	r3, r4, r4, lsl #1
70000dc0:	fa26 f303 	lsr.w	r3, r6, r3
70000dc4:	f003 0307 	and.w	r3, r3, #7
    if ((cache_type >= 2U) && (cache_type <= 4U))
70000dc8:	3b02      	subs	r3, #2
70000dca:	2b02      	cmp	r3, #2
    cache_type = (clidr >> i*3U) & 0x7UL;
70000dcc:	ea4f 0544 	mov.w	r5, r4, lsl #1
    if ((cache_type >= 2U) && (cache_type <= 4U))
70000dd0:	d831      	bhi.n	70000e36 <arch_dcache_invd_all+0x82>
  __set_CP(15, 2, value, 0, 0, 0);
70000dd2:	ee40 5f10 	mcr	15, 2, r5, cr0, cr0, {0}
  __get_CP(15, 1, result, 0, 0, 0);
70000dd6:	ee30 7f10 	mrc	15, 1, r7, cr0, cr0, {0}
  num_ways = ((ccsidr & 0x00001FF8U) >> 3U) + 1U;
70000dda:	f3c7 0cc9 	ubfx	ip, r7, #3, #10
70000dde:	f10c 0e01 	add.w	lr, ip, #1
  if (n < 2U) {
70000de2:	f1bc 0f00 	cmp.w	ip, #0
70000de6:	d02b      	beq.n	70000e40 <arch_dcache_invd_all+0x8c>
70000de8:	4672      	mov	r2, lr
  uint8_t log = 0U;
70000dea:	2300      	movs	r3, #0
    t >>= 1U;
70000dec:	0852      	lsrs	r2, r2, #1
    log++;
70000dee:	1c59      	adds	r1, r3, #1
70000df0:	4618      	mov	r0, r3
  while(t > 1U)
70000df2:	2a01      	cmp	r2, #1
    log++;
70000df4:	b2cb      	uxtb	r3, r1
  while(t > 1U)
70000df6:	d1f9      	bne.n	70000dec <arch_dcache_invd_all+0x38>
  if (n & 1U) { log++; }
70000df8:	f01e 0f01 	tst.w	lr, #1
70000dfc:	bf1c      	itt	ne
70000dfe:	3002      	addne	r0, #2
70000e00:	b2c3      	uxtbne	r3, r0
  if ((log2_num_ways < 0) || (log2_num_ways > 32)) {
70000e02:	2b20      	cmp	r3, #32
  shift_way = 32U - (uint32_t)log2_num_ways;
70000e04:	bf98      	it	ls
70000e06:	f1c3 0e20 	rsbls	lr, r3, #32
  if ((log2_num_ways < 0) || (log2_num_ways > 32)) {
70000e0a:	d814      	bhi.n	70000e36 <arch_dcache_invd_all+0x82>
  log2_linesize = (ccsidr & 0x00000007U) + 2U + 2U;
70000e0c:	f007 0007 	and.w	r0, r7, #7
70000e10:	3004      	adds	r0, #4
  num_sets = ((ccsidr & 0x0FFFE000U) >> 13U) + 1U;
70000e12:	f3c7 374e 	ubfx	r7, r7, #13, #15
    for(int32_t set = num_sets-1; set >= 0; set--)
70000e16:	463b      	mov	r3, r7
      Dummy = (level << 1U) | (((uint32_t)set) << log2_linesize) | (((uint32_t)way) << shift_way);
70000e18:	fa0c f10e 	lsl.w	r1, ip, lr
70000e1c:	4329      	orrs	r1, r5
70000e1e:	fa03 f200 	lsl.w	r2, r3, r0
70000e22:	430a      	orrs	r2, r1
/** \brief  Set DCISW
 */
__STATIC_FORCEINLINE void __set_DCISW(uint32_t value)
{
//  __ASM volatile("MCR p15, 0, %0, c7, c6, 2" : : "r"(value) : "memory")
  __set_CP(15, 0, value, 7, 6, 2);
70000e24:	ee07 2f56 	mcr	15, 0, r2, cr7, cr6, {2}
    for(int32_t set = num_sets-1; set >= 0; set--)
70000e28:	3b01      	subs	r3, #1
70000e2a:	d2f8      	bcs.n	70000e1e <arch_dcache_invd_all+0x6a>
  for(int32_t way = num_ways-1; way >= 0; way--)
70000e2c:	f1bc 0c01 	subs.w	ip, ip, #1
70000e30:	d2f1      	bcs.n	70000e16 <arch_dcache_invd_all+0x62>
  \details Ensures the apparent order of the explicit memory operations before
           and after the instruction, without ensuring their completion.
 */
__STATIC_FORCEINLINE  void __DMB(void)
{
  __ASM volatile ("dmb 0xF":::"memory");
70000e32:	f3bf 8f5f 	dmb	sy
  for(uint32_t i = 0U; i<7U; i++)
70000e36:	3401      	adds	r4, #1
70000e38:	2c07      	cmp	r4, #7
70000e3a:	d1bf      	bne.n	70000dbc <arch_dcache_invd_all+0x8>
	L1C_InvalidateDCacheAll();

	return 0;
}
70000e3c:	2000      	movs	r0, #0
70000e3e:	bdf0      	pop	{r4, r5, r6, r7, pc}
70000e40:	f04f 0e20 	mov.w	lr, #32
70000e44:	e7e2      	b.n	70000e0c <arch_dcache_invd_all+0x58>
70000e46:	bf00      	nop

70000e48 <arch_dcache_enable>:
{
70000e48:	b508      	push	{r3, lr}
	arch_dcache_invd_all();
70000e4a:	f7ff ffb3 	bl	70000db4 <arch_dcache_invd_all>
  __get_CP(15, 0, result, 1, 0, 0);
70000e4e:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}
  __ASM volatile ("dsb 0xF":::"memory");
70000e52:	f3bf 8f4f 	dsb	sy
	val |= SCTLR_C_Msk;
70000e56:	f043 0304 	orr.w	r3, r3, #4
  __set_CP(15, 0, sctlr, 1, 0, 0);
70000e5a:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
  __ASM volatile ("isb 0xF":::"memory");
70000e5e:	f3bf 8f6f 	isb	sy
}
70000e62:	bd08      	pop	{r3, pc}

70000e64 <arch_icache_enable>:
  __set_CP(15, 0, value, 7, 5, 0);
70000e64:	2300      	movs	r3, #0
70000e66:	ee07 3f15 	mcr	15, 0, r3, cr7, cr5, {0}
  __ASM volatile ("dsb 0xF":::"memory");
70000e6a:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
70000e6e:	f3bf 8f6f 	isb	sy
  __get_CP(15, 0, result, 1, 0, 0);
70000e72:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}
#ifdef CONFIG_ICACHE

void arch_icache_enable(void)
{
	arch_icache_invd_all();
	__set_SCTLR(__get_SCTLR() | SCTLR_I_Msk);
70000e76:	f443 5380 	orr.w	r3, r3, #4096	; 0x1000
  __set_CP(15, 0, sctlr, 1, 0, 0);
70000e7a:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
70000e7e:	f3bf 8f6f 	isb	sy
	barrier_isync_fence_full();
}
70000e82:	4770      	bx	lr

70000e84 <arch_cache_init>:

#endif

void arch_cache_init(void)
{
}
70000e84:	4770      	bx	lr
70000e86:	bf00      	nop

70000e88 <z_arm_do_swap>:
    bl z_thread_mark_switched_out
    pop {r0, lr}
#endif /* CONFIG_INSTRUMENT_THREAD_SWITCHING */

    /* load current _cpu into r1 and current k_thread into r2 */
    get_cpu r1
70000e88:	ee1d1f70 	mrc	15, 0, r1, cr13, cr0, {3}
70000e8c:	e3c11003 	bic	r1, r1, #3
    ldr r2, [r1, #___cpu_t_current_OFFSET]
70000e90:	e5912008 	ldr	r2, [r1, #8]
    /* Store LSB of LR (EXC_RETURN) to the thread's 'mode' word. */
    strb lr, [r2, #_thread_offset_to_mode_exc_return]
#endif

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
70000e94:	e3a00030 	mov	r0, #48	; 0x30
    add r0, r2
70000e98:	e0800002 	add	r0, r0, r2

    /* Store rest of process context */
    cps #MODE_SYS
70000e9c:	f102001f 	cps	#31
    stm r0, {r4-r11, sp}
70000ea0:	e8802ff0 	stm	r0, {r4, r5, r6, r7, r8, r9, sl, fp, sp}
    cps #MODE_SVC
70000ea4:	f1020013 	cps	#19
    mov r0, #0
    str r0, [r1, #___cpu_t_fp_ctx_OFFSET]
#endif /* CONFIG_FPU_SHARING */

    /* fetch the thread to run from the ready queue cache */
    ldr r3, =_kernel
70000ea8:	e59f3028 	ldr	r3, [pc, #40]	; 70000ed8 <z_arm_do_swap+0x50>
    ldr r2, [r3, #_kernel_offset_to_ready_q_cache]
70000eac:	e5932014 	ldr	r2, [r3, #20]

    str r2, [r1, #___cpu_t_current_OFFSET]
70000eb0:	e5812008 	str	r2, [r1, #8]
#endif

    /* Restore previous interrupt disable state (irq_lock key)
     * (We clear the arch.basepri field after restoring state)
     */
    ldr r0, [r2, #_thread_offset_to_basepri]
70000eb4:	e592006c 	ldr	r0, [r2, #108]	; 0x6c
    movs r3, #0
70000eb8:	e3b03000 	movs	r3, #0
    str r3, [r2, #_thread_offset_to_basepri]
70000ebc:	e582306c 	str	r3, [r2, #108]	; 0x6c

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
70000ec0:	e3a00030 	mov	r0, #48	; 0x30
    add r0, r2
70000ec4:	e0800002 	add	r0, r0, r2

    /* restore r4-r11 and sp for incoming thread */
    cps #MODE_SYS
70000ec8:	f102001f 	cps	#31
    ldm r0, {r4-r11, sp}
70000ecc:	e8902ff0 	ldm	r0, {r4, r5, r6, r7, r8, r9, sl, fp, sp}
    cps #MODE_SVC
70000ed0:	f1020013 	cps	#19
#endif /* CONFIG_INSTRUMENT_THREAD_SWITCHING */

    /*
     * Cortex-R: return to the caller (z_arm_{exc,int}_exit, or z_arm_svc)
     */
    bx lr
70000ed4:	e12fff1e 	bx	lr
    ldr r3, =_kernel
70000ed8:	70006c98 	.word	0x70006c98

70000edc <z_arm_svc>:
    /*
     * Switch to system mode to store r0-r3 to the process stack pointer.
     * Save r12 and the lr as we could be swapping in another process and
     * returning to a different location.
     */
    srsdb #MODE_SYS!
70000edc:	f96d051f 	srsdb	sp!, #31
    cps #MODE_SYS
70000ee0:	f102001f 	cps	#31
    push {r0-r3, r12, lr}
70000ee4:	e92d500f 	push	{r0, r1, r2, r3, ip, lr}
    ldr r0, [r2, #___cpu_t_fp_ctx_OFFSET]
    cmp r0, #0
    streq sp, [r2, #___cpu_t_fp_ctx_OFFSET]
#endif /* CONFIG_FPU_SHARING */

    mov ip, sp
70000ee8:	e1a0c00d 	mov	ip, sp

    cps #MODE_SVC
70000eec:	f1020013 	cps	#19

    /*
     * Store lr_svc to the SVC mode stack. This value will be restored prior to
     * exiting the SVC call in z_arm_int_exit.
     */
    push {lr}
70000ef0:	e52de004 	push	{lr}		; (str lr, [sp, #-4]!)

    /* Align stack at double-word boundary */
    /* TODO: Question, why push {r2, r3} here */
    and r3, sp, #4
70000ef4:	e20d3004 	and	r3, sp, #4
    sub sp, sp, r3
70000ef8:	e04dd003 	sub	sp, sp, r3
    push {r2, r3}
70000efc:	e92d000c 	push	{r2, r3}

    /* Increment interrupt nesting count */
    get_cpu r2
70000f00:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000f04:	e3c22003 	bic	r2, r2, #3
    ldr r0, [r2, #___cpu_t_nested_OFFSET]
70000f08:	e5920000 	ldr	r0, [r2]
    add r0, r0, #1
70000f0c:	e2800001 	add	r0, r0, #1
    str r0, [r2, #___cpu_t_nested_OFFSET]
70000f10:	e5820000 	str	r0, [r2]

    /* Get SVC number */
    mrs r0, spsr
70000f14:	e14f0000 	mrs	r0, SPSR
    tst r0, #0x20
70000f18:	e3100020 	tst	r0, #32

    ldreq r1, [lr, #-4]
70000f1c:	051e1004 	ldreq	r1, [lr, #-4]
    biceq r1, #0xff000000
70000f20:	03c114ff 	biceq	r1, r1, #-16777216	; 0xff000000
    beq demux
70000f24:	0a000001 	beq	70000f30 <demux>

    ldr r1, [lr, #-2]
70000f28:	e51e1002 	ldr	r1, [lr, #-2]
    and r1, #0xff
70000f2c:	e20110ff 	and	r1, r1, #255	; 0xff

70000f30 <demux>:
#if defined(CONFIG_USERSPACE)
    cmp r1, #_SVC_CALL_SYSTEM_CALL
    beq _do_syscall
#endif

    cmp r1, #_SVC_CALL_CONTEXT_SWITCH
70000f30:	e3510000 	cmp	r1, #0
    beq _context_switch
70000f34:	0a000001 	beq	70000f40 <_context_switch>

    cmp r1, #_SVC_CALL_RUNTIME_EXCEPT
70000f38:	e3510002 	cmp	r1, #2
    beq _oops
70000f3c:	0a000001 	beq	70000f48 <_oops>

70000f40 <_context_switch>:
    b z_arm_int_exit
#endif

_context_switch:
    /* handler mode exit, to PendSV */
    bl z_arm_do_swap
70000f40:	ebffffd0 	bl	70000e88 <z_arm_do_swap>

    b z_arm_int_exit
70000f44:	ea000008 	b	70000f6c <z_arm_int_exit>

70000f48 <_oops>:

_oops:
    /*
     * Pass the exception frame to z_do_kernel_oops.
     */
    cps #MODE_SYS
70000f48:	f102001f 	cps	#31
    mov r0, sp
70000f4c:	e1a0000d 	mov	r0, sp
    cps #MODE_SVC
70000f50:	f1020013 	cps	#19
    /* Zero callee_regs and exc_return (only used on Cortex-M) */
    mov r1, #0
70000f54:	e3a01000 	mov	r1, #0
    mov r2, #0
70000f58:	e3a02000 	mov	r2, #0
    bl z_do_kernel_oops
70000f5c:	fafffea9 	blx	70000a08 <z_do_kernel_oops>
    b z_arm_int_exit
70000f60:	ea000001 	b	70000f6c <z_arm_int_exit>

70000f64 <z_arm_cortex_r_svc>:
    b z_arm_int_exit
#endif

GTEXT(z_arm_cortex_r_svc)
SECTION_FUNC(TEXT, z_arm_cortex_r_svc)
    svc #_SVC_CALL_CONTEXT_SWITCH
70000f64:	ef000000 	svc	0x00000000
    bx lr
70000f68:	e12fff1e 	bx	lr

70000f6c <z_arm_int_exit>:
#endif /* CONFIG_STACK_SENTINEL */

	/* Disable nested interrupts while exiting, this should happens
	 * before context switch also, to ensure interrupts are disabled.
	 */
	cpsid i
70000f6c:	f10c0080 	cpsid	i

#ifdef CONFIG_PREEMPT_ENABLED
	/* Do not context switch if exiting a nested interrupt */
	get_cpu r3
70000f70:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70000f74:	e3c33003 	bic	r3, r3, #3
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
70000f78:	e5930000 	ldr	r0, [r3]
	cmp r0, #1
70000f7c:	e3500001 	cmp	r0, #1
	bhi __EXIT_INT
70000f80:	8a000004 	bhi	70000f98 <__EXIT_INT>

	ldr r1, [r3, #___cpu_t_current_OFFSET]
70000f84:	e5931008 	ldr	r1, [r3, #8]
	ldr r2, =_kernel
70000f88:	e59f2094 	ldr	r2, [pc, #148]	; 70001024 <__EXIT_EXC+0x18>
	ldr r0, [r2, #_kernel_offset_to_ready_q_cache]
70000f8c:	e5920014 	ldr	r0, [r2, #20]
	cmp r0, r1
70000f90:	e1500001 	cmp	r0, r1
	blne z_arm_do_swap
70000f94:	1bffffbb 	blne	70000e88 <z_arm_do_swap>

70000f98 <__EXIT_INT>:
__EXIT_INT:
#endif /* CONFIG_PREEMPT_ENABLED */

	/* Decrement interrupt nesting count */
	get_cpu r2
70000f98:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000f9c:	e3c22003 	bic	r2, r2, #3
	ldr r0, [r2, #___cpu_t_nested_OFFSET]
70000fa0:	e5920000 	ldr	r0, [r2]
	sub r0, r0, #1
70000fa4:	e2400001 	sub	r0, r0, #1
	str r0, [r2, #___cpu_t_nested_OFFSET]
70000fa8:	e5820000 	str	r0, [r2]

	/* Restore previous stack pointer */
	pop {r2, r3}
70000fac:	e8bd000c 	pop	{r2, r3}
	add sp, sp, r3
70000fb0:	e08dd003 	add	sp, sp, r3
	/*
	 * Restore lr_svc stored into the SVC mode stack by the mode entry
	 * function. This ensures that the return address of the interrupted
	 * context is preserved in case of interrupt nesting.
	 */
	pop {lr}
70000fb4:	e49de004 	pop	{lr}		; (ldr lr, [sp], #4)
	 * IRQ mode and z_arm_svc for SVC mode.
	 *
	 * r0-r3 are either the values from the thread before it was switched
	 * out or they are the args to _new_thread for a new thread.
	 */
	cps #MODE_SYS
70000fb8:	f102001f 	cps	#31

#if defined(CONFIG_FPU_SHARING)
	fpu_exc_exit
#endif

	pop {r0-r3, r12, lr}
70000fbc:	e8bd500f 	pop	{r0, r1, r2, r3, ip, lr}
	userspace_exc_exit
	rfeia sp!
70000fc0:	f8bd0a00 	rfeia	sp!

70000fc4 <z_arm_exc_exit>:
 *
 * @param fatal True if exiting from a fatal fault; otherwise, false
 */
SECTION_SUBSEC_FUNC(TEXT, _HandlerModeExit, z_arm_exc_exit)
	/* Do not context switch if exiting a nested exception */
	get_cpu r3
70000fc4:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70000fc8:	e3c33003 	bic	r3, r3, #3
	ldr r1, [r3, #___cpu_t_nested_OFFSET]
70000fcc:	e5931000 	ldr	r1, [r3]
	cmp r1, #1
70000fd0:	e3510001 	cmp	r1, #1
	bhi __EXIT_EXC
70000fd4:	8a00000c 	bhi	7000100c <__EXIT_EXC>

	/* If the fault is not fatal, return to the current thread context */
	cmp r0, #0
70000fd8:	e3500000 	cmp	r0, #0
	beq __EXIT_EXC
70000fdc:	0a00000a 	beq	7000100c <__EXIT_EXC>

	/* Clean up exception stack frame */
#if defined(CONFIG_FPU_SHARING)
	add sp, sp, #___fpu_t_SIZEOF
#endif
	add sp, #32
70000fe0:	e28dd020 	add	sp, sp, #32
	 *
	 * Note that z_arm_do_swap must be called in the SVC mode because it
	 * switches to the SVC mode during context switch and returns to the
	 * caller using lr_svc.
	 */
	cps #MODE_SVC
70000fe4:	f1020013 	cps	#19
	bl z_arm_do_swap
70000fe8:	ebffffa6 	bl	70000e88 <z_arm_do_swap>

	/* Decrement exception nesting count */
	get_cpu r3
70000fec:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70000ff0:	e3c33003 	bic	r3, r3, #3
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
70000ff4:	e5930000 	ldr	r0, [r3]
	sub r0, r0, #1
70000ff8:	e2400001 	sub	r0, r0, #1
	str r0, [r3, #___cpu_t_nested_OFFSET]
70000ffc:	e5830000 	str	r0, [r3]

	/* Return to the switched thread */
	cps #MODE_SYS
70001000:	f102001f 	cps	#31
#if defined(CONFIG_FPU_SHARING)
	fpu_exc_exit
#endif
	pop {r0-r3, r12, lr}
70001004:	e8bd500f 	pop	{r0, r1, r2, r3, ip, lr}
	userspace_exc_exit
	rfeia sp!
70001008:	f8bd0a00 	rfeia	sp!

7000100c <__EXIT_EXC>:

__EXIT_EXC:
	/* Decrement exception nesting count */
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
7000100c:	e5930000 	ldr	r0, [r3]
	sub r0, r0, #1
70001010:	e2400001 	sub	r0, r0, #1
	str r0, [r3, #___cpu_t_nested_OFFSET]
70001014:	e5830000 	str	r0, [r3]
#endif
	/*
	 * Restore r0-r3, r12, lr, lr_und and spsr_und from the exception stack
	 * and return to the current thread.
	 */
	ldmia sp, {r0-r3, r12, lr}^
70001018:	e8dd500f 	ldm	sp, {r0, r1, r2, r3, ip, lr}^
	add sp, #24
7000101c:	e28dd018 	add	sp, sp, #24
	rfeia sp!
70001020:	f8bd0a00 	rfeia	sp!
	ldr r2, =_kernel
70001024:	70006c98 	.word	0x70006c98

70001028 <picolibc_put>:
}
#include <zephyr/syscalls/zephyr_fputc_mrsh.c>
#endif

static int picolibc_put(char a, FILE *f)
{
70001028:	b508      	push	{r3, lr}
	(*_stdout_hook)(a);
7000102a:	f646 4384 	movw	r3, #27780	; 0x6c84
7000102e:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001032:	681b      	ldr	r3, [r3, #0]
70001034:	4798      	blx	r3
	zephyr_fputc(a, f);
	return 0;
}
70001036:	2000      	movs	r0, #0
70001038:	bd08      	pop	{r3, pc}
7000103a:	bf00      	nop

7000103c <__stdout_hook_install>:
FILE *const stdout = &__stdout;
STDIO_ALIAS(stderr);

void __stdout_hook_install(int (*hook)(int))
{
	_stdout_hook = hook;
7000103c:	f646 4184 	movw	r1, #27780	; 0x6c84
	__stdout.flags |= _FDEV_SETUP_WRITE;
70001040:	f24b 1368 	movw	r3, #45416	; 0xb168
70001044:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001048:	789a      	ldrb	r2, [r3, #2]
	_stdout_hook = hook;
7000104a:	f2c7 0100 	movt	r1, #28672	; 0x7000
	__stdout.flags |= _FDEV_SETUP_WRITE;
7000104e:	f042 0202 	orr.w	r2, r2, #2
	_stdout_hook = hook;
70001052:	6008      	str	r0, [r1, #0]
	__stdout.flags |= _FDEV_SETUP_WRITE;
70001054:	709a      	strb	r2, [r3, #2]
}
70001056:	4770      	bx	lr

70001058 <malloc_prepare>:
			break;
		}
		heap_size >>= 1;
	}
#else
	heap_base = UINT_TO_POINTER(HEAP_BASE);
70001058:	4907      	ldr	r1, [pc, #28]	; (70001078 <malloc_prepare+0x20>)
	z_malloc_partition.start = POINTER_TO_UINT(heap_base);
	z_malloc_partition.size = heap_size;
	z_malloc_partition.attr = K_MEM_PARTITION_P_RW_U_RW;
#endif

	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
7000105a:	f646 4088 	movw	r0, #27784	; 0x6c88
7000105e:	f2c7 0000 	movt	r0, #28672	; 0x7000
	heap_base = UINT_TO_POINTER(HEAP_BASE);
70001062:	f021 0107 	bic.w	r1, r1, #7
	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
70001066:	f1c1 42e0 	rsb	r2, r1, #1879048192	; 0x70000000
7000106a:	f502 3200 	add.w	r2, r2, #131072	; 0x20000
{
7000106e:	b508      	push	{r3, lr}
	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
70001070:	f7ff fc48 	bl	70000904 <sys_heap_init>

	return 0;
}
70001074:	2000      	movs	r0, #0
70001076:	bd08      	pop	{r3, pc}
70001078:	7000b1a3 	.word	0x7000b1a3

7000107c <z_vim_irq_get_active>:

static ALWAYS_INLINE uint32_t sys_read32(mem_addr_t addr)
{
	uint32_t val;

	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000107c:	2318      	movs	r3, #24
7000107e:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
70001082:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001084:	f3bf 8f5f 	dmb	sy
70001088:	2320      	movs	r3, #32
7000108a:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
7000108e:	681b      	ldr	r3, [r3, #0]
70001090:	f3bf 8f5f 	dmb	sy
	actirq = sys_read32(VIM_ACTIRQ);

	/* Check if the irq number is valid, else return invalid irq number.
	 * which will be considered as spurious interrupt
	 */
	if ((actirq & (VIM_ACTIRQ_VALID_MASK)) == 0) {
70001094:	2b00      	cmp	r3, #0
70001096:	da14      	bge.n	700010c2 <z_vim_irq_get_active+0x46>
		return CONFIG_NUM_IRQS + 1;
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(actirq & VIM_PRIIRQ_NUM_MASK);
70001098:	f3c3 0009 	ubfx	r0, r3, #0, #10
7000109c:	f3bf 8f5f 	dmb	sy
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(actirq & VIM_PRIIRQ_NUM_MASK);

	/* Ack the interrupt in IRQSTS register */
	sys_write32(BIT(irq_bit_num), VIM_IRQSTS(irq_group_num));
700010a0:	2101      	movs	r1, #1
700010a2:	f44f 6282 	mov.w	r2, #1040	; 0x410
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(actirq & VIM_PRIIRQ_NUM_MASK);
700010a6:	f003 0c1f 	and.w	ip, r3, #31
	sys_write32(BIT(irq_bit_num), VIM_IRQSTS(irq_group_num));
700010aa:	f6c2 72ff 	movt	r2, #12287	; 0x2fff
700010ae:	f403 7378 	and.w	r3, r3, #992	; 0x3e0
700010b2:	fa01 f10c 	lsl.w	r1, r1, ip
700010b6:	441a      	add	r2, r3
}

static ALWAYS_INLINE void sys_write32(uint32_t data, mem_addr_t addr)
{
	barrier_dmem_fence_full();
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700010b8:	6011      	str	r1, [r2, #0]

	if (irq_group_num > VIM_MAX_GROUP_NUM) {
700010ba:	f5b0 7f08 	cmp.w	r0, #544	; 0x220
700010be:	d200      	bcs.n	700010c2 <z_vim_irq_get_active+0x46>
		return (CONFIG_NUM_IRQS + 1);
	}

	return (actirq & VIM_ACTIRQ_NUM_MASK);
}
700010c0:	4770      	bx	lr
		return CONFIG_NUM_IRQS + 1;
700010c2:	f240 2001 	movw	r0, #513	; 0x201
700010c6:	4770      	bx	lr

700010c8 <z_vim_irq_eoi>:
700010c8:	f3bf 8f5f 	dmb	sy
700010cc:	2318      	movs	r3, #24
700010ce:	2200      	movs	r2, #0
700010d0:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
700010d4:	601a      	str	r2, [r3, #0]

void z_vim_irq_eoi(unsigned int irq)
{
	sys_write32(0, VIM_IRQVEC);
}
700010d6:	4770      	bx	lr

700010d8 <z_vim_irq_init>:
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700010d8:	2004      	movs	r0, #4
700010da:	f6c2 70ff 	movt	r0, #12287	; 0x2fff

void z_vim_irq_init(void)
{
700010de:	b500      	push	{lr}
700010e0:	6800      	ldr	r0, [r0, #0]
700010e2:	f3bf 8f5f 	dmb	sy
	uint32_t num_of_irqs = sys_read32(VIM_INFO) & VIM_INFO_INTERRUPTS_MASK;
700010e6:	f3c0 000a 	ubfx	r0, r0, #0, #11
	unsigned int irq;

	LOG_DBG("VIM: Number of IRQs = %u\n", num_of_irqs);

	/* make sure all IRQs are initially disabled and cleared */
	for (irq = 0; irq < num_of_irqs; irq+=32)
700010ea:	b1b8      	cbz	r0, 7000111c <z_vim_irq_init+0x44>
	{
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
700010ec:	f240 4e0c 	movw	lr, #1036	; 0x40c
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
700010f0:	f240 4c04 	movw	ip, #1028	; 0x404
	for (irq = 0; irq < num_of_irqs; irq+=32)
700010f4:	2300      	movs	r3, #0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700010f6:	f06f 4200 	mvn.w	r2, #2147483648	; 0x80000000
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
700010fa:	f6c2 7eff 	movt	lr, #12287	; 0x2fff
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
700010fe:	f6c2 7cff 	movt	ip, #12287	; 0x2fff
70001102:	f3bf 8f5f 	dmb	sy
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
70001106:	eb03 010e 	add.w	r1, r3, lr
7000110a:	600a      	str	r2, [r1, #0]
7000110c:	f3bf 8f5f 	dmb	sy
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
70001110:	eb03 010c 	add.w	r1, r3, ip
70001114:	600a      	str	r2, [r1, #0]
	for (irq = 0; irq < num_of_irqs; irq+=32)
70001116:	3320      	adds	r3, #32
70001118:	4298      	cmp	r0, r3
7000111a:	d8f2      	bhi.n	70001102 <z_vim_irq_init+0x2a>
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000111c:	2318      	movs	r3, #24
7000111e:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
70001122:	681a      	ldr	r2, [r3, #0]
70001124:	f3bf 8f5f 	dmb	sy
70001128:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000112c:	2200      	movs	r2, #0
7000112e:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001130:	231c      	movs	r3, #28
70001132:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
70001136:	6819      	ldr	r1, [r3, #0]
70001138:	f3bf 8f5f 	dmb	sy
7000113c:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001140:	601a      	str	r2, [r3, #0]
	/* ACK and clear pending IRQs */
	(void) sys_read32(VIM_IRQVEC);
	sys_write32(0, VIM_IRQVEC);
	(void) sys_read32(VIM_FIQVEC);
	sys_write32(0, VIM_FIQVEC);
}
70001142:	f85d fb04 	ldr.w	pc, [sp], #4
70001146:	bf00      	nop

70001148 <z_vim_irq_priority_set>:

void z_vim_irq_priority_set(unsigned int irq, unsigned int prio, uint32_t flags)
{
	uint32_t irq_group_num, irq_bit_num, regval;

	if (irq > CONFIG_NUM_IRQS || prio > VIM_PRI_INT_MAX ||
70001148:	290f      	cmp	r1, #15
7000114a:	bf98      	it	ls
7000114c:	f5b0 7f00 	cmpls.w	r0, #512	; 0x200
70001150:	d824      	bhi.n	7000119c <z_vim_irq_priority_set+0x54>
	    (flags != IRQ_TYPE_EDGE && flags != IRQ_TYPE_LEVEL)) {
70001152:	1e93      	subs	r3, r2, #2
	if (irq > CONFIG_NUM_IRQS || prio > VIM_PRI_INT_MAX ||
70001154:	f033 0302 	bics.w	r3, r3, #2
70001158:	d120      	bne.n	7000119c <z_vim_irq_priority_set+0x54>
7000115a:	f3bf 8f5f 	dmb	sy
		LOG_ERR("%s: Invalid argument irq = %u prio = %u flags = %u\n",
			__func__, irq, prio, flags);
		return;
	}

	sys_write8(prio, VIM_PRI_INT(irq));
7000115e:	f100 6340 	add.w	r3, r0, #201326592	; 0xc000000
70001162:	f5a3 5370 	sub.w	r3, r3, #15360	; 0x3c00
70001166:	009b      	lsls	r3, r3, #2
	__asm__ volatile("strb %0, [%1]" : : "r" (data), "r" (addr));
70001168:	7019      	strb	r1, [r3, #0]

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	regval = sys_read32(VIM_INTTYPE(irq_group_num));
7000116a:	f240 431c 	movw	r3, #1052	; 0x41c
7000116e:	f020 011f 	bic.w	r1, r0, #31
70001172:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
70001176:	440b      	add	r3, r1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001178:	6819      	ldr	r1, [r3, #0]
7000117a:	f3bf 8f5f 	dmb	sy

	if (flags == IRQ_TYPE_EDGE) {
		regval |= (BIT(irq_bit_num));
7000117e:	f04f 0c01 	mov.w	ip, #1
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
70001182:	f000 001f 	and.w	r0, r0, #31
	if (flags == IRQ_TYPE_EDGE) {
70001186:	2a04      	cmp	r2, #4
		regval |= (BIT(irq_bit_num));
70001188:	fa0c f000 	lsl.w	r0, ip, r0
7000118c:	bf0c      	ite	eq
7000118e:	ea40 0201 	orreq.w	r2, r0, r1
	} else {
		regval &= ~(BIT(irq_bit_num));
70001192:	ea21 0200 	bicne.w	r2, r1, r0
70001196:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000119a:	601a      	str	r2, [r3, #0]
	}

	sys_write32(regval, VIM_INTTYPE(irq_group_num));
}
7000119c:	4770      	bx	lr
7000119e:	bf00      	nop

700011a0 <z_vim_irq_enable>:

void z_vim_irq_enable(unsigned int irq)
{
	uint32_t irq_group_num, irq_bit_num;

	if (irq > CONFIG_NUM_IRQS) {
700011a0:	f5b0 7f00 	cmp.w	r0, #512	; 0x200
700011a4:	d80d      	bhi.n	700011c2 <z_vim_irq_enable+0x22>
700011a6:	f3bf 8f5f 	dmb	sy
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	sys_write32(BIT(irq_bit_num), VIM_INTR_EN_SET(irq_group_num));
700011aa:	2201      	movs	r2, #1
700011ac:	f44f 6381 	mov.w	r3, #1032	; 0x408
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
700011b0:	f000 011f 	and.w	r1, r0, #31
	sys_write32(BIT(irq_bit_num), VIM_INTR_EN_SET(irq_group_num));
700011b4:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
700011b8:	f020 001f 	bic.w	r0, r0, #31
700011bc:	408a      	lsls	r2, r1
700011be:	4403      	add	r3, r0
700011c0:	601a      	str	r2, [r3, #0]
}
700011c2:	4770      	bx	lr

700011c4 <console_out>:
		 * function MUST return the byte output.
		 */
		return c;
	}

	if ('\n' == c) {
700011c4:	280a      	cmp	r0, #10
{
700011c6:	b538      	push	{r3, r4, r5, lr}
700011c8:	4604      	mov	r4, r0
	if ('\n' == c) {
700011ca:	d00d      	beq.n	700011e8 <console_out+0x24>
700011cc:	f643 15c4 	movw	r5, #14788	; 0x39c4
700011d0:	f2c7 0500 	movt	r5, #28672	; 0x7000

static inline void z_impl_uart_poll_out(const struct device *dev, unsigned char out_char)
{
	const struct uart_driver_api *api = (const struct uart_driver_api *)dev->api;

	api->poll_out(dev, out_char);
700011d4:	68ab      	ldr	r3, [r5, #8]
700011d6:	f643 10c4 	movw	r0, #14788	; 0x39c4
700011da:	b2e1      	uxtb	r1, r4
700011dc:	f2c7 0000 	movt	r0, #28672	; 0x7000
700011e0:	685b      	ldr	r3, [r3, #4]
700011e2:	4798      	blx	r3
	 * As errors cannot be returned, ignore the return value
	 */
	(void)pm_device_runtime_put_async(uart_console_dev, K_MSEC(1));

	return c;
}
700011e4:	4620      	mov	r0, r4
700011e6:	bd38      	pop	{r3, r4, r5, pc}
700011e8:	f643 15c4 	movw	r5, #14788	; 0x39c4
700011ec:	210d      	movs	r1, #13
700011ee:	f2c7 0500 	movt	r5, #28672	; 0x7000
700011f2:	4628      	mov	r0, r5
700011f4:	68ab      	ldr	r3, [r5, #8]
700011f6:	685b      	ldr	r3, [r3, #4]
700011f8:	4798      	blx	r3
		return;
	}
#endif
	compiler_barrier();
	z_impl_uart_poll_out(dev, out_char);
}
700011fa:	e7eb      	b.n	700011d4 <console_out+0x10>

700011fc <uart_console_init>:
 * @brief Initialize one UART as the console/debug port
 *
 * @return 0 if successful, otherwise failed.
 */
static int uart_console_init(void)
{
700011fc:	b508      	push	{r3, lr}
		union { uintptr_t x; const struct device * val; } parm0 = { .val = dev };
		return (bool) arch_syscall_invoke1(parm0.x, K_SYSCALL_DEVICE_IS_READY);
	}
#endif
	compiler_barrier();
	return z_impl_device_is_ready(dev);
700011fe:	f643 10c4 	movw	r0, #14788	; 0x39c4
70001202:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001206:	f000 fbe1 	bl	700019cc <z_impl_device_is_ready>
	if (!device_is_ready(uart_console_dev)) {
7000120a:	b168      	cbz	r0, 70001228 <uart_console_init+0x2c>
	__stdout_hook_install(console_out);
7000120c:	f241 10c5 	movw	r0, #4549	; 0x11c5
70001210:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001214:	f7ff ff12 	bl	7000103c <__stdout_hook_install>
	__printk_hook_install(console_out);
70001218:	f241 10c5 	movw	r0, #4549	; 0x11c5
7000121c:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001220:	f7ff fbae 	bl	70000980 <__printk_hook_install>
		return -ENODEV;
	}

	uart_console_hook_install();

	return 0;
70001224:	2000      	movs	r0, #0
}
70001226:	bd08      	pop	{r3, pc}
		return -ENODEV;
70001228:	f06f 0012 	mvn.w	r0, #18
}
7000122c:	bd08      	pop	{r3, pc}
7000122e:	bf00      	nop

70001230 <pinctrl_lookup_state>:
#include <zephyr/drivers/pinctrl.h>

int pinctrl_lookup_state(const struct pinctrl_dev_config *config, uint8_t id,
			 const struct pinctrl_state **state)
{
	*state = &config->states[0];
70001230:	6803      	ldr	r3, [r0, #0]
70001232:	6013      	str	r3, [r2, #0]
	while (*state < &config->states[config->state_cnt]) {
70001234:	f890 c004 	ldrb.w	ip, [r0, #4]
70001238:	eb03 0ccc 	add.w	ip, r3, ip, lsl #3
7000123c:	4563      	cmp	r3, ip
7000123e:	d21f      	bcs.n	70001280 <pinctrl_lookup_state+0x50>
		if (id == (*state)->id) {
70001240:	f893 c005 	ldrb.w	ip, [r3, #5]
70001244:	458c      	cmp	ip, r1
			return 0;
		}

		(*state)++;
70001246:	f103 0308 	add.w	r3, r3, #8
		if (id == (*state)->id) {
7000124a:	d017      	beq.n	7000127c <pinctrl_lookup_state+0x4c>
{
7000124c:	b500      	push	{lr}
7000124e:	e005      	b.n	7000125c <pinctrl_lookup_state+0x2c>
		if (id == (*state)->id) {
70001250:	f893 c005 	ldrb.w	ip, [r3, #5]
70001254:	458c      	cmp	ip, r1
		(*state)++;
70001256:	f103 0308 	add.w	r3, r3, #8
		if (id == (*state)->id) {
7000125a:	d00c      	beq.n	70001276 <pinctrl_lookup_state+0x46>
		(*state)++;
7000125c:	6013      	str	r3, [r2, #0]
	while (*state < &config->states[config->state_cnt]) {
7000125e:	f890 c004 	ldrb.w	ip, [r0, #4]
70001262:	f8d0 e000 	ldr.w	lr, [r0]
70001266:	eb0e 0ccc 	add.w	ip, lr, ip, lsl #3
7000126a:	4563      	cmp	r3, ip
7000126c:	d3f0      	bcc.n	70001250 <pinctrl_lookup_state+0x20>
	}

	return -ENOENT;
7000126e:	f06f 0001 	mvn.w	r0, #1
}
70001272:	f85d fb04 	ldr.w	pc, [sp], #4
			return 0;
70001276:	2000      	movs	r0, #0
}
70001278:	f85d fb04 	ldr.w	pc, [sp], #4
			return 0;
7000127c:	2000      	movs	r0, #0
}
7000127e:	4770      	bx	lr
	return -ENOENT;
70001280:	f06f 0001 	mvn.w	r0, #1
70001284:	4770      	bx	lr
70001286:	bf00      	nop

70001288 <pinctrl_ti_k3_init>:

static int pinctrl_ti_k3_init(const struct device *dev)
{
	DEVICE_MMIO_MAP(dev, K_MEM_CACHE_NONE);
	return 0;
}
70001288:	2000      	movs	r0, #0
7000128a:	4770      	bx	lr

7000128c <pinctrl_configure_pins>:
	uintptr_t virt_reg_base = DEVICE_MMIO_GET(dev);
7000128c:	f24b 1378 	movw	r3, #45432	; 0xb178
70001290:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
70001294:	b410      	push	{r4}
	uintptr_t virt_reg_base = DEVICE_MMIO_GET(dev);
70001296:	681c      	ldr	r4, [r3, #0]
	for (uint8_t i = 0; i < pin_cnt; i++) {
70001298:	b151      	cbz	r1, 700012b0 <pinctrl_configure_pins+0x24>
7000129a:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
		sys_write32(pins[i].value, virt_reg_base + pins[i].offset);
7000129e:	6842      	ldr	r2, [r0, #4]
700012a0:	f850 3b08 	ldr.w	r3, [r0], #8
700012a4:	4423      	add	r3, r4
700012a6:	f3bf 8f5f 	dmb	sy
700012aa:	601a      	str	r2, [r3, #0]
	for (uint8_t i = 0; i < pin_cnt; i++) {
700012ac:	4288      	cmp	r0, r1
700012ae:	d1f6      	bne.n	7000129e <pinctrl_configure_pins+0x12>
}
700012b0:	bc10      	pop	{r4}
700012b2:	2000      	movs	r0, #0
700012b4:	4770      	bx	lr
700012b6:	bf00      	nop

700012b8 <uart_ns16550_config_get>:
};

#ifdef CONFIG_UART_USE_RUNTIME_CONFIGURE
static int uart_ns16550_config_get(const struct device *dev,
				   struct uart_config *cfg)
{
700012b8:	4603      	mov	r3, r0
	cfg->stop_bits = data->uart_config.stop_bits;
	cfg->data_bits = data->uart_config.data_bits;
	cfg->flow_ctrl = data->uart_config.flow_ctrl;

	return 0;
}
700012ba:	2000      	movs	r0, #0
	struct uart_ns16550_dev_data *data = dev->data;
700012bc:	691b      	ldr	r3, [r3, #16]
	cfg->baudrate = data->uart_config.baudrate;
700012be:	681a      	ldr	r2, [r3, #0]
700012c0:	600a      	str	r2, [r1, #0]
	cfg->parity = data->uart_config.parity;
700012c2:	791a      	ldrb	r2, [r3, #4]
700012c4:	710a      	strb	r2, [r1, #4]
	cfg->stop_bits = data->uart_config.stop_bits;
700012c6:	795a      	ldrb	r2, [r3, #5]
700012c8:	714a      	strb	r2, [r1, #5]
	cfg->data_bits = data->uart_config.data_bits;
700012ca:	799a      	ldrb	r2, [r3, #6]
700012cc:	718a      	strb	r2, [r1, #6]
	cfg->flow_ctrl = data->uart_config.flow_ctrl;
700012ce:	79db      	ldrb	r3, [r3, #7]
700012d0:	71cb      	strb	r3, [r1, #7]
}
700012d2:	4770      	bx	lr

700012d4 <uart_ns16550_poll_out>:
 * @param dev UART device struct
 * @param c Character to send
 */
static void uart_ns16550_poll_out(const struct device *dev,
					   unsigned char c)
{
700012d4:	b410      	push	{r4}
	key = __get_BASEPRI();
	__set_BASEPRI_MAX(_EXC_IRQ_DEFAULT_PRIO);
	__ISB();
#elif defined(CONFIG_ARMV7_R) || defined(CONFIG_AARCH32_ARMV8_R) \
	|| defined(CONFIG_ARMV7_A)
	__asm__ volatile(
700012d6:	f3ef 8400 	mrs	r4, CPSR
700012da:	f004 0480 	and.w	r4, r4, #128	; 0x80
700012de:	b672      	cpsid	i
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	while ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_THRE) == 0) {
700012e0:	f04f 0c05 	mov.w	ip, #5
		port = DEVICE_MMIO_GET(dev);
700012e4:	6842      	ldr	r2, [r0, #4]
	while ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_THRE) == 0) {
700012e6:	7d13      	ldrb	r3, [r2, #20]
700012e8:	6812      	ldr	r2, [r2, #0]
700012ea:	fb1c 2303 	smlabb	r3, ip, r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700012ee:	681b      	ldr	r3, [r3, #0]
700012f0:	f3bf 8f5f 	dmb	sy
700012f4:	069b      	lsls	r3, r3, #26
700012f6:	d5f5      	bpl.n	700012e4 <uart_ns16550_poll_out+0x10>
		port = DEVICE_MMIO_GET(dev);
700012f8:	6843      	ldr	r3, [r0, #4]
700012fa:	681b      	ldr	r3, [r3, #0]
700012fc:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001300:	6019      	str	r1, [r3, #0]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	__set_BASEPRI(key);
	__ISB();
#elif defined(CONFIG_ARMV7_R) || defined(CONFIG_AARCH32_ARMV8_R) \
	|| defined(CONFIG_ARMV7_A)
	if (key != 0U) {
70001302:	b904      	cbnz	r4, 70001306 <uart_ns16550_poll_out+0x32>
  \details Enables IRQ interrupts by clearing the I-bit in the CPSR.
           Can only be executed in Privileged modes.
 */
__STATIC_FORCEINLINE void __enable_irq(void)
{
  __ASM volatile ("cpsie i" : : : "memory");
70001304:	b662      	cpsie	i
	}

	ns16550_outbyte(dev_cfg, THR(dev), c);

	k_spin_unlock(&data->lock, key);
}
70001306:	bc10      	pop	{r4}
70001308:	4770      	bx	lr
7000130a:	bf00      	nop

7000130c <uart_ns16550_err_check>:
	__asm__ volatile(
7000130c:	f3ef 8200 	mrs	r2, CPSR
70001310:	f002 0280 	and.w	r2, r2, #128	; 0x80
70001314:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70001316:	6843      	ldr	r3, [r0, #4]
static int uart_ns16550_err_check(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);
	int check = (ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_EOB_MASK);
70001318:	7d19      	ldrb	r1, [r3, #20]
7000131a:	2005      	movs	r0, #5
7000131c:	681b      	ldr	r3, [r3, #0]
7000131e:	fb10 3001 	smlabb	r0, r0, r1, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001322:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001324:	f3bf 8f5f 	dmb	sy
	if (key != 0U) {
70001328:	b902      	cbnz	r2, 7000132c <uart_ns16550_err_check+0x20>
  __ASM volatile ("cpsie i" : : : "memory");
7000132a:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return check >> 1;
}
7000132c:	f3c0 0043 	ubfx	r0, r0, #1, #4
70001330:	4770      	bx	lr
70001332:	bf00      	nop

70001334 <uart_ns16550_fifo_fill>:
 * @return Number of bytes sent
 */
static int uart_ns16550_fifo_fill(const struct device *dev,
				  const uint8_t *tx_data,
				  int size)
{
70001334:	b470      	push	{r4, r5, r6}
	struct uart_ns16550_dev_data *data = dev->data;
70001336:	6905      	ldr	r5, [r0, #16]
	__asm__ volatile(
70001338:	f3ef 8600 	mrs	r6, CPSR
7000133c:	f006 0680 	and.w	r6, r6, #128	; 0x80
70001340:	b672      	cpsid	i
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	int i;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
70001342:	2a00      	cmp	r2, #0
70001344:	dd15      	ble.n	70001372 <uart_ns16550_fifo_fill+0x3e>
70001346:	4684      	mov	ip, r0
70001348:	3901      	subs	r1, #1
7000134a:	2000      	movs	r0, #0
7000134c:	e00a      	b.n	70001364 <uart_ns16550_fifo_fill+0x30>
		port = DEVICE_MMIO_GET(dev);
7000134e:	f8dc 4004 	ldr.w	r4, [ip, #4]
			sys_write32(val, port);
70001352:	f811 3f01 	ldrb.w	r3, [r1, #1]!
		port = DEVICE_MMIO_GET(dev);
70001356:	6824      	ldr	r4, [r4, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001358:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000135c:	6023      	str	r3, [r4, #0]
	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
7000135e:	3001      	adds	r0, #1
70001360:	4282      	cmp	r2, r0
70001362:	d002      	beq.n	7000136a <uart_ns16550_fifo_fill+0x36>
70001364:	7a2b      	ldrb	r3, [r5, #8]
70001366:	4283      	cmp	r3, r0
70001368:	dcf1      	bgt.n	7000134e <uart_ns16550_fifo_fill+0x1a>
	if (key != 0U) {
7000136a:	b906      	cbnz	r6, 7000136e <uart_ns16550_fifo_fill+0x3a>
  __ASM volatile ("cpsie i" : : : "memory");
7000136c:	b662      	cpsie	i
	}

	k_spin_unlock(&data->lock, key);

	return i;
}
7000136e:	bc70      	pop	{r4, r5, r6}
70001370:	4770      	bx	lr
	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
70001372:	2000      	movs	r0, #0
70001374:	e7f9      	b.n	7000136a <uart_ns16550_fifo_fill+0x36>
70001376:	bf00      	nop

70001378 <uart_ns16550_irq_tx_enable>:
	__asm__ volatile(
70001378:	f3ef 8100 	mrs	r1, CPSR
7000137c:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001380:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70001382:	6843      	ldr	r3, [r0, #4]
		for (uint8_t i = 0U; i < num_cpu_states; i++) {
			pm_policy_state_lock_get(cpu_states[i].state, PM_ALL_SUBSTATES);
		}
	}
#endif
	ns16550_outbyte(dev_cfg, IER(dev), ns16550_inbyte(dev_cfg, IER(dev)) | IER_TBE);
70001384:	7d1a      	ldrb	r2, [r3, #20]
70001386:	681b      	ldr	r3, [r3, #0]
70001388:	441a      	add	r2, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000138a:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
7000138c:	f3bf 8f5f 	dmb	sy
70001390:	f3bf 8f5f 	dmb	sy
70001394:	f043 0302 	orr.w	r3, r3, #2
			sys_write32(val, port);
70001398:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000139a:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
7000139c:	b901      	cbnz	r1, 700013a0 <uart_ns16550_irq_tx_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
7000139e:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);
}
700013a0:	4770      	bx	lr
700013a2:	bf00      	nop

700013a4 <uart_ns16550_irq_tx_disable>:
	__asm__ volatile(
700013a4:	f3ef 8100 	mrs	r1, CPSR
700013a8:	f001 0180 	and.w	r1, r1, #128	; 0x80
700013ac:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700013ae:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
700013b0:	7d13      	ldrb	r3, [r2, #20]
700013b2:	6812      	ldr	r2, [r2, #0]
700013b4:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700013b6:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700013b8:	f3bf 8f5f 	dmb	sy
700013bc:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
700013c0:	f002 02fd 	and.w	r2, r2, #253	; 0xfd
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700013c4:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
700013c6:	b901      	cbnz	r1, 700013ca <uart_ns16550_irq_tx_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
700013c8:	b662      	cpsie	i
			pm_policy_state_lock_put(cpu_states[i].state, PM_ALL_SUBSTATES);
		}
	}
#endif
	k_spin_unlock(&data->lock, key);
}
700013ca:	4770      	bx	lr

700013cc <uart_ns16550_irq_tx_ready>:
	__asm__ volatile(
700013cc:	f3ef 8300 	mrs	r3, CPSR
700013d0:	f003 0380 	and.w	r3, r3, #128	; 0x80
700013d4:	b672      	cpsid	i
static int uart_ns16550_irq_tx_ready(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((IIRC(dev) & IIR_ID) == IIR_THRE) ? 1 : 0;
700013d6:	6902      	ldr	r2, [r0, #16]
700013d8:	7a50      	ldrb	r0, [r2, #9]
700013da:	f000 0006 	and.w	r0, r0, #6
700013de:	f1a0 0002 	sub.w	r0, r0, #2
700013e2:	fab0 f080 	clz	r0, r0
700013e6:	0940      	lsrs	r0, r0, #5
	if (key != 0U) {
700013e8:	b903      	cbnz	r3, 700013ec <uart_ns16550_irq_tx_ready+0x20>
700013ea:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
700013ec:	4770      	bx	lr
700013ee:	bf00      	nop

700013f0 <uart_ns16550_irq_tx_complete>:
	__asm__ volatile(
700013f0:	f3ef 8200 	mrs	r2, CPSR
700013f4:	f002 0280 	and.w	r2, r2, #128	; 0x80
700013f8:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700013fa:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((ns16550_inbyte(dev_cfg, LSR(dev)) & (LSR_TEMT | LSR_THRE))
700013fc:	7d19      	ldrb	r1, [r3, #20]
700013fe:	2005      	movs	r0, #5
70001400:	681b      	ldr	r3, [r3, #0]
70001402:	fb10 3001 	smlabb	r0, r0, r1, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001406:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001408:	f3bf 8f5f 	dmb	sy
				== (LSR_TEMT | LSR_THRE)) ? 1 : 0;
7000140c:	f000 0060 	and.w	r0, r0, #96	; 0x60
70001410:	f1a0 0060 	sub.w	r0, r0, #96	; 0x60
70001414:	fab0 f080 	clz	r0, r0
70001418:	0940      	lsrs	r0, r0, #5
	if (key != 0U) {
7000141a:	b902      	cbnz	r2, 7000141e <uart_ns16550_irq_tx_complete+0x2e>
  __ASM volatile ("cpsie i" : : : "memory");
7000141c:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
7000141e:	4770      	bx	lr

70001420 <uart_ns16550_irq_rx_enable>:
	__asm__ volatile(
70001420:	f3ef 8100 	mrs	r1, CPSR
70001424:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001428:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000142a:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev), ns16550_inbyte(dev_cfg, IER(dev)) | IER_RXRDY);
7000142c:	7d1a      	ldrb	r2, [r3, #20]
7000142e:	681b      	ldr	r3, [r3, #0]
70001430:	441a      	add	r2, r3
70001432:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001434:	f3bf 8f5f 	dmb	sy
70001438:	f3bf 8f5f 	dmb	sy
7000143c:	f043 0301 	orr.w	r3, r3, #1
			sys_write32(val, port);
70001440:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001442:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
70001444:	b901      	cbnz	r1, 70001448 <uart_ns16550_irq_rx_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
70001446:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);
}
70001448:	4770      	bx	lr
7000144a:	bf00      	nop

7000144c <uart_ns16550_irq_rx_disable>:
	__asm__ volatile(
7000144c:	f3ef 8100 	mrs	r1, CPSR
70001450:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001454:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70001456:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
70001458:	7d13      	ldrb	r3, [r2, #20]
7000145a:	6812      	ldr	r2, [r2, #0]
7000145c:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000145e:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001460:	f3bf 8f5f 	dmb	sy
70001464:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
70001468:	f002 02fe 	and.w	r2, r2, #254	; 0xfe
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000146c:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
7000146e:	b901      	cbnz	r1, 70001472 <uart_ns16550_irq_rx_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
70001470:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) & (~IER_RXRDY));

	k_spin_unlock(&data->lock, key);
}
70001472:	4770      	bx	lr

70001474 <uart_ns16550_irq_rx_ready>:
	__asm__ volatile(
70001474:	f3ef 8300 	mrs	r3, CPSR
70001478:	f003 0380 	and.w	r3, r3, #128	; 0x80
7000147c:	b672      	cpsid	i
static int uart_ns16550_irq_rx_ready(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((IIRC(dev) & IIR_ID) == IIR_RBRF) ? 1 : 0;
7000147e:	6902      	ldr	r2, [r0, #16]
70001480:	7a50      	ldrb	r0, [r2, #9]
70001482:	f000 0006 	and.w	r0, r0, #6
70001486:	f1a0 0004 	sub.w	r0, r0, #4
7000148a:	fab0 f080 	clz	r0, r0
7000148e:	0940      	lsrs	r0, r0, #5
	if (key != 0U) {
70001490:	b903      	cbnz	r3, 70001494 <uart_ns16550_irq_rx_ready+0x20>
70001492:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
70001494:	4770      	bx	lr
70001496:	bf00      	nop

70001498 <uart_ns16550_irq_err_enable>:
	__asm__ volatile(
70001498:	f3ef 8100 	mrs	r1, CPSR
7000149c:	f001 0180 	and.w	r1, r1, #128	; 0x80
700014a0:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700014a2:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
700014a4:	7d1a      	ldrb	r2, [r3, #20]
700014a6:	681b      	ldr	r3, [r3, #0]
700014a8:	441a      	add	r2, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700014aa:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700014ac:	f3bf 8f5f 	dmb	sy
700014b0:	f3bf 8f5f 	dmb	sy
700014b4:	f043 0304 	orr.w	r3, r3, #4
			sys_write32(val, port);
700014b8:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700014ba:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
700014bc:	b901      	cbnz	r1, 700014c0 <uart_ns16550_irq_err_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
700014be:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) | IER_LSR);

	k_spin_unlock(&data->lock, key);
}
700014c0:	4770      	bx	lr
700014c2:	bf00      	nop

700014c4 <uart_ns16550_irq_err_disable>:
	__asm__ volatile(
700014c4:	f3ef 8100 	mrs	r1, CPSR
700014c8:	f001 0180 	and.w	r1, r1, #128	; 0x80
700014cc:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700014ce:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
700014d0:	7d13      	ldrb	r3, [r2, #20]
700014d2:	6812      	ldr	r2, [r2, #0]
700014d4:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700014d6:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700014d8:	f3bf 8f5f 	dmb	sy
700014dc:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
700014e0:	f002 02fb 	and.w	r2, r2, #251	; 0xfb
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700014e4:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
700014e6:	b901      	cbnz	r1, 700014ea <uart_ns16550_irq_err_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
700014e8:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) & (~IER_LSR));

	k_spin_unlock(&data->lock, key);
}
700014ea:	4770      	bx	lr

700014ec <uart_ns16550_irq_is_pending>:
	__asm__ volatile(
700014ec:	f3ef 8300 	mrs	r3, CPSR
700014f0:	f003 0380 	and.w	r3, r3, #128	; 0x80
700014f4:	b672      	cpsid	i
static int uart_ns16550_irq_is_pending(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = (!(IIRC(dev) & IIR_NIP)) ? 1 : 0;
700014f6:	6902      	ldr	r2, [r0, #16]
700014f8:	7a50      	ldrb	r0, [r2, #9]
700014fa:	43c0      	mvns	r0, r0
700014fc:	f000 0001 	and.w	r0, r0, #1
	if (key != 0U) {
70001500:	b903      	cbnz	r3, 70001504 <uart_ns16550_irq_is_pending+0x18>
70001502:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
70001504:	4770      	bx	lr
70001506:	bf00      	nop

70001508 <uart_ns16550_irq_update>:
	__asm__ volatile(
70001508:	f3ef 8200 	mrs	r2, CPSR
7000150c:	f002 0280 	and.w	r2, r2, #128	; 0x80
70001510:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70001512:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	IIRC(dev) = ns16550_inbyte(dev_cfg, IIR(dev));
70001514:	6901      	ldr	r1, [r0, #16]
70001516:	7d18      	ldrb	r0, [r3, #20]
70001518:	681b      	ldr	r3, [r3, #0]
7000151a:	eb03 0340 	add.w	r3, r3, r0, lsl #1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000151e:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001520:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
70001524:	724b      	strb	r3, [r1, #9]
	if (key != 0U) {
70001526:	b902      	cbnz	r2, 7000152a <uart_ns16550_irq_update+0x22>
  __ASM volatile ("cpsie i" : : : "memory");
70001528:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return 1;
}
7000152a:	2001      	movs	r0, #1
7000152c:	4770      	bx	lr
7000152e:	bf00      	nop

70001530 <uart_ns16550_irq_callback_set>:
 */
static void uart_ns16550_irq_callback_set(const struct device *dev,
					  uart_irq_callback_user_data_t cb,
					  void *cb_data)
{
	struct uart_ns16550_dev_data * const dev_data = dev->data;
70001530:	6903      	ldr	r3, [r0, #16]
	__asm__ volatile(
70001532:	f3ef 8000 	mrs	r0, CPSR
70001536:	f000 0080 	and.w	r0, r0, #128	; 0x80
7000153a:	b672      	cpsid	i
	k_spinlock_key_t key = k_spin_lock(&dev_data->lock);

	dev_data->cb = cb;
	dev_data->cb_data = cb_data;
7000153c:	e9c3 1203 	strd	r1, r2, [r3, #12]
	if (key != 0U) {
70001540:	b900      	cbnz	r0, 70001544 <uart_ns16550_irq_callback_set+0x14>
70001542:	b662      	cpsie	i

	k_spin_unlock(&dev_data->lock, key);
}
70001544:	4770      	bx	lr
70001546:	bf00      	nop

70001548 <uart_ns16550_isr>:
 *
 * @param arg Argument to ISR.
 */
static void uart_ns16550_isr(const struct device *dev)
{
	struct uart_ns16550_dev_data * const dev_data = dev->data;
70001548:	6902      	ldr	r2, [r0, #16]
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;

	if (dev_data->cb) {
7000154a:	68d3      	ldr	r3, [r2, #12]
7000154c:	b10b      	cbz	r3, 70001552 <uart_ns16550_isr+0xa>
		dev_data->cb(dev, dev_data->cb_data);
7000154e:	6911      	ldr	r1, [r2, #16]
70001550:	4718      	bx	r3
	uint8_t cached_ier = ns16550_inbyte(dev_cfg, IER(dev));

	ns16550_outbyte(dev_cfg, IER(dev), 0U);
	ns16550_outbyte(dev_cfg, IER(dev), cached_ier);
#endif
}
70001552:	4770      	bx	lr

70001554 <uart_ns16550_irq_config_func0>:
#define UART_NS16550_DEVICE_INIT(n)                                                  \
	COND_CODE_1(DT_INST_ON_BUS(n, pcie),                                         \
		    (UART_NS16550_DEVICE_PCIE_INIT(n)),                              \
		    (UART_NS16550_DEVICE_IO_MMIO_INIT(n)))

DT_INST_FOREACH_STATUS_OKAY(UART_NS16550_DEVICE_INIT)
70001554:	20d2      	movs	r0, #210	; 0xd2
70001556:	2200      	movs	r2, #0
70001558:	b508      	push	{r3, lr}
7000155a:	210f      	movs	r1, #15
7000155c:	f7ff fa46 	bl	700009ec <z_soc_irq_priority_set>
70001560:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
70001564:	20d2      	movs	r0, #210	; 0xd2
70001566:	f7ff ba43 	b.w	700009f0 <z_soc_irq_enable>
7000156a:	bf00      	nop

7000156c <uart_ns16550_configure>:
{
7000156c:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
	uint32_t pclk = 0U;
70001570:	f04f 0900 	mov.w	r9, #0
{
70001574:	b083      	sub	sp, #12
	struct uart_ns16550_dev_data * const dev_data = dev->data;
70001576:	6906      	ldr	r6, [r0, #16]
{
70001578:	4604      	mov	r4, r0
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
7000157a:	f8d0 8004 	ldr.w	r8, [r0, #4]
{
7000157e:	460d      	mov	r5, r1
	uint32_t pclk = 0U;
70001580:	f8cd 9000 	str.w	r9, [sp]
	__asm__ volatile(
70001584:	f3ef 8700 	mrs	r7, CPSR
70001588:	f007 0780 	and.w	r7, r7, #128	; 0x80
7000158c:	b672      	cpsid	i
	if (dev_cfg->pincfg != NULL) {
7000158e:	f8d8 0018 	ldr.w	r0, [r8, #24]
70001592:	b158      	cbz	r0, 700015ac <uart_ns16550_configure+0x40>
				      uint8_t id)
{
	int ret;
	const struct pinctrl_state *state;

	ret = pinctrl_lookup_state(config, id, &state);
70001594:	4649      	mov	r1, r9
70001596:	aa01      	add	r2, sp, #4
70001598:	f7ff fe4a 	bl	70001230 <pinctrl_lookup_state>
	if (ret < 0) {
7000159c:	4548      	cmp	r0, r9
7000159e:	db05      	blt.n	700015ac <uart_ns16550_configure+0x40>
		return ret;
	}

	return pinctrl_apply_state_direct(config, state);
700015a0:	9b01      	ldr	r3, [sp, #4]
	return pinctrl_configure_pins(state->pins, state->pin_cnt, reg);
700015a2:	464a      	mov	r2, r9
700015a4:	7919      	ldrb	r1, [r3, #4]
700015a6:	6818      	ldr	r0, [r3, #0]
700015a8:	f7ff fe70 	bl	7000128c <pinctrl_configure_pins>
	dev_data->iir_cache = 0U;
700015ac:	2300      	movs	r3, #0
	uint32_t mdr = ns16550_inbyte(dev_cfg, MDR1(dev));
700015ae:	2208      	movs	r2, #8
	dev_data->iir_cache = 0U;
700015b0:	7273      	strb	r3, [r6, #9]
		port = DEVICE_MMIO_GET(dev);
700015b2:	6861      	ldr	r1, [r4, #4]
	uint32_t mdr = ns16550_inbyte(dev_cfg, MDR1(dev));
700015b4:	7d0b      	ldrb	r3, [r1, #20]
700015b6:	6809      	ldr	r1, [r1, #0]
700015b8:	fb12 1303 	smlabb	r3, r2, r3, r1
700015bc:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700015be:	f3bf 8f5f 	dmb	sy
		port = DEVICE_MMIO_GET(dev);
700015c2:	6861      	ldr	r1, [r4, #4]
	ns16550_outbyte(dev_cfg, MDR1(dev), mdr);
700015c4:	7d08      	ldrb	r0, [r1, #20]
700015c6:	6809      	ldr	r1, [r1, #0]
700015c8:	fb12 1200 	smlabb	r2, r2, r0, r1
700015cc:	f3bf 8f5f 	dmb	sy
	mdr = ((mdr & ~MDR1_MODE_SELECT_FIELD_MASK) | ((((MDR1_STD_MODE) <<
700015d0:	f003 03f8 	and.w	r3, r3, #248	; 0xf8
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700015d4:	6013      	str	r3, [r2, #0]
	if (dev_cfg->sys_clk_freq != 0U) {
700015d6:	f8d8 3004 	ldr.w	r3, [r8, #4]
700015da:	2b00      	cmp	r3, #0
700015dc:	f000 80ad 	beq.w	7000173a <uart_ns16550_configure+0x1ce>
		pclk = dev_cfg->sys_clk_freq;
700015e0:	9300      	str	r3, [sp, #0]
	set_baud_rate(dev, cfg->baudrate, pclk);
700015e2:	6829      	ldr	r1, [r5, #0]
	if ((baud_rate != 0U) && (pclk != 0U)) {
700015e4:	2900      	cmp	r1, #0
700015e6:	bf18      	it	ne
700015e8:	2b00      	cmpne	r3, #0
700015ea:	d168      	bne.n	700016be <uart_ns16550_configure+0x152>
	switch (cfg->data_bits) {
700015ec:	79aa      	ldrb	r2, [r5, #6]
700015ee:	2a03      	cmp	r2, #3
700015f0:	d862      	bhi.n	700016b8 <uart_ns16550_configure+0x14c>
	switch (cfg->stop_bits) {
700015f2:	796b      	ldrb	r3, [r5, #5]
700015f4:	2b01      	cmp	r3, #1
700015f6:	f000 80af 	beq.w	70001758 <uart_ns16550_configure+0x1ec>
700015fa:	2b03      	cmp	r3, #3
700015fc:	bf08      	it	eq
700015fe:	f04f 0e04 	moveq.w	lr, #4
70001602:	d159      	bne.n	700016b8 <uart_ns16550_configure+0x14c>
	switch (cfg->parity) {
70001604:	792b      	ldrb	r3, [r5, #4]
70001606:	b113      	cbz	r3, 7000160e <uart_ns16550_configure+0xa2>
70001608:	2b02      	cmp	r3, #2
7000160a:	d155      	bne.n	700016b8 <uart_ns16550_configure+0x14c>
7000160c:	2310      	movs	r3, #16
	dev_data->uart_config = *cfg;
7000160e:	e895 0003 	ldmia.w	r5, {r0, r1}
	ns16550_outbyte(dev_cfg, LCR(dev),
70001612:	f04f 0c03 	mov.w	ip, #3
	dev_data->uart_config = *cfg;
70001616:	e886 0003 	stmia.w	r6, {r0, r1}
		port = DEVICE_MMIO_GET(dev);
7000161a:	6861      	ldr	r1, [r4, #4]
	ns16550_outbyte(dev_cfg, LCR(dev),
7000161c:	7d08      	ldrb	r0, [r1, #20]
7000161e:	6809      	ldr	r1, [r1, #0]
70001620:	fb1c 1c00 	smlabb	ip, ip, r0, r1
70001624:	f3bf 8f5f 	dmb	sy
70001628:	ea42 020e 	orr.w	r2, r2, lr
			sys_write32(val, port);
7000162c:	4313      	orrs	r3, r2
7000162e:	f8cc 3000 	str.w	r3, [ip]
		port = DEVICE_MMIO_GET(dev);
70001632:	6862      	ldr	r2, [r4, #4]
	if (cfg->flow_ctrl == UART_CFG_FLOW_CTRL_RTS_CTS) {
70001634:	79eb      	ldrb	r3, [r5, #7]
70001636:	2b01      	cmp	r3, #1
70001638:	bf0c      	ite	eq
7000163a:	212b      	moveq	r1, #43	; 0x2b
7000163c:	210b      	movne	r1, #11
	ns16550_outbyte(dev_cfg, MDC(dev), mdc);
7000163e:	6813      	ldr	r3, [r2, #0]
70001640:	7d12      	ldrb	r2, [r2, #20]
70001642:	eb03 0382 	add.w	r3, r3, r2, lsl #2
70001646:	f3bf 8f5f 	dmb	sy
7000164a:	6019      	str	r1, [r3, #0]
		port = DEVICE_MMIO_GET(dev);
7000164c:	6863      	ldr	r3, [r4, #4]
	ns16550_outbyte(dev_cfg, FCR(dev),
7000164e:	7d1a      	ldrb	r2, [r3, #20]
70001650:	6819      	ldr	r1, [r3, #0]
70001652:	2302      	movs	r3, #2
70001654:	fb13 1202 	smlabb	r2, r3, r2, r1
70001658:	f3bf 8f5f 	dmb	sy
7000165c:	21a7      	movs	r1, #167	; 0xa7
7000165e:	6011      	str	r1, [r2, #0]
		port = DEVICE_MMIO_GET(dev);
70001660:	6862      	ldr	r2, [r4, #4]
	if ((ns16550_inbyte(dev_cfg, IIR(dev)) & IIR_FE) == IIR_FE) {
70001662:	7d11      	ldrb	r1, [r2, #20]
70001664:	6812      	ldr	r2, [r2, #0]
70001666:	fb13 2301 	smlabb	r3, r3, r1, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000166a:	681b      	ldr	r3, [r3, #0]
7000166c:	f3bf 8f5f 	dmb	sy
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
70001670:	2205      	movs	r2, #5
	if ((ns16550_inbyte(dev_cfg, IIR(dev)) & IIR_FE) == IIR_FE) {
70001672:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
		dev_data->fifo_size = 64;
70001676:	2bc0      	cmp	r3, #192	; 0xc0
70001678:	bf14      	ite	ne
7000167a:	2301      	movne	r3, #1
7000167c:	2340      	moveq	r3, #64	; 0x40
7000167e:	7233      	strb	r3, [r6, #8]
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
70001680:	6863      	ldr	r3, [r4, #4]
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
70001682:	7d19      	ldrb	r1, [r3, #20]
70001684:	681b      	ldr	r3, [r3, #0]
70001686:	fb12 3301 	smlabb	r3, r2, r1, r3
7000168a:	681b      	ldr	r3, [r3, #0]
7000168c:	f3bf 8f5f 	dmb	sy
70001690:	07db      	lsls	r3, r3, #31
70001692:	d504      	bpl.n	7000169e <uart_ns16550_configure+0x132>
		port = DEVICE_MMIO_GET(dev);
70001694:	6863      	ldr	r3, [r4, #4]
70001696:	681b      	ldr	r3, [r3, #0]
70001698:	681b      	ldr	r3, [r3, #0]
7000169a:	f3bf 8f5f 	dmb	sy
7000169e:	6862      	ldr	r2, [r4, #4]
	ns16550_outbyte(dev_cfg, IER(dev), 0x00);
700016a0:	7d13      	ldrb	r3, [r2, #20]
700016a2:	6812      	ldr	r2, [r2, #0]
700016a4:	4413      	add	r3, r2
700016a6:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700016aa:	2000      	movs	r0, #0
700016ac:	6018      	str	r0, [r3, #0]
	if (key != 0U) {
700016ae:	b907      	cbnz	r7, 700016b2 <uart_ns16550_configure+0x146>
  __ASM volatile ("cpsie i" : : : "memory");
700016b0:	b662      	cpsie	i
};
700016b2:	b003      	add	sp, #12
700016b4:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	switch (cfg->parity) {
700016b8:	f06f 0085 	mvn.w	r0, #133	; 0x85
700016bc:	e7f7      	b.n	700016ae <uart_ns16550_configure+0x142>
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
700016be:	6860      	ldr	r0, [r4, #4]
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
700016c0:	7d02      	ldrb	r2, [r0, #20]
700016c2:	f04f 0c03 	mov.w	ip, #3
	return ((pclk + (baud_rate << 3)) / baud_rate) >> 4;
700016c6:	eb03 03c1 	add.w	r3, r3, r1, lsl #3
	struct uart_ns16550_dev_data * const dev_data = dev->data;
700016ca:	f8d4 e010 	ldr.w	lr, [r4, #16]
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
700016ce:	6800      	ldr	r0, [r0, #0]
	return ((pclk + (baud_rate << 3)) / baud_rate) >> 4;
700016d0:	fbb3 f3f1 	udiv	r3, r3, r1
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
700016d4:	fb1c 0202 	smlabb	r2, ip, r2, r0
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700016d8:	6812      	ldr	r2, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700016da:	f3bf 8f5f 	dmb	sy
		port = DEVICE_MMIO_GET(dev);
700016de:	6860      	ldr	r0, [r4, #4]
		ns16550_outbyte(dev_cfg, LCR(dev), LCR_DLAB | lcr_cache);
700016e0:	f890 8014 	ldrb.w	r8, [r0, #20]
700016e4:	6800      	ldr	r0, [r0, #0]
700016e6:	fb1c 0808 	smlabb	r8, ip, r8, r0
700016ea:	f3bf 8f5f 	dmb	sy
700016ee:	f062 007f 	orn	r0, r2, #127	; 0x7f
			sys_write32(val, port);
700016f2:	b2c0      	uxtb	r0, r0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700016f4:	f8c8 0000 	str.w	r0, [r8]
		port = DEVICE_MMIO_GET(dev);
700016f8:	6860      	ldr	r0, [r4, #4]
700016fa:	f8d0 8000 	ldr.w	r8, [r0]
700016fe:	f3bf 8f5f 	dmb	sy
70001702:	f3c3 1007 	ubfx	r0, r3, #4, #8
70001706:	f8c8 0000 	str.w	r0, [r8]
7000170a:	f8d4 8004 	ldr.w	r8, [r4, #4]
		ns16550_outbyte(dev_cfg, BRDH(dev), (unsigned char)((divisor >> 8) & 0xff));
7000170e:	f898 0014 	ldrb.w	r0, [r8, #20]
70001712:	f8d8 8000 	ldr.w	r8, [r8]
70001716:	4440      	add	r0, r8
70001718:	f3bf 8f5f 	dmb	sy
7000171c:	f3c3 3307 	ubfx	r3, r3, #12, #8
70001720:	6003      	str	r3, [r0, #0]
		port = DEVICE_MMIO_GET(dev);
70001722:	6863      	ldr	r3, [r4, #4]
		ns16550_outbyte(dev_cfg, LCR(dev), lcr_cache);
70001724:	7d18      	ldrb	r0, [r3, #20]
70001726:	681b      	ldr	r3, [r3, #0]
70001728:	fb1c 3300 	smlabb	r3, ip, r0, r3
7000172c:	f3bf 8f5f 	dmb	sy
70001730:	b2d2      	uxtb	r2, r2
70001732:	601a      	str	r2, [r3, #0]
		dev_data->uart_config.baudrate = baud_rate;
70001734:	f8ce 1000 	str.w	r1, [lr]
70001738:	e758      	b.n	700015ec <uart_ns16550_configure+0x80>
		if (!device_is_ready(dev_cfg->clock_dev)) {
7000173a:	f8d8 0008 	ldr.w	r0, [r8, #8]
7000173e:	f000 f945 	bl	700019cc <z_impl_device_is_ready>
70001742:	b180      	cbz	r0, 70001766 <uart_ns16550_configure+0x1fa>
					   dev_cfg->clock_subsys,
70001744:	e9d8 0102 	ldrd	r0, r1, [r8, #8]
					 uint32_t *rate)
{
	const struct clock_control_driver_api *api =
		(const struct clock_control_driver_api *)dev->api;

	if (api->get_rate == NULL) {
70001748:	6883      	ldr	r3, [r0, #8]
7000174a:	68db      	ldr	r3, [r3, #12]
7000174c:	b15b      	cbz	r3, 70001766 <uart_ns16550_configure+0x1fa>
		return -ENOSYS;
	}

	return api->get_rate(dev, sys, rate);
7000174e:	466a      	mov	r2, sp
70001750:	4798      	blx	r3
		if (clock_control_get_rate(dev_cfg->clock_dev,
70001752:	b940      	cbnz	r0, 70001766 <uart_ns16550_configure+0x1fa>
	set_baud_rate(dev, cfg->baudrate, pclk);
70001754:	9b00      	ldr	r3, [sp, #0]
70001756:	e744      	b.n	700015e2 <uart_ns16550_configure+0x76>
		uart_cfg.stop_bits = LCR_1_STB;
70001758:	f04f 0e00 	mov.w	lr, #0
	switch (cfg->parity) {
7000175c:	792b      	ldrb	r3, [r5, #4]
7000175e:	2b00      	cmp	r3, #0
70001760:	f47f af52 	bne.w	70001608 <uart_ns16550_configure+0x9c>
70001764:	e753      	b.n	7000160e <uart_ns16550_configure+0xa2>
			ret = -EINVAL;
70001766:	f06f 0015 	mvn.w	r0, #21
7000176a:	e7a0      	b.n	700016ae <uart_ns16550_configure+0x142>

7000176c <uart_ns16550_init>:
{
7000176c:	b570      	push	{r4, r5, r6, lr}
	ret = uart_ns16550_configure(dev, &data->uart_config);
7000176e:	6901      	ldr	r1, [r0, #16]
{
70001770:	4604      	mov	r4, r0
	const struct uart_ns16550_dev_config *dev_cfg = dev->config;
70001772:	6846      	ldr	r6, [r0, #4]
	ret = uart_ns16550_configure(dev, &data->uart_config);
70001774:	f7ff fefa 	bl	7000156c <uart_ns16550_configure>
	if (ret != 0) {
70001778:	4605      	mov	r5, r0
7000177a:	b910      	cbnz	r0, 70001782 <uart_ns16550_init+0x16>
	dev_cfg->irq_config_func(dev);
7000177c:	6933      	ldr	r3, [r6, #16]
7000177e:	4620      	mov	r0, r4
70001780:	4798      	blx	r3
}
70001782:	4628      	mov	r0, r5
70001784:	bd70      	pop	{r4, r5, r6, pc}
70001786:	bf00      	nop

70001788 <uart_ns16550_fifo_read>:
{
70001788:	b530      	push	{r4, r5, lr}
	__asm__ volatile(
7000178a:	f3ef 8400 	mrs	r4, CPSR
7000178e:	f004 0480 	and.w	r4, r4, #128	; 0x80
70001792:	b672      	cpsid	i
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
70001794:	2a00      	cmp	r2, #0
70001796:	dd1d      	ble.n	700017d4 <uart_ns16550_fifo_read+0x4c>
70001798:	4686      	mov	lr, r0
7000179a:	f101 3cff 	add.w	ip, r1, #4294967295	; 0xffffffff
7000179e:	2000      	movs	r0, #0
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
700017a0:	2505      	movs	r5, #5
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
700017a2:	f8de 1004 	ldr.w	r1, [lr, #4]
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
700017a6:	7d0b      	ldrb	r3, [r1, #20]
700017a8:	6809      	ldr	r1, [r1, #0]
700017aa:	fb15 1303 	smlabb	r3, r5, r3, r1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700017ae:	681b      	ldr	r3, [r3, #0]
700017b0:	f3bf 8f5f 	dmb	sy
700017b4:	07db      	lsls	r3, r3, #31
700017b6:	d50a      	bpl.n	700017ce <uart_ns16550_fifo_read+0x46>
		port = DEVICE_MMIO_GET(dev);
700017b8:	f8de 3004 	ldr.w	r3, [lr, #4]
700017bc:	681b      	ldr	r3, [r3, #0]
700017be:	681b      	ldr	r3, [r3, #0]
700017c0:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
700017c4:	f80c 3f01 	strb.w	r3, [ip, #1]!
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
700017c8:	3001      	adds	r0, #1
700017ca:	4282      	cmp	r2, r0
700017cc:	d1e9      	bne.n	700017a2 <uart_ns16550_fifo_read+0x1a>
	if (key != 0U) {
700017ce:	b904      	cbnz	r4, 700017d2 <uart_ns16550_fifo_read+0x4a>
  __ASM volatile ("cpsie i" : : : "memory");
700017d0:	b662      	cpsie	i
}
700017d2:	bd30      	pop	{r4, r5, pc}
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
700017d4:	2000      	movs	r0, #0
700017d6:	e7fa      	b.n	700017ce <uart_ns16550_fifo_read+0x46>

700017d8 <uart_ns16550_poll_in>:
{
700017d8:	b410      	push	{r4}
	__asm__ volatile(
700017da:	f3ef 8200 	mrs	r2, CPSR
700017de:	f002 0280 	and.w	r2, r2, #128	; 0x80
700017e2:	b672      	cpsid	i
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
700017e4:	6843      	ldr	r3, [r0, #4]
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
700017e6:	f893 c014 	ldrb.w	ip, [r3, #20]
700017ea:	681c      	ldr	r4, [r3, #0]
700017ec:	2305      	movs	r3, #5
700017ee:	fb13 430c 	smlabb	r3, r3, ip, r4
700017f2:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700017f4:	f3bf 8f5f 	dmb	sy
700017f8:	07db      	lsls	r3, r3, #31
700017fa:	d50a      	bpl.n	70001812 <uart_ns16550_poll_in+0x3a>
		port = DEVICE_MMIO_GET(dev);
700017fc:	6843      	ldr	r3, [r0, #4]
700017fe:	681b      	ldr	r3, [r3, #0]
70001800:	681b      	ldr	r3, [r3, #0]
70001802:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
70001806:	700b      	strb	r3, [r1, #0]
		return 0;
70001808:	2000      	movs	r0, #0
	if (key != 0U) {
7000180a:	b902      	cbnz	r2, 7000180e <uart_ns16550_poll_in+0x36>
  __ASM volatile ("cpsie i" : : : "memory");
7000180c:	b662      	cpsie	i
}
7000180e:	bc10      	pop	{r4}
70001810:	4770      	bx	lr
	return -1;
70001812:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
70001816:	e7f8      	b.n	7000180a <uart_ns16550_poll_in+0x32>

70001818 <sys_clock_driver_init>:
	return delta_ticks;
}

static int sys_clock_driver_init(void)
{
	last_cycle = 0;
70001818:	f646 4394 	movw	r3, #27796	; 0x6c94

	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
7000181c:	2202      	movs	r2, #2
{
7000181e:	b510      	push	{r4, lr}
	last_cycle = 0;
70001820:	2400      	movs	r4, #0
70001822:	f2c7 0300 	movt	r3, #28672	; 0x7000
	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
70001826:	210f      	movs	r1, #15
70001828:	209f      	movs	r0, #159	; 0x9f
	last_cycle = 0;
7000182a:	601c      	str	r4, [r3, #0]
	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
7000182c:	f7ff f8de 	bl	700009ec <z_soc_irq_priority_set>
70001830:	2338      	movs	r3, #56	; 0x38
70001832:	f2c0 2347 	movt	r3, #583	; 0x247
70001836:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001838:	f3bf 8f5f 	dmb	sy
7000183c:	f3bf 8f5f 	dmb	sy
	reg_val = (reg_val & ~(mask)) | (data << shift);
70001840:	f022 0220 	bic.w	r2, r2, #32
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001844:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001846:	681a      	ldr	r2, [r3, #0]
70001848:	f3bf 8f5f 	dmb	sy
7000184c:	f3bf 8f5f 	dmb	sy
70001850:	f042 0202 	orr.w	r2, r2, #2
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001854:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001856:	212c      	movs	r1, #44	; 0x2c
70001858:	f2c0 2147 	movt	r1, #583	; 0x247
7000185c:	680a      	ldr	r2, [r1, #0]
7000185e:	f3bf 8f5f 	dmb	sy
70001862:	f3bf 8f5f 	dmb	sy
70001866:	f042 0201 	orr.w	r2, r2, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000186a:	600a      	str	r2, [r1, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000186c:	223c      	movs	r2, #60	; 0x3c
7000186e:	f2c0 2247 	movt	r2, #583	; 0x247
70001872:	6811      	ldr	r1, [r2, #0]
70001874:	f3bf 8f5f 	dmb	sy
70001878:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000187c:	6014      	str	r4, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000187e:	2240      	movs	r2, #64	; 0x40
70001880:	f2c0 2247 	movt	r2, #583	; 0x247
70001884:	6811      	ldr	r1, [r2, #0]
70001886:	f3bf 8f5f 	dmb	sy
7000188a:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000188e:	6014      	str	r4, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001890:	224c      	movs	r2, #76	; 0x4c
70001892:	f2c0 2247 	movt	r2, #583	; 0x247
70001896:	6811      	ldr	r1, [r2, #0]
70001898:	f3bf 8f5f 	dmb	sy
7000189c:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700018a0:	f246 11a8 	movw	r1, #25000	; 0x61a8
700018a4:	6011      	str	r1, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700018a6:	681a      	ldr	r2, [r3, #0]
700018a8:	f3bf 8f5f 	dmb	sy
700018ac:	f3bf 8f5f 	dmb	sy
700018b0:	f042 0240 	orr.w	r2, r2, #64	; 0x40
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700018b4:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700018b6:	681a      	ldr	r2, [r3, #0]
700018b8:	f3bf 8f5f 	dmb	sy
700018bc:	f3bf 8f5f 	dmb	sy
700018c0:	f042 0201 	orr.w	r2, r2, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700018c4:	601a      	str	r2, [r3, #0]
	TI_DM_TIMER_WRITE(1, TCLR, CE);

	/* Start the timer */
	TI_DM_TIMER_WRITE(1, TCLR, ST);

	irq_enable(TIMER_IRQ_NUM);
700018c6:	209f      	movs	r0, #159	; 0x9f
700018c8:	f7ff f892 	bl	700009f0 <z_soc_irq_enable>

	return 0;
}
700018cc:	4620      	mov	r0, r4
700018ce:	bd10      	pop	{r4, pc}

700018d0 <ti_dmtimer_isr>:
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700018d0:	2228      	movs	r2, #40	; 0x28
700018d2:	f2c0 2247 	movt	r2, #583	; 0x247
700018d6:	6813      	ldr	r3, [r2, #0]
700018d8:	f3bf 8f5f 	dmb	sy
	if (!TI_DM_TIMER_READ(IRQSTATUS)) {
700018dc:	b33b      	cbz	r3, 7000192e <ti_dmtimer_isr+0x5e>
{
700018de:	b410      	push	{r4}
	__asm__ volatile(
700018e0:	f3ef 8400 	mrs	r4, CPSR
700018e4:	f004 0480 	and.w	r4, r4, #128	; 0x80
700018e8:	b672      	cpsid	i
700018ea:	233c      	movs	r3, #60	; 0x3c
700018ec:	f2c0 2347 	movt	r3, #583	; 0x247
700018f0:	681b      	ldr	r3, [r3, #0]
700018f2:	f3bf 8f5f 	dmb	sy
	uint32_t delta_cycles = curr_cycle - last_cycle;
700018f6:	f646 4194 	movw	r1, #27796	; 0x6c94
700018fa:	f2c7 0100 	movt	r1, #28672	; 0x7000
700018fe:	6808      	ldr	r0, [r1, #0]
	last_cycle = curr_cycle;
70001900:	600b      	str	r3, [r1, #0]
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001902:	1a18      	subs	r0, r3, r0
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70001904:	f24b 5389 	movw	r3, #46473	; 0xb589
70001908:	f2c1 43f8 	movt	r3, #5368	; 0x14f8
7000190c:	08c0      	lsrs	r0, r0, #3
7000190e:	fba3 3000 	umull	r3, r0, r3, r0
70001912:	0a00      	lsrs	r0, r0, #8
70001914:	6813      	ldr	r3, [r2, #0]
70001916:	f3bf 8f5f 	dmb	sy
7000191a:	f3bf 8f5f 	dmb	sy
	reg_val = (reg_val & ~(mask)) | (data << shift);
7000191e:	f043 0301 	orr.w	r3, r3, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001922:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
70001924:	b904      	cbnz	r4, 70001928 <ti_dmtimer_isr+0x58>
  __ASM volatile ("cpsie i" : : : "memory");
70001926:	b662      	cpsie	i
}
70001928:	bc10      	pop	{r4}
	sys_clock_announce(delta_ticks);
7000192a:	f000 bf8d 	b.w	70002848 <sys_clock_announce>
7000192e:	4770      	bx	lr

70001930 <sys_clock_set_timeout>:
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
70001930:	1c43      	adds	r3, r0, #1
70001932:	d028      	beq.n	70001986 <sys_clock_set_timeout+0x56>
	ticks = CLAMP(ticks, 1, (int32_t)MAX_TICKS);
70001934:	2801      	cmp	r0, #1
70001936:	bfd8      	it	le
70001938:	f246 10a8 	movwle	r0, #25000	; 0x61a8
7000193c:	dd0a      	ble.n	70001954 <sys_clock_set_timeout+0x24>
7000193e:	f649 7315 	movw	r3, #40725	; 0x9f15
	uint32_t next_cycle = curr_cycle + (ticks * CYC_PER_TICK);
70001942:	f246 12a8 	movw	r2, #25000	; 0x61a8
	ticks = CLAMP(ticks, 1, (int32_t)MAX_TICKS);
70001946:	f2c0 0302 	movt	r3, #2
7000194a:	4298      	cmp	r0, r3
7000194c:	bfa8      	it	ge
7000194e:	4618      	movge	r0, r3
	uint32_t next_cycle = curr_cycle + (ticks * CYC_PER_TICK);
70001950:	fb02 f000 	mul.w	r0, r2, r0
	__asm__ volatile(
70001954:	f3ef 8100 	mrs	r1, CPSR
70001958:	f001 0180 	and.w	r1, r1, #128	; 0x80
7000195c:	b672      	cpsid	i
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000195e:	233c      	movs	r3, #60	; 0x3c
70001960:	f2c0 2347 	movt	r3, #583	; 0x247
70001964:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001966:	f3bf 8f5f 	dmb	sy
7000196a:	224c      	movs	r2, #76	; 0x4c
7000196c:	f2c0 2247 	movt	r2, #583	; 0x247
70001970:	f8d2 c000 	ldr.w	ip, [r2]
70001974:	f3bf 8f5f 	dmb	sy
70001978:	f3bf 8f5f 	dmb	sy
7000197c:	4403      	add	r3, r0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000197e:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
70001980:	b901      	cbnz	r1, 70001984 <sys_clock_set_timeout+0x54>
  __ASM volatile ("cpsie i" : : : "memory");
70001982:	b662      	cpsie	i
}
70001984:	4770      	bx	lr
70001986:	f645 20c8 	movw	r0, #23240	; 0x5ac8
7000198a:	f6cf 70ff 	movt	r0, #65535	; 0xffff
7000198e:	e7e1      	b.n	70001954 <sys_clock_set_timeout+0x24>

70001990 <sys_clock_elapsed>:
	__asm__ volatile(
70001990:	f3ef 8100 	mrs	r1, CPSR
70001994:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001998:	b672      	cpsid	i
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000199a:	233c      	movs	r3, #60	; 0x3c
7000199c:	f2c0 2347 	movt	r3, #583	; 0x247
700019a0:	6818      	ldr	r0, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700019a2:	f3bf 8f5f 	dmb	sy
	uint32_t delta_cycles = curr_cycle - last_cycle;
700019a6:	f646 4294 	movw	r2, #27796	; 0x6c94
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
700019aa:	f24b 5389 	movw	r3, #46473	; 0xb589
	uint32_t delta_cycles = curr_cycle - last_cycle;
700019ae:	f2c7 0200 	movt	r2, #28672	; 0x7000
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
700019b2:	f2c1 43f8 	movt	r3, #5368	; 0x14f8
	uint32_t delta_cycles = curr_cycle - last_cycle;
700019b6:	6812      	ldr	r2, [r2, #0]
700019b8:	1a80      	subs	r0, r0, r2
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
700019ba:	08c0      	lsrs	r0, r0, #3
700019bc:	fba3 3000 	umull	r3, r0, r3, r0
700019c0:	0a00      	lsrs	r0, r0, #8
	if (key != 0U) {
700019c2:	b901      	cbnz	r1, 700019c6 <sys_clock_elapsed+0x36>
  __ASM volatile ("cpsie i" : : : "memory");
700019c4:	b662      	cpsie	i
}
700019c6:	4770      	bx	lr

700019c8 <z_device_state_init>:
void z_device_state_init(void)
{
	STRUCT_SECTION_FOREACH(device, dev) {
		k_object_init(dev);
	}
}
700019c8:	4770      	bx	lr
700019ca:	bf00      	nop

700019cc <z_impl_device_is_ready>:
{
	/*
	 * if an invalid device pointer is passed as argument, this call
	 * reports the `device` as not ready for usage.
	 */
	if (dev == NULL) {
700019cc:	b140      	cbz	r0, 700019e0 <z_impl_device_is_ready+0x14>
		return false;
	}

	return dev->state->initialized && (dev->state->init_res == 0U);
700019ce:	68c3      	ldr	r3, [r0, #12]
700019d0:	7858      	ldrb	r0, [r3, #1]
700019d2:	f010 0001 	ands.w	r0, r0, #1
700019d6:	bf1e      	ittt	ne
700019d8:	7818      	ldrbne	r0, [r3, #0]
700019da:	fab0 f080 	clzne	r0, r0
700019de:	0940      	lsrne	r0, r0, #5
}
700019e0:	4770      	bx	lr
700019e2:	bf00      	nop

700019e4 <arch_system_halt>:
	__asm__ volatile(
700019e4:	f3ef 8300 	mrs	r3, CPSR
700019e8:	f003 0380 	and.w	r3, r3, #128	; 0x80
700019ec:	b672      	cpsid	i
	/* TODO: What's the best way to totally halt the system if SMP
	 * is enabled?
	 */

	(void)arch_irq_lock();
	for (;;) {
700019ee:	e7fe      	b.n	700019ee <arch_system_halt+0xa>

700019f0 <k_sys_fatal_error_handler>:
/* LCOV_EXCL_STOP */

/* LCOV_EXCL_START */
__weak void k_sys_fatal_error_handler(unsigned int reason,
				      const struct arch_esf *esf)
{
700019f0:	b508      	push	{r3, lr}
	ARG_UNUSED(esf);

	LOG_PANIC();
	LOG_ERR("Halting system");
	arch_system_halt(reason);
700019f2:	f7ff fff7 	bl	700019e4 <arch_system_halt>
700019f6:	bf00      	nop

700019f8 <z_fatal_error>:
	arch_system_halt(reason);
}
/* LCOV_EXCL_STOP */

void z_fatal_error(unsigned int reason, const struct arch_esf *esf)
{
700019f8:	b538      	push	{r3, r4, r5, lr}
700019fa:	f3ef 8500 	mrs	r5, CPSR
700019fe:	f005 0580 	and.w	r5, r5, #128	; 0x80
70001a02:	b672      	cpsid	i

	struct k_thread *ret = _current_cpu->current;

	arch_irq_unlock(k);
#else
	struct k_thread *ret = _kernel.cpus[0].current;
70001a04:	f646 4298 	movw	r2, #27800	; 0x6c98
70001a08:	f2c7 0200 	movt	r2, #28672	; 0x7000
70001a0c:	6894      	ldr	r4, [r2, #8]
	 * an IRQ or exception was being handled, or thread context.
	 *
	 * See #17656
	 */
#if defined(CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION)
	if ((esf != NULL) && arch_is_in_nested_exception(esf)) {
70001a0e:	b161      	cbz	r1, 70001a2a <z_fatal_error+0x32>
70001a10:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
		LOG_ERR("Current thread: %p (%s)", thread, thread_name_get(thread));
	}

	coredump(reason, esf, thread);

	k_sys_fatal_error_handler(reason, esf);
70001a14:	f7ff ffec 	bl	700019f0 <k_sys_fatal_error_handler>
70001a18:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
	if (key != 0U) {
70001a1c:	b905      	cbnz	r5, 70001a20 <z_fatal_error+0x28>
70001a1e:	b662      	cpsie	i
70001a20:	4620      	mov	r0, r4
	arch_irq_unlock(key);

	if (IS_ENABLED(CONFIG_MULTITHREADING)) {
		k_thread_abort(thread);
	}
}
70001a22:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
70001a26:	f000 bdf7 	b.w	70002618 <z_impl_k_thread_abort>
	k_sys_fatal_error_handler(reason, esf);
70001a2a:	f7ff ffe1 	bl	700019f0 <k_sys_fatal_error_handler>
		if ((esf != NULL) && arch_is_in_nested_exception(esf)) {
70001a2e:	e7f5      	b.n	70001a1c <z_fatal_error+0x24>

70001a30 <z_sys_init_run_level>:
		/* End marker */
		__init_end,
	};
	const struct init_entry *entry;

	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001a30:	f644 437c 	movw	r3, #19580	; 0x4c7c
70001a34:	1c42      	adds	r2, r0, #1
70001a36:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
70001a3a:	b570      	push	{r4, r5, r6, lr}
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001a3c:	f853 4020 	ldr.w	r4, [r3, r0, lsl #2]
70001a40:	f853 6022 	ldr.w	r6, [r3, r2, lsl #2]
70001a44:	42b4      	cmp	r4, r6
70001a46:	d314      	bcc.n	70001a72 <z_sys_init_run_level+0x42>
70001a48:	e01b      	b.n	70001a82 <z_sys_init_run_level+0x52>
		rc = entry->init_fn.dev(dev);
70001a4a:	4628      	mov	r0, r5
	if (entry->init_fn.dev != NULL) {
70001a4c:	b14b      	cbz	r3, 70001a62 <z_sys_init_run_level+0x32>
		rc = entry->init_fn.dev(dev);
70001a4e:	4798      	blx	r3
		if (rc != 0) {
70001a50:	b138      	cbz	r0, 70001a62 <z_sys_init_run_level+0x32>
			dev->state->init_res = rc;
70001a52:	68eb      	ldr	r3, [r5, #12]
			if (rc < 0) {
70001a54:	2800      	cmp	r0, #0
70001a56:	bfb8      	it	lt
70001a58:	4240      	neglt	r0, r0
			if (rc > UINT8_MAX) {
70001a5a:	28ff      	cmp	r0, #255	; 0xff
70001a5c:	bfa8      	it	ge
70001a5e:	20ff      	movge	r0, #255	; 0xff
			dev->state->init_res = rc;
70001a60:	7018      	strb	r0, [r3, #0]
	dev->state->initialized = true;
70001a62:	68ea      	ldr	r2, [r5, #12]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001a64:	3408      	adds	r4, #8
	dev->state->initialized = true;
70001a66:	7853      	ldrb	r3, [r2, #1]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001a68:	42a6      	cmp	r6, r4
	dev->state->initialized = true;
70001a6a:	f043 0301 	orr.w	r3, r3, #1
70001a6e:	7053      	strb	r3, [r2, #1]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001a70:	d907      	bls.n	70001a82 <z_sys_init_run_level+0x52>

		sys_trace_sys_init_enter(entry, level);
		if (dev != NULL) {
			result = do_device_init(entry);
		} else {
			result = entry->init_fn.sys();
70001a72:	e9d4 3500 	ldrd	r3, r5, [r4]
		if (dev != NULL) {
70001a76:	2d00      	cmp	r5, #0
70001a78:	d1e7      	bne.n	70001a4a <z_sys_init_run_level+0x1a>
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001a7a:	3408      	adds	r4, #8
			result = entry->init_fn.sys();
70001a7c:	4798      	blx	r3
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001a7e:	42a6      	cmp	r6, r4
70001a80:	d8f7      	bhi.n	70001a72 <z_sys_init_run_level+0x42>
		}
		sys_trace_sys_init_exit(entry, level, result);
	}
}
70001a82:	bd70      	pop	{r4, r5, r6, pc}

70001a84 <bg_thread_main>:
	 * may perform memory management tasks (except for
	 * k_mem_map_phys_bare() which is allowed at any time)
	 */
	z_mem_manage_init();
#endif /* CONFIG_MMU */
	z_sys_post_kernel = true;
70001a84:	f646 43bc 	movw	r3, #27836	; 0x6cbc
70001a88:	2201      	movs	r2, #1
70001a8a:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
70001a8e:	b5f0      	push	{r4, r5, r6, r7, lr}

#if CONFIG_IRQ_OFFLOAD
	arch_irq_offload_init();
#endif
	z_sys_init_run_level(INIT_LEVEL_POST_KERNEL);
70001a90:	2003      	movs	r0, #3
{
70001a92:	b087      	sub	sp, #28
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001a94:	f644 16d8 	movw	r6, #18904	; 0x49d8
70001a98:	f644 2508 	movw	r5, #18952	; 0x4a08
	z_sys_post_kernel = true;
70001a9c:	701a      	strb	r2, [r3, #0]
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001a9e:	f2c7 0600 	movt	r6, #28672	; 0x7000
	z_sys_init_run_level(INIT_LEVEL_POST_KERNEL);
70001aa2:	f7ff ffc5 	bl	70001a30 <z_sys_init_run_level>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001aa6:	f2c7 0500 	movt	r5, #28672	; 0x7000
#endif

#if defined(CONFIG_STACK_POINTER_RANDOM) && (CONFIG_STACK_POINTER_RANDOM != 0)
	z_stack_adjust_initialized = 1;
#endif /* CONFIG_STACK_POINTER_RANDOM */
	boot_banner();
70001aaa:	f000 ffe5 	bl	70002a78 <boot_banner>

	void z_init_static(void);
	z_init_static();
70001aae:	f000 f8d3 	bl	70001c58 <z_init_static>

	/* Final init level before app starts */
	z_sys_init_run_level(INIT_LEVEL_APPLICATION);
70001ab2:	2004      	movs	r0, #4
70001ab4:	f7ff ffbc 	bl	70001a30 <z_sys_init_run_level>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001ab8:	42ae      	cmp	r6, r5
70001aba:	d217      	bcs.n	70001aec <bg_thread_main+0x68>
70001abc:	4634      	mov	r4, r6
		z_setup_new_thread(
70001abe:	6a67      	ldr	r7, [r4, #36]	; 0x24
70001ac0:	e9d4 2302 	ldrd	r2, r3, [r4, #8]
70001ac4:	e9d4 0100 	ldrd	r0, r1, [r4]
70001ac8:	9705      	str	r7, [sp, #20]
70001aca:	6a27      	ldr	r7, [r4, #32]
70001acc:	9704      	str	r7, [sp, #16]
70001ace:	69e7      	ldr	r7, [r4, #28]
70001ad0:	9703      	str	r7, [sp, #12]
70001ad2:	69a7      	ldr	r7, [r4, #24]
70001ad4:	9702      	str	r7, [sp, #8]
70001ad6:	6967      	ldr	r7, [r4, #20]
70001ad8:	9701      	str	r7, [sp, #4]
70001ada:	6927      	ldr	r7, [r4, #16]
70001adc:	9700      	str	r7, [sp, #0]
70001ade:	f000 f9af 	bl	70001e40 <z_setup_new_thread>
		thread_data->init_thread->init_data = thread_data;
70001ae2:	6823      	ldr	r3, [r4, #0]
70001ae4:	655c      	str	r4, [r3, #84]	; 0x54
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001ae6:	3430      	adds	r4, #48	; 0x30
70001ae8:	42ac      	cmp	r4, r5
70001aea:	d3e8      	bcc.n	70001abe <bg_thread_main+0x3a>
	k_sched_lock();
70001aec:	f000 fc70 	bl	700023d0 <k_sched_lock>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001af0:	42ae      	cmp	r6, r5
70001af2:	d222      	bcs.n	70001b3a <bg_thread_main+0xb6>
70001af4:	f644 14d8 	movw	r4, #18904	; 0x49d8

extern void z_thread_timeout(struct _timeout *timeout);

static inline void z_add_thread_timeout(struct k_thread *thread, k_timeout_t ticks)
{
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
70001af8:	f242 27f5 	movw	r7, #8949	; 0x22f5
70001afc:	f2c7 0400 	movt	r4, #28672	; 0x7000
70001b00:	f2c7 0700 	movt	r7, #28672	; 0x7000
70001b04:	e005      	b.n	70001b12 <bg_thread_main+0x8e>
	z_impl_k_wakeup(thread);
70001b06:	4630      	mov	r0, r6
70001b08:	f000 fd5a 	bl	700025c0 <z_impl_k_wakeup>
70001b0c:	3430      	adds	r4, #48	; 0x30
70001b0e:	42ac      	cmp	r4, r5
70001b10:	d213      	bcs.n	70001b3a <bg_thread_main+0xb6>
		k_timeout_t init_delay = Z_THREAD_INIT_DELAY(thread_data);
70001b12:	e9d4 230a 	ldrd	r2, r3, [r4, #40]	; 0x28
		if (!K_TIMEOUT_EQ(init_delay, K_FOREVER)) {
70001b16:	f1b3 3fff 	cmp.w	r3, #4294967295	; 0xffffffff
70001b1a:	bf08      	it	eq
70001b1c:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
70001b20:	d0f4      	beq.n	70001b0c <bg_thread_main+0x88>
			thread_schedule_new(thread_data->init_thread,
70001b22:	6826      	ldr	r6, [r4, #0]


static inline void thread_schedule_new(struct k_thread *thread, k_timeout_t delay)
{
#ifdef CONFIG_SYS_CLOCK_EXISTS
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
70001b24:	ea52 0003 	orrs.w	r0, r2, r3
70001b28:	4639      	mov	r1, r7
70001b2a:	f106 0018 	add.w	r0, r6, #24
70001b2e:	d0ea      	beq.n	70001b06 <bg_thread_main+0x82>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b30:	3430      	adds	r4, #48	; 0x30
70001b32:	f000 fdcf 	bl	700026d4 <z_add_timeout>
70001b36:	42ac      	cmp	r4, r5
70001b38:	d3eb      	bcc.n	70001b12 <bg_thread_main+0x8e>
	k_sched_unlock();
70001b3a:	f000 fc59 	bl	700023f0 <k_sched_unlock>
	char **argv = prepare_main_args(&argc);
	(void)main(argc, argv);
#else
	extern int main(void);

	(void)main();
70001b3e:	f7fe fc8f 	bl	70000460 <main>
 * Exceptions raised by this thread may be recoverable.
 * (This is the default tag for a thread.)
 */
static inline void z_thread_essential_clear(struct k_thread *thread)
{
	thread->base.user_options &= ~K_ESSENTIAL;
70001b42:	f245 2390 	movw	r3, #21136	; 0x5290
70001b46:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001b4a:	7b1a      	ldrb	r2, [r3, #12]
70001b4c:	f022 0201 	bic.w	r2, r2, #1
70001b50:	731a      	strb	r2, [r3, #12]

#ifdef CONFIG_COVERAGE_DUMP
	/* Dump coverage data once the main() has exited. */
	gcov_coverage_dump();
#endif /* CONFIG_COVERAGE_DUMP */
} /* LCOV_EXCL_LINE ... because we just dumped final coverage data */
70001b52:	b007      	add	sp, #28
70001b54:	bdf0      	pop	{r4, r5, r6, r7, pc}
70001b56:	bf00      	nop

70001b58 <z_early_memset>:
	(void) memset(dst, c, n);
70001b58:	f001 b988 	b.w	70002e6c <memset>

70001b5c <z_bss_zero>:
	z_early_memset(__bss_start, 0, __bss_end - __bss_start);
70001b5c:	f646 42c0 	movw	r2, #27840	; 0x6cc0
70001b60:	f644 40f0 	movw	r0, #19696	; 0x4cf0
70001b64:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001b68:	2100      	movs	r1, #0
70001b6a:	f2c7 0200 	movt	r2, #28672	; 0x7000
70001b6e:	1a12      	subs	r2, r2, r0
{
70001b70:	b508      	push	{r3, lr}
	z_early_memset(__bss_start, 0, __bss_end - __bss_start);
70001b72:	f7ff fff1 	bl	70001b58 <z_early_memset>
}
70001b76:	bd08      	pop	{r3, pc}

70001b78 <z_cstart>:
 * @return Does not return
 */
__boot_func
FUNC_NO_STACK_PROTECTOR
FUNC_NORETURN void z_cstart(void)
{
70001b78:	b580      	push	{r7, lr}
	/* gcov hook needed to get the coverage report.*/
	gcov_static_init();

	/* initialize early init calls */
	z_sys_init_run_level(INIT_LEVEL_EARLY);
70001b7a:	2000      	movs	r0, #0
{
70001b7c:	b086      	sub	sp, #24
	z_sys_init_run_level(INIT_LEVEL_EARLY);
70001b7e:	f7ff ff57 	bl	70001a30 <z_sys_init_run_level>
	return ret;
}

static ALWAYS_INLINE void arch_current_thread_set(struct k_thread *thread)
{
	_current_cpu->current = thread;
70001b82:	f646 4498 	movw	r4, #27800	; 0x6c98
{
	dummy_thread->base.thread_state = _THREAD_DUMMY;
#ifdef CONFIG_SCHED_CPU_MASK
	dummy_thread->base.cpu_mask = -1;
#endif /* CONFIG_SCHED_CPU_MASK */
	dummy_thread->base.user_options = K_ESSENTIAL;
70001b86:	f245 3308 	movw	r3, #21256	; 0x5308
	dummy_thread->mem_domain_info.mem_domain = &k_mem_domain_default;
#endif /* CONFIG_USERSPACE */
#if (K_HEAP_MEM_POOL_SIZE > 0)
	k_thread_system_pool_assign(dummy_thread);
#else
	dummy_thread->resource_pool = NULL;
70001b8a:	2500      	movs	r5, #0
	dummy_thread->base.user_options = K_ESSENTIAL;
70001b8c:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001b90:	f240 1201 	movw	r2, #257	; 0x101
70001b94:	f2c7 0400 	movt	r4, #28672	; 0x7000
	dummy_thread->resource_pool = NULL;
70001b98:	669d      	str	r5, [r3, #104]	; 0x68
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001b9a:	2701      	movs	r7, #1
	dummy_thread->base.user_options = K_ESSENTIAL;
70001b9c:	819a      	strh	r2, [r3, #12]
	_kernel.ready_q.cache = &z_main_thread;
70001b9e:	f245 2690 	movw	r6, #21136	; 0x5290
70001ba2:	60a3      	str	r3, [r4, #8]

#if defined(CONFIG_MULTITHREADING)
	z_dummy_thread_init(&_thread_dummy);
#endif /* CONFIG_MULTITHREADING */
	/* do any necessary initialization of static devices */
	z_device_state_init();
70001ba4:	f7ff ff10 	bl	700019c8 <z_device_state_init>
#endif
#if CONFIG_BOARD_EARLY_INIT_HOOK
	board_early_init_hook();
#endif
	/* perform basic hardware initialization */
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_1);
70001ba8:	2001      	movs	r0, #1
	_kernel.ready_q.cache = &z_main_thread;
70001baa:	f2c7 0600 	movt	r6, #28672	; 0x7000
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_1);
70001bae:	f7ff ff3f 	bl	70001a30 <z_sys_init_run_level>
#if defined(CONFIG_SMP)
	arch_smp_init();
#endif
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_2);
70001bb2:	2002      	movs	r0, #2
70001bb4:	f7ff ff3c 	bl	70001a30 <z_sys_init_run_level>
	z_sched_init();
70001bb8:	f000 fc54 	bl	70002464 <z_sched_init>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001bbc:	f644 4374 	movw	r3, #19572	; 0x4c74
70001bc0:	f64a 01c0 	movw	r1, #43200	; 0xa8c0
70001bc4:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001bc8:	f44f 6280 	mov.w	r2, #1024	; 0x400
70001bcc:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001bd0:	9305      	str	r3, [sp, #20]
70001bd2:	f641 2385 	movw	r3, #6789	; 0x1a85
70001bd6:	4630      	mov	r0, r6
70001bd8:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001bdc:	e9cd 5703 	strd	r5, r7, [sp, #12]
70001be0:	9502      	str	r5, [sp, #8]
70001be2:	e9cd 5500 	strd	r5, r5, [sp]
	_kernel.ready_q.cache = &z_main_thread;
70001be6:	6166      	str	r6, [r4, #20]
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001be8:	f000 f92a 	bl	70001e40 <z_setup_new_thread>
	thread->base.thread_state &= ~_THREAD_SLEEPING;
70001bec:	7b73      	ldrb	r3, [r6, #13]
	z_ready_thread(&z_main_thread);
70001bee:	4630      	mov	r0, r6
70001bf0:	f023 0304 	bic.w	r3, r3, #4
70001bf4:	7373      	strb	r3, [r6, #13]
70001bf6:	f000 faf1 	bl	700021dc <z_ready_thread>
	z_setup_new_thread(thread, stack,
70001bfa:	230f      	movs	r3, #15
70001bfc:	f245 2618 	movw	r6, #21016	; 0x5218
70001c00:	f24a 71c0 	movw	r1, #42944	; 0xa7c0
70001c04:	f2c7 0600 	movt	r6, #28672	; 0x7000
70001c08:	9303      	str	r3, [sp, #12]
70001c0a:	f641 43b9 	movw	r3, #7353	; 0x1cb9
70001c0e:	f44f 7280 	mov.w	r2, #256	; 0x100
70001c12:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001c16:	4630      	mov	r0, r6
70001c18:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001c1c:	e9cd 7504 	strd	r7, r5, [sp, #16]
70001c20:	e9cd 5501 	strd	r5, r5, [sp, #4]
70001c24:	9400      	str	r4, [sp, #0]
70001c26:	f000 f90b 	bl	70001e40 <z_setup_new_thread>
70001c2a:	7b73      	ldrb	r3, [r6, #13]
	_kernel.cpus[id].irq_stack =
70001c2c:	4a09      	ldr	r2, [pc, #36]	; (70001c54 <z_cstart+0xdc>)
70001c2e:	f023 0304 	bic.w	r3, r3, #4
70001c32:	6062      	str	r2, [r4, #4]
	_kernel.cpus[id].idle_thread = &z_idle_threads[id];
70001c34:	60e6      	str	r6, [r4, #12]
70001c36:	7373      	strb	r3, [r6, #13]
	_kernel.cpus[id].id = id;
70001c38:	7425      	strb	r5, [r4, #16]
	__asm__ volatile(
70001c3a:	f3ef 8100 	mrs	r1, CPSR
70001c3e:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001c42:	b672      	cpsid	i
	struct k_thread *ret = _kernel.cpus[0].current;
70001c44:	68a3      	ldr	r3, [r4, #8]

static ALWAYS_INLINE int arch_swap(unsigned int key)
{
	/* store off key and return value */
	arch_current_thread()->arch.basepri = key;
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
70001c46:	f06f 020a 	mvn.w	r2, #10
70001c4a:	e9c3 121b 	strd	r1, r2, [r3, #108]	; 0x6c

	z_arm_cortex_r_svc();
70001c4e:	f7ff e98a 	blx	70000f64 <z_arm_cortex_r_svc>
70001c52:	b662      	cpsie	i
	CODE_UNREACHABLE; /* LCOV_EXCL_LINE */
70001c54:	7000a7c0 	.word	0x7000a7c0

70001c58 <z_init_static>:
	__do_global_ctors_aux();
	__do_init_array_aux();
#elif defined(__CCAC__) /* ARC MWDT */
	__do_global_ctors_aux();
#endif
}
70001c58:	4770      	bx	lr
70001c5a:	bf00      	nop

70001c5c <init_mem_slab_obj_core_list>:
#endif /* CONFIG_OBJ_CORE_STATS_MEM_SLAB */
#endif /* CONFIG_OBJ_CORE_MEM_SLAB */

	/* Initialize statically defined mem_slabs */

	STRUCT_SECTION_FOREACH(k_mem_slab, slab) {
70001c5c:	f24b 119c 	movw	r1, #45468	; 0xb19c
70001c60:	f24b 1c9c 	movw	ip, #45468	; 0xb19c
70001c64:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001c68:	f2c7 0c00 	movt	ip, #28672	; 0x7000
70001c6c:	4561      	cmp	r1, ip
70001c6e:	d221      	bcs.n	70001cb4 <init_mem_slab_obj_core_list+0x58>
{
70001c70:	b410      	push	{r4}
	CHECKIF(((slab->info.block_size | (uintptr_t)slab->buffer) &
70001c72:	694c      	ldr	r4, [r1, #20]
70001c74:	688b      	ldr	r3, [r1, #8]
70001c76:	ea43 0004 	orr.w	r0, r3, r4
70001c7a:	f010 0003 	ands.w	r0, r0, #3
70001c7e:	d116      	bne.n	70001cae <init_mem_slab_obj_core_list+0x52>
	p = slab->buffer + slab->info.block_size * (slab->info.num_blocks - 1);
70001c80:	690a      	ldr	r2, [r1, #16]
	slab->free_list = NULL;
70001c82:	60c8      	str	r0, [r1, #12]
	p = slab->buffer + slab->info.block_size * (slab->info.num_blocks - 1);
70001c84:	3a01      	subs	r2, #1
70001c86:	fb04 3202 	mla	r2, r4, r2, r3
	while (p >= slab->buffer) {
70001c8a:	4293      	cmp	r3, r2
70001c8c:	d901      	bls.n	70001c92 <init_mem_slab_obj_core_list+0x36>
70001c8e:	e008      	b.n	70001ca2 <init_mem_slab_obj_core_list+0x46>
		p -= slab->info.block_size;
70001c90:	461a      	mov	r2, r3
		*(char **)p = slab->free_list;
70001c92:	6010      	str	r0, [r2, #0]
		p -= slab->info.block_size;
70001c94:	4610      	mov	r0, r2
70001c96:	694b      	ldr	r3, [r1, #20]
	while (p >= slab->buffer) {
70001c98:	688c      	ldr	r4, [r1, #8]
		p -= slab->info.block_size;
70001c9a:	1ad3      	subs	r3, r2, r3
	while (p >= slab->buffer) {
70001c9c:	42a3      	cmp	r3, r4
70001c9e:	d2f7      	bcs.n	70001c90 <init_mem_slab_obj_core_list+0x34>
70001ca0:	60ca      	str	r2, [r1, #12]
	STRUCT_SECTION_FOREACH(k_mem_slab, slab) {
70001ca2:	311c      	adds	r1, #28
70001ca4:	4561      	cmp	r1, ip
70001ca6:	d3e4      	bcc.n	70001c72 <init_mem_slab_obj_core_list+0x16>
70001ca8:	2000      	movs	r0, #0
#endif /* CONFIG_OBJ_CORE_MEM_SLAB */
	}

out:
	return rc;
}
70001caa:	bc10      	pop	{r4}
70001cac:	4770      	bx	lr
70001cae:	f06f 0015 	mvn.w	r0, #21
	return rc;
70001cb2:	e7fa      	b.n	70001caa <init_mem_slab_obj_core_list+0x4e>
70001cb4:	2000      	movs	r0, #0
}
70001cb6:	4770      	bx	lr

70001cb8 <idle>:
#include <wait_q.h>

LOG_MODULE_DECLARE(os, CONFIG_KERNEL_LOG_LEVEL);

void idle(void *unused1, void *unused2, void *unused3)
{
70001cb8:	b508      	push	{r3, lr}
70001cba:	f3ef 8300 	mrs	r3, CPSR
70001cbe:	f003 0380 	and.w	r3, r3, #128	; 0x80
70001cc2:	b672      	cpsid	i
 * @note In some architectures, before returning, the function unmasks interrupts
 * unconditionally.
 */
static inline void k_cpu_idle(void)
{
	arch_cpu_idle();
70001cc4:	f7ff e830 	blx	70000d28 <arch_cpu_idle>
70001cc8:	e7f7      	b.n	70001cba <idle+0x2>
70001cca:	bf00      	nop

70001ccc <z_impl_k_msgq_put>:
	return 0;
}


int z_impl_k_msgq_put(struct k_msgq *msgq, const void *data, k_timeout_t timeout)
{
70001ccc:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
70001cd0:	4604      	mov	r4, r0
70001cd2:	b082      	sub	sp, #8
70001cd4:	460d      	mov	r5, r1
70001cd6:	4616      	mov	r6, r2

	struct k_thread *pending_thread;
	k_spinlock_key_t key;
	int result;

	key = k_spin_lock(&msgq->lock);
70001cd8:	f100 0708 	add.w	r7, r0, #8
70001cdc:	f3ef 8800 	mrs	r8, CPSR
70001ce0:	f008 0880 	and.w	r8, r8, #128	; 0x80
70001ce4:	b672      	cpsid	i

	SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_msgq, put, msgq, timeout);

	if (msgq->used_msgs < msgq->max_msgs) {
70001ce6:	6a02      	ldr	r2, [r0, #32]
70001ce8:	68c0      	ldr	r0, [r0, #12]
70001cea:	4282      	cmp	r2, r0
70001cec:	d224      	bcs.n	70001d38 <z_impl_k_msgq_put+0x6c>
 * @return true if empty, false otherwise
 */

static inline bool sys_dlist_is_empty(sys_dlist_t *list)
{
	return list->head == list;
70001cee:	f8d4 9000 	ldr.w	r9, [r4]
	__ASSERT_EVAL(, int key = arch_irq_lock(); arch_irq_unlock(key),
		      !arch_irq_unlocked(key), "");

	LOCK_SCHED_SPINLOCK {
		thread = _priq_wait_best(&wait_q->waitq);
		if (unlikely(thread != NULL)) {
70001cf2:	f1b9 0f00 	cmp.w	r9, #0
70001cf6:	bf18      	it	ne
70001cf8:	454c      	cmpne	r4, r9
70001cfa:	d135      	bne.n	70001d68 <z_impl_k_msgq_put+0x9c>
			return 0;
		} else {
			/* put message in queue */
			__ASSERT_NO_MSG(msgq->write_ptr >= msgq->buffer_start &&
					msgq->write_ptr < msgq->buffer_end);
			(void)memcpy(msgq->write_ptr, (char *)data, msgq->msg_size);
70001cfc:	68a2      	ldr	r2, [r4, #8]
			msgq->used_msgs++;
#ifdef CONFIG_POLL
			handle_poll_events(msgq, K_POLL_STATE_MSGQ_DATA_AVAILABLE);
#endif /* CONFIG_POLL */
		}
		result = 0;
70001cfe:	2600      	movs	r6, #0
			(void)memcpy(msgq->write_ptr, (char *)data, msgq->msg_size);
70001d00:	69e0      	ldr	r0, [r4, #28]
70001d02:	f001 f84b 	bl	70002d9c <memcpy>
			msgq->write_ptr += msgq->msg_size;
70001d06:	69e3      	ldr	r3, [r4, #28]
70001d08:	68a2      	ldr	r2, [r4, #8]
	z_handle_obj_poll_events(&msgq->poll_events, state);
70001d0a:	2110      	movs	r1, #16
70001d0c:	f104 0024 	add.w	r0, r4, #36	; 0x24
			msgq->write_ptr += msgq->msg_size;
70001d10:	4413      	add	r3, r2
			if (msgq->write_ptr == msgq->buffer_end) {
70001d12:	6962      	ldr	r2, [r4, #20]
			msgq->write_ptr += msgq->msg_size;
70001d14:	61e3      	str	r3, [r4, #28]
			if (msgq->write_ptr == msgq->buffer_end) {
70001d16:	4293      	cmp	r3, r2
				msgq->write_ptr = msgq->buffer_start;
70001d18:	bf04      	itt	eq
70001d1a:	6923      	ldreq	r3, [r4, #16]
70001d1c:	61e3      	streq	r3, [r4, #28]
			msgq->used_msgs++;
70001d1e:	6a23      	ldr	r3, [r4, #32]
70001d20:	3301      	adds	r3, #1
70001d22:	6223      	str	r3, [r4, #32]
	z_handle_obj_poll_events(&msgq->poll_events, state);
70001d24:	f000 fe92 	bl	70002a4c <z_handle_obj_poll_events>
		return result;
	}

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_msgq, put, msgq, timeout, result);

	z_reschedule(&msgq->lock, key);
70001d28:	4641      	mov	r1, r8
70001d2a:	4638      	mov	r0, r7
70001d2c:	f000 fb1a 	bl	70002364 <z_reschedule>

	return result;
}
70001d30:	4630      	mov	r0, r6
70001d32:	b002      	add	sp, #8
70001d34:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
70001d38:	ea56 0203 	orrs.w	r2, r6, r3
		result = -ENOMSG;
70001d3c:	bf08      	it	eq
70001d3e:	f06f 0622 	mvneq.w	r6, #34	; 0x22
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
70001d42:	d0f1      	beq.n	70001d28 <z_impl_k_msgq_put+0x5c>
		result = z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
70001d44:	4622      	mov	r2, r4
70001d46:	f646 4498 	movw	r4, #27800	; 0x6c98
70001d4a:	4641      	mov	r1, r8
70001d4c:	f2c7 0400 	movt	r4, #28672	; 0x7000
70001d50:	4638      	mov	r0, r7
		arch_current_thread()->base.swap_data = (void *) data;
70001d52:	68a4      	ldr	r4, [r4, #8]
70001d54:	6165      	str	r5, [r4, #20]
		result = z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
70001d56:	e9cd 6300 	strd	r6, r3, [sp]
70001d5a:	f000 facf 	bl	700022fc <z_pend_curr>
70001d5e:	4606      	mov	r6, r0
}
70001d60:	4630      	mov	r0, r6
70001d62:	b002      	add	sp, #8
70001d64:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
 */

static inline void sys_dlist_remove(sys_dnode_t *node)
{
	sys_dnode_t *const prev = node->prev;
	sys_dnode_t *const next = node->next;
70001d68:	e9d9 3200 	ldrd	r3, r2, [r9]
	thread->base.pended_on = NULL;
70001d6c:	f04f 0a00 	mov.w	sl, #0

	prev->next = next;
70001d70:	6013      	str	r3, [r2, #0]
}

static inline int z_abort_thread_timeout(struct k_thread *thread)
{
	return z_abort_timeout(&thread->base.timeout);
70001d72:	f109 0018 	add.w	r0, r9, #24
	next->prev = prev;
70001d76:	605a      	str	r2, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
70001d78:	f899 300d 	ldrb.w	r3, [r9, #13]
	node->next = NULL;
70001d7c:	2200      	movs	r2, #0
70001d7e:	f023 0302 	bic.w	r3, r3, #2
70001d82:	f8c9 a008 	str.w	sl, [r9, #8]
			return 0;
70001d86:	4656      	mov	r6, sl
70001d88:	f889 300d 	strb.w	r3, [r9, #13]
70001d8c:	2300      	movs	r3, #0
70001d8e:	e9c9 2300 	strd	r2, r3, [r9]
70001d92:	f000 fd31 	bl	700027f8 <z_abort_timeout>
			(void)memcpy(pending_thread->base.swap_data, data,
70001d96:	68a2      	ldr	r2, [r4, #8]
70001d98:	f8d9 0014 	ldr.w	r0, [r9, #20]
70001d9c:	4629      	mov	r1, r5
70001d9e:	f000 fffd 	bl	70002d9c <memcpy>
}

static ALWAYS_INLINE void
arch_thread_return_value_set(struct k_thread *thread, unsigned int value)
{
	thread->arch.swap_return_value = value;
70001da2:	f8c9 a070 	str.w	sl, [r9, #112]	; 0x70
			z_ready_thread(pending_thread);
70001da6:	4648      	mov	r0, r9
70001da8:	f000 fa18 	bl	700021dc <z_ready_thread>
			z_reschedule(&msgq->lock, key);
70001dac:	4641      	mov	r1, r8
70001dae:	4638      	mov	r0, r7
70001db0:	f000 fad8 	bl	70002364 <z_reschedule>
			return 0;
70001db4:	e7bc      	b.n	70001d30 <z_impl_k_msgq_put+0x64>
70001db6:	bf00      	nop

70001db8 <z_impl_k_sem_give>:
	return false;
#endif /* CONFIG_POLL */
}

void z_impl_k_sem_give(struct k_sem *sem)
{
70001db8:	b570      	push	{r4, r5, r6, lr}
70001dba:	f3ef 8500 	mrs	r5, CPSR
70001dbe:	f005 0580 	and.w	r5, r5, #128	; 0x80
70001dc2:	b672      	cpsid	i
	return list->head == list;
70001dc4:	6804      	ldr	r4, [r0, #0]
		if (unlikely(thread != NULL)) {
70001dc6:	2c00      	cmp	r4, #0
70001dc8:	bf18      	it	ne
70001dca:	42a0      	cmpne	r0, r4
70001dcc:	d113      	bne.n	70001df6 <z_impl_k_sem_give+0x3e>

	if (unlikely(thread != NULL)) {
		arch_thread_return_value_set(thread, 0);
		z_ready_thread(thread);
	} else {
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
70001dce:	e9d0 3202 	ldrd	r3, r2, [r0, #8]
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
70001dd2:	2102      	movs	r1, #2
70001dd4:	3010      	adds	r0, #16
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
70001dd6:	429a      	cmp	r2, r3
70001dd8:	bf18      	it	ne
70001dda:	3301      	addne	r3, #1
70001ddc:	f840 3c08 	str.w	r3, [r0, #-8]
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
70001de0:	f000 fe34 	bl	70002a4c <z_handle_obj_poll_events>
		resched = handle_poll_events(sem);
	}

	if (unlikely(resched)) {
		z_reschedule(&lock, key);
70001de4:	f646 40b8 	movw	r0, #27832	; 0x6cb8
70001de8:	4629      	mov	r1, r5
70001dea:	f2c7 0000 	movt	r0, #28672	; 0x7000
	} else {
		k_spin_unlock(&lock, key);
	}

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_sem, give, sem);
}
70001dee:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		z_reschedule(&lock, key);
70001df2:	f000 bab7 	b.w	70002364 <z_reschedule>
	sys_dnode_t *const next = node->next;
70001df6:	e9d4 3200 	ldrd	r3, r2, [r4]
	thread->base.pended_on = NULL;
70001dfa:	2600      	movs	r6, #0
	prev->next = next;
70001dfc:	6013      	str	r3, [r2, #0]
	node->next = NULL;
70001dfe:	2100      	movs	r1, #0
	next->prev = prev;
70001e00:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70001e02:	2000      	movs	r0, #0
70001e04:	7b63      	ldrb	r3, [r4, #13]
70001e06:	60a6      	str	r6, [r4, #8]
70001e08:	e9c4 0100 	strd	r0, r1, [r4]
70001e0c:	f023 0302 	bic.w	r3, r3, #2
70001e10:	f104 0018 	add.w	r0, r4, #24
70001e14:	7363      	strb	r3, [r4, #13]
70001e16:	f000 fcef 	bl	700027f8 <z_abort_timeout>
70001e1a:	6726      	str	r6, [r4, #112]	; 0x70
		z_ready_thread(thread);
70001e1c:	4620      	mov	r0, r4
70001e1e:	f000 f9dd 	bl	700021dc <z_ready_thread>
70001e22:	e7df      	b.n	70001de4 <z_impl_k_sem_give+0x2c>

70001e24 <k_is_in_isr>:
70001e24:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
#include <zephyr/arch/arm/cortex_a_r/lib_helpers.h>
#include <zephyr/arch/arm/cortex_a_r/tpidruro.h>

static ALWAYS_INLINE _cpu_t *arch_curr_cpu(void)
{
	return (_cpu_t *)(read_tpidruro() & TPIDRURO_CURR_CPU);
70001e28:	f023 0303 	bic.w	r3, r3, #3
#endif

/* Check the CPSR mode bits to see if we are in IRQ or FIQ mode */
static ALWAYS_INLINE bool arch_is_in_isr(void)
{
	return (arch_curr_cpu()->nested != 0U);
70001e2c:	6818      	ldr	r0, [r3, #0]
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data)

bool k_is_in_isr(void)
{
	return arch_is_in_isr();
}
70001e2e:	3800      	subs	r0, #0
70001e30:	bf18      	it	ne
70001e32:	2001      	movne	r0, #1
70001e34:	4770      	bx	lr
70001e36:	bf00      	nop

70001e38 <z_impl_k_thread_name_set>:

	SYS_PORT_TRACING_OBJ_FUNC(k_thread, name_set, thread, -ENOSYS);

	return -ENOSYS;
#endif /* CONFIG_THREAD_NAME */
}
70001e38:	f06f 0057 	mvn.w	r0, #87	; 0x57
70001e3c:	4770      	bx	lr
70001e3e:	bf00      	nop

70001e40 <z_setup_new_thread>:
		stack_buf_size = stack_obj_size - K_THREAD_STACK_RESERVED;
	} else
#endif /* CONFIG_USERSPACE */
	{
		/* Object cannot host a user mode thread */
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
70001e40:	3207      	adds	r2, #7
70001e42:	f022 0207 	bic.w	r2, r2, #7
char *z_setup_new_thread(struct k_thread *new_thread,
			 k_thread_stack_t *stack, size_t stack_size,
			 k_thread_entry_t entry,
			 void *p1, void *p2, void *p3,
			 int prio, uint32_t options, const char *name)
{
70001e46:	e92d 4370 	stmdb	sp!, {r4, r5, r6, r8, r9, lr}
	stack_ptr = (char *)stack + stack_obj_size;
70001e4a:	188d      	adds	r5, r1, r2
	SYS_DLIST_FOR_EACH_CONTAINER(&((wq)->waitq), thread_ptr, \
				     base.qnode_dlist)

static inline void z_waitq_init(_wait_q_t *w)
{
	sys_dlist_init(&w->waitq);
70001e4c:	f100 0258 	add.w	r2, r0, #88	; 0x58

void z_init_thread_base(struct _thread_base *thread_base, int priority,
		       uint32_t initial_state, unsigned int options)
{
	/* k_q_node is initialized upon first insertion in a list */
	thread_base->pended_on = NULL;
70001e50:	2600      	movs	r6, #0
{
70001e52:	b084      	sub	sp, #16
	list->head = (sys_dnode_t *)list;
70001e54:	e9c0 2216 	strd	r2, r2, [r0, #88]	; 0x58
	thread_base->user_options = (uint8_t)options;
	thread_base->thread_state = (uint8_t)initial_state;
70001e58:	2204      	movs	r2, #4
	thread_base->pended_on = NULL;
70001e5a:	6086      	str	r6, [r0, #8]
	node->next = NULL;
70001e5c:	f04f 0800 	mov.w	r8, #0
	thread_base->thread_state = (uint8_t)initial_state;
70001e60:	7342      	strb	r2, [r0, #13]
70001e62:	f04f 0900 	mov.w	r9, #0
{
70001e66:	9a0a      	ldr	r2, [sp, #40]	; 0x28
70001e68:	4604      	mov	r4, r0

	thread_base->prio = priority;

	thread_base->sched_locked = 0U;
70001e6a:	73c6      	strb	r6, [r0, #15]
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001e6c:	9200      	str	r2, [sp, #0]
{
70001e6e:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001e70:	9201      	str	r2, [sp, #4]
{
70001e72:	9a0c      	ldr	r2, [sp, #48]	; 0x30
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001e74:	9202      	str	r2, [sp, #8]
{
70001e76:	9a0d      	ldr	r2, [sp, #52]	; 0x34
	thread_base->prio = priority;
70001e78:	7382      	strb	r2, [r0, #14]
{
70001e7a:	9a0e      	ldr	r2, [sp, #56]	; 0x38
	thread_base->user_options = (uint8_t)options;
70001e7c:	7302      	strb	r2, [r0, #12]
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001e7e:	462a      	mov	r2, r5
70001e80:	e9c0 8906 	strd	r8, r9, [r0, #24]
70001e84:	f7fe ff32 	bl	70000cec <arch_new_thread>
70001e88:	f646 4398 	movw	r3, #27800	; 0x6c98
	new_thread->init_data = NULL;
70001e8c:	6566      	str	r6, [r4, #84]	; 0x54
70001e8e:	f2c7 0300 	movt	r3, #28672	; 0x7000
}
70001e92:	4628      	mov	r0, r5
	new_thread->resource_pool = arch_current_thread()->resource_pool;
70001e94:	689b      	ldr	r3, [r3, #8]
70001e96:	6e9b      	ldr	r3, [r3, #104]	; 0x68
70001e98:	66a3      	str	r3, [r4, #104]	; 0x68
}
70001e9a:	b004      	add	sp, #16
70001e9c:	e8bd 8370 	ldmia.w	sp!, {r4, r5, r6, r8, r9, pc}

70001ea0 <z_impl_k_thread_create>:
{
70001ea0:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
70001ea4:	f100 0658 	add.w	r6, r0, #88	; 0x58
	thread_base->pended_on = NULL;
70001ea8:	2500      	movs	r5, #0
{
70001eaa:	b085      	sub	sp, #20
	list->head = (sys_dnode_t *)list;
70001eac:	e9c0 6616 	strd	r6, r6, [r0, #88]	; 0x58
	thread_base->thread_state = (uint8_t)initial_state;
70001eb0:	2604      	movs	r6, #4
	thread_base->pended_on = NULL;
70001eb2:	6085      	str	r5, [r0, #8]
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
70001eb4:	3207      	adds	r2, #7
	thread_base->thread_state = (uint8_t)initial_state;
70001eb6:	7346      	strb	r6, [r0, #13]
	node->next = NULL;
70001eb8:	f04f 0800 	mov.w	r8, #0
{
70001ebc:	9e0c      	ldr	r6, [sp, #48]	; 0x30
70001ebe:	f04f 0900 	mov.w	r9, #0
	thread_base->sched_locked = 0U;
70001ec2:	73c5      	strb	r5, [r0, #15]
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
70001ec4:	f022 0207 	bic.w	r2, r2, #7
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001ec8:	9600      	str	r6, [sp, #0]
70001eca:	440a      	add	r2, r1
{
70001ecc:	9e0d      	ldr	r6, [sp, #52]	; 0x34
70001ece:	4604      	mov	r4, r0
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001ed0:	9601      	str	r6, [sp, #4]
{
70001ed2:	9e0e      	ldr	r6, [sp, #56]	; 0x38
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001ed4:	9602      	str	r6, [sp, #8]
{
70001ed6:	9e0f      	ldr	r6, [sp, #60]	; 0x3c
	thread_base->prio = priority;
70001ed8:	7386      	strb	r6, [r0, #14]
{
70001eda:	9e10      	ldr	r6, [sp, #64]	; 0x40
	thread_base->user_options = (uint8_t)options;
70001edc:	7306      	strb	r6, [r0, #12]
70001ede:	e9c0 8906 	strd	r8, r9, [r0, #24]
{
70001ee2:	e9dd 7612 	ldrd	r7, r6, [sp, #72]	; 0x48
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70001ee6:	f7fe ff01 	bl	70000cec <arch_new_thread>
	new_thread->init_data = NULL;
70001eea:	6565      	str	r5, [r4, #84]	; 0x54
70001eec:	f646 4398 	movw	r3, #27800	; 0x6c98
70001ef0:	f2c7 0300 	movt	r3, #28672	; 0x7000
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
70001ef4:	f1b6 3fff 	cmp.w	r6, #4294967295	; 0xffffffff
70001ef8:	bf08      	it	eq
70001efa:	f1b7 3fff 	cmpeq.w	r7, #4294967295	; 0xffffffff
	new_thread->resource_pool = arch_current_thread()->resource_pool;
70001efe:	689b      	ldr	r3, [r3, #8]
70001f00:	6e9b      	ldr	r3, [r3, #104]	; 0x68
70001f02:	66a3      	str	r3, [r4, #104]	; 0x68
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
70001f04:	d103      	bne.n	70001f0e <z_impl_k_thread_create+0x6e>
}
70001f06:	4620      	mov	r0, r4
70001f08:	b005      	add	sp, #20
70001f0a:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
70001f0e:	ea56 0307 	orrs.w	r3, r6, r7
70001f12:	d106      	bne.n	70001f22 <z_impl_k_thread_create+0x82>
70001f14:	4620      	mov	r0, r4
70001f16:	f000 fb53 	bl	700025c0 <z_impl_k_wakeup>
70001f1a:	4620      	mov	r0, r4
70001f1c:	b005      	add	sp, #20
70001f1e:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
70001f22:	f242 21f5 	movw	r1, #8949	; 0x22f5
70001f26:	f104 0018 	add.w	r0, r4, #24
70001f2a:	463a      	mov	r2, r7
70001f2c:	4633      	mov	r3, r6
70001f2e:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001f32:	f000 fbcf 	bl	700026d4 <z_add_timeout>
70001f36:	4620      	mov	r0, r4
70001f38:	b005      	add	sp, #20
70001f3a:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
70001f3e:	bf00      	nop

70001f40 <unready_thread>:
}
#include <zephyr/syscalls/k_thread_resume_mrsh.c>
#endif /* CONFIG_USERSPACE */

static void unready_thread(struct k_thread *thread)
{
70001f40:	b410      	push	{r4}
	return (thread->base.thread_state & state) != 0U;
70001f42:	7b43      	ldrb	r3, [r0, #13]
	if (z_is_thread_queued(thread)) {
70001f44:	061c      	lsls	r4, r3, #24
70001f46:	d509      	bpl.n	70001f5c <unready_thread+0x1c>
70001f48:	2200      	movs	r2, #0
	thread->base.thread_state &= ~_THREAD_QUEUED;
70001f4a:	f003 037f 	and.w	r3, r3, #127	; 0x7f
	sys_dnode_t *const next = node->next;
70001f4e:	e9d0 1400 	ldrd	r1, r4, [r0]
70001f52:	7343      	strb	r3, [r0, #13]
	prev->next = next;
70001f54:	6021      	str	r1, [r4, #0]
	next->prev = prev;
70001f56:	604c      	str	r4, [r1, #4]
	node->next = NULL;
70001f58:	6002      	str	r2, [r0, #0]
70001f5a:	6042      	str	r2, [r0, #4]
70001f5c:	f646 4398 	movw	r3, #27800	; 0x6c98
70001f60:	f2c7 0300 	movt	r3, #28672	; 0x7000
	return list->head == list;
70001f64:	4619      	mov	r1, r3
70001f66:	689c      	ldr	r4, [r3, #8]
70001f68:	f851 2f18 	ldr.w	r2, [r1, #24]!
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70001f6c:	428a      	cmp	r2, r1
70001f6e:	bf18      	it	ne
70001f70:	2a00      	cmpne	r2, #0
70001f72:	bf08      	it	eq
70001f74:	68da      	ldreq	r2, [r3, #12]
					 int preempt_ok)
{
	/* Preemption is OK if it's being explicitly allowed by
	 * software state (e.g. the thread called k_yield())
	 */
	if (preempt_ok != 0) {
70001f76:	42a0      	cmp	r0, r4
70001f78:	d006      	beq.n	70001f88 <unready_thread+0x48>
	}

	__ASSERT(arch_current_thread() != NULL, "");

	/* Or if we're pended/suspended/dummy (duh) */
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
70001f7a:	7b61      	ldrb	r1, [r4, #13]
70001f7c:	06c9      	lsls	r1, r1, #27
70001f7e:	d103      	bne.n	70001f88 <unready_thread+0x48>
	}

	/* Otherwise we have to be running a preemptible thread or
	 * switching to a metairq
	 */
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
70001f80:	89e1      	ldrh	r1, [r4, #14]
		_kernel.ready_q.cache = arch_current_thread();
70001f82:	297f      	cmp	r1, #127	; 0x7f
70001f84:	bf88      	it	hi
70001f86:	4622      	movhi	r2, r4
70001f88:	615a      	str	r2, [r3, #20]
		dequeue_thread(thread);
	}
	update_cache(thread == arch_current_thread());
}
70001f8a:	bc10      	pop	{r4}
70001f8c:	4770      	bx	lr
70001f8e:	bf00      	nop

70001f90 <add_to_waitq_locked>:

/* _sched_spinlock must be held */
static void add_to_waitq_locked(struct k_thread *thread, _wait_q_t *wait_q)
{
70001f90:	b538      	push	{r3, r4, r5, lr}
70001f92:	460d      	mov	r5, r1
	unready_thread(thread);
70001f94:	f7ff ffd4 	bl	70001f40 <unready_thread>
	thread->base.thread_state |= _THREAD_PENDING;
70001f98:	7b43      	ldrb	r3, [r0, #13]
70001f9a:	f043 0302 	orr.w	r3, r3, #2
70001f9e:	7343      	strb	r3, [r0, #13]
	z_mark_thread_as_pending(thread);

	SYS_PORT_TRACING_FUNC(k_thread, sched_pend, thread);

	if (wait_q != NULL) {
70001fa0:	b1bd      	cbz	r5, 70001fd2 <add_to_waitq_locked+0x42>
		thread->base.pended_on = wait_q;
70001fa2:	6085      	str	r5, [r0, #8]
70001fa4:	4604      	mov	r4, r0
70001fa6:	682b      	ldr	r3, [r5, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70001fa8:	429d      	cmp	r5, r3
70001faa:	d00d      	beq.n	70001fc8 <add_to_waitq_locked+0x38>
static ALWAYS_INLINE void z_priq_dumb_add(sys_dlist_t *pq,
					  struct k_thread *thread)
{
	struct k_thread *t;

	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
70001fac:	b163      	cbz	r3, 70001fc8 <add_to_waitq_locked+0x38>
	int32_t b2 = thread_2->base.prio;
70001fae:	f993 c00e 	ldrsb.w	ip, [r3, #14]
	int32_t b1 = thread_1->base.prio;
70001fb2:	f994 200e 	ldrsb.w	r2, [r4, #14]
	if (b1 != b2) {
70001fb6:	4562      	cmp	r2, ip
70001fb8:	d001      	beq.n	70001fbe <add_to_waitq_locked+0x2e>
		if (z_sched_prio_cmp(thread, t) > 0) {
70001fba:	4594      	cmp	ip, r2
70001fbc:	dc0a      	bgt.n	70001fd4 <add_to_waitq_locked+0x44>
	return (node == list->tail) ? NULL : node->next;
70001fbe:	686a      	ldr	r2, [r5, #4]
70001fc0:	4293      	cmp	r3, r2
70001fc2:	d002      	beq.n	70001fca <add_to_waitq_locked+0x3a>
70001fc4:	681b      	ldr	r3, [r3, #0]
70001fc6:	e7f1      	b.n	70001fac <add_to_waitq_locked+0x1c>
70001fc8:	686a      	ldr	r2, [r5, #4]
	node->prev = tail;
70001fca:	e9c4 5200 	strd	r5, r2, [r4]
	tail->next = node;
70001fce:	6014      	str	r4, [r2, #0]
	list->tail = node;
70001fd0:	606c      	str	r4, [r5, #4]
		_priq_wait_add(&wait_q->waitq, thread);
	}
}
70001fd2:	bd38      	pop	{r3, r4, r5, pc}
	sys_dnode_t *const prev = successor->prev;
70001fd4:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
70001fd6:	e9c4 3200 	strd	r3, r2, [r4]
	prev->next = node;
70001fda:	6014      	str	r4, [r2, #0]
	successor->prev = node;
70001fdc:	605c      	str	r4, [r3, #4]
70001fde:	bd38      	pop	{r3, r4, r5, pc}

70001fe0 <ready_thread>:
	return (thread->base.thread_state & state) != 0U;
70001fe0:	7b43      	ldrb	r3, [r0, #13]
	if (!z_is_thread_queued(thread) && z_is_thread_ready(thread)) {
70001fe2:	0619      	lsls	r1, r3, #24
70001fe4:	d403      	bmi.n	70001fee <ready_thread+0xe>
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
70001fe6:	06da      	lsls	r2, r3, #27
70001fe8:	d101      	bne.n	70001fee <ready_thread+0xe>
	return node->next != NULL;
70001fea:	6982      	ldr	r2, [r0, #24]
70001fec:	b102      	cbz	r2, 70001ff0 <ready_thread+0x10>
70001fee:	4770      	bx	lr
	return list->head == list;
70001ff0:	f646 4c98 	movw	ip, #27800	; 0x6c98
	thread->base.thread_state |= _THREAD_QUEUED;
70001ff4:	f063 037f 	orn	r3, r3, #127	; 0x7f
70001ff8:	f2c7 0c00 	movt	ip, #28672	; 0x7000
{
70001ffc:	b430      	push	{r4, r5}
	thread->base.thread_state |= _THREAD_QUEUED;
70001ffe:	7343      	strb	r3, [r0, #13]
70002000:	4665      	mov	r5, ip
	return (node == list->tail) ? NULL : node->next;
70002002:	f8dc 401c 	ldr.w	r4, [ip, #28]
	return list->head == list;
70002006:	f855 3f18 	ldr.w	r3, [r5, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
7000200a:	42ab      	cmp	r3, r5
7000200c:	bf08      	it	eq
7000200e:	2300      	moveq	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
70002010:	b15b      	cbz	r3, 7000202a <ready_thread+0x4a>
	int32_t b2 = thread_2->base.prio;
70002012:	f993 100e 	ldrsb.w	r1, [r3, #14]
	int32_t b1 = thread_1->base.prio;
70002016:	f990 200e 	ldrsb.w	r2, [r0, #14]
	if (b1 != b2) {
7000201a:	428a      	cmp	r2, r1
7000201c:	d001      	beq.n	70002022 <ready_thread+0x42>
		if (z_sched_prio_cmp(thread, t) > 0) {
7000201e:	4291      	cmp	r1, r2
70002020:	dc20      	bgt.n	70002064 <ready_thread+0x84>
	return (node == list->tail) ? NULL : node->next;
70002022:	42a3      	cmp	r3, r4
70002024:	d001      	beq.n	7000202a <ready_thread+0x4a>
70002026:	681b      	ldr	r3, [r3, #0]
70002028:	e7f2      	b.n	70002010 <ready_thread+0x30>
	node->prev = tail;
7000202a:	e9c0 5400 	strd	r5, r4, [r0]
	tail->next = node;
7000202e:	6020      	str	r0, [r4, #0]
	list->tail = node;
70002030:	f8cc 001c 	str.w	r0, [ip, #28]
	return list->head == list;
70002034:	f8dc 3018 	ldr.w	r3, [ip, #24]
70002038:	f8dc 2008 	ldr.w	r2, [ip, #8]
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
7000203c:	7b51      	ldrb	r1, [r2, #13]
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
7000203e:	2b00      	cmp	r3, #0
70002040:	bf18      	it	ne
70002042:	42ab      	cmpne	r3, r5
70002044:	bf08      	it	eq
70002046:	f8dc 300c 	ldreq.w	r3, [ip, #12]
7000204a:	06c9      	lsls	r1, r1, #27
7000204c:	d107      	bne.n	7000205e <ready_thread+0x7e>
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
7000204e:	89d1      	ldrh	r1, [r2, #14]
70002050:	297f      	cmp	r1, #127	; 0x7f
		_kernel.ready_q.cache = arch_current_thread();
70002052:	bf88      	it	hi
70002054:	f8cc 2014 	strhi.w	r2, [ip, #20]
70002058:	d901      	bls.n	7000205e <ready_thread+0x7e>
}
7000205a:	bc30      	pop	{r4, r5}
7000205c:	4770      	bx	lr
		_kernel.ready_q.cache = thread;
7000205e:	f8cc 3014 	str.w	r3, [ip, #20]
}
70002062:	e7fa      	b.n	7000205a <ready_thread+0x7a>
	sys_dnode_t *const prev = successor->prev;
70002064:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
70002066:	e9c0 3200 	strd	r3, r2, [r0]
	prev->next = node;
7000206a:	6010      	str	r0, [r2, #0]
	successor->prev = node;
7000206c:	6058      	str	r0, [r3, #4]
}
7000206e:	e7e1      	b.n	70002034 <ready_thread+0x54>

70002070 <z_thread_halt>:
		halt_thread(thread, terminate ? _THREAD_DEAD : _THREAD_SUSPENDED);
70002070:	2a00      	cmp	r2, #0
70002072:	bf0c      	ite	eq
70002074:	2210      	moveq	r2, #16
70002076:	2208      	movne	r2, #8
{
70002078:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	bool dummify = false;

	/* We hold the lock, and the thread is known not to be running
	 * anywhere.
	 */
	if ((thread->base.thread_state & new_state) == 0U) {
7000207c:	7b43      	ldrb	r3, [r0, #13]
{
7000207e:	460f      	mov	r7, r1
	if ((thread->base.thread_state & new_state) == 0U) {
70002080:	ea12 0103 	ands.w	r1, r2, r3
70002084:	bf18      	it	ne
70002086:	f646 4398 	movwne	r3, #27800	; 0x6c98
{
7000208a:	4605      	mov	r5, r0
7000208c:	bf18      	it	ne
7000208e:	f2c7 0300 	movtne	r3, #28672	; 0x7000
	if ((thread->base.thread_state & new_state) == 0U) {
70002092:	d122      	bne.n	700020da <z_thread_halt+0x6a>
		thread->base.thread_state |= new_state;
70002094:	ea42 0003 	orr.w	r0, r2, r3
		if (z_is_thread_queued(thread)) {
70002098:	09db      	lsrs	r3, r3, #7
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000209a:	bf17      	itett	ne
7000209c:	f000 007f 	andne.w	r0, r0, #127	; 0x7f
		thread->base.thread_state |= new_state;
700020a0:	7368      	strbeq	r0, [r5, #13]
	thread->base.thread_state &= ~_THREAD_QUEUED;
700020a2:	7368      	strbne	r0, [r5, #13]
	sys_dnode_t *const next = node->next;
700020a4:	e9d5 3000 	ldrdne	r3, r0, [r5]
	prev->next = next;
700020a8:	bf1e      	ittt	ne
700020aa:	6003      	strne	r3, [r0, #0]
	next->prev = prev;
700020ac:	6058      	strne	r0, [r3, #4]
	node->prev = NULL;
700020ae:	e9c5 1100 	strdne	r1, r1, [r5]
			dequeue_thread(thread);
		}

		if (new_state == _THREAD_DEAD) {
700020b2:	2a08      	cmp	r2, #8
700020b4:	d029      	beq.n	7000210a <z_thread_halt+0x9a>
	return list->head == list;
700020b6:	f646 4398 	movw	r3, #27800	; 0x6c98
700020ba:	f2c7 0300 	movt	r3, #28672	; 0x7000
700020be:	461a      	mov	r2, r3
700020c0:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
700020c4:	4291      	cmp	r1, r2
700020c6:	d05f      	beq.n	70002188 <z_thread_halt+0x118>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700020c8:	2900      	cmp	r1, #0
700020ca:	d069      	beq.n	700021a0 <z_thread_halt+0x130>
		_kernel.ready_q.cache = thread;
700020cc:	6159      	str	r1, [r3, #20]
  __ASM volatile ("dmb 0xF":::"memory");
700020ce:	f3bf 8f5f 	dmb	sy
	thread->base.thread_state &= ~(_THREAD_ABORTING | _THREAD_SUSPENDING);
700020d2:	7b6a      	ldrb	r2, [r5, #13]
700020d4:	f022 0260 	bic.w	r2, r2, #96	; 0x60
700020d8:	736a      	strb	r2, [r5, #13]
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
700020da:	689a      	ldr	r2, [r3, #8]
700020dc:	4295      	cmp	r5, r2
700020de:	d003      	beq.n	700020e8 <z_thread_halt+0x78>
	if (key != 0U) {
700020e0:	b907      	cbnz	r7, 700020e4 <z_thread_halt+0x74>
  __ASM volatile ("cpsie i" : : : "memory");
700020e2:	b662      	cpsie	i
}
700020e4:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
700020e8:	ee1d 2f70 	mrc	15, 0, r2, cr13, cr0, {3}
700020ec:	f022 0203 	bic.w	r2, r2, #3
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
700020f0:	6812      	ldr	r2, [r2, #0]
700020f2:	2a00      	cmp	r2, #0
700020f4:	d1f4      	bne.n	700020e0 <z_thread_halt+0x70>
700020f6:	689b      	ldr	r3, [r3, #8]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700020f8:	f06f 020a 	mvn.w	r2, #10
700020fc:	e9c3 721b 	strd	r7, r2, [r3, #108]	; 0x6c
	z_arm_cortex_r_svc();
70002100:	f7fe ef30 	blx	70000f64 <z_arm_cortex_r_svc>
70002104:	2f00      	cmp	r7, #0
70002106:	d0ec      	beq.n	700020e2 <z_thread_halt+0x72>
70002108:	e7ec      	b.n	700020e4 <z_thread_halt+0x74>
			if (thread->base.pended_on != NULL) {
7000210a:	68ab      	ldr	r3, [r5, #8]
7000210c:	b15b      	cbz	r3, 70002126 <z_thread_halt+0xb6>
	sys_dnode_t *const next = node->next;
7000210e:	e9d5 3100 	ldrd	r3, r1, [r5]
	node->next = NULL;
70002112:	2200      	movs	r2, #0
	prev->next = next;
70002114:	600b      	str	r3, [r1, #0]
	next->prev = prev;
70002116:	6059      	str	r1, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
70002118:	7b6b      	ldrb	r3, [r5, #13]
	node->prev = NULL;
7000211a:	e9c5 2200 	strd	r2, r2, [r5]
7000211e:	f023 0302 	bic.w	r3, r3, #2
70002122:	60aa      	str	r2, [r5, #8]
70002124:	736b      	strb	r3, [r5, #13]
	return z_abort_timeout(&thread->base.timeout);
70002126:	f105 0018 	add.w	r0, r5, #24
7000212a:	f000 fb65 	bl	700027f8 <z_abort_timeout>
	return list->head == list;
7000212e:	6dac      	ldr	r4, [r5, #88]	; 0x58
}

static inline struct k_thread *z_waitq_head(_wait_q_t *w)
{
	return (struct k_thread *)sys_dlist_peek_head(&w->waitq);
70002130:	f105 0858 	add.w	r8, r5, #88	; 0x58
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002134:	45a0      	cmp	r8, r4
70002136:	d019      	beq.n	7000216c <z_thread_halt+0xfc>
	for (thread = z_waitq_head(wait_q); thread != NULL; thread = z_waitq_head(wait_q)) {
70002138:	b1c4      	cbz	r4, 7000216c <z_thread_halt+0xfc>
	node->next = NULL;
7000213a:	2600      	movs	r6, #0
7000213c:	e000      	b.n	70002140 <z_thread_halt+0xd0>
7000213e:	b1ac      	cbz	r4, 7000216c <z_thread_halt+0xfc>
	sys_dnode_t *const next = node->next;
70002140:	e9d4 3200 	ldrd	r3, r2, [r4]
70002144:	f104 0018 	add.w	r0, r4, #24
	prev->next = next;
70002148:	6013      	str	r3, [r2, #0]
	next->prev = prev;
7000214a:	605a      	str	r2, [r3, #4]
7000214c:	7b63      	ldrb	r3, [r4, #13]
	node->prev = NULL;
7000214e:	e9c4 6600 	strd	r6, r6, [r4]
70002152:	f023 0302 	bic.w	r3, r3, #2
70002156:	60a6      	str	r6, [r4, #8]
70002158:	7363      	strb	r3, [r4, #13]
7000215a:	f000 fb4d 	bl	700027f8 <z_abort_timeout>
	thread->arch.swap_return_value = value;
7000215e:	6726      	str	r6, [r4, #112]	; 0x70
		ready_thread(thread);
70002160:	4620      	mov	r0, r4
70002162:	f7ff ff3d 	bl	70001fe0 <ready_thread>
	return list->head == list;
70002166:	6dac      	ldr	r4, [r5, #88]	; 0x58
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002168:	45a0      	cmp	r8, r4
7000216a:	d1e8      	bne.n	7000213e <z_thread_halt+0xce>
7000216c:	f646 4398 	movw	r3, #27800	; 0x6c98
70002170:	f2c7 0300 	movt	r3, #28672	; 0x7000
			 * ISR that preempted it requires clearing the
			 * arch_current_thread() pointer so the upcoming context
			 * switch doesn't clobber the now-freed
			 * memory
			 */
			if (thread == arch_current_thread() && arch_is_in_isr()) {
70002174:	689a      	ldr	r2, [r3, #8]
70002176:	4295      	cmp	r5, r2
70002178:	d014      	beq.n	700021a4 <z_thread_halt+0x134>
	return list->head == list;
7000217a:	461a      	mov	r2, r3
7000217c:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002180:	4291      	cmp	r1, r2
70002182:	d001      	beq.n	70002188 <z_thread_halt+0x118>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002184:	2900      	cmp	r1, #0
70002186:	d1a1      	bne.n	700020cc <z_thread_halt+0x5c>
		_kernel.ready_q.cache = thread;
70002188:	68da      	ldr	r2, [r3, #12]
7000218a:	615a      	str	r2, [r3, #20]
  __ASM volatile ("dmb 0xF":::"memory");
7000218c:	f3bf 8f5f 	dmb	sy
	thread->base.thread_state &= ~(_THREAD_ABORTING | _THREAD_SUSPENDING);
70002190:	7b6a      	ldrb	r2, [r5, #13]
70002192:	f022 0260 	bic.w	r2, r2, #96	; 0x60
70002196:	736a      	strb	r2, [r5, #13]
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
70002198:	689a      	ldr	r2, [r3, #8]
7000219a:	4295      	cmp	r5, r2
7000219c:	d1a0      	bne.n	700020e0 <z_thread_halt+0x70>
7000219e:	e7a3      	b.n	700020e8 <z_thread_halt+0x78>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700021a0:	68d9      	ldr	r1, [r3, #12]
#ifdef CONFIG_SMP
		unpend_all(&thread->halt_queue);
#endif /* CONFIG_SMP */
		update_cache(1);

		if (new_state == _THREAD_SUSPENDED) {
700021a2:	e793      	b.n	700020cc <z_thread_halt+0x5c>
700021a4:	ee1d 2f70 	mrc	15, 0, r2, cr13, cr0, {3}
700021a8:	f022 0203 	bic.w	r2, r2, #3
			if (thread == arch_current_thread() && arch_is_in_isr()) {
700021ac:	6812      	ldr	r2, [r2, #0]
700021ae:	2a00      	cmp	r2, #0
700021b0:	d0e3      	beq.n	7000217a <z_thread_halt+0x10a>
	return list->head == list;
700021b2:	461a      	mov	r2, r3
700021b4:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
700021b8:	4291      	cmp	r1, r2
700021ba:	d00c      	beq.n	700021d6 <z_thread_halt+0x166>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700021bc:	b159      	cbz	r1, 700021d6 <z_thread_halt+0x166>
		_kernel.ready_q.cache = thread;
700021be:	6159      	str	r1, [r3, #20]
700021c0:	f245 3208 	movw	r2, #21256	; 0x5308
700021c4:	f240 1101 	movw	r1, #257	; 0x101
700021c8:	f2c7 0200 	movt	r2, #28672	; 0x7000
700021cc:	8191      	strh	r1, [r2, #12]
	dummy_thread->resource_pool = NULL;
700021ce:	2100      	movs	r1, #0
	_current_cpu->current = thread;
700021d0:	609a      	str	r2, [r3, #8]
700021d2:	6691      	str	r1, [r2, #104]	; 0x68
#ifdef CONFIG_TIMESLICE_PER_THREAD
	dummy_thread->base.slice_ticks = 0;
#endif /* CONFIG_TIMESLICE_PER_THREAD */

	arch_current_thread_set(dummy_thread);
}
700021d4:	e7da      	b.n	7000218c <z_thread_halt+0x11c>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700021d6:	68d9      	ldr	r1, [r3, #12]
		 * code.  Note that we must leave a non-null switch
		 * handle for any threads spinning in join() (this can
		 * never be used, as our thread is flagged dead, but
		 * it must not be NULL otherwise join can deadlock).
		 */
		if (dummify && !IS_ENABLED(CONFIG_ARCH_POSIX)) {
700021d8:	e7f1      	b.n	700021be <z_thread_halt+0x14e>
700021da:	bf00      	nop

700021dc <z_ready_thread>:
{
700021dc:	b510      	push	{r4, lr}
	__asm__ volatile(
700021de:	f3ef 8400 	mrs	r4, CPSR
700021e2:	f004 0480 	and.w	r4, r4, #128	; 0x80
700021e6:	b672      	cpsid	i
			ready_thread(thread);
700021e8:	f7ff fefa 	bl	70001fe0 <ready_thread>
	if (key != 0U) {
700021ec:	b904      	cbnz	r4, 700021f0 <z_ready_thread+0x14>
  __ASM volatile ("cpsie i" : : : "memory");
700021ee:	b662      	cpsie	i
}
700021f0:	bd10      	pop	{r4, pc}
700021f2:	bf00      	nop

700021f4 <z_impl_k_thread_suspend>:
	struct k_thread *ret = _kernel.cpus[0].current;
700021f4:	f646 4398 	movw	r3, #27800	; 0x6c98
700021f8:	f2c7 0300 	movt	r3, #28672	; 0x7000
	if (thread == arch_current_thread() && !arch_is_in_isr() && !IS_ENABLED(CONFIG_SMP)) {
700021fc:	689a      	ldr	r2, [r3, #8]
700021fe:	4282      	cmp	r2, r0
70002200:	d00e      	beq.n	70002220 <z_impl_k_thread_suspend+0x2c>
	__asm__ volatile(
70002202:	f3ef 8100 	mrs	r1, CPSR
70002206:	f001 0180 	and.w	r1, r1, #128	; 0x80
7000220a:	b672      	cpsid	i
	if ((thread->base.thread_state & _THREAD_SUSPENDED) != 0U) {
7000220c:	7b42      	ldrb	r2, [r0, #13]
7000220e:	f012 0210 	ands.w	r2, r2, #16
70002212:	d002      	beq.n	7000221a <z_impl_k_thread_suspend+0x26>
	if (key != 0U) {
70002214:	b919      	cbnz	r1, 7000221e <z_impl_k_thread_suspend+0x2a>
70002216:	b662      	cpsie	i
}
70002218:	4770      	bx	lr
	z_thread_halt(thread, key, false);
7000221a:	f7ff bf29 	b.w	70002070 <z_thread_halt>
7000221e:	4770      	bx	lr
70002220:	ee1d 1f70 	mrc	15, 0, r1, cr13, cr0, {3}
70002224:	f021 0103 	bic.w	r1, r1, #3
	if (thread == arch_current_thread() && !arch_is_in_isr() && !IS_ENABLED(CONFIG_SMP)) {
70002228:	6809      	ldr	r1, [r1, #0]
7000222a:	2900      	cmp	r1, #0
7000222c:	d1e9      	bne.n	70002202 <z_impl_k_thread_suspend+0xe>
{
7000222e:	b570      	push	{r4, r5, r6, lr}
	__asm__ volatile(
70002230:	f3ef 8400 	mrs	r4, CPSR
70002234:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002238:	b672      	cpsid	i
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000223a:	7b50      	ldrb	r0, [r2, #13]
	sys_dnode_t *const prev = node->prev;
7000223c:	6856      	ldr	r6, [r2, #4]
	sys_dnode_t *const next = node->next;
7000223e:	6815      	ldr	r5, [r2, #0]
70002240:	f000 007f 	and.w	r0, r0, #127	; 0x7f
70002244:	f040 0010 	orr.w	r0, r0, #16
70002248:	7350      	strb	r0, [r2, #13]
	return list->head == list;
7000224a:	4618      	mov	r0, r3
	prev->next = next;
7000224c:	6035      	str	r5, [r6, #0]
	next->prev = prev;
7000224e:	606e      	str	r6, [r5, #4]
	node->next = NULL;
70002250:	6011      	str	r1, [r2, #0]
70002252:	6051      	str	r1, [r2, #4]
	return list->head == list;
70002254:	f850 2f18 	ldr.w	r2, [r0, #24]!
70002258:	6899      	ldr	r1, [r3, #8]
	arch_current_thread()->arch.basepri = key;
7000225a:	66cc      	str	r4, [r1, #108]	; 0x6c
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
7000225c:	4282      	cmp	r2, r0
7000225e:	bf18      	it	ne
70002260:	2a00      	cmpne	r2, #0
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
70002262:	f06f 000a 	mvn.w	r0, #10
70002266:	bf08      	it	eq
70002268:	68da      	ldreq	r2, [r3, #12]
7000226a:	6708      	str	r0, [r1, #112]	; 0x70
		_kernel.ready_q.cache = thread;
7000226c:	615a      	str	r2, [r3, #20]
	z_arm_cortex_r_svc();
7000226e:	f7fe ee7a 	blx	70000f64 <z_arm_cortex_r_svc>
	if (key != 0U) {
70002272:	b904      	cbnz	r4, 70002276 <z_impl_k_thread_suspend+0x82>
  __ASM volatile ("cpsie i" : : : "memory");
70002274:	b662      	cpsie	i
}
70002276:	bd70      	pop	{r4, r5, r6, pc}

70002278 <z_unpend_thread_no_timeout>:
	__asm__ volatile(
70002278:	f3ef 8100 	mrs	r1, CPSR
7000227c:	f001 0180 	and.w	r1, r1, #128	; 0x80
70002280:	b672      	cpsid	i
		if (thread->base.pended_on != NULL) {
70002282:	6883      	ldr	r3, [r0, #8]
70002284:	b193      	cbz	r3, 700022ac <z_unpend_thread_no_timeout+0x34>
	sys_dnode_t *const next = node->next;
70002286:	e9d0 3200 	ldrd	r3, r2, [r0]
{
7000228a:	b430      	push	{r4, r5}
	prev->next = next;
7000228c:	6013      	str	r3, [r2, #0]
	node->next = NULL;
7000228e:	2400      	movs	r4, #0
	next->prev = prev;
70002290:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70002292:	2500      	movs	r5, #0
70002294:	7b43      	ldrb	r3, [r0, #13]
70002296:	2200      	movs	r2, #0
70002298:	e9c0 4500 	strd	r4, r5, [r0]
7000229c:	f023 0302 	bic.w	r3, r3, #2
700022a0:	6082      	str	r2, [r0, #8]
700022a2:	7343      	strb	r3, [r0, #13]
	if (key != 0U) {
700022a4:	b901      	cbnz	r1, 700022a8 <z_unpend_thread_no_timeout+0x30>
700022a6:	b662      	cpsie	i
}
700022a8:	bc30      	pop	{r4, r5}
700022aa:	4770      	bx	lr
700022ac:	b909      	cbnz	r1, 700022b2 <z_unpend_thread_no_timeout+0x3a>
700022ae:	b662      	cpsie	i
	K_SPINLOCK(&_sched_spinlock) {
700022b0:	4770      	bx	lr
700022b2:	4770      	bx	lr

700022b4 <z_sched_wake_thread>:
{
700022b4:	b5d0      	push	{r4, r6, r7, lr}
	__asm__ volatile(
700022b6:	f3ef 8400 	mrs	r4, CPSR
700022ba:	f004 0480 	and.w	r4, r4, #128	; 0x80
700022be:	b672      	cpsid	i
		bool killed = (thread->base.thread_state &
700022c0:	7b43      	ldrb	r3, [r0, #13]
		if (!killed) {
700022c2:	f013 0128 	ands.w	r1, r3, #40	; 0x28
700022c6:	d112      	bne.n	700022ee <z_sched_wake_thread+0x3a>
			if (thread->base.pended_on != NULL) {
700022c8:	6882      	ldr	r2, [r0, #8]
700022ca:	b15a      	cbz	r2, 700022e4 <z_sched_wake_thread+0x30>
	sys_dnode_t *const next = node->next;
700022cc:	e9d0 3200 	ldrd	r3, r2, [r0]
	node->next = NULL;
700022d0:	2600      	movs	r6, #0
	prev->next = next;
700022d2:	6013      	str	r3, [r2, #0]
	node->next = NULL;
700022d4:	2700      	movs	r7, #0
	next->prev = prev;
700022d6:	605a      	str	r2, [r3, #4]
700022d8:	7b43      	ldrb	r3, [r0, #13]
	node->next = NULL;
700022da:	e9c0 6700 	strd	r6, r7, [r0]
700022de:	f003 03fd 	and.w	r3, r3, #253	; 0xfd
700022e2:	6081      	str	r1, [r0, #8]
	thread->base.thread_state &= ~_THREAD_SLEEPING;
700022e4:	f023 0304 	bic.w	r3, r3, #4
700022e8:	7343      	strb	r3, [r0, #13]
			ready_thread(thread);
700022ea:	f7ff fe79 	bl	70001fe0 <ready_thread>
	if (key != 0U) {
700022ee:	b904      	cbnz	r4, 700022f2 <z_sched_wake_thread+0x3e>
700022f0:	b662      	cpsie	i
}
700022f2:	bdd0      	pop	{r4, r6, r7, pc}

700022f4 <z_thread_timeout>:
	z_sched_wake_thread(thread, true);
700022f4:	2101      	movs	r1, #1
700022f6:	3818      	subs	r0, #24
700022f8:	f7ff bfdc 	b.w	700022b4 <z_sched_wake_thread>

700022fc <z_pend_curr>:
{
700022fc:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
700022fe:	e9dd 7606 	ldrd	r7, r6, [sp, #24]
70002302:	460d      	mov	r5, r1
70002304:	4611      	mov	r1, r2
	__asm__ volatile(
70002306:	f3ef 8300 	mrs	r3, CPSR
7000230a:	f003 0380 	and.w	r3, r3, #128	; 0x80
7000230e:	b672      	cpsid	i
70002310:	f646 4498 	movw	r4, #27800	; 0x6c98
70002314:	f2c7 0400 	movt	r4, #28672	; 0x7000
70002318:	68a0      	ldr	r0, [r4, #8]
	add_to_waitq_locked(thread, wait_q);
7000231a:	f7ff fe39 	bl	70001f90 <add_to_waitq_locked>
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
7000231e:	f1b6 3fff 	cmp.w	r6, #4294967295	; 0xffffffff
70002322:	bf08      	it	eq
70002324:	f1b7 3fff 	cmpeq.w	r7, #4294967295	; 0xffffffff
70002328:	d008      	beq.n	7000233c <z_pend_curr+0x40>
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
7000232a:	f242 21f5 	movw	r1, #8949	; 0x22f5
7000232e:	463a      	mov	r2, r7
70002330:	4633      	mov	r3, r6
70002332:	3018      	adds	r0, #24
70002334:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002338:	f000 f9cc 	bl	700026d4 <z_add_timeout>
7000233c:	68a3      	ldr	r3, [r4, #8]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
7000233e:	f06f 020a 	mvn.w	r2, #10
70002342:	e9c3 521b 	strd	r5, r2, [r3, #108]	; 0x6c
	z_arm_cortex_r_svc();
70002346:	f7fe ee0e 	blx	70000f64 <z_arm_cortex_r_svc>
	if (key != 0U) {
7000234a:	b905      	cbnz	r5, 7000234e <z_pend_curr+0x52>
7000234c:	b662      	cpsie	i
	return arch_current_thread()->arch.swap_return_value;
7000234e:	68a3      	ldr	r3, [r4, #8]
}
70002350:	6f18      	ldr	r0, [r3, #112]	; 0x70
70002352:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}

70002354 <z_unpend_thread>:
{
70002354:	b510      	push	{r4, lr}
	z_unpend_thread_no_timeout(thread);
70002356:	f7ff ff8f 	bl	70002278 <z_unpend_thread_no_timeout>
}
7000235a:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	return z_abort_timeout(&thread->base.timeout);
7000235e:	3018      	adds	r0, #24
70002360:	f000 ba4a 	b.w	700027f8 <z_abort_timeout>

70002364 <z_reschedule>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
70002364:	b9c1      	cbnz	r1, 70002398 <z_reschedule+0x34>
{
70002366:	b508      	push	{r3, lr}
70002368:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
7000236c:	f023 0303 	bic.w	r3, r3, #3
	return arch_irq_unlocked(key) && !arch_is_in_isr();
70002370:	681a      	ldr	r2, [r3, #0]
70002372:	b97a      	cbnz	r2, 70002394 <z_reschedule+0x30>
70002374:	f646 4398 	movw	r3, #27800	; 0x6c98
70002378:	f2c7 0300 	movt	r3, #28672	; 0x7000
7000237c:	6899      	ldr	r1, [r3, #8]
	if (resched(key.key) && need_swap()) {
7000237e:	695b      	ldr	r3, [r3, #20]
70002380:	428b      	cmp	r3, r1
70002382:	d007      	beq.n	70002394 <z_reschedule+0x30>
	arch_current_thread()->arch.basepri = key;
70002384:	66ca      	str	r2, [r1, #108]	; 0x6c
70002386:	f06f 030a 	mvn.w	r3, #10
7000238a:	670b      	str	r3, [r1, #112]	; 0x70
	z_arm_cortex_r_svc();
7000238c:	f7fe edea 	blx	70000f64 <z_arm_cortex_r_svc>
70002390:	b662      	cpsie	i
}
70002392:	bd08      	pop	{r3, pc}
70002394:	b662      	cpsie	i
70002396:	bd08      	pop	{r3, pc}
70002398:	4770      	bx	lr
7000239a:	bf00      	nop

7000239c <z_impl_k_thread_resume>:
{
7000239c:	b510      	push	{r4, lr}
	__asm__ volatile(
7000239e:	f3ef 8400 	mrs	r4, CPSR
700023a2:	f004 0480 	and.w	r4, r4, #128	; 0x80
700023a6:	b672      	cpsid	i
	return (thread->base.thread_state & _THREAD_SUSPENDED) != 0U;
700023a8:	7b42      	ldrb	r2, [r0, #13]
	if (!z_is_thread_suspended(thread)) {
700023aa:	06d3      	lsls	r3, r2, #27
700023ac:	d402      	bmi.n	700023b4 <z_impl_k_thread_resume+0x18>
	if (key != 0U) {
700023ae:	b904      	cbnz	r4, 700023b2 <z_impl_k_thread_resume+0x16>
700023b0:	b662      	cpsie	i
}
700023b2:	bd10      	pop	{r4, pc}
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
700023b4:	f022 0210 	bic.w	r2, r2, #16
700023b8:	7342      	strb	r2, [r0, #13]
	ready_thread(thread);
700023ba:	f7ff fe11 	bl	70001fe0 <ready_thread>
	z_reschedule(&_sched_spinlock, key);
700023be:	f646 40b8 	movw	r0, #27832	; 0x6cb8
700023c2:	4621      	mov	r1, r4
700023c4:	f2c7 0000 	movt	r0, #28672	; 0x7000
}
700023c8:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&_sched_spinlock, key);
700023cc:	f7ff bfca 	b.w	70002364 <z_reschedule>

700023d0 <k_sched_lock>:
	__asm__ volatile(
700023d0:	f3ef 8100 	mrs	r1, CPSR
700023d4:	f001 0180 	and.w	r1, r1, #128	; 0x80
700023d8:	b672      	cpsid	i
700023da:	f646 4398 	movw	r3, #27800	; 0x6c98
700023de:	f2c7 0300 	movt	r3, #28672	; 0x7000
700023e2:	689a      	ldr	r2, [r3, #8]
	--arch_current_thread()->base.sched_locked;
700023e4:	7bd3      	ldrb	r3, [r2, #15]
700023e6:	3b01      	subs	r3, #1
700023e8:	73d3      	strb	r3, [r2, #15]
	if (key != 0U) {
700023ea:	b901      	cbnz	r1, 700023ee <k_sched_lock+0x1e>
700023ec:	b662      	cpsie	i
}
700023ee:	4770      	bx	lr

700023f0 <k_sched_unlock>:
{
700023f0:	b510      	push	{r4, lr}
	__asm__ volatile(
700023f2:	f3ef 8400 	mrs	r4, CPSR
700023f6:	f004 0480 	and.w	r4, r4, #128	; 0x80
700023fa:	b672      	cpsid	i
700023fc:	f646 4098 	movw	r0, #27800	; 0x6c98
70002400:	f2c7 0000 	movt	r0, #28672	; 0x7000
	return list->head == list;
70002404:	4601      	mov	r1, r0
70002406:	6882      	ldr	r2, [r0, #8]
		++arch_current_thread()->base.sched_locked;
70002408:	7bd3      	ldrb	r3, [r2, #15]
7000240a:	3301      	adds	r3, #1
7000240c:	73d3      	strb	r3, [r2, #15]
7000240e:	f851 3f18 	ldr.w	r3, [r1, #24]!
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002412:	428b      	cmp	r3, r1
70002414:	bf18      	it	ne
70002416:	2b00      	cmpne	r3, #0
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
70002418:	7b51      	ldrb	r1, [r2, #13]
7000241a:	bf08      	it	eq
7000241c:	68c3      	ldreq	r3, [r0, #12]
7000241e:	06c9      	lsls	r1, r1, #27
70002420:	d103      	bne.n	7000242a <k_sched_unlock+0x3a>
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
70002422:	89d1      	ldrh	r1, [r2, #14]
70002424:	297f      	cmp	r1, #127	; 0x7f
70002426:	bf88      	it	hi
70002428:	4613      	movhi	r3, r2
7000242a:	6143      	str	r3, [r0, #20]
	if (key != 0U) {
7000242c:	b904      	cbnz	r4, 70002430 <k_sched_unlock+0x40>
7000242e:	b662      	cpsie	i
	__asm__ volatile(
70002430:	f3ef 8300 	mrs	r3, CPSR
70002434:	f003 0380 	and.w	r3, r3, #128	; 0x80
70002438:	b672      	cpsid	i
	return arch_irq_unlocked(key) && !arch_is_in_isr();
7000243a:	b983      	cbnz	r3, 7000245e <k_sched_unlock+0x6e>
7000243c:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70002440:	f023 0303 	bic.w	r3, r3, #3
70002444:	681b      	ldr	r3, [r3, #0]
70002446:	b95b      	cbnz	r3, 70002460 <k_sched_unlock+0x70>
70002448:	6882      	ldr	r2, [r0, #8]
	if (resched(key) && need_swap()) {
7000244a:	6941      	ldr	r1, [r0, #20]
7000244c:	4291      	cmp	r1, r2
7000244e:	d007      	beq.n	70002460 <k_sched_unlock+0x70>
	arch_current_thread()->arch.basepri = key;
70002450:	66d3      	str	r3, [r2, #108]	; 0x6c
70002452:	f06f 010a 	mvn.w	r1, #10
70002456:	6711      	str	r1, [r2, #112]	; 0x70
	z_arm_cortex_r_svc();
70002458:	f7fe ed84 	blx	70000f64 <z_arm_cortex_r_svc>
7000245c:	b662      	cpsie	i
}
7000245e:	bd10      	pop	{r4, pc}
70002460:	b662      	cpsie	i
70002462:	bd10      	pop	{r4, pc}

70002464 <z_sched_init>:
{
70002464:	4a02      	ldr	r2, [pc, #8]	; (70002470 <z_sched_init+0xc>)
	list->head = (sys_dnode_t *)list;
70002466:	4613      	mov	r3, r2
70002468:	f843 2918 	str.w	r2, [r3], #-24
7000246c:	61da      	str	r2, [r3, #28]
}
7000246e:	4770      	bx	lr
70002470:	70006cb0 	.word	0x70006cb0

70002474 <z_impl_k_yield>:
{
70002474:	b570      	push	{r4, r5, r6, lr}
70002476:	f3ef 8600 	mrs	r6, CPSR
7000247a:	f006 0680 	and.w	r6, r6, #128	; 0x80
7000247e:	b672      	cpsid	i
70002480:	f646 4c98 	movw	ip, #27800	; 0x6c98
70002484:	f2c7 0c00 	movt	ip, #28672	; 0x7000
	return list->head == list;
70002488:	4665      	mov	r5, ip
7000248a:	f8dc 3008 	ldr.w	r3, [ip, #8]
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000248e:	7b5a      	ldrb	r2, [r3, #13]
70002490:	f002 027f 	and.w	r2, r2, #127	; 0x7f
70002494:	735a      	strb	r2, [r3, #13]
	node->next = NULL;
70002496:	2200      	movs	r2, #0
	sys_dnode_t *const prev = node->prev;
70002498:	6858      	ldr	r0, [r3, #4]
	sys_dnode_t *const next = node->next;
7000249a:	6819      	ldr	r1, [r3, #0]
	prev->next = next;
7000249c:	6001      	str	r1, [r0, #0]
	next->prev = prev;
7000249e:	6048      	str	r0, [r1, #4]
	node->next = NULL;
700024a0:	601a      	str	r2, [r3, #0]
700024a2:	605a      	str	r2, [r3, #4]
700024a4:	f8dc 0008 	ldr.w	r0, [ip, #8]
	thread->base.thread_state |= _THREAD_QUEUED;
700024a8:	7b43      	ldrb	r3, [r0, #13]
700024aa:	f063 037f 	orn	r3, r3, #127	; 0x7f
700024ae:	7343      	strb	r3, [r0, #13]
	return list->head == list;
700024b0:	f855 3f18 	ldr.w	r3, [r5, #24]!
	return (node == list->tail) ? NULL : node->next;
700024b4:	f8dc 401c 	ldr.w	r4, [ip, #28]
	return sys_dlist_is_empty(list) ? NULL : list->head;
700024b8:	42ab      	cmp	r3, r5
700024ba:	bf08      	it	eq
700024bc:	4613      	moveq	r3, r2
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
700024be:	b163      	cbz	r3, 700024da <z_impl_k_yield+0x66>
	int32_t b2 = thread_2->base.prio;
700024c0:	f993 100e 	ldrsb.w	r1, [r3, #14]
	int32_t b1 = thread_1->base.prio;
700024c4:	f990 200e 	ldrsb.w	r2, [r0, #14]
	if (b1 != b2) {
700024c8:	428a      	cmp	r2, r1
700024ca:	d001      	beq.n	700024d0 <z_impl_k_yield+0x5c>
		if (z_sched_prio_cmp(thread, t) > 0) {
700024cc:	4291      	cmp	r1, r2
700024ce:	dc1e      	bgt.n	7000250e <z_impl_k_yield+0x9a>
	return (node == list->tail) ? NULL : node->next;
700024d0:	42a3      	cmp	r3, r4
700024d2:	d002      	beq.n	700024da <z_impl_k_yield+0x66>
700024d4:	681b      	ldr	r3, [r3, #0]
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
700024d6:	2b00      	cmp	r3, #0
700024d8:	d1f2      	bne.n	700024c0 <z_impl_k_yield+0x4c>
	node->prev = tail;
700024da:	e9c0 5400 	strd	r5, r4, [r0]
	tail->next = node;
700024de:	6020      	str	r0, [r4, #0]
	list->tail = node;
700024e0:	f8cc 001c 	str.w	r0, [ip, #28]
	return list->head == list;
700024e4:	f8dc 3018 	ldr.w	r3, [ip, #24]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700024e8:	f06f 010a 	mvn.w	r1, #10
700024ec:	f8dc 2008 	ldr.w	r2, [ip, #8]
	arch_current_thread()->arch.basepri = key;
700024f0:	66d6      	str	r6, [r2, #108]	; 0x6c
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700024f2:	42ab      	cmp	r3, r5
700024f4:	bf18      	it	ne
700024f6:	2b00      	cmpne	r3, #0
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700024f8:	6711      	str	r1, [r2, #112]	; 0x70
700024fa:	bf08      	it	eq
700024fc:	f8dc 300c 	ldreq.w	r3, [ip, #12]
		_kernel.ready_q.cache = thread;
70002500:	f8cc 3014 	str.w	r3, [ip, #20]
	z_arm_cortex_r_svc();
70002504:	f7fe ed2e 	blx	70000f64 <z_arm_cortex_r_svc>
	if (key != 0U) {
70002508:	b906      	cbnz	r6, 7000250c <z_impl_k_yield+0x98>
7000250a:	b662      	cpsie	i
}
7000250c:	bd70      	pop	{r4, r5, r6, pc}
	sys_dnode_t *const prev = successor->prev;
7000250e:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
70002510:	e9c0 3200 	strd	r3, r2, [r0]
	prev->next = node;
70002514:	6010      	str	r0, [r2, #0]
	successor->prev = node;
70002516:	6058      	str	r0, [r3, #4]
}
70002518:	e7e4      	b.n	700024e4 <z_impl_k_yield+0x70>
7000251a:	bf00      	nop

7000251c <z_tick_sleep>:
	if (ticks == 0) {
7000251c:	ea50 0301 	orrs.w	r3, r0, r1
{
70002520:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	if (ticks == 0) {
70002524:	d039      	beq.n	7000259a <z_tick_sleep+0x7e>
70002526:	4604      	mov	r4, r0
	if (Z_TICK_ABS(ticks) <= 0) {
70002528:	1c83      	adds	r3, r0, #2
7000252a:	460d      	mov	r5, r1
7000252c:	f171 33ff 	sbcs.w	r3, r1, #4294967295	; 0xffffffff
		expected_wakeup_ticks = Z_TICK_ABS(ticks);
70002530:	bfbc      	itt	lt
70002532:	f06f 0001 	mvnlt.w	r0, #1
70002536:	1b06      	sublt	r6, r0, r4
	if (Z_TICK_ABS(ticks) <= 0) {
70002538:	da2b      	bge.n	70002592 <z_tick_sleep+0x76>
	__asm__ volatile(
7000253a:	f3ef 8800 	mrs	r8, CPSR
7000253e:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002542:	b672      	cpsid	i
70002544:	f646 4798 	movw	r7, #27800	; 0x6c98
70002548:	f2c7 0700 	movt	r7, #28672	; 0x7000
	unready_thread(arch_current_thread());
7000254c:	68b8      	ldr	r0, [r7, #8]
7000254e:	f7ff fcf7 	bl	70001f40 <unready_thread>
70002552:	68b8      	ldr	r0, [r7, #8]
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
70002554:	f242 21f5 	movw	r1, #8949	; 0x22f5
70002558:	4622      	mov	r2, r4
7000255a:	462b      	mov	r3, r5
7000255c:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002560:	3018      	adds	r0, #24
70002562:	f000 f8b7 	bl	700026d4 <z_add_timeout>
70002566:	68bb      	ldr	r3, [r7, #8]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
70002568:	f06f 010a 	mvn.w	r1, #10
	thread->base.thread_state |= _THREAD_SLEEPING;
7000256c:	7b5a      	ldrb	r2, [r3, #13]
7000256e:	f042 0204 	orr.w	r2, r2, #4
70002572:	e9c3 811b 	strd	r8, r1, [r3, #108]	; 0x6c
70002576:	735a      	strb	r2, [r3, #13]
	z_arm_cortex_r_svc();
70002578:	f7fe ecf4 	blx	70000f64 <z_arm_cortex_r_svc>
	if (key != 0U) {
7000257c:	f1b8 0f00 	cmp.w	r8, #0
70002580:	d100      	bne.n	70002584 <z_tick_sleep+0x68>
70002582:	b662      	cpsie	i
	uint32_t left_ticks = expected_wakeup_ticks - sys_clock_tick_get_32();
70002584:	f000 fa02 	bl	7000298c <sys_clock_tick_get_32>
70002588:	1a30      	subs	r0, r6, r0
	if (ticks > 0) {
7000258a:	ea20 70e0 	bic.w	r0, r0, r0, asr #31
}
7000258e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		expected_wakeup_ticks = ticks + sys_clock_tick_get_32();
70002592:	f000 f9fb 	bl	7000298c <sys_clock_tick_get_32>
70002596:	1906      	adds	r6, r0, r4
70002598:	e7cf      	b.n	7000253a <z_tick_sleep+0x1e>
	z_impl_k_yield();
7000259a:	f7ff ff6b 	bl	70002474 <z_impl_k_yield>
		return 0;
7000259e:	2000      	movs	r0, #0
}
700025a0:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

700025a4 <z_impl_k_sleep>:
{
700025a4:	b538      	push	{r3, r4, r5, lr}
700025a6:	4605      	mov	r5, r0
700025a8:	460c      	mov	r4, r1
	ticks = z_tick_sleep(ticks);
700025aa:	f7ff ffb7 	bl	7000251c <z_tick_sleep>
	int32_t ret = K_TIMEOUT_EQ(timeout, K_FOREVER) ? K_TICKS_FOREVER :
700025ae:	f1b4 3fff 	cmp.w	r4, #4294967295	; 0xffffffff
700025b2:	bf08      	it	eq
700025b4:	f1b5 3fff 	cmpeq.w	r5, #4294967295	; 0xffffffff
700025b8:	bf08      	it	eq
700025ba:	f04f 30ff 	moveq.w	r0, #4294967295	; 0xffffffff
}
700025be:	bd38      	pop	{r3, r4, r5, pc}

700025c0 <z_impl_k_wakeup>:
{
700025c0:	b538      	push	{r3, r4, r5, lr}
700025c2:	4604      	mov	r4, r0
	return z_abort_timeout(&thread->base.timeout);
700025c4:	3018      	adds	r0, #24
700025c6:	f000 f917 	bl	700027f8 <z_abort_timeout>
	__asm__ volatile(
700025ca:	f3ef 8500 	mrs	r5, CPSR
700025ce:	f005 0580 	and.w	r5, r5, #128	; 0x80
700025d2:	b672      	cpsid	i
	return (thread->base.thread_state & _THREAD_SLEEPING) != 0U;
700025d4:	7b63      	ldrb	r3, [r4, #13]
	if (!z_is_thread_sleeping(thread)) {
700025d6:	075a      	lsls	r2, r3, #29
700025d8:	d402      	bmi.n	700025e0 <z_impl_k_wakeup+0x20>
	if (key != 0U) {
700025da:	b905      	cbnz	r5, 700025de <z_impl_k_wakeup+0x1e>
700025dc:	b662      	cpsie	i
}
700025de:	bd38      	pop	{r3, r4, r5, pc}
	ready_thread(thread);
700025e0:	4620      	mov	r0, r4
	thread->base.thread_state &= ~_THREAD_SLEEPING;
700025e2:	f023 0304 	bic.w	r3, r3, #4
700025e6:	7363      	strb	r3, [r4, #13]
700025e8:	f7ff fcfa 	bl	70001fe0 <ready_thread>
700025ec:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
700025f0:	f023 0303 	bic.w	r3, r3, #3
	if (arch_is_in_isr()) {
700025f4:	681b      	ldr	r3, [r3, #0]
700025f6:	2b00      	cmp	r3, #0
700025f8:	d1ef      	bne.n	700025da <z_impl_k_wakeup+0x1a>
		z_reschedule(&_sched_spinlock, key);
700025fa:	f646 40b8 	movw	r0, #27832	; 0x6cb8
700025fe:	4629      	mov	r1, r5
70002600:	f2c7 0000 	movt	r0, #28672	; 0x7000
}
70002604:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		z_reschedule(&_sched_spinlock, key);
70002608:	f7ff beac 	b.w	70002364 <z_reschedule>

7000260c <z_impl_k_sched_current_thread_query>:
7000260c:	f646 4398 	movw	r3, #27800	; 0x6c98
70002610:	f2c7 0300 	movt	r3, #28672	; 0x7000
}
70002614:	6898      	ldr	r0, [r3, #8]
70002616:	4770      	bx	lr

70002618 <z_impl_k_thread_abort>:
	__asm__ volatile(
70002618:	f3ef 8100 	mrs	r1, CPSR
7000261c:	f001 0180 	and.w	r1, r1, #128	; 0x80
70002620:	b672      	cpsid	i
	return (thread->base.user_options & K_ESSENTIAL) == K_ESSENTIAL;
70002622:	7b02      	ldrb	r2, [r0, #12]

void z_thread_abort(struct k_thread *thread)
{
	k_spinlock_key_t key = k_spin_lock(&_sched_spinlock);

	if (z_is_thread_essential(thread)) {
70002624:	07d2      	lsls	r2, r2, #31
70002626:	d409      	bmi.n	7000263c <z_impl_k_thread_abort+0x24>
		__ASSERT(false, "aborting essential thread %p", thread);
		k_panic();
		return;
	}

	if ((thread->base.thread_state & _THREAD_DEAD) != 0U) {
70002628:	7b43      	ldrb	r3, [r0, #13]
7000262a:	071b      	lsls	r3, r3, #28
7000262c:	d502      	bpl.n	70002634 <z_impl_k_thread_abort+0x1c>
	if (key != 0U) {
7000262e:	b921      	cbnz	r1, 7000263a <z_impl_k_thread_abort+0x22>
70002630:	b662      	cpsie	i
}
70002632:	4770      	bx	lr
		k_spin_unlock(&_sched_spinlock, key);
		return;
	}

	z_thread_halt(thread, key, true);
70002634:	2201      	movs	r2, #1
70002636:	f7ff bd1b 	b.w	70002070 <z_thread_halt>
	z_thread_abort(thread);

	__ASSERT_NO_MSG((thread->base.thread_state & _THREAD_DEAD) != 0);

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_thread, abort, thread);
}
7000263a:	4770      	bx	lr
7000263c:	b901      	cbnz	r1, 70002640 <z_impl_k_thread_abort+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
7000263e:	b662      	cpsie	i
		k_panic();
70002640:	2004      	movs	r0, #4
70002642:	b500      	push	{lr}
70002644:	b662      	cpsie	i
70002646:	df02      	svc	2
70002648:	f85d eb04 	ldr.w	lr, [sp], #4
		return;
7000264c:	4770      	bx	lr
7000264e:	bf00      	nop

70002650 <z_sched_wake>:

/*
 * future scheduler.h API implementations
 */
bool z_sched_wake(_wait_q_t *wait_q, int swap_retval, void *swap_data)
{
70002650:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	__asm__ volatile(
70002654:	f3ef 8800 	mrs	r8, CPSR
70002658:	f008 0880 	and.w	r8, r8, #128	; 0x80
7000265c:	b672      	cpsid	i
	return list->head == list;
7000265e:	6804      	ldr	r4, [r0, #0]
	bool ret = false;

	K_SPINLOCK(&_sched_spinlock) {
		thread = _priq_wait_best(&wait_q->waitq);

		if (thread != NULL) {
70002660:	42a0      	cmp	r0, r4
70002662:	bf18      	it	ne
70002664:	2c00      	cmpne	r4, #0
70002666:	bf14      	ite	ne
70002668:	2501      	movne	r5, #1
7000266a:	2500      	moveq	r5, #0
7000266c:	d106      	bne.n	7000267c <z_sched_wake+0x2c>
	if (key != 0U) {
7000266e:	f1b8 0f00 	cmp.w	r8, #0
70002672:	d100      	bne.n	70002676 <z_sched_wake+0x26>
70002674:	b662      	cpsie	i
			ret = true;
		}
	}

	return ret;
}
70002676:	4628      	mov	r0, r5
70002678:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	sys_dnode_t *const next = node->next;
7000267c:	e9d4 3000 	ldrd	r3, r0, [r4]
	node->next = NULL;
70002680:	2600      	movs	r6, #0
z_thread_return_value_set_with_data(struct k_thread *thread,
				   unsigned int value,
				   void *data)
{
	arch_thread_return_value_set(thread, value);
	thread->base.swap_data = data;
70002682:	6162      	str	r2, [r4, #20]
70002684:	2700      	movs	r7, #0
	thread->arch.swap_return_value = value;
70002686:	6721      	str	r1, [r4, #112]	; 0x70
	thread->base.pended_on = NULL;
70002688:	2200      	movs	r2, #0
	prev->next = next;
7000268a:	6003      	str	r3, [r0, #0]
	next->prev = prev;
7000268c:	6058      	str	r0, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
7000268e:	7b63      	ldrb	r3, [r4, #13]
70002690:	f023 0302 	bic.w	r3, r3, #2
	node->next = NULL;
70002694:	e9c4 6700 	strd	r6, r7, [r4]
70002698:	f104 0018 	add.w	r0, r4, #24
7000269c:	7363      	strb	r3, [r4, #13]
7000269e:	60a2      	str	r2, [r4, #8]
700026a0:	f000 f8aa 	bl	700027f8 <z_abort_timeout>
			ready_thread(thread);
700026a4:	4620      	mov	r0, r4
700026a6:	f7ff fc9b 	bl	70001fe0 <ready_thread>
			ret = true;
700026aa:	e7e0      	b.n	7000266e <z_sched_wake+0x1e>

700026ac <z_sched_wait>:

int z_sched_wait(struct k_spinlock *lock, k_spinlock_key_t key,
		 _wait_q_t *wait_q, k_timeout_t timeout, void **data)
{
700026ac:	b510      	push	{r4, lr}
700026ae:	b082      	sub	sp, #8
	int ret = z_pend_curr(lock, key, wait_q, timeout);
700026b0:	e9dd 3404 	ldrd	r3, r4, [sp, #16]
700026b4:	e9cd 3400 	strd	r3, r4, [sp]
{
700026b8:	9c06      	ldr	r4, [sp, #24]
	int ret = z_pend_curr(lock, key, wait_q, timeout);
700026ba:	f7ff fe1f 	bl	700022fc <z_pend_curr>

	if (data != NULL) {
700026be:	b134      	cbz	r4, 700026ce <z_sched_wait+0x22>
700026c0:	f646 4398 	movw	r3, #27800	; 0x6c98
700026c4:	f2c7 0300 	movt	r3, #28672	; 0x7000
		*data = arch_current_thread()->base.swap_data;
700026c8:	689b      	ldr	r3, [r3, #8]
700026ca:	695b      	ldr	r3, [r3, #20]
700026cc:	6023      	str	r3, [r4, #0]
	}
	return ret;
}
700026ce:	b002      	add	sp, #8
700026d0:	bd10      	pop	{r4, pc}
700026d2:	bf00      	nop

700026d4 <z_add_timeout>:
}

void z_add_timeout(struct _timeout *to, _timeout_func_t fn,
		   k_timeout_t timeout)
{
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
700026d4:	f1b3 3fff 	cmp.w	r3, #4294967295	; 0xffffffff
700026d8:	bf08      	it	eq
700026da:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
700026de:	f000 808a 	beq.w	700027f6 <z_add_timeout+0x122>
{
700026e2:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
700026e4:	4606      	mov	r6, r0
700026e6:	461d      	mov	r5, r3
700026e8:	4614      	mov	r4, r2
700026ea:	4618      	mov	r0, r3
#ifdef CONFIG_KERNEL_COHERENCE
	__ASSERT_NO_MSG(arch_mem_coherent(to));
#endif /* CONFIG_KERNEL_COHERENCE */

	__ASSERT(!sys_dnode_is_linked(&to->node), "");
	to->fn = fn;
700026ec:	60b1      	str	r1, [r6, #8]
	__asm__ volatile(
700026ee:	f3ef 8700 	mrs	r7, CPSR
700026f2:	f007 0780 	and.w	r7, r7, #128	; 0x80
700026f6:	b672      	cpsid	i

	K_SPINLOCK(&timeout_lock) {
		struct _timeout *t;

		if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) &&
700026f8:	3201      	adds	r2, #1
700026fa:	f175 33ff 	sbcs.w	r3, r5, #4294967295	; 0xffffffff
700026fe:	da5f      	bge.n	700027c0 <z_add_timeout+0xec>
		    (Z_TICK_ABS(timeout.ticks) >= 0)) {
			k_ticks_t ticks = Z_TICK_ABS(timeout.ticks) - curr_tick;
70002700:	f245 3280 	movw	r2, #21376	; 0x5380
70002704:	f06f 0301 	mvn.w	r3, #1
70002708:	f2c7 0200 	movt	r2, #28672	; 0x7000
7000270c:	e9d2 1500 	ldrd	r1, r5, [r2]
70002710:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
70002714:	1a5b      	subs	r3, r3, r1
70002716:	eb62 0505 	sbc.w	r5, r2, r5
7000271a:	1b1c      	subs	r4, r3, r4
7000271c:	eb65 0500 	sbc.w	r5, r5, r0

			to->dticks = MAX(1, ticks);
70002720:	2c01      	cmp	r4, #1
70002722:	f175 0300 	sbcs.w	r3, r5, #0
70002726:	bfbc      	itt	lt
70002728:	2401      	movlt	r4, #1
7000272a:	2500      	movlt	r5, #0
7000272c:	6134      	str	r4, [r6, #16]
	return list->head == list;
7000272e:	f24b 1090 	movw	r0, #45456	; 0xb190
70002732:	6175      	str	r5, [r6, #20]
70002734:	f2c7 0000 	movt	r0, #28672	; 0x7000
	return (node == list->tail) ? NULL : node->next;
70002738:	e9d0 2c00 	ldrd	r2, ip, [r0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
7000273c:	4282      	cmp	r2, r0
7000273e:	d011      	beq.n	70002764 <z_add_timeout+0x90>
		} else {
			to->dticks = timeout.ticks + 1 + elapsed();
		}

		for (t = first(); t != NULL; t = next(t)) {
70002740:	b182      	cbz	r2, 70002764 <z_add_timeout+0x90>
			if (t->dticks > to->dticks) {
70002742:	e9d2 3104 	ldrd	r3, r1, [r2, #16]
70002746:	429c      	cmp	r4, r3
70002748:	eb75 0e01 	sbcs.w	lr, r5, r1
7000274c:	db48      	blt.n	700027e0 <z_add_timeout+0x10c>
				t->dticks -= to->dticks;
				sys_dlist_insert(&t->node, &to->node);
				break;
			}
			to->dticks -= t->dticks;
7000274e:	1ae3      	subs	r3, r4, r3
70002750:	461c      	mov	r4, r3
70002752:	eb65 0501 	sbc.w	r5, r5, r1
	return (node == list->tail) ? NULL : node->next;
70002756:	4562      	cmp	r2, ip
70002758:	e9c6 3504 	strd	r3, r5, [r6, #16]
7000275c:	d002      	beq.n	70002764 <z_add_timeout+0x90>
7000275e:	6812      	ldr	r2, [r2, #0]
		for (t = first(); t != NULL; t = next(t)) {
70002760:	2a00      	cmp	r2, #0
70002762:	d1ee      	bne.n	70002742 <z_add_timeout+0x6e>
	node->prev = tail;
70002764:	e9c6 0c00 	strd	r0, ip, [r6]
	tail->next = node;
70002768:	f8cc 6000 	str.w	r6, [ip]
	list->tail = node;
7000276c:	6046      	str	r6, [r0, #4]
	return list->head == list;
7000276e:	6804      	ldr	r4, [r0, #0]

		if (t == NULL) {
			sys_dlist_append(&timeout_list, &to->node);
		}

		if (to == first() && announce_remaining == 0) {
70002770:	1a20      	subs	r0, r4, r0
70002772:	bf18      	it	ne
70002774:	2001      	movne	r0, #1
70002776:	42a6      	cmp	r6, r4
70002778:	bf18      	it	ne
7000277a:	2000      	movne	r0, #0
7000277c:	b910      	cbnz	r0, 70002784 <z_add_timeout+0xb0>
	if (key != 0U) {
7000277e:	b907      	cbnz	r7, 70002782 <z_add_timeout+0xae>
70002780:	b662      	cpsie	i
			sys_clock_set_timeout(next_timeout(), false);
		}
	}
}
70002782:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		if (to == first() && announce_remaining == 0) {
70002784:	f646 43b8 	movw	r3, #27832	; 0x6cb8
70002788:	f2c7 0300 	movt	r3, #28672	; 0x7000
7000278c:	681b      	ldr	r3, [r3, #0]
7000278e:	2b00      	cmp	r3, #0
70002790:	d1f5      	bne.n	7000277e <z_add_timeout+0xaa>
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002792:	f7ff f8fd 	bl	70001990 <sys_clock_elapsed>
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
70002796:	6923      	ldr	r3, [r4, #16]
70002798:	6962      	ldr	r2, [r4, #20]
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
7000279a:	4601      	mov	r1, r0
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
7000279c:	1a18      	subs	r0, r3, r0
7000279e:	eb62 73e1 	sbc.w	r3, r2, r1, asr #31
			sys_clock_set_timeout(next_timeout(), false);
700027a2:	2100      	movs	r1, #0
		ret = MAX(0, to->dticks - ticks_elapsed);
700027a4:	2b00      	cmp	r3, #0
700027a6:	bfbc      	itt	lt
700027a8:	2000      	movlt	r0, #0
700027aa:	2300      	movlt	r3, #0
			sys_clock_set_timeout(next_timeout(), false);
700027ac:	f1b0 4f00 	cmp.w	r0, #2147483648	; 0x80000000
700027b0:	f173 0300 	sbcs.w	r3, r3, #0
700027b4:	bfa8      	it	ge
700027b6:	f06f 4000 	mvnge.w	r0, #2147483648	; 0x80000000
700027ba:	f7ff f8b9 	bl	70001930 <sys_clock_set_timeout>
700027be:	e7de      	b.n	7000277e <z_add_timeout+0xaa>
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
700027c0:	f646 42b8 	movw	r2, #27832	; 0x6cb8
			to->dticks = timeout.ticks + 1 + elapsed();
700027c4:	3401      	adds	r4, #1
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
700027c6:	f2c7 0200 	movt	r2, #28672	; 0x7000
			to->dticks = timeout.ticks + 1 + elapsed();
700027ca:	f145 0500 	adc.w	r5, r5, #0
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
700027ce:	6813      	ldr	r3, [r2, #0]
700027d0:	2b00      	cmp	r3, #0
700027d2:	d1ab      	bne.n	7000272c <z_add_timeout+0x58>
700027d4:	f7ff f8dc 	bl	70001990 <sys_clock_elapsed>
			to->dticks = timeout.ticks + 1 + elapsed();
700027d8:	1904      	adds	r4, r0, r4
700027da:	eb45 75e0 	adc.w	r5, r5, r0, asr #31
700027de:	e7a5      	b.n	7000272c <z_add_timeout+0x58>
				t->dticks -= to->dticks;
700027e0:	1b1b      	subs	r3, r3, r4
	sys_dnode_t *const prev = successor->prev;
700027e2:	6854      	ldr	r4, [r2, #4]
700027e4:	eb61 0105 	sbc.w	r1, r1, r5
700027e8:	e9c2 3104 	strd	r3, r1, [r2, #16]
	node->next = successor;
700027ec:	e9c6 2400 	strd	r2, r4, [r6]
	prev->next = node;
700027f0:	6026      	str	r6, [r4, #0]
	successor->prev = node;
700027f2:	6056      	str	r6, [r2, #4]
		if (t == NULL) {
700027f4:	e7bb      	b.n	7000276e <z_add_timeout+0x9a>
700027f6:	4770      	bx	lr

700027f8 <z_abort_timeout>:

int z_abort_timeout(struct _timeout *to)
{
700027f8:	b430      	push	{r4, r5}
	__asm__ volatile(
700027fa:	f3ef 8500 	mrs	r5, CPSR
700027fe:	f005 0580 	and.w	r5, r5, #128	; 0x80
70002802:	b672      	cpsid	i
	return node->next != NULL;
70002804:	6802      	ldr	r2, [r0, #0]
	int ret = -EINVAL;

	K_SPINLOCK(&timeout_lock) {
		if (sys_dnode_is_linked(&to->node)) {
70002806:	b1e2      	cbz	r2, 70002842 <z_abort_timeout+0x4a>
	return (node == list->tail) ? NULL : node->next;
70002808:	f24b 1190 	movw	r1, #45456	; 0xb190
7000280c:	4603      	mov	r3, r0
7000280e:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002812:	6849      	ldr	r1, [r1, #4]
70002814:	4288      	cmp	r0, r1
70002816:	d009      	beq.n	7000282c <z_abort_timeout+0x34>
		next(t)->dticks += t->dticks;
70002818:	6904      	ldr	r4, [r0, #16]
7000281a:	6911      	ldr	r1, [r2, #16]
7000281c:	6950      	ldr	r0, [r2, #20]
7000281e:	1909      	adds	r1, r1, r4
70002820:	695c      	ldr	r4, [r3, #20]
70002822:	eb40 0004 	adc.w	r0, r0, r4
70002826:	e9c2 1004 	strd	r1, r0, [r2, #16]
	sys_dnode_t *const next = node->next;
7000282a:	681a      	ldr	r2, [r3, #0]
	sys_dnode_t *const prev = node->prev;
7000282c:	685c      	ldr	r4, [r3, #4]
	node->next = NULL;
7000282e:	2100      	movs	r1, #0
	prev->next = next;
70002830:	6022      	str	r2, [r4, #0]
			remove_timeout(to);
			ret = 0;
70002832:	4608      	mov	r0, r1
	next->prev = prev;
70002834:	6054      	str	r4, [r2, #4]
	node->next = NULL;
70002836:	6019      	str	r1, [r3, #0]
70002838:	6059      	str	r1, [r3, #4]
	if (key != 0U) {
7000283a:	b905      	cbnz	r5, 7000283e <z_abort_timeout+0x46>
7000283c:	b662      	cpsie	i
		}
	}

	return ret;
}
7000283e:	bc30      	pop	{r4, r5}
70002840:	4770      	bx	lr
	int ret = -EINVAL;
70002842:	f06f 0015 	mvn.w	r0, #21
70002846:	e7f8      	b.n	7000283a <z_abort_timeout+0x42>

70002848 <sys_clock_announce>:
	}
	return ret;
}

void sys_clock_announce(int32_t ticks)
{
70002848:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
7000284c:	4603      	mov	r3, r0
	__asm__ volatile(
7000284e:	f3ef 8800 	mrs	r8, CPSR
70002852:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002856:	b672      	cpsid	i
	return list->head == list;
70002858:	f24b 1990 	movw	r9, #45456	; 0xb190
		announce_remaining += ticks;
		k_spin_unlock(&timeout_lock, key);
		return;
	}

	announce_remaining = ticks;
7000285c:	f646 4ab8 	movw	sl, #27832	; 0x6cb8
70002860:	f2c7 0900 	movt	r9, #28672	; 0x7000
70002864:	f2c7 0a00 	movt	sl, #28672	; 0x7000
70002868:	f8ca 0000 	str.w	r0, [sl]
7000286c:	f8d9 0000 	ldr.w	r0, [r9]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002870:	4548      	cmp	r0, r9
70002872:	bf04      	itt	eq
70002874:	f245 3580 	movweq	r5, #21376	; 0x5380
70002878:	f2c7 0500 	movteq	r5, #28672	; 0x7000
7000287c:	d068      	beq.n	70002950 <sys_clock_announce+0x108>

	struct _timeout *t;

	for (t = first();
	     (t != NULL) && (t->dticks <= announce_remaining);
7000287e:	2800      	cmp	r0, #0
70002880:	d076      	beq.n	70002970 <sys_clock_announce+0x128>
70002882:	f245 3580 	movw	r5, #21376	; 0x5380
	node->next = NULL;
70002886:	f04f 0b00 	mov.w	fp, #0
	     t = first()) {
		int dt = t->dticks;

		curr_tick += dt;
		t->dticks = 0;
7000288a:	2600      	movs	r6, #0
7000288c:	f2c7 0500 	movt	r5, #28672	; 0x7000
70002890:	2700      	movs	r7, #0
	     (t != NULL) && (t->dticks <= announce_remaining);
70002892:	e9d0 4204 	ldrd	r4, r2, [r0, #16]
70002896:	17d9      	asrs	r1, r3, #31
70002898:	42a3      	cmp	r3, r4
7000289a:	eb71 0c02 	sbcs.w	ip, r1, r2
7000289e:	db29      	blt.n	700028f4 <sys_clock_announce+0xac>
		curr_tick += dt;
700028a0:	e9d5 3200 	ldrd	r3, r2, [r5]
	sys_dnode_t *const prev = node->prev;
700028a4:	6841      	ldr	r1, [r0, #4]
		t->dticks = 0;
700028a6:	e9c0 6704 	strd	r6, r7, [r0, #16]
		curr_tick += dt;
700028aa:	191b      	adds	r3, r3, r4
700028ac:	eb42 72e4 	adc.w	r2, r2, r4, asr #31
700028b0:	602b      	str	r3, [r5, #0]
	sys_dnode_t *const next = node->next;
700028b2:	6803      	ldr	r3, [r0, #0]
	prev->next = next;
700028b4:	600b      	str	r3, [r1, #0]
700028b6:	606a      	str	r2, [r5, #4]
	next->prev = prev;
700028b8:	6059      	str	r1, [r3, #4]
	node->next = NULL;
700028ba:	f8c0 b000 	str.w	fp, [r0]
700028be:	f8c0 b004 	str.w	fp, [r0, #4]
	if (key != 0U) {
700028c2:	f1b8 0f00 	cmp.w	r8, #0
700028c6:	d100      	bne.n	700028ca <sys_clock_announce+0x82>
700028c8:	b662      	cpsie	i
		remove_timeout(t);

		k_spin_unlock(&timeout_lock, key);
		t->fn(t);
700028ca:	6883      	ldr	r3, [r0, #8]
700028cc:	4798      	blx	r3
	__asm__ volatile(
700028ce:	f3ef 8800 	mrs	r8, CPSR
700028d2:	f008 0880 	and.w	r8, r8, #128	; 0x80
700028d6:	b672      	cpsid	i
		key = k_spin_lock(&timeout_lock);
		announce_remaining -= dt;
700028d8:	f8da 3000 	ldr.w	r3, [sl]
	return list->head == list;
700028dc:	f8d9 0000 	ldr.w	r0, [r9]
700028e0:	1b1b      	subs	r3, r3, r4
	return sys_dlist_is_empty(list) ? NULL : list->head;
700028e2:	4548      	cmp	r0, r9
700028e4:	f8ca 3000 	str.w	r3, [sl]
700028e8:	d032      	beq.n	70002950 <sys_clock_announce+0x108>
	     (t != NULL) && (t->dticks <= announce_remaining);
700028ea:	2800      	cmp	r0, #0
700028ec:	d1d1      	bne.n	70002892 <sys_clock_announce+0x4a>
	return list->head == list;
700028ee:	4604      	mov	r4, r0
700028f0:	17d9      	asrs	r1, r3, #31
700028f2:	e006      	b.n	70002902 <sys_clock_announce+0xba>
	}

	if (t != NULL) {
		t->dticks -= announce_remaining;
700028f4:	1ae4      	subs	r4, r4, r3
700028f6:	eb62 0201 	sbc.w	r2, r2, r1
700028fa:	6104      	str	r4, [r0, #16]
700028fc:	f8d9 4000 	ldr.w	r4, [r9]
70002900:	6142      	str	r2, [r0, #20]
	}

	curr_tick += announce_remaining;
70002902:	682a      	ldr	r2, [r5, #0]
70002904:	18d2      	adds	r2, r2, r3
70002906:	686b      	ldr	r3, [r5, #4]
70002908:	602a      	str	r2, [r5, #0]
7000290a:	eb43 0301 	adc.w	r3, r3, r1
	return sys_dlist_is_empty(list) ? NULL : list->head;
7000290e:	454c      	cmp	r4, r9
70002910:	606b      	str	r3, [r5, #4]
	announce_remaining = 0;
70002912:	f04f 0300 	mov.w	r3, #0
70002916:	f8ca 3000 	str.w	r3, [sl]
7000291a:	d024      	beq.n	70002966 <sys_clock_announce+0x11e>
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
7000291c:	f7ff f838 	bl	70001990 <sys_clock_elapsed>
	if ((to == NULL) ||
70002920:	b31c      	cbz	r4, 7000296a <sys_clock_announce+0x122>
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
70002922:	e9d4 3204 	ldrd	r3, r2, [r4, #16]
70002926:	1a1b      	subs	r3, r3, r0
70002928:	eb62 72e0 	sbc.w	r2, r2, r0, asr #31
	if ((to == NULL) ||
7000292c:	f1b3 4f00 	cmp.w	r3, #2147483648	; 0x80000000
70002930:	f172 0100 	sbcs.w	r1, r2, #0
70002934:	da19      	bge.n	7000296a <sys_clock_announce+0x122>
		ret = MAX(0, to->dticks - ticks_elapsed);
70002936:	2a00      	cmp	r2, #0
70002938:	bfac      	ite	ge
7000293a:	4618      	movge	r0, r3
7000293c:	2000      	movlt	r0, #0

	sys_clock_set_timeout(next_timeout(), false);
7000293e:	2100      	movs	r1, #0
70002940:	f7fe fff6 	bl	70001930 <sys_clock_set_timeout>
	if (key != 0U) {
70002944:	f1b8 0f00 	cmp.w	r8, #0
70002948:	d100      	bne.n	7000294c <sys_clock_announce+0x104>
7000294a:	b662      	cpsie	i
	k_spin_unlock(&timeout_lock, key);

#ifdef CONFIG_TIMESLICING
	z_time_slice();
#endif /* CONFIG_TIMESLICING */
}
7000294c:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
	curr_tick += announce_remaining;
70002950:	682a      	ldr	r2, [r5, #0]
70002952:	18d2      	adds	r2, r2, r3
70002954:	602a      	str	r2, [r5, #0]
	announce_remaining = 0;
70002956:	f04f 0200 	mov.w	r2, #0
7000295a:	f8ca 2000 	str.w	r2, [sl]
	curr_tick += announce_remaining;
7000295e:	686a      	ldr	r2, [r5, #4]
70002960:	eb42 72e3 	adc.w	r2, r2, r3, asr #31
70002964:	606a      	str	r2, [r5, #4]
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002966:	f7ff f813 	bl	70001990 <sys_clock_elapsed>
		ret = MAX_WAIT;
7000296a:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
7000296e:	e7e6      	b.n	7000293e <sys_clock_announce+0xf6>
	announce_remaining = 0;
70002970:	f8ca 0000 	str.w	r0, [sl]
	curr_tick += announce_remaining;
70002974:	f245 3280 	movw	r2, #21376	; 0x5380
70002978:	f2c7 0200 	movt	r2, #28672	; 0x7000
7000297c:	e9d2 1000 	ldrd	r1, r0, [r2]
70002980:	18c9      	adds	r1, r1, r3
70002982:	eb40 70e3 	adc.w	r0, r0, r3, asr #31
70002986:	e9c2 1000 	strd	r1, r0, [r2]
7000298a:	e7ec      	b.n	70002966 <sys_clock_announce+0x11e>

7000298c <sys_clock_tick_get_32>:
	}
	return t;
}

uint32_t sys_clock_tick_get_32(void)
{
7000298c:	b510      	push	{r4, lr}
	__asm__ volatile(
7000298e:	f3ef 8400 	mrs	r4, CPSR
70002992:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002996:	b672      	cpsid	i
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002998:	f646 43b8 	movw	r3, #27832	; 0x6cb8
7000299c:	2000      	movs	r0, #0
7000299e:	f2c7 0300 	movt	r3, #28672	; 0x7000
700029a2:	681b      	ldr	r3, [r3, #0]
700029a4:	b90b      	cbnz	r3, 700029aa <sys_clock_tick_get_32+0x1e>
700029a6:	f7fe fff3 	bl	70001990 <sys_clock_elapsed>
		t = curr_tick + elapsed();
700029aa:	f245 3380 	movw	r3, #21376	; 0x5380
700029ae:	f2c7 0300 	movt	r3, #28672	; 0x7000
700029b2:	681b      	ldr	r3, [r3, #0]
700029b4:	18c0      	adds	r0, r0, r3
	if (key != 0U) {
700029b6:	b904      	cbnz	r4, 700029ba <sys_clock_tick_get_32+0x2e>
700029b8:	b662      	cpsie	i
#ifdef CONFIG_TICKLESS_KERNEL
	return (uint32_t)sys_clock_tick_get();
#else
	return (uint32_t)curr_tick;
#endif /* CONFIG_TICKLESS_KERNEL */
}
700029ba:	bd10      	pop	{r4, pc}

700029bc <signal_poll_event.constprop.0>:
}
#include <zephyr/syscalls/k_poll_mrsh.c>
#endif /* CONFIG_USERSPACE */

/* must be called with interrupts locked */
static int signal_poll_event(struct k_poll_event *event, uint32_t state)
700029bc:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
{
	struct z_poller *poller = event->poller;
700029c0:	6886      	ldr	r6, [r0, #8]
static int signal_poll_event(struct k_poll_event *event, uint32_t state)
700029c2:	4604      	mov	r4, r0
700029c4:	460d      	mov	r5, r1
	int retcode = 0;

	if (poller != NULL) {
700029c6:	b136      	cbz	r6, 700029d6 <signal_poll_event.constprop.0+0x1a>
		if (poller->mode == MODE_POLL) {
700029c8:	7873      	ldrb	r3, [r6, #1]
700029ca:	2b01      	cmp	r3, #1
700029cc:	d022      	beq.n	70002a14 <signal_poll_event.constprop.0+0x58>
			retcode = signal_poller(event, state);
		} else if (poller->mode == MODE_TRIGGERED) {
700029ce:	2b02      	cmp	r3, #2
700029d0:	d00c      	beq.n	700029ec <signal_poll_event.constprop.0+0x30>
		} else {
			/* Poller is not poll or triggered mode. No action needed.*/
			;
		}

		poller->is_polling = false;
700029d2:	2300      	movs	r3, #0
700029d4:	7033      	strb	r3, [r6, #0]
	event->state |= state;
700029d6:	68e3      	ldr	r3, [r4, #12]
	event->poller = NULL;
700029d8:	2000      	movs	r0, #0
700029da:	60a0      	str	r0, [r4, #8]
	event->state |= state;
700029dc:	f3c3 3286 	ubfx	r2, r3, #14, #7
700029e0:	4315      	orrs	r5, r2
700029e2:	f365 3394 	bfi	r3, r5, #14, #7
700029e6:	60e3      	str	r3, [r4, #12]
		}
	}

	set_event_ready(event, state);
	return retcode;
}
700029e8:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
{
	struct z_poller *poller = event->poller;
	struct k_work_poll *twork =
		CONTAINER_OF(poller, struct k_work_poll, poller);

	if (poller->is_polling && twork->workq != NULL) {
700029ec:	7833      	ldrb	r3, [r6, #0]
700029ee:	2b00      	cmp	r3, #0
700029f0:	d0ef      	beq.n	700029d2 <signal_poll_event.constprop.0+0x16>
700029f2:	f856 7c04 	ldr.w	r7, [r6, #-4]
700029f6:	2f00      	cmp	r7, #0
700029f8:	d0eb      	beq.n	700029d2 <signal_poll_event.constprop.0+0x16>
		struct k_work_q *work_q = twork->workq;

		z_abort_timeout(&twork->timeout);
700029fa:	f106 0014 	add.w	r0, r6, #20
700029fe:	f7ff fefb 	bl	700027f8 <z_abort_timeout>
		twork->poll_result = 0;
70002a02:	2300      	movs	r3, #0
		z_work_submit_to_queue(work_q, &twork->work);
70002a04:	4638      	mov	r0, r7
		z_abort_timeout(&twork->timeout);
70002a06:	f1a6 0814 	sub.w	r8, r6, #20
		twork->poll_result = 0;
70002a0a:	62f3      	str	r3, [r6, #44]	; 0x2c
		z_work_submit_to_queue(work_q, &twork->work);
70002a0c:	4641      	mov	r1, r8
70002a0e:	f000 f977 	bl	70002d00 <z_work_submit_to_queue>
70002a12:	e7de      	b.n	700029d2 <signal_poll_event.constprop.0+0x16>
	if (!z_is_thread_pending(thread)) {
70002a14:	f816 3c53 	ldrb.w	r3, [r6, #-83]
70002a18:	079a      	lsls	r2, r3, #30
70002a1a:	d5da      	bpl.n	700029d2 <signal_poll_event.constprop.0+0x16>
	return p ? CONTAINER_OF(p, struct k_thread, poller) : NULL;
70002a1c:	f1a6 0760 	sub.w	r7, r6, #96	; 0x60
	z_unpend_thread(thread);
70002a20:	4638      	mov	r0, r7
70002a22:	f7ff fc97 	bl	70002354 <z_unpend_thread>
	arch_thread_return_value_set(thread,
70002a26:	2d08      	cmp	r5, #8
70002a28:	bf14      	ite	ne
70002a2a:	2300      	movne	r3, #0
70002a2c:	f06f 0303 	mvneq.w	r3, #3
70002a30:	6133      	str	r3, [r6, #16]
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
70002a32:	f816 3c53 	ldrb.w	r3, [r6, #-83]
70002a36:	06db      	lsls	r3, r3, #27
70002a38:	d1cb      	bne.n	700029d2 <signal_poll_event.constprop.0+0x16>
70002a3a:	f856 3c48 	ldr.w	r3, [r6, #-72]
70002a3e:	2b00      	cmp	r3, #0
70002a40:	d1c7      	bne.n	700029d2 <signal_poll_event.constprop.0+0x16>
	z_ready_thread(thread);
70002a42:	4638      	mov	r0, r7
70002a44:	f7ff fbca 	bl	700021dc <z_ready_thread>
	return 0;
70002a48:	e7c3      	b.n	700029d2 <signal_poll_event.constprop.0+0x16>
70002a4a:	bf00      	nop

70002a4c <z_handle_obj_poll_events>:
{
70002a4c:	4603      	mov	r3, r0
70002a4e:	b510      	push	{r4, lr}
	__asm__ volatile(
70002a50:	f3ef 8400 	mrs	r4, CPSR
70002a54:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002a58:	b672      	cpsid	i
	return list->head == list;
70002a5a:	6800      	ldr	r0, [r0, #0]

static inline sys_dnode_t *sys_dlist_get(sys_dlist_t *list)
{
	sys_dnode_t *node = NULL;

	if (!sys_dlist_is_empty(list)) {
70002a5c:	4283      	cmp	r3, r0
70002a5e:	d008      	beq.n	70002a72 <z_handle_obj_poll_events+0x26>
	sys_dnode_t *const next = node->next;
70002a60:	e9d0 3200 	ldrd	r3, r2, [r0]
	prev->next = next;
70002a64:	6013      	str	r3, [r2, #0]
	next->prev = prev;
70002a66:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70002a68:	2300      	movs	r3, #0
70002a6a:	6003      	str	r3, [r0, #0]
70002a6c:	6043      	str	r3, [r0, #4]
		(void) signal_poll_event(poll_event, state);
70002a6e:	f7ff ffa5 	bl	700029bc <signal_poll_event.constprop.0>
	if (key != 0U) {
70002a72:	b904      	cbnz	r4, 70002a76 <z_handle_obj_poll_events+0x2a>
70002a74:	b662      	cpsie	i
}
70002a76:	bd10      	pop	{r4, pc}

70002a78 <boot_banner>:
	  */
	printk("\x1b[3J\x1b[2J\x1b[H");
#endif /* CONFIG_BOOT_CLEAR_SCREEN */

#ifdef CONFIG_BOOT_BANNER
	printk("*** " CONFIG_BOOT_BANNER_STRING " " BANNER_VERSION BANNER_POSTFIX " ***\n");
70002a78:	f644 4094 	movw	r0, #19604	; 0x4c94
70002a7c:	f2c7 0000 	movt	r0, #28672	; 0x7000
70002a80:	f7fd bf84 	b.w	7000098c <printk>

70002a84 <statics_init>:

	SYS_PORT_TRACING_OBJ_INIT(k_heap, heap);
}

static int statics_init(void)
{
70002a84:	b538      	push	{r3, r4, r5, lr}
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70002a86:	f24b 149c 	movw	r4, #45468	; 0xb19c
70002a8a:	f24b 159c 	movw	r5, #45468	; 0xb19c
70002a8e:	f2c7 0400 	movt	r4, #28672	; 0x7000
70002a92:	f2c7 0500 	movt	r5, #28672	; 0x7000
70002a96:	42ac      	cmp	r4, r5
70002a98:	d20b      	bcs.n	70002ab2 <statics_init+0x2e>
	sys_heap_init(&heap->heap, mem, bytes);
70002a9a:	e9d4 1201 	ldrd	r1, r2, [r4, #4]
70002a9e:	f104 030c 	add.w	r3, r4, #12
70002aa2:	4620      	mov	r0, r4
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70002aa4:	3414      	adds	r4, #20
	list->head = (sys_dnode_t *)list;
70002aa6:	601b      	str	r3, [r3, #0]
70002aa8:	605b      	str	r3, [r3, #4]
	sys_heap_init(&heap->heap, mem, bytes);
70002aaa:	f7fd ff2b 	bl	70000904 <sys_heap_init>
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70002aae:	42ac      	cmp	r4, r5
70002ab0:	d3f3      	bcc.n	70002a9a <statics_init+0x16>
		{
			k_heap_init(heap, heap->heap.init_mem, heap->heap.init_bytes);
		}
	}
	return 0;
}
70002ab2:	2000      	movs	r0, #0
70002ab4:	bd38      	pop	{r3, r4, r5, pc}
70002ab6:	bf00      	nop

70002ab8 <k_sys_work_q_init>:

struct k_work_q k_sys_work_q;

static int k_sys_work_q_init(void)
{
	struct k_work_queue_config cfg = {
70002ab8:	f644 2154 	movw	r1, #19028	; 0x4a54
		.name = "sysworkq",
		.no_yield = IS_ENABLED(CONFIG_SYSTEM_WORKQUEUE_NO_YIELD),
		.essential = true,
	};

	k_work_queue_start(&k_sys_work_q,
70002abc:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
	struct k_work_queue_config cfg = {
70002ac0:	f2c7 0100 	movt	r1, #28672	; 0x7000
{
70002ac4:	b510      	push	{r4, lr}
	struct k_work_queue_config cfg = {
70002ac6:	c903      	ldmia	r1, {r0, r1}
{
70002ac8:	b084      	sub	sp, #16
	k_work_queue_start(&k_sys_work_q,
70002aca:	f44f 6280 	mov.w	r2, #1024	; 0x400
	struct k_work_queue_config cfg = {
70002ace:	ac02      	add	r4, sp, #8
	k_work_queue_start(&k_sys_work_q,
70002ad0:	9400      	str	r4, [sp, #0]
	struct k_work_queue_config cfg = {
70002ad2:	e884 0003 	stmia.w	r4, {r0, r1}
	k_work_queue_start(&k_sys_work_q,
70002ad6:	f64a 41c0 	movw	r1, #44224	; 0xacc0
70002ada:	f245 3088 	movw	r0, #21384	; 0x5388
70002ade:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002ae2:	f2c7 0000 	movt	r0, #28672	; 0x7000
70002ae6:	f000 f91b 	bl	70002d20 <k_work_queue_start>
			    sys_work_q_stack,
			    K_KERNEL_STACK_SIZEOF(sys_work_q_stack),
			    CONFIG_SYSTEM_WORKQUEUE_PRIORITY, &cfg);
	return 0;
}
70002aea:	2000      	movs	r0, #0
70002aec:	b004      	add	sp, #16
70002aee:	bd10      	pop	{r4, pc}

70002af0 <work_queue_main>:
/* Loop executed by a work queue thread.
 *
 * @param workq_ptr pointer to the work queue structure
 */
static void work_queue_main(void *workq_ptr, void *p2, void *p3)
{
70002af0:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
 *
 * @return A pointer on the first node of the list (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_head(sys_slist_t *list)
{
	return list->head;
70002af4:	f245 4620 	movw	r6, #21536	; 0x5420
70002af8:	b084      	sub	sp, #16
70002afa:	4605      	mov	r5, r0
70002afc:	f2c7 0600 	movt	r6, #28672	; 0x7000
	return node->next;
70002b00:	2700      	movs	r7, #0
	__asm__ volatile(
70002b02:	f3ef 8800 	mrs	r8, CPSR
70002b06:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002b0a:	b672      	cpsid	i
	return list->head;
70002b0c:	6fac      	ldr	r4, [r5, #120]	; 0x78
 *
 * @return A pointer to the first node of the list (or NULL if empty)
 */
static inline sys_snode_t *sys_slist_get(sys_slist_t *list);

Z_GENLIST_GET(slist, snode)
70002b0e:	2c00      	cmp	r4, #0
70002b10:	d060      	beq.n	70002bd4 <work_queue_main+0xe4>
Z_GENLIST_GET_NOT_EMPTY(slist, snode)
70002b12:	6fea      	ldr	r2, [r5, #124]	; 0x7c
	return node->next;
70002b14:	6823      	ldr	r3, [r4, #0]
	list->head = node;
70002b16:	67ab      	str	r3, [r5, #120]	; 0x78
Z_GENLIST_GET_NOT_EMPTY(slist, snode)
70002b18:	4294      	cmp	r4, r2
	list->tail = node;
70002b1a:	bf08      	it	eq
70002b1c:	67eb      	streq	r3, [r5, #124]	; 0x7c
	*flagp |= BIT(bit);
70002b1e:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
70002b22:	f043 0302 	orr.w	r3, r3, #2
70002b26:	f8c5 3090 	str.w	r3, [r5, #144]	; 0x90
	*flagp &= ~BIT(bit);
70002b2a:	68e3      	ldr	r3, [r4, #12]
			 * of struct k_work object that has been placed at address NULL,
			 * which should never happen, even line 'if (work != NULL)'
			 * ensures that.
			 * This means that if node is not NULL, then work will not be NULL.
			 */
			handler = work->handler;
70002b2c:	6862      	ldr	r2, [r4, #4]
	*flagp &= ~BIT(bit);
70002b2e:	f023 0304 	bic.w	r3, r3, #4
70002b32:	f043 0301 	orr.w	r3, r3, #1
70002b36:	60e3      	str	r3, [r4, #12]
	if (key != 0U) {
70002b38:	f1b8 0f00 	cmp.w	r8, #0
70002b3c:	d100      	bne.n	70002b40 <work_queue_main+0x50>
70002b3e:	b662      	cpsie	i
		}

		k_spin_unlock(&lock, key);

		__ASSERT_NO_MSG(handler != NULL);
		handler(work);
70002b40:	4620      	mov	r0, r4
70002b42:	4790      	blx	r2
	__asm__ volatile(
70002b44:	f3ef 8800 	mrs	r8, CPSR
70002b48:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002b4c:	b672      	cpsid	i
	*flagp &= ~BIT(bit);
70002b4e:	68e2      	ldr	r2, [r4, #12]
70002b50:	f022 0301 	bic.w	r3, r2, #1
		 * yield to prevent starving other threads.
		 */
		key = k_spin_lock(&lock);

		flag_clear(&work->flags, K_WORK_RUNNING_BIT);
		if (flag_test(&work->flags, K_WORK_FLUSHING_BIT)) {
70002b54:	06d1      	lsls	r1, r2, #27
	*flagp &= ~BIT(bit);
70002b56:	bf58      	it	pl
70002b58:	60e3      	strpl	r3, [r4, #12]
		if (flag_test(&work->flags, K_WORK_FLUSHING_BIT)) {
70002b5a:	d432      	bmi.n	70002bc2 <work_queue_main+0xd2>
			finalize_flush_locked(work);
		}
		if (flag_test(&work->flags, K_WORK_CANCELING_BIT)) {
70002b5c:	079a      	lsls	r2, r3, #30
70002b5e:	d410      	bmi.n	70002b82 <work_queue_main+0x92>
	*flagp &= ~BIT(bit);
70002b60:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
70002b64:	f023 0302 	bic.w	r3, r3, #2
	return (*flagp & BIT(bit)) != 0U;
70002b68:	f3c3 2200 	ubfx	r2, r3, #8, #1
	*flagp &= ~BIT(bit);
70002b6c:	f8c5 3090 	str.w	r3, [r5, #144]	; 0x90
	if (key != 0U) {
70002b70:	f1b8 0f00 	cmp.w	r8, #0
70002b74:	d100      	bne.n	70002b78 <work_queue_main+0x88>
70002b76:	b662      	cpsie	i
		k_spin_unlock(&lock, key);

		/* Optionally yield to prevent the work queue from
		 * starving other threads.
		 */
		if (yield) {
70002b78:	2a00      	cmp	r2, #0
70002b7a:	d1c2      	bne.n	70002b02 <work_queue_main+0x12>
70002b7c:	f7ff fc7a 	bl	70002474 <z_impl_k_yield>
}
70002b80:	e7bf      	b.n	70002b02 <work_queue_main+0x12>
	return list->head;
70002b82:	6830      	ldr	r0, [r6, #0]
	*flagp &= ~BIT(bit);
70002b84:	f023 0302 	bic.w	r3, r3, #2
70002b88:	60e3      	str	r3, [r4, #12]
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(&pending_cancels, wc, tmp, node) {
70002b8a:	2800      	cmp	r0, #0
70002b8c:	d0e8      	beq.n	70002b60 <work_queue_main+0x70>
		if (wc->work == work) {
70002b8e:	6842      	ldr	r2, [r0, #4]
	return node->next;
70002b90:	2100      	movs	r1, #0
70002b92:	6803      	ldr	r3, [r0, #0]
70002b94:	4294      	cmp	r4, r2
70002b96:	d007      	beq.n	70002ba8 <work_queue_main+0xb8>
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(&pending_cancels, wc, tmp, node) {
70002b98:	2b00      	cmp	r3, #0
70002b9a:	d0e1      	beq.n	70002b60 <work_queue_main+0x70>
			sys_slist_remove(&pending_cancels, prev, &wc->node);
70002b9c:	4601      	mov	r1, r0
70002b9e:	4618      	mov	r0, r3
Z_GENLIST_PEEK_NEXT(slist, snode)
70002ba0:	681b      	ldr	r3, [r3, #0]
		if (wc->work == work) {
70002ba2:	6842      	ldr	r2, [r0, #4]
70002ba4:	4294      	cmp	r4, r2
70002ba6:	d1f7      	bne.n	70002b98 <work_queue_main+0xa8>
	return node->next;
70002ba8:	6803      	ldr	r3, [r0, #0]
 */
static inline void sys_slist_remove(sys_slist_t *list,
				    sys_snode_t *prev_node,
				    sys_snode_t *node);

Z_GENLIST_REMOVE(slist, snode)
70002baa:	2900      	cmp	r1, #0
70002bac:	d042      	beq.n	70002c34 <work_queue_main+0x144>
	parent->next = child;
70002bae:	600b      	str	r3, [r1, #0]
Z_GENLIST_REMOVE(slist, snode)
70002bb0:	6873      	ldr	r3, [r6, #4]
70002bb2:	4283      	cmp	r3, r0
	list->tail = node;
70002bb4:	bf08      	it	eq
70002bb6:	6071      	streq	r1, [r6, #4]
	parent->next = child;
70002bb8:	f840 7b08 	str.w	r7, [r0], #8
	z_impl_k_sem_give(sem);
70002bbc:	f7ff f8fc 	bl	70001db8 <z_impl_k_sem_give>
}
70002bc0:	e7ce      	b.n	70002b60 <work_queue_main+0x70>
	*flagp &= ~BIT(bit);
70002bc2:	f022 0211 	bic.w	r2, r2, #17
70002bc6:	60e2      	str	r2, [r4, #12]
	z_impl_k_sem_give(sem);
70002bc8:	f104 0010 	add.w	r0, r4, #16
70002bcc:	f7ff f8f4 	bl	70001db8 <z_impl_k_sem_give>
	return (*flagp & BIT(bit)) != 0U;
70002bd0:	68e3      	ldr	r3, [r4, #12]
};
70002bd2:	e7c3      	b.n	70002b5c <work_queue_main+0x6c>
	return (*flagp & BIT(bit)) != 0U;
70002bd4:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
	*flagp &= ~BIT(bit);
70002bd8:	f023 0204 	bic.w	r2, r3, #4
		} else if (flag_test_and_clear(&queue->flags,
70002bdc:	075c      	lsls	r4, r3, #29
	*flagp &= ~BIT(bit);
70002bde:	f8c5 2090 	str.w	r2, [r5, #144]	; 0x90
		} else if (flag_test_and_clear(&queue->flags,
70002be2:	f3c3 0180 	ubfx	r1, r3, #2, #1
70002be6:	d40a      	bmi.n	70002bfe <work_queue_main+0x10e>
		} else if (flag_test(&queue->flags, K_WORK_QUEUE_STOP_BIT)) {
70002be8:	06d0      	lsls	r0, r2, #27
70002bea:	d511      	bpl.n	70002c10 <work_queue_main+0x120>
	*flagp = flags;
70002bec:	f8c5 1090 	str.w	r1, [r5, #144]	; 0x90
70002bf0:	f1b8 0f00 	cmp.w	r8, #0
70002bf4:	d100      	bne.n	70002bf8 <work_queue_main+0x108>
70002bf6:	b662      	cpsie	i
			k_yield();
		}
	}
}
70002bf8:	b004      	add	sp, #16
70002bfa:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
			(void)z_sched_wake_all(&queue->drainq, 1, NULL);
70002bfe:	f105 0488 	add.w	r4, r5, #136	; 0x88
static inline bool z_sched_wake_all(_wait_q_t *wait_q, int swap_retval,
				    void *swap_data)
{
	bool woken = false;

	while (z_sched_wake(wait_q, swap_retval, swap_data)) {
70002c02:	2200      	movs	r2, #0
70002c04:	2101      	movs	r1, #1
70002c06:	4620      	mov	r0, r4
70002c08:	f7ff fd22 	bl	70002650 <z_sched_wake>
70002c0c:	2800      	cmp	r0, #0
70002c0e:	d1f8      	bne.n	70002c02 <work_queue_main+0x112>
					   K_FOREVER, NULL);
70002c10:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
70002c14:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
			(void)z_sched_wait(&lock, key, &queue->notifyq,
70002c18:	f646 40bc 	movw	r0, #27836	; 0x6cbc
70002c1c:	4641      	mov	r1, r8
70002c1e:	e9cd 2300 	strd	r2, r3, [sp]
70002c22:	2300      	movs	r3, #0
70002c24:	f105 0280 	add.w	r2, r5, #128	; 0x80
70002c28:	9302      	str	r3, [sp, #8]
70002c2a:	f2c7 0000 	movt	r0, #28672	; 0x7000
70002c2e:	f7ff fd3d 	bl	700026ac <z_sched_wait>
			continue;
70002c32:	e766      	b.n	70002b02 <work_queue_main+0x12>
Z_GENLIST_REMOVE(slist, snode)
70002c34:	6872      	ldr	r2, [r6, #4]
	list->head = node;
70002c36:	6033      	str	r3, [r6, #0]
Z_GENLIST_REMOVE(slist, snode)
70002c38:	4282      	cmp	r2, r0
	list->tail = node;
70002c3a:	bf08      	it	eq
70002c3c:	6073      	streq	r3, [r6, #4]
70002c3e:	e7bb      	b.n	70002bb8 <work_queue_main+0xc8>

70002c40 <submit_to_queue_locked>:
{
70002c40:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	return (*flagp & BIT(bit)) != 0U;
70002c42:	68c3      	ldr	r3, [r0, #12]
{
70002c44:	460d      	mov	r5, r1
	if (flag_test(&work->flags, K_WORK_CANCELING_BIT)) {
70002c46:	079a      	lsls	r2, r3, #30
70002c48:	f3c3 0640 	ubfx	r6, r3, #1, #1
70002c4c:	d407      	bmi.n	70002c5e <submit_to_queue_locked+0x1e>
	} else if (!flag_test(&work->flags, K_WORK_QUEUED_BIT)) {
70002c4e:	075f      	lsls	r7, r3, #29
	return (*flagp & BIT(bit)) != 0U;
70002c50:	f3c3 0280 	ubfx	r2, r3, #2, #1
	} else if (!flag_test(&work->flags, K_WORK_QUEUED_BIT)) {
70002c54:	d506      	bpl.n	70002c64 <submit_to_queue_locked+0x24>
		*queuep = NULL;
70002c56:	2300      	movs	r3, #0
}
70002c58:	4630      	mov	r0, r6
		*queuep = NULL;
70002c5a:	602b      	str	r3, [r5, #0]
}
70002c5c:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		ret = -EBUSY;
70002c5e:	f06f 060f 	mvn.w	r6, #15
70002c62:	e7f8      	b.n	70002c56 <submit_to_queue_locked+0x16>
		if (*queuep == NULL) {
70002c64:	680f      	ldr	r7, [r1, #0]
70002c66:	4604      	mov	r4, r0
70002c68:	2f00      	cmp	r7, #0
70002c6a:	d032      	beq.n	70002cd2 <submit_to_queue_locked+0x92>
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002c6c:	07db      	lsls	r3, r3, #31
		ret = 1;
70002c6e:	bf58      	it	pl
70002c70:	2601      	movpl	r6, #1
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002c72:	d504      	bpl.n	70002c7e <submit_to_queue_locked+0x3e>
			*queuep = work->queue;
70002c74:	68a7      	ldr	r7, [r4, #8]
			ret = 2;
70002c76:	2602      	movs	r6, #2
			*queuep = work->queue;
70002c78:	602f      	str	r7, [r5, #0]
	if (queue == NULL) {
70002c7a:	2f00      	cmp	r7, #0
70002c7c:	d03d      	beq.n	70002cfa <submit_to_queue_locked+0xba>
70002c7e:	f646 4398 	movw	r3, #27800	; 0x6c98
70002c82:	f2c7 0300 	movt	r3, #28672	; 0x7000
	bool chained = (arch_current_thread() == &queue->thread) && !k_is_in_isr();
70002c86:	689b      	ldr	r3, [r3, #8]
70002c88:	42bb      	cmp	r3, r7
70002c8a:	d02d      	beq.n	70002ce8 <submit_to_queue_locked+0xa8>
	return (*flagp & BIT(bit)) != 0U;
70002c8c:	f8d7 0090 	ldr.w	r0, [r7, #144]	; 0x90
70002c90:	f3c0 0380 	ubfx	r3, r0, #2, #1
70002c94:	f3c0 01c0 	ubfx	r1, r0, #3, #1
	if (!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT)) {
70002c98:	07c0      	lsls	r0, r0, #31
70002c9a:	d52b      	bpl.n	70002cf4 <submit_to_queue_locked+0xb4>
	} else if (draining && !chained) {
70002c9c:	f082 0201 	eor.w	r2, r2, #1
70002ca0:	4213      	tst	r3, r2
70002ca2:	d1dc      	bne.n	70002c5e <submit_to_queue_locked+0x1e>
	} else if (plugged && !draining) {
70002ca4:	f083 0301 	eor.w	r3, r3, #1
70002ca8:	4019      	ands	r1, r3
70002caa:	d1d8      	bne.n	70002c5e <submit_to_queue_locked+0x1e>
	parent->next = child;
70002cac:	6021      	str	r1, [r4, #0]
	return list->tail;
70002cae:	6ffb      	ldr	r3, [r7, #124]	; 0x7c
Z_GENLIST_APPEND(slist, snode)
70002cb0:	b1bb      	cbz	r3, 70002ce2 <submit_to_queue_locked+0xa2>
	parent->next = child;
70002cb2:	601c      	str	r4, [r3, #0]
	list->tail = node;
70002cb4:	67fc      	str	r4, [r7, #124]	; 0x7c
		rv = z_sched_wake(&queue->notifyq, 0, NULL);
70002cb6:	2200      	movs	r2, #0
70002cb8:	f107 0080 	add.w	r0, r7, #128	; 0x80
70002cbc:	4611      	mov	r1, r2
70002cbe:	f7ff fcc7 	bl	70002650 <z_sched_wake>
	*flagp |= BIT(bit);
70002cc2:	68e3      	ldr	r3, [r4, #12]
}
70002cc4:	4630      	mov	r0, r6
	*flagp |= BIT(bit);
70002cc6:	f043 0304 	orr.w	r3, r3, #4
70002cca:	60e3      	str	r3, [r4, #12]
			work->queue = *queuep;
70002ccc:	682b      	ldr	r3, [r5, #0]
70002cce:	60a3      	str	r3, [r4, #8]
}
70002cd0:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
			*queuep = work->queue;
70002cd2:	6887      	ldr	r7, [r0, #8]
70002cd4:	600f      	str	r7, [r1, #0]
	return (*flagp & BIT(bit)) != 0U;
70002cd6:	68c3      	ldr	r3, [r0, #12]
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002cd8:	07de      	lsls	r6, r3, #31
		ret = 1;
70002cda:	bf58      	it	pl
70002cdc:	2601      	movpl	r6, #1
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002cde:	d5cc      	bpl.n	70002c7a <submit_to_queue_locked+0x3a>
70002ce0:	e7c8      	b.n	70002c74 <submit_to_queue_locked+0x34>
	list->head = node;
70002ce2:	67bc      	str	r4, [r7, #120]	; 0x78
70002ce4:	67fc      	str	r4, [r7, #124]	; 0x7c
	if (queue != NULL) {
70002ce6:	e7e6      	b.n	70002cb6 <submit_to_queue_locked+0x76>
	bool chained = (arch_current_thread() == &queue->thread) && !k_is_in_isr();
70002ce8:	f7ff f89c 	bl	70001e24 <k_is_in_isr>
70002cec:	f080 0201 	eor.w	r2, r0, #1
70002cf0:	b2d2      	uxtb	r2, r2
70002cf2:	e7cb      	b.n	70002c8c <submit_to_queue_locked+0x4c>
		ret = -ENODEV;
70002cf4:	f06f 0612 	mvn.w	r6, #18
70002cf8:	e7ad      	b.n	70002c56 <submit_to_queue_locked+0x16>
		return -EINVAL;
70002cfa:	f06f 0615 	mvn.w	r6, #21
70002cfe:	e7aa      	b.n	70002c56 <submit_to_queue_locked+0x16>

70002d00 <z_work_submit_to_queue>:
{
70002d00:	b510      	push	{r4, lr}
70002d02:	b082      	sub	sp, #8
70002d04:	9001      	str	r0, [sp, #4]
70002d06:	4608      	mov	r0, r1
	__asm__ volatile(
70002d08:	f3ef 8400 	mrs	r4, CPSR
70002d0c:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002d10:	b672      	cpsid	i
	int ret = submit_to_queue_locked(work, &queue);
70002d12:	a901      	add	r1, sp, #4
70002d14:	f7ff ff94 	bl	70002c40 <submit_to_queue_locked>
	if (key != 0U) {
70002d18:	b904      	cbnz	r4, 70002d1c <z_work_submit_to_queue+0x1c>
70002d1a:	b662      	cpsie	i
}
70002d1c:	b002      	add	sp, #8
70002d1e:	bd10      	pop	{r4, pc}

70002d20 <k_work_queue_start>:
void k_work_queue_start(struct k_work_q *queue,
			k_thread_stack_t *stack,
			size_t stack_size,
			int prio,
			const struct k_work_queue_config *cfg)
{
70002d20:	b5f0      	push	{r4, r5, r6, r7, lr}
70002d22:	4604      	mov	r4, r0
70002d24:	b089      	sub	sp, #36	; 0x24
	list->head = NULL;
70002d26:	2000      	movs	r0, #0
70002d28:	67a0      	str	r0, [r4, #120]	; 0x78
70002d2a:	67e0      	str	r0, [r4, #124]	; 0x7c
	sys_dlist_init(&w->waitq);
70002d2c:	f104 0080 	add.w	r0, r4, #128	; 0x80
70002d30:	9d0e      	ldr	r5, [sp, #56]	; 0x38
	list->tail = (sys_dnode_t *)list;
70002d32:	e9c4 0020 	strd	r0, r0, [r4, #128]	; 0x80
70002d36:	f104 0088 	add.w	r0, r4, #136	; 0x88
70002d3a:	e9c4 0022 	strd	r0, r0, [r4, #136]	; 0x88
	__ASSERT_NO_MSG(queue);
	__ASSERT_NO_MSG(stack);
	__ASSERT_NO_MSG(!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT));
	uint32_t flags = K_WORK_QUEUE_STARTED;
70002d3e:	2001      	movs	r0, #1

	sys_slist_init(&queue->pending);
	z_waitq_init(&queue->notifyq);
	z_waitq_init(&queue->drainq);

	if ((cfg != NULL) && cfg->no_yield) {
70002d40:	b12d      	cbz	r5, 70002d4e <k_work_queue_start+0x2e>
70002d42:	792e      	ldrb	r6, [r5, #4]
		flags |= K_WORK_QUEUE_NO_YIELD;
70002d44:	f240 1001 	movw	r0, #257	; 0x101
70002d48:	2e00      	cmp	r6, #0
70002d4a:	bf08      	it	eq
70002d4c:	2001      	moveq	r0, #1
	*flagp = flags;
70002d4e:	f04f 36ff 	mov.w	r6, #4294967295	; 0xffffffff
70002d52:	f04f 37ff 	mov.w	r7, #4294967295	; 0xffffffff
70002d56:	f8c4 0090 	str.w	r0, [r4, #144]	; 0x90
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
70002d5a:	9303      	str	r3, [sp, #12]
70002d5c:	2000      	movs	r0, #0
70002d5e:	e9cd 6706 	strd	r6, r7, [sp, #24]
70002d62:	f642 23f1 	movw	r3, #10993	; 0x2af1
70002d66:	9004      	str	r0, [sp, #16]
70002d68:	f2c7 0300 	movt	r3, #28672	; 0x7000
70002d6c:	e9cd 0001 	strd	r0, r0, [sp, #4]
70002d70:	4620      	mov	r0, r4
70002d72:	9400      	str	r4, [sp, #0]
70002d74:	f7ff f894 	bl	70001ea0 <z_impl_k_thread_create>

	(void)k_thread_create(&queue->thread, stack, stack_size,
			      work_queue_main, queue, NULL, NULL,
			      prio, 0, K_FOREVER);

	if ((cfg != NULL) && (cfg->name != NULL)) {
70002d78:	b155      	cbz	r5, 70002d90 <k_work_queue_start+0x70>
70002d7a:	6829      	ldr	r1, [r5, #0]
70002d7c:	b111      	cbz	r1, 70002d84 <k_work_queue_start+0x64>
	return z_impl_k_thread_name_set(thread, str);
70002d7e:	4620      	mov	r0, r4
70002d80:	f7ff f85a 	bl	70001e38 <z_impl_k_thread_name_set>
		k_thread_name_set(&queue->thread, cfg->name);
	}

	if ((cfg != NULL) && (cfg->essential)) {
70002d84:	796b      	ldrb	r3, [r5, #5]
70002d86:	b11b      	cbz	r3, 70002d90 <k_work_queue_start+0x70>
		queue->thread.base.user_options |= K_ESSENTIAL;
70002d88:	7b23      	ldrb	r3, [r4, #12]
70002d8a:	f043 0301 	orr.w	r3, r3, #1
70002d8e:	7323      	strb	r3, [r4, #12]
	z_impl_k_wakeup(thread);
70002d90:	4620      	mov	r0, r4
	}

	k_thread_start(&queue->thread);

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_work_queue, start, queue);
}
70002d92:	b009      	add	sp, #36	; 0x24
70002d94:	e8bd 40f0 	ldmia.w	sp!, {r4, r5, r6, r7, lr}
70002d98:	f7ff bc12 	b.w	700025c0 <z_impl_k_wakeup>

70002d9c <memcpy>:
  long *aligned_dst;
  const long *aligned_src;

  /* If the size is small, or either SRC or DST is unaligned,
     then punt into the byte copy loop.  This should be rare.  */
  if (!TOO_SMALL(len0) && !UNALIGNED (src, dst))
70002d9c:	2a0f      	cmp	r2, #15
70002d9e:	d913      	bls.n	70002dc8 <memcpy+0x2c>
70002da0:	ea40 0301 	orr.w	r3, r0, r1
70002da4:	f013 0303 	ands.w	r3, r3, #3
  char *dst = dst0;
70002da8:	bf1c      	itt	ne
70002daa:	4603      	movne	r3, r0
       /* Pick up any residual with a byte copier.  */
      dst = (char*)aligned_dst;
      src = (char*)aligned_src;
    }

  while (len0--)
70002dac:	f102 3cff 	addne.w	ip, r2, #4294967295	; 0xffffffff
  if (!TOO_SMALL(len0) && !UNALIGNED (src, dst))
70002db0:	d010      	beq.n	70002dd4 <memcpy+0x38>
70002db2:	f10c 0c01 	add.w	ip, ip, #1
70002db6:	3b01      	subs	r3, #1
70002db8:	448c      	add	ip, r1
    *dst++ = *src++;
70002dba:	f811 2b01 	ldrb.w	r2, [r1], #1
70002dbe:	f803 2f01 	strb.w	r2, [r3, #1]!
  while (len0--)
70002dc2:	458c      	cmp	ip, r1
70002dc4:	d1f9      	bne.n	70002dba <memcpy+0x1e>
70002dc6:	4770      	bx	lr
  char *dst = dst0;
70002dc8:	4603      	mov	r3, r0
  while (len0--)
70002dca:	f102 3cff 	add.w	ip, r2, #4294967295	; 0xffffffff
70002dce:	2a00      	cmp	r2, #0
70002dd0:	d1ef      	bne.n	70002db2 <memcpy+0x16>

  return dst0;
#endif /* not PREFER_SIZE_OVER_SPEED */
}
70002dd2:	4770      	bx	lr
{
70002dd4:	b5f0      	push	{r4, r5, r6, r7, lr}
70002dd6:	4684      	mov	ip, r0
70002dd8:	f1a2 0710 	sub.w	r7, r2, #16
70002ddc:	468e      	mov	lr, r1
70002dde:	093f      	lsrs	r7, r7, #4
70002de0:	3701      	adds	r7, #1
          *aligned_dst++ = *aligned_src++;
70002de2:	f8de 4008 	ldr.w	r4, [lr, #8]
70002de6:	3301      	adds	r3, #1
70002de8:	f8de 6000 	ldr.w	r6, [lr]
70002dec:	429f      	cmp	r7, r3
70002dee:	f8de 5004 	ldr.w	r5, [lr, #4]
70002df2:	f10c 0c10 	add.w	ip, ip, #16
70002df6:	f84c 4c08 	str.w	r4, [ip, #-8]
70002dfa:	f10e 0e10 	add.w	lr, lr, #16
70002dfe:	f85e 4c04 	ldr.w	r4, [lr, #-4]
70002e02:	f84c 6c10 	str.w	r6, [ip, #-16]
70002e06:	f84c 5c0c 	str.w	r5, [ip, #-12]
70002e0a:	f84c 4c04 	str.w	r4, [ip, #-4]
      while (len0 >= BIGBLOCKSIZE)
70002e0e:	d8e8      	bhi.n	70002de2 <memcpy+0x46>
      while (len0 >= LITTLEBLOCKSIZE)
70002e10:	f012 0f0c 	tst.w	r2, #12
          len0 -= BIGBLOCKSIZE;
70002e14:	f002 050f 	and.w	r5, r2, #15
          *aligned_dst++ = *aligned_src++;
70002e18:	eb01 1107 	add.w	r1, r1, r7, lsl #4
          len0 -= BIGBLOCKSIZE;
70002e1c:	bf08      	it	eq
70002e1e:	462a      	moveq	r2, r5
          *aligned_dst++ = *aligned_src++;
70002e20:	eb00 1307 	add.w	r3, r0, r7, lsl #4
      while (len0 >= LITTLEBLOCKSIZE)
70002e24:	d013      	beq.n	70002e4e <memcpy+0xb2>
70002e26:	3d04      	subs	r5, #4
70002e28:	f025 0c03 	bic.w	ip, r5, #3
70002e2c:	1f1c      	subs	r4, r3, #4
70002e2e:	08ad      	lsrs	r5, r5, #2
          *aligned_dst++ = *aligned_src++;
70002e30:	460e      	mov	r6, r1
70002e32:	449c      	add	ip, r3
          *aligned_dst++ = *aligned_src++;
70002e34:	f856 7b04 	ldr.w	r7, [r6], #4
70002e38:	f844 7f04 	str.w	r7, [r4, #4]!
      while (len0 >= LITTLEBLOCKSIZE)
70002e3c:	4564      	cmp	r4, ip
70002e3e:	d1f9      	bne.n	70002e34 <memcpy+0x98>
70002e40:	1c6c      	adds	r4, r5, #1
          len0 -= LITTLEBLOCKSIZE;
70002e42:	f002 0203 	and.w	r2, r2, #3
          *aligned_dst++ = *aligned_src++;
70002e46:	eb03 0384 	add.w	r3, r3, r4, lsl #2
70002e4a:	eb01 0184 	add.w	r1, r1, r4, lsl #2
  while (len0--)
70002e4e:	f102 3cff 	add.w	ip, r2, #4294967295	; 0xffffffff
70002e52:	f10c 0c01 	add.w	ip, ip, #1
70002e56:	3b01      	subs	r3, #1
70002e58:	448c      	add	ip, r1
70002e5a:	b12a      	cbz	r2, 70002e68 <memcpy+0xcc>
    *dst++ = *src++;
70002e5c:	f811 2b01 	ldrb.w	r2, [r1], #1
70002e60:	f803 2f01 	strb.w	r2, [r3, #1]!
  while (len0--)
70002e64:	458c      	cmp	ip, r1
70002e66:	d1f9      	bne.n	70002e5c <memcpy+0xc0>
}
70002e68:	bdf0      	pop	{r4, r5, r6, r7, pc}
70002e6a:	bf00      	nop

70002e6c <memset>:
  unsigned long buffer;
  unsigned long *aligned_addr;
  unsigned int d = c & 0xff;	/* To avoid sign extension, copy C to an
				   unsigned variable.  */

  while (UNALIGNED (s))
70002e6c:	0783      	lsls	r3, r0, #30
{
70002e6e:	b530      	push	{r4, r5, lr}
  while (UNALIGNED (s))
70002e70:	d04a      	beq.n	70002f08 <memset+0x9c>
    {
      if (n--)
70002e72:	1e54      	subs	r4, r2, #1
70002e74:	2a00      	cmp	r2, #0
70002e76:	d041      	beq.n	70002efc <memset+0x90>
  char *s = (char *) m;
70002e78:	4603      	mov	r3, r0
        *s++ = (char) c;
70002e7a:	b2ca      	uxtb	r2, r1
70002e7c:	e001      	b.n	70002e82 <memset+0x16>
      if (n--)
70002e7e:	3c01      	subs	r4, #1
70002e80:	d33c      	bcc.n	70002efc <memset+0x90>
        *s++ = (char) c;
70002e82:	f803 2b01 	strb.w	r2, [r3], #1
  while (UNALIGNED (s))
70002e86:	079d      	lsls	r5, r3, #30
70002e88:	d1f9      	bne.n	70002e7e <memset+0x12>
      else
        return m;
    }

  if (!TOO_SMALL (n))
70002e8a:	2c03      	cmp	r4, #3
70002e8c:	d92f      	bls.n	70002eee <memset+0x82>
  unsigned int d = c & 0xff;	/* To avoid sign extension, copy C to an
70002e8e:	b2cd      	uxtb	r5, r1
      buffer |= (buffer << 16);
      for (i = 32; i < LBLOCKSIZE * 8; i <<= 1)
        buffer = (buffer << i) | buffer;

      /* Unroll the loop.  */
      while (n >= LBLOCKSIZE*4)
70002e90:	2c0f      	cmp	r4, #15
70002e92:	eb05 2505 	add.w	r5, r5, r5, lsl #8
70002e96:	eb05 4505 	add.w	r5, r5, r5, lsl #16
70002e9a:	d938      	bls.n	70002f0e <memset+0xa2>
70002e9c:	f1a4 0210 	sub.w	r2, r4, #16
70002ea0:	f022 0c0f 	bic.w	ip, r2, #15
70002ea4:	f103 0e10 	add.w	lr, r3, #16
70002ea8:	44e6      	add	lr, ip
70002eaa:	ea4f 1c12 	mov.w	ip, r2, lsr #4
70002eae:	461a      	mov	r2, r3
        {
          *aligned_addr++ = buffer;
70002eb0:	6015      	str	r5, [r2, #0]
      while (n >= LBLOCKSIZE*4)
70002eb2:	3210      	adds	r2, #16
          *aligned_addr++ = buffer;
70002eb4:	f842 5c0c 	str.w	r5, [r2, #-12]
70002eb8:	f842 5c08 	str.w	r5, [r2, #-8]
70002ebc:	f842 5c04 	str.w	r5, [r2, #-4]
      while (n >= LBLOCKSIZE*4)
70002ec0:	4572      	cmp	r2, lr
70002ec2:	d1f5      	bne.n	70002eb0 <memset+0x44>
          *aligned_addr++ = buffer;
          *aligned_addr++ = buffer;
          *aligned_addr++ = buffer;
70002ec4:	f10c 0201 	add.w	r2, ip, #1
          n -= 4*LBLOCKSIZE;
        }

      while (n >= LBLOCKSIZE)
70002ec8:	f014 0f0c 	tst.w	r4, #12
          *aligned_addr++ = buffer;
70002ecc:	eb03 1202 	add.w	r2, r3, r2, lsl #4
          n -= 4*LBLOCKSIZE;
70002ed0:	f004 0c0f 	and.w	ip, r4, #15
      while (n >= LBLOCKSIZE)
70002ed4:	d013      	beq.n	70002efe <memset+0x92>
70002ed6:	f1ac 0304 	sub.w	r3, ip, #4
70002eda:	f023 0303 	bic.w	r3, r3, #3
70002ede:	3304      	adds	r3, #4
70002ee0:	4413      	add	r3, r2
        {
          *aligned_addr++ = buffer;
70002ee2:	f842 5b04 	str.w	r5, [r2], #4
      while (n >= LBLOCKSIZE)
70002ee6:	429a      	cmp	r2, r3
70002ee8:	d1fb      	bne.n	70002ee2 <memset+0x76>
          n -= LBLOCKSIZE;
70002eea:	f00c 0403 	and.w	r4, ip, #3
      s = (char*)aligned_addr;
    }

#endif /* not PREFER_SIZE_OVER_SPEED */

  while (n--)
70002eee:	b12c      	cbz	r4, 70002efc <memset+0x90>
        *s++ = (char) c;
70002ef0:	b2c9      	uxtb	r1, r1
70002ef2:	441c      	add	r4, r3
    *s++ = (char) c;
70002ef4:	f803 1b01 	strb.w	r1, [r3], #1
  while (n--)
70002ef8:	429c      	cmp	r4, r3
70002efa:	d1fb      	bne.n	70002ef4 <memset+0x88>

  return m;
}
70002efc:	bd30      	pop	{r4, r5, pc}
          n -= 4*LBLOCKSIZE;
70002efe:	4664      	mov	r4, ip
          *aligned_addr++ = buffer;
70002f00:	4613      	mov	r3, r2
  while (n--)
70002f02:	2c00      	cmp	r4, #0
70002f04:	d1f4      	bne.n	70002ef0 <memset+0x84>
70002f06:	e7f9      	b.n	70002efc <memset+0x90>
  char *s = (char *) m;
70002f08:	4603      	mov	r3, r0
  while (UNALIGNED (s))
70002f0a:	4614      	mov	r4, r2
70002f0c:	e7bd      	b.n	70002e8a <memset+0x1e>
      while (n >= LBLOCKSIZE*4)
70002f0e:	461a      	mov	r2, r3
70002f10:	46a4      	mov	ip, r4
70002f12:	e7e0      	b.n	70002ed6 <memset+0x6a>

70002f14 <strnlen>:
strnlen (const char *str,
	size_t n)
{
  const char *start = str;

  while (n-- > 0 && *str)
70002f14:	4603      	mov	r3, r0
70002f16:	eb00 0c01 	add.w	ip, r0, r1
70002f1a:	b911      	cbnz	r1, 70002f22 <strnlen+0xe>
70002f1c:	e00a      	b.n	70002f34 <strnlen+0x20>
70002f1e:	4563      	cmp	r3, ip
70002f20:	d006      	beq.n	70002f30 <strnlen+0x1c>
    str++;
70002f22:	461a      	mov	r2, r3
70002f24:	3301      	adds	r3, #1
  while (n-- > 0 && *str)
70002f26:	7811      	ldrb	r1, [r2, #0]
70002f28:	2900      	cmp	r1, #0
70002f2a:	d1f8      	bne.n	70002f1e <strnlen+0xa>

  return str - start;
70002f2c:	1a10      	subs	r0, r2, r0
}
70002f2e:	4770      	bx	lr
  return str - start;
70002f30:	1a18      	subs	r0, r3, r0
70002f32:	4770      	bx	lr
  while (n-- > 0 && *str)
70002f34:	4608      	mov	r0, r1
70002f36:	4770      	bx	lr

70002f38 <snprintf>:

#include "stdio_private.h"

int
snprintf(char *s, size_t n, const char *fmt, ...)
{
70002f38:	b40c      	push	{r2, r3}
	   that f.size will be a max number of nonzero symbols.	*/

	if ((int) n < 0)
		n = (unsigned)INT_MAX + 1;

	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
70002f3a:	f643 1249 	movw	r2, #14665	; 0x3949
{
70002f3e:	4603      	mov	r3, r0
70002f40:	b510      	push	{r4, lr}
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
70002f42:	2002      	movs	r0, #2
{
70002f44:	b088      	sub	sp, #32
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
70002f46:	2400      	movs	r4, #0
70002f48:	f2c7 0200 	movt	r2, #28672	; 0x7000
70002f4c:	9305      	str	r3, [sp, #20]
70002f4e:	e9cd 4201 	strd	r4, r2, [sp, #4]
70002f52:	e9cd 4403 	strd	r4, r4, [sp, #12]
70002f56:	f88d 0006 	strb.w	r0, [sp, #6]
70002f5a:	9407      	str	r4, [sp, #28]
70002f5c:	b1a1      	cbz	r1, 70002f88 <snprintf+0x50>
70002f5e:	f1b1 4f00 	cmp.w	r1, #2147483648	; 0x80000000
70002f62:	bf28      	it	cs
70002f64:	f04f 4100 	movcs.w	r1, #2147483648	; 0x80000000

	va_start(ap, fmt);
70002f68:	aa0b      	add	r2, sp, #44	; 0x2c
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
70002f6a:	3901      	subs	r1, #1
70002f6c:	440b      	add	r3, r1
	i = vfprintf(&f.file, fmt, ap);
70002f6e:	990a      	ldr	r1, [sp, #40]	; 0x28
70002f70:	a801      	add	r0, sp, #4
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
70002f72:	9306      	str	r3, [sp, #24]
	va_start(ap, fmt);
70002f74:	9200      	str	r2, [sp, #0]
	i = vfprintf(&f.file, fmt, ap);
70002f76:	f000 f951 	bl	7000321c <__l_vfprintf>
	va_end(ap);

	if (n)
            *f.pos = '\0';
70002f7a:	9b05      	ldr	r3, [sp, #20]
70002f7c:	701c      	strb	r4, [r3, #0]

	return i;
}
70002f7e:	b008      	add	sp, #32
70002f80:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
70002f84:	b002      	add	sp, #8
70002f86:	4770      	bx	lr
	i = vfprintf(&f.file, fmt, ap);
70002f88:	990a      	ldr	r1, [sp, #40]	; 0x28
	va_start(ap, fmt);
70002f8a:	aa0b      	add	r2, sp, #44	; 0x2c
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
70002f8c:	9306      	str	r3, [sp, #24]
	i = vfprintf(&f.file, fmt, ap);
70002f8e:	a801      	add	r0, sp, #4
	va_start(ap, fmt);
70002f90:	9200      	str	r2, [sp, #0]
	i = vfprintf(&f.file, fmt, ap);
70002f92:	f000 f943 	bl	7000321c <__l_vfprintf>
}
70002f96:	b008      	add	sp, #32
70002f98:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
70002f9c:	b002      	add	sp, #8
70002f9e:	4770      	bx	lr

70002fa0 <__ultoa_invert>:
#endif
#endif

static __noinline char *
__ultoa_invert(ultoa_unsigned_t val, char *str, int base)
{
70002fa0:	b570      	push	{r4, r5, r6, lr}
70002fa2:	4684      	mov	ip, r0
	char hex = ('a' - '0' - 10 + 16) - base;
70002fa4:	f1c3 0437 	rsb	r4, r3, #55	; 0x37
{
70002fa8:	4610      	mov	r0, r2
	char hex = ('a' - '0' - 10 + 16) - base;
70002faa:	b2e2      	uxtb	r2, r4

        base &= 31;
70002fac:	f003 041f 	and.w	r4, r3, #31
    switch(base) {
70002fb0:	2c08      	cmp	r4, #8
        *dig = val & 1;
70002fb2:	fa5f fe8c 	uxtb.w	lr, ip
    switch(base) {
70002fb6:	d042      	beq.n	7000303e <__ultoa_invert+0x9e>
70002fb8:	2c10      	cmp	r4, #16
	q = (n >> 1) + (n >> 2);
70002fba:	ea4f 035c 	mov.w	r3, ip, lsr #1
70002fbe:	ea4f 069c 	mov.w	r6, ip, lsr #2
70002fc2:	ea43 73c1 	orr.w	r3, r3, r1, lsl #31
70002fc6:	ea46 7681 	orr.w	r6, r6, r1, lsl #30
70002fca:	ea4f 0591 	mov.w	r5, r1, lsr #2
    switch(base) {
70002fce:	d04c      	beq.n	7000306a <__ultoa_invert+0xca>
70002fd0:	2c02      	cmp	r4, #2
70002fd2:	d042      	beq.n	7000305a <__ultoa_invert+0xba>
	q = (n >> 1) + (n >> 2);
70002fd4:	199b      	adds	r3, r3, r6
70002fd6:	eb45 0551 	adc.w	r5, r5, r1, lsr #1
	q = q + (q >> 4);
70002fda:	0919      	lsrs	r1, r3, #4
70002fdc:	ea41 7105 	orr.w	r1, r1, r5, lsl #28
70002fe0:	185b      	adds	r3, r3, r1
70002fe2:	eb45 1515 	adc.w	r5, r5, r5, lsr #4
	q = q + (q >> 8);
70002fe6:	0a19      	lsrs	r1, r3, #8
70002fe8:	ea41 6105 	orr.w	r1, r1, r5, lsl #24
70002fec:	185b      	adds	r3, r3, r1
70002fee:	eb45 2515 	adc.w	r5, r5, r5, lsr #8
	q = q + (q >> 16);
70002ff2:	0c19      	lsrs	r1, r3, #16
70002ff4:	ea41 4105 	orr.w	r1, r1, r5, lsl #16
70002ff8:	185b      	adds	r3, r3, r1
70002ffa:	eb45 4515 	adc.w	r5, r5, r5, lsr #16
        q = q + (q >> 32);
70002ffe:	195b      	adds	r3, r3, r5
70003000:	f145 0500 	adc.w	r5, r5, #0
	q = q >> 3;
70003004:	ea4f 0cd3 	mov.w	ip, r3, lsr #3
70003008:	ea4c 7c45 	orr.w	ip, ip, r5, lsl #29
7000300c:	08e9      	lsrs	r1, r5, #3
	r = (char) (n - (((q << 2) + q) << 1));
7000300e:	eb0c 038c 	add.w	r3, ip, ip, lsl #2
70003012:	ebae 0343 	sub.w	r3, lr, r3, lsl #1
70003016:	b2db      	uxtb	r3, r3
            r -= 10;
70003018:	f1a3 050a 	sub.w	r5, r3, #10
        if (r > 9) {
7000301c:	2b09      	cmp	r3, #9
            r -= 10;
7000301e:	b2ed      	uxtb	r5, r5
        if (r > 9) {
70003020:	d914      	bls.n	7000304c <__ultoa_invert+0xac>
            q++;
70003022:	f11c 0c01 	adds.w	ip, ip, #1
70003026:	f141 0100 	adc.w	r1, r1, #0
                val = udivmod(val, base, &v);
#else
                v = val % base;
                val /= base;
#endif
		if (v > 9)
7000302a:	2d09      	cmp	r5, #9
7000302c:	d92a      	bls.n	70003084 <__ultoa_invert+0xe4>
                        v += hex;
7000302e:	4415      	add	r5, r2
                v += '0';
70003030:	3530      	adds	r5, #48	; 0x30
    switch(base) {
70003032:	2c08      	cmp	r4, #8
		*str++ = v;
70003034:	f800 5b01 	strb.w	r5, [r0], #1
        *dig = val & 1;
70003038:	fa5f fe8c 	uxtb.w	lr, ip
    switch(base) {
7000303c:	d1bc      	bne.n	70002fb8 <__ultoa_invert+0x18>
        return val >> 3;
7000303e:	ea4f 0cdc 	mov.w	ip, ip, lsr #3
70003042:	ea4c 7c41 	orr.w	ip, ip, r1, lsl #29
        *dig = val & 7;
70003046:	f00e 0307 	and.w	r3, lr, #7
        return val >> 3;
7000304a:	08c9      	lsrs	r1, r1, #3
                v += '0';
7000304c:	3330      	adds	r3, #48	; 0x30
		*str++ = v;
7000304e:	f800 3b01 	strb.w	r3, [r0], #1
	} while (val);
70003052:	ea5c 0301 	orrs.w	r3, ip, r1
70003056:	d1ab      	bne.n	70002fb0 <__ultoa_invert+0x10>
	return str;
}
70003058:	bd70      	pop	{r4, r5, r6, pc}
        return val >> 1;
7000305a:	ea4f 0c5c 	mov.w	ip, ip, lsr #1
7000305e:	ea4c 7cc1 	orr.w	ip, ip, r1, lsl #31
        *dig = val & 1;
70003062:	f00e 0301 	and.w	r3, lr, #1
        return val >> 1;
70003066:	0849      	lsrs	r1, r1, #1
		if (v > 9)
70003068:	e7f0      	b.n	7000304c <__ultoa_invert+0xac>
        *dig = val & 15;
7000306a:	f00e 030f 	and.w	r3, lr, #15
		if (v > 9)
7000306e:	2b09      	cmp	r3, #9
                        v += hex;
70003070:	bf88      	it	hi
70003072:	189b      	addhi	r3, r3, r2
        return val >> 4;
70003074:	ea4f 1c1c 	mov.w	ip, ip, lsr #4
70003078:	ea4c 7c01 	orr.w	ip, ip, r1, lsl #28
                        v += hex;
7000307c:	bf88      	it	hi
7000307e:	b2db      	uxtbhi	r3, r3
        return val >> 4;
70003080:	0909      	lsrs	r1, r1, #4
		if (v > 9)
70003082:	e7e3      	b.n	7000304c <__ultoa_invert+0xac>
                v += '0';
70003084:	3326      	adds	r3, #38	; 0x26
        *dig = val & 1;
70003086:	fa5f fe8c 	uxtb.w	lr, ip
		*str++ = v;
7000308a:	f800 3b01 	strb.w	r3, [r0], #1
    switch(base) {
7000308e:	e793      	b.n	70002fb8 <__ultoa_invert+0x18>

70003090 <skip_to_arg>:
 * and types to slowly walk the argument vector until it points at the
 * target_argno so that the outer printf code can then extract it.
 */
static void
skip_to_arg(const CHAR *fmt_orig, my_va_list *ap, int target_argno)
{
70003090:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
    unsigned c;		/* holds a char from the format string */
    uint16_t flags;
    int current_argno = 1;
70003094:	f04f 0e01 	mov.w	lr, #1
70003098:	4603      	mov	r3, r0
    int argno;
    int width;
    const CHAR *fmt = fmt_orig;

    while (current_argno < target_argno) {
7000309a:	4572      	cmp	r2, lr
7000309c:	dc02      	bgt.n	700030a4 <skip_to_arg+0x14>
7000309e:	e006      	b.n	700030ae <skip_to_arg+0x1e>
        for (;;) {
            c = *fmt++;
            if (!c) return;
            if (c == '%') {
700030a0:	2c25      	cmp	r4, #37	; 0x25
700030a2:	d006      	beq.n	700030b2 <skip_to_arg+0x22>
700030a4:	469c      	mov	ip, r3
            c = *fmt++;
700030a6:	f813 4b01 	ldrb.w	r4, [r3], #1
            if (!c) return;
700030aa:	2c00      	cmp	r4, #0
700030ac:	d1f8      	bne.n	700030a0 <skip_to_arg+0x10>
            }
            ++current_argno;
            fmt = fmt_orig;
        }
    }
}
700030ae:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
                c = *fmt++;
700030b2:	781c      	ldrb	r4, [r3, #0]
                if (c != '%') break;
700030b4:	2c25      	cmp	r4, #37	; 0x25
                c = *fmt++;
700030b6:	f10c 0c02 	add.w	ip, ip, #2
700030ba:	4663      	mov	r3, ip
                if (c != '%') break;
700030bc:	d0f2      	beq.n	700030a4 <skip_to_arg+0x14>
        width = 0;
700030be:	2600      	movs	r6, #0
		switch (c) {
700030c0:	f642 0789 	movw	r7, #10377	; 0x2889
        argno = 0;
700030c4:	46b0      	mov	r8, r6
		switch (c) {
700030c6:	f2c0 0701 	movt	r7, #1
        flags = 0;
700030ca:	4633      	mov	r3, r6
	    if (flags < FL_WIDTH) {
700030cc:	2b1f      	cmp	r3, #31
700030ce:	d847      	bhi.n	70003160 <skip_to_arg+0xd0>
		switch (c) {
700030d0:	f1a4 0520 	sub.w	r5, r4, #32
700030d4:	2d10      	cmp	r5, #16
700030d6:	d856      	bhi.n	70003186 <skip_to_arg+0xf6>
700030d8:	fa27 f505 	lsr.w	r5, r7, r5
700030dc:	07ed      	lsls	r5, r5, #31
700030de:	d434      	bmi.n	7000314a <skip_to_arg+0xba>
		if (c >= '0' && c <= '9') {
700030e0:	f1a4 0530 	sub.w	r5, r4, #48	; 0x30
700030e4:	2d09      	cmp	r5, #9
700030e6:	d952      	bls.n	7000318e <skip_to_arg+0xfe>
                if (c == '$') {
700030e8:	2c24      	cmp	r4, #36	; 0x24
700030ea:	d10a      	bne.n	70003102 <skip_to_arg+0x72>
                    if (argno) {
700030ec:	f1b8 0f00 	cmp.w	r8, #0
700030f0:	d053      	beq.n	7000319a <skip_to_arg+0x10a>
                        if (width == current_argno) {
700030f2:	4576      	cmp	r6, lr
700030f4:	d137      	bne.n	70003166 <skip_to_arg+0xd6>
                SKIP_FLOAT_ARG(flags, ap->ap);
700030f6:	680d      	ldr	r5, [r1, #0]
                arg_to_unsigned(ap->ap, flags, x);
700030f8:	3504      	adds	r5, #4
                SKIP_FLOAT_ARG(flags, ap->ap);
700030fa:	600d      	str	r5, [r1, #0]
            ++current_argno;
700030fc:	f10e 0e01 	add.w	lr, lr, #1
            fmt = fmt_orig;
70003100:	e7ca      	b.n	70003098 <skip_to_arg+0x8>
		if (c == '*') {
70003102:	f024 0504 	bic.w	r5, r4, #4
		if (c == '.') {
70003106:	2d2a      	cmp	r5, #42	; 0x2a
70003108:	d02d      	beq.n	70003166 <skip_to_arg+0xd6>
            CHECK_INT_SIZES(c, flags);
7000310a:	f1a4 054c 	sub.w	r5, r4, #76	; 0x4c
7000310e:	2d2e      	cmp	r5, #46	; 0x2e
70003110:	d81f      	bhi.n	70003152 <skip_to_arg+0xc2>
70003112:	e8df f005 	tbb	[pc, r5]
70003116:	1e18      	.short	0x1e18
70003118:	1e1e1e1e 	.word	0x1e1e1e1e
7000311c:	1e1e1e1e 	.word	0x1e1e1e1e
70003120:	1e1e1e1e 	.word	0x1e1e1e1e
70003124:	1e1e1e1e 	.word	0x1e1e1e1e
70003128:	1e1e1e1e 	.word	0x1e1e1e1e
7000312c:	1e1e1e1e 	.word	0x1e1e1e1e
70003130:	1e2a1e1e 	.word	0x1e2a1e1e
70003134:	1e311e18 	.word	0x1e311e18
70003138:	1e1e1e1e 	.word	0x1e1e1e1e
7000313c:	1e1a1e1e 	.word	0x1e1a1e1e
70003140:	1e1e1e1e 	.word	0x1e1e1e1e
70003144:	1a          	.byte	0x1a
70003145:	00          	.byte	0x00
70003146:	f443 7320 	orr.w	r3, r3, #640	; 0x280
	} while ( (c = *fmt++) != 0);
7000314a:	f81c 4b01 	ldrb.w	r4, [ip], #1
7000314e:	2c00      	cmp	r4, #0
70003150:	d1bc      	bne.n	700030cc <skip_to_arg+0x3c>
        if (argno == 0)
70003152:	f1b8 0f00 	cmp.w	r8, #0
70003156:	d0aa      	beq.n	700030ae <skip_to_arg+0x1e>
        if (argno == current_argno) {
70003158:	45f0      	cmp	r8, lr
7000315a:	d021      	beq.n	700031a0 <skip_to_arg+0x110>
7000315c:	4663      	mov	r3, ip
7000315e:	e79c      	b.n	7000309a <skip_to_arg+0xa>
	    if (flags < FL_LONG) {
70003160:	2b7f      	cmp	r3, #127	; 0x7f
70003162:	d8d2      	bhi.n	7000310a <skip_to_arg+0x7a>
70003164:	e7bc      	b.n	700030e0 <skip_to_arg+0x50>
                    width = 0;
70003166:	2600      	movs	r6, #0
70003168:	e7ef      	b.n	7000314a <skip_to_arg+0xba>
            CHECK_INT_SIZES(c, flags);
7000316a:	05dd      	lsls	r5, r3, #23
7000316c:	bf48      	it	mi
7000316e:	f443 7300 	orrmi.w	r3, r3, #512	; 0x200
70003172:	f443 7380 	orr.w	r3, r3, #256	; 0x100
70003176:	e7e8      	b.n	7000314a <skip_to_arg+0xba>
70003178:	061c      	lsls	r4, r3, #24
7000317a:	bf48      	it	mi
7000317c:	f443 7300 	orrmi.w	r3, r3, #512	; 0x200
70003180:	f043 0380 	orr.w	r3, r3, #128	; 0x80
70003184:	e7e1      	b.n	7000314a <skip_to_arg+0xba>
		if (c >= '0' && c <= '9') {
70003186:	f1a4 0530 	sub.w	r5, r4, #48	; 0x30
7000318a:	2d09      	cmp	r5, #9
7000318c:	d8b9      	bhi.n	70003102 <skip_to_arg+0x72>
                    flags |= FL_WIDTH;
7000318e:	2320      	movs	r3, #32
                    width = 10 * width + c;
70003190:	eb06 0686 	add.w	r6, r6, r6, lsl #2
70003194:	eb05 0646 	add.w	r6, r5, r6, lsl #1
		    continue;
70003198:	e7d7      	b.n	7000314a <skip_to_arg+0xba>
7000319a:	46b0      	mov	r8, r6
                    width = 0;
7000319c:	2600      	movs	r6, #0
7000319e:	e7d4      	b.n	7000314a <skip_to_arg+0xba>
                SKIP_FLOAT_ARG(flags, ap->ap);
700031a0:	680d      	ldr	r5, [r1, #0]
            if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
700031a2:	f044 0620 	orr.w	r6, r4, #32
                || TOLOWER(c) == 'a'
700031a6:	f1a6 0765 	sub.w	r7, r6, #101	; 0x65
            if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
700031aa:	2e61      	cmp	r6, #97	; 0x61
700031ac:	bf18      	it	ne
700031ae:	2f02      	cmpne	r7, #2
700031b0:	d92e      	bls.n	70003210 <skip_to_arg+0x180>
            } else if (c == 'c') {
700031b2:	3c63      	subs	r4, #99	; 0x63
700031b4:	2c10      	cmp	r4, #16
700031b6:	d825      	bhi.n	70003204 <skip_to_arg+0x174>
700031b8:	a601      	add	r6, pc, #4	; (adr r6, 700031c0 <skip_to_arg+0x130>)
700031ba:	f856 f024 	ldr.w	pc, [r6, r4, lsl #2]
700031be:	bf00      	nop
700031c0:	700030f9 	.word	0x700030f9
700031c4:	70003205 	.word	0x70003205
700031c8:	70003205 	.word	0x70003205
700031cc:	70003205 	.word	0x70003205
700031d0:	70003205 	.word	0x70003205
700031d4:	70003205 	.word	0x70003205
700031d8:	70003205 	.word	0x70003205
700031dc:	70003205 	.word	0x70003205
700031e0:	70003205 	.word	0x70003205
700031e4:	70003205 	.word	0x70003205
700031e8:	70003205 	.word	0x70003205
700031ec:	70003205 	.word	0x70003205
700031f0:	70003205 	.word	0x70003205
700031f4:	70003205 	.word	0x70003205
700031f8:	70003205 	.word	0x70003205
700031fc:	70003205 	.word	0x70003205
70003200:	700030f9 	.word	0x700030f9
                arg_to_unsigned(ap->ap, flags, x);
70003204:	061c      	lsls	r4, r3, #24
70003206:	f57f af77 	bpl.w	700030f8 <skip_to_arg+0x68>
7000320a:	059b      	lsls	r3, r3, #22
7000320c:	f57f af74 	bpl.w	700030f8 <skip_to_arg+0x68>
70003210:	3507      	adds	r5, #7
70003212:	f025 0507 	bic.w	r5, r5, #7
70003216:	3508      	adds	r5, #8
70003218:	e76f      	b.n	700030fa <skip_to_arg+0x6a>
7000321a:	bf00      	nop

7000321c <__l_vfprintf>:
    return len;
}
#endif

int vfprintf (FILE * stream, const CHAR *fmt, va_list ap_orig)
{
7000321c:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    int (*put)(char, FILE *) = stream->put;
#define my_putc(c, stream) do { ++stream_len; if (put(c, stream) < 0) goto fail; } while(0)
#endif
#endif

    if ((stream->flags & __SWR) == 0)
70003220:	7883      	ldrb	r3, [r0, #2]
    int (*put)(char, FILE *) = stream->put;
70003222:	f8d0 b004 	ldr.w	fp, [r0, #4]
    if ((stream->flags & __SWR) == 0)
70003226:	079e      	lsls	r6, r3, #30
{
70003228:	b09b      	sub	sp, #108	; 0x6c
    if ((stream->flags & __SWR) == 0)
7000322a:	f140 836c 	bpl.w	70003906 <__l_vfprintf+0x6ea>
7000322e:	4607      	mov	r7, r0
#endif

    for (;;) {

	for (;;) {
	    c = *fmt++;
70003230:	460b      	mov	r3, r1
    va_copy(ap, ap_orig);
70003232:	9209      	str	r2, [sp, #36]	; 0x24
	    c = *fmt++;
70003234:	4696      	mov	lr, r2
70003236:	f813 0b01 	ldrb.w	r0, [r3], #1
	    if (!c) goto ret;
7000323a:	2800      	cmp	r0, #0
7000323c:	f000 835a 	beq.w	700038f4 <__l_vfprintf+0x6d8>
70003240:	460d      	mov	r5, r1
    int stream_len = 0;
70003242:	2400      	movs	r4, #0
70003244:	e9cd 1203 	strd	r1, r2, [sp, #12]
70003248:	e00a      	b.n	70003260 <__l_vfprintf+0x44>
	    if (c == '%') {
		c = *fmt++;
		if (c != '%') break;
	    }
	    my_putc (c, stream);
7000324a:	4639      	mov	r1, r7
7000324c:	b2c0      	uxtb	r0, r0
7000324e:	461d      	mov	r5, r3
70003250:	47d8      	blx	fp
70003252:	3401      	adds	r4, #1
70003254:	2800      	cmp	r0, #0
70003256:	db10      	blt.n	7000327a <__l_vfprintf+0x5e>
	    c = *fmt++;
70003258:	462b      	mov	r3, r5
7000325a:	f813 0b01 	ldrb.w	r0, [r3], #1
	    if (!c) goto ret;
7000325e:	b190      	cbz	r0, 70003286 <__l_vfprintf+0x6a>
	    if (c == '%') {
70003260:	2825      	cmp	r0, #37	; 0x25
70003262:	d1f2      	bne.n	7000324a <__l_vfprintf+0x2e>
		c = *fmt++;
70003264:	f105 0802 	add.w	r8, r5, #2
70003268:	786d      	ldrb	r5, [r5, #1]
		if (c != '%') break;
7000326a:	2d25      	cmp	r5, #37	; 0x25
7000326c:	d10f      	bne.n	7000328e <__l_vfprintf+0x72>
	    my_putc (c, stream);
7000326e:	4639      	mov	r1, r7
		c = *fmt++;
70003270:	4645      	mov	r5, r8
	    my_putc (c, stream);
70003272:	47d8      	blx	fp
70003274:	3401      	adds	r4, #1
70003276:	2800      	cmp	r0, #0
70003278:	daee      	bge.n	70003258 <__l_vfprintf+0x3c>
#endif
    return stream_len;
#undef my_putc
#undef ap
  fail:
    stream->flags |= __SERR;
7000327a:	78bb      	ldrb	r3, [r7, #2]
    stream_len = -1;
7000327c:	f04f 34ff 	mov.w	r4, #4294967295	; 0xffffffff
    stream->flags |= __SERR;
70003280:	f043 0304 	orr.w	r3, r3, #4
70003284:	70bb      	strb	r3, [r7, #2]
    goto ret;
}
70003286:	4620      	mov	r0, r4
70003288:	b01b      	add	sp, #108	; 0x6c
7000328a:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
        argno = 0;
7000328e:	f04f 0a00 	mov.w	sl, #0
	width = 0;
70003292:	46d1      	mov	r9, sl
	flags = 0;
70003294:	4656      	mov	r6, sl
	prec = 0;
70003296:	f8cd a004 	str.w	sl, [sp, #4]
	    if (flags < FL_WIDTH) {
7000329a:	2e1f      	cmp	r6, #31
7000329c:	d857      	bhi.n	7000334e <__l_vfprintf+0x132>
		switch (c) {
7000329e:	f1a5 0320 	sub.w	r3, r5, #32
700032a2:	2b10      	cmp	r3, #16
700032a4:	d80a      	bhi.n	700032bc <__l_vfprintf+0xa0>
700032a6:	e8df f003 	tbb	[pc, r3]
700032aa:	0946      	.short	0x0946
700032ac:	09094909 	.word	0x09094909
700032b0:	09091409 	.word	0x09091409
700032b4:	4f094409 	.word	0x4f094409
700032b8:	0909      	.short	0x0909
700032ba:	4c          	.byte	0x4c
700032bb:	00          	.byte	0x00
		if (c >= '0' && c <= '9') {
700032bc:	f1a5 0330 	sub.w	r3, r5, #48	; 0x30
700032c0:	2b09      	cmp	r3, #9
700032c2:	f200 80b0 	bhi.w	70003426 <__l_vfprintf+0x20a>
		    width = 10*width + c;
700032c6:	eb09 0989 	add.w	r9, r9, r9, lsl #2
		    flags |= FL_WIDTH;
700032ca:	f046 0620 	orr.w	r6, r6, #32
		    width = 10*width + c;
700032ce:	eb03 0949 	add.w	r9, r3, r9, lsl #1
	} while ( (c = *fmt++) != 0);
700032d2:	f818 5b01 	ldrb.w	r5, [r8], #1
700032d6:	2d00      	cmp	r5, #0
700032d8:	d1df      	bne.n	7000329a <__l_vfprintf+0x7e>
        if (argno) {
700032da:	9502      	str	r5, [sp, #8]
700032dc:	2320      	movs	r3, #32
700032de:	f1ba 0f00 	cmp.w	sl, #0
700032e2:	f040 80c9 	bne.w	70003478 <__l_vfprintf+0x25c>
	if (prec < 0) {
700032e6:	9a01      	ldr	r2, [sp, #4]
700032e8:	2a00      	cmp	r2, #0
	    prec = 0;
700032ea:	bfbf      	itttt	lt
700032ec:	2200      	movlt	r2, #0
	    flags &= ~FL_PREC;
700032ee:	f026 0640 	biclt.w	r6, r6, #64	; 0x40
	    prec = 0;
700032f2:	9201      	strlt	r2, [sp, #4]
	    flags &= ~FL_PREC;
700032f4:	b2b6      	uxthlt	r6, r6
	if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
700032f6:	9a02      	ldr	r2, [sp, #8]
700032f8:	2a00      	cmp	r2, #0
700032fa:	f040 80f1 	bne.w	700034e0 <__l_vfprintf+0x2c4>
            if (c == 'c') {
700032fe:	f1a5 0263 	sub.w	r2, r5, #99	; 0x63
70003302:	2a12      	cmp	r2, #18
70003304:	f200 8141 	bhi.w	7000358a <__l_vfprintf+0x36e>
70003308:	e8df f012 	tbh	[pc, r2, lsl #1]
7000330c:	0158018e 	.word	0x0158018e
70003310:	013f013f 	.word	0x013f013f
70003314:	013f013f 	.word	0x013f013f
70003318:	013f0158 	.word	0x013f0158
7000331c:	013f013f 	.word	0x013f013f
70003320:	013f013f 	.word	0x013f013f
70003324:	019802cb 	.word	0x019802cb
70003328:	013f013f 	.word	0x013f013f
7000332c:	013f01e5 	.word	0x013f01e5
70003330:	01e0      	.short	0x01e0
		    flags |= FL_PLUS;
70003332:	f046 0602 	orr.w	r6, r6, #2
		    flags |= FL_SPACE;
70003336:	f046 0604 	orr.w	r6, r6, #4
		    continue;
7000333a:	e7ca      	b.n	700032d2 <__l_vfprintf+0xb6>
		    flags |= FL_ALT;
7000333c:	f046 0610 	orr.w	r6, r6, #16
		    continue;
70003340:	e7c7      	b.n	700032d2 <__l_vfprintf+0xb6>
		    flags |= FL_ZFILL;
70003342:	f046 0601 	orr.w	r6, r6, #1
		    continue;
70003346:	e7c4      	b.n	700032d2 <__l_vfprintf+0xb6>
		    flags |= FL_LPAD;
70003348:	f046 0608 	orr.w	r6, r6, #8
		    continue;
7000334c:	e7c1      	b.n	700032d2 <__l_vfprintf+0xb6>
	    if (flags < FL_LONG) {
7000334e:	2e7f      	cmp	r6, #127	; 0x7f
70003350:	f240 82eb 	bls.w	7000392a <__l_vfprintf+0x70e>
            CHECK_INT_SIZES(c, flags);
70003354:	f1a5 034c 	sub.w	r3, r5, #76	; 0x4c
70003358:	2b2e      	cmp	r3, #46	; 0x2e
7000335a:	d87e      	bhi.n	7000345a <__l_vfprintf+0x23e>
7000335c:	a201      	add	r2, pc, #4	; (adr r2, 70003364 <__l_vfprintf+0x148>)
7000335e:	f852 f023 	ldr.w	pc, [r2, r3, lsl #2]
70003362:	bf00      	nop
70003364:	70003421 	.word	0x70003421
70003368:	7000345b 	.word	0x7000345b
7000336c:	7000345b 	.word	0x7000345b
70003370:	7000345b 	.word	0x7000345b
70003374:	7000345b 	.word	0x7000345b
70003378:	7000345b 	.word	0x7000345b
7000337c:	7000345b 	.word	0x7000345b
70003380:	7000345b 	.word	0x7000345b
70003384:	7000345b 	.word	0x7000345b
70003388:	7000345b 	.word	0x7000345b
7000338c:	7000345b 	.word	0x7000345b
70003390:	7000345b 	.word	0x7000345b
70003394:	7000345b 	.word	0x7000345b
70003398:	7000345b 	.word	0x7000345b
7000339c:	7000345b 	.word	0x7000345b
700033a0:	7000345b 	.word	0x7000345b
700033a4:	7000345b 	.word	0x7000345b
700033a8:	7000345b 	.word	0x7000345b
700033ac:	7000345b 	.word	0x7000345b
700033b0:	7000345b 	.word	0x7000345b
700033b4:	7000345b 	.word	0x7000345b
700033b8:	7000345b 	.word	0x7000345b
700033bc:	7000345b 	.word	0x7000345b
700033c0:	7000345b 	.word	0x7000345b
700033c4:	7000345b 	.word	0x7000345b
700033c8:	7000345b 	.word	0x7000345b
700033cc:	7000345b 	.word	0x7000345b
700033d0:	7000345b 	.word	0x7000345b
700033d4:	7000349b 	.word	0x7000349b
700033d8:	7000345b 	.word	0x7000345b
700033dc:	70003421 	.word	0x70003421
700033e0:	7000345b 	.word	0x7000345b
700033e4:	7000348d 	.word	0x7000348d
700033e8:	7000345b 	.word	0x7000345b
700033ec:	7000345b 	.word	0x7000345b
700033f0:	7000345b 	.word	0x7000345b
700033f4:	7000345b 	.word	0x7000345b
700033f8:	7000345b 	.word	0x7000345b
700033fc:	7000345b 	.word	0x7000345b
70003400:	7000345b 	.word	0x7000345b
70003404:	700032d3 	.word	0x700032d3
70003408:	7000345b 	.word	0x7000345b
7000340c:	7000345b 	.word	0x7000345b
70003410:	7000345b 	.word	0x7000345b
70003414:	7000345b 	.word	0x7000345b
70003418:	7000345b 	.word	0x7000345b
7000341c:	700032d3 	.word	0x700032d3
70003420:	f446 7620 	orr.w	r6, r6, #640	; 0x280
70003424:	e755      	b.n	700032d2 <__l_vfprintf+0xb6>
		if (c == '*') {
70003426:	2d2a      	cmp	r5, #42	; 0x2a
70003428:	d03e      	beq.n	700034a8 <__l_vfprintf+0x28c>
		if (c == '.') {
7000342a:	2d2e      	cmp	r5, #46	; 0x2e
7000342c:	d052      	beq.n	700034d4 <__l_vfprintf+0x2b8>
                if (c == '$') {
7000342e:	2d24      	cmp	r5, #36	; 0x24
70003430:	d190      	bne.n	70003354 <__l_vfprintf+0x138>
                    if (argno) {
70003432:	f1ba 0f00 	cmp.w	sl, #0
70003436:	f000 821c 	beq.w	70003872 <__l_vfprintf+0x656>
                        va_copy(ap, ap_orig);
7000343a:	9b04      	ldr	r3, [sp, #16]
                        skip_to_arg(fmt_orig, &my_ap, (flags & FL_PREC) ? prec : width);
7000343c:	0672      	lsls	r2, r6, #25
                        va_copy(ap, ap_orig);
7000343e:	9309      	str	r3, [sp, #36]	; 0x24
                        skip_to_arg(fmt_orig, &my_ap, (flags & FL_PREC) ? prec : width);
70003440:	f140 823d 	bpl.w	700038be <__l_vfprintf+0x6a2>
70003444:	9a01      	ldr	r2, [sp, #4]
70003446:	a909      	add	r1, sp, #36	; 0x24
70003448:	9803      	ldr	r0, [sp, #12]
7000344a:	f7ff fe21 	bl	70003090 <skip_to_arg>
                            prec = va_arg(ap, int);
7000344e:	9b09      	ldr	r3, [sp, #36]	; 0x24
70003450:	1d1a      	adds	r2, r3, #4
70003452:	9209      	str	r2, [sp, #36]	; 0x24
70003454:	681b      	ldr	r3, [r3, #0]
70003456:	9301      	str	r3, [sp, #4]
70003458:	e73b      	b.n	700032d2 <__l_vfprintf+0xb6>
	if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
7000345a:	f045 0320 	orr.w	r3, r5, #32
            || TOLOWER(c) == 'a'
7000345e:	f1a3 0265 	sub.w	r2, r3, #101	; 0x65
70003462:	2b61      	cmp	r3, #97	; 0x61
70003464:	bf18      	it	ne
70003466:	2a02      	cmpne	r2, #2
70003468:	bf94      	ite	ls
7000346a:	2201      	movls	r2, #1
7000346c:	2200      	movhi	r2, #0
7000346e:	9202      	str	r2, [sp, #8]
        if (argno) {
70003470:	f1ba 0f00 	cmp.w	sl, #0
70003474:	f43f af37 	beq.w	700032e6 <__l_vfprintf+0xca>
            va_copy(ap, ap_orig);
70003478:	9305      	str	r3, [sp, #20]
            skip_to_arg(fmt_orig, &my_ap, argno);
7000347a:	4652      	mov	r2, sl
            va_copy(ap, ap_orig);
7000347c:	9b04      	ldr	r3, [sp, #16]
            skip_to_arg(fmt_orig, &my_ap, argno);
7000347e:	a909      	add	r1, sp, #36	; 0x24
70003480:	9803      	ldr	r0, [sp, #12]
            va_copy(ap, ap_orig);
70003482:	9309      	str	r3, [sp, #36]	; 0x24
            skip_to_arg(fmt_orig, &my_ap, argno);
70003484:	f7ff fe04 	bl	70003090 <skip_to_arg>
70003488:	9b05      	ldr	r3, [sp, #20]
7000348a:	e72c      	b.n	700032e6 <__l_vfprintf+0xca>
            CHECK_INT_SIZES(c, flags);
7000348c:	0633      	lsls	r3, r6, #24
7000348e:	bf48      	it	mi
70003490:	f446 7600 	orrmi.w	r6, r6, #512	; 0x200
70003494:	f046 0680 	orr.w	r6, r6, #128	; 0x80
70003498:	e71b      	b.n	700032d2 <__l_vfprintf+0xb6>
7000349a:	05f5      	lsls	r5, r6, #23
7000349c:	bf48      	it	mi
7000349e:	f446 7600 	orrmi.w	r6, r6, #512	; 0x200
700034a2:	f446 7680 	orr.w	r6, r6, #256	; 0x100
700034a6:	e714      	b.n	700032d2 <__l_vfprintf+0xb6>
                    if (argno)
700034a8:	f1ba 0f00 	cmp.w	sl, #0
700034ac:	f47f af11 	bne.w	700032d2 <__l_vfprintf+0xb6>
			prec = va_arg(ap, int);
700034b0:	9b09      	ldr	r3, [sp, #36]	; 0x24
		    if (flags & FL_PREC) {
700034b2:	0670      	lsls	r0, r6, #25
			prec = va_arg(ap, int);
700034b4:	f103 0204 	add.w	r2, r3, #4
700034b8:	9209      	str	r2, [sp, #36]	; 0x24
		    if (flags & FL_PREC) {
700034ba:	d4cb      	bmi.n	70003454 <__l_vfprintf+0x238>
			width = va_arg(ap, int);
700034bc:	f8d3 9000 	ldr.w	r9, [r3]
			if (width < 0) {
700034c0:	f1b9 0f00 	cmp.w	r9, #0
			flags |= FL_WIDTH;
700034c4:	bfae      	itee	ge
700034c6:	f046 0620 	orrge.w	r6, r6, #32
			    width = -width;
700034ca:	f1c9 0900 	rsblt	r9, r9, #0
			    flags |= FL_LPAD;
700034ce:	f046 0628 	orrlt.w	r6, r6, #40	; 0x28
700034d2:	e6fe      	b.n	700032d2 <__l_vfprintf+0xb6>
		    if (flags & FL_PREC)
700034d4:	0671      	lsls	r1, r6, #25
700034d6:	f53f aed6 	bmi.w	70003286 <__l_vfprintf+0x6a>
		    flags |= FL_PREC;
700034da:	f046 0640 	orr.w	r6, r6, #64	; 0x40
		    continue;
700034de:	e6f8      	b.n	700032d2 <__l_vfprintf+0xb6>
            SKIP_FLOAT_ARG(flags, ap);
700034e0:	9b09      	ldr	r3, [sp, #36]	; 0x24
	    pnt = "*float*";
700034e2:	f644 42e4 	movw	r2, #19684	; 0x4ce4
	    size = sizeof ("*float*") - 1;
700034e6:	f04f 0a07 	mov.w	sl, #7
	    pnt = "*float*";
700034ea:	f2c7 0200 	movt	r2, #28672	; 0x7000
            SKIP_FLOAT_ARG(flags, ap);
700034ee:	3307      	adds	r3, #7
700034f0:	f023 0307 	bic.w	r3, r3, #7
700034f4:	3308      	adds	r3, #8
700034f6:	9309      	str	r3, [sp, #36]	; 0x24
                    while ((size_t) width > size) {
700034f8:	4649      	mov	r1, r9
                if (!(flags & FL_LPAD)) {
700034fa:	0730      	lsls	r0, r6, #28
700034fc:	d419      	bmi.n	70003532 <__l_vfprintf+0x316>
                    while ((size_t) width > size) {
700034fe:	45ca      	cmp	sl, r9
70003500:	bf3e      	ittt	cc
70003502:	465d      	movcc	r5, fp
70003504:	4616      	movcc	r6, r2
70003506:	46cb      	movcc	fp, r9
70003508:	d303      	bcc.n	70003512 <__l_vfprintf+0x2f6>
7000350a:	e012      	b.n	70003532 <__l_vfprintf+0x316>
7000350c:	459a      	cmp	sl, r3
7000350e:	d208      	bcs.n	70003522 <__l_vfprintf+0x306>
                        width--;
70003510:	4699      	mov	r9, r3
                        my_putc (' ', stream);
70003512:	4639      	mov	r1, r7
70003514:	2020      	movs	r0, #32
70003516:	47a8      	blx	r5
                        width--;
70003518:	f109 33ff 	add.w	r3, r9, #4294967295	; 0xffffffff
                        my_putc (' ', stream);
7000351c:	2800      	cmp	r0, #0
7000351e:	daf5      	bge.n	7000350c <__l_vfprintf+0x2f0>
70003520:	e6ab      	b.n	7000327a <__l_vfprintf+0x5e>
70003522:	4659      	mov	r1, fp
70003524:	3401      	adds	r4, #1
70003526:	4632      	mov	r2, r6
70003528:	440c      	add	r4, r1
7000352a:	46ab      	mov	fp, r5
7000352c:	eba4 0409 	sub.w	r4, r4, r9
                    while ((size_t) width > size) {
70003530:	4619      	mov	r1, r3
                    while (size--)
70003532:	4623      	mov	r3, r4
70003534:	465e      	mov	r6, fp
70003536:	4614      	mov	r4, r2
70003538:	eb02 050a 	add.w	r5, r2, sl
7000353c:	4693      	mov	fp, r2
7000353e:	4699      	mov	r9, r3
70003540:	9101      	str	r1, [sp, #4]
70003542:	e005      	b.n	70003550 <__l_vfprintf+0x334>
                        my_putc (*pnt++, stream);
70003544:	f814 0b01 	ldrb.w	r0, [r4], #1
70003548:	47b0      	blx	r6
7000354a:	2800      	cmp	r0, #0
7000354c:	f6ff ae95 	blt.w	7000327a <__l_vfprintf+0x5e>
70003550:	4639      	mov	r1, r7
                    while (size--)
70003552:	42ac      	cmp	r4, r5
70003554:	d1f6      	bne.n	70003544 <__l_vfprintf+0x328>
70003556:	465a      	mov	r2, fp
70003558:	464b      	mov	r3, r9
7000355a:	9901      	ldr	r1, [sp, #4]
7000355c:	46a1      	mov	r9, r4
7000355e:	46b3      	mov	fp, r6
70003560:	1a9b      	subs	r3, r3, r2
                width -= size;
70003562:	eba1 060a 	sub.w	r6, r1, sl
70003566:	4499      	add	r9, r3
                while (prec > buf_len) {
70003568:	464c      	mov	r4, r9
7000356a:	444e      	add	r6, r9
7000356c:	465d      	mov	r5, fp
7000356e:	e004      	b.n	7000357a <__l_vfprintf+0x35e>
	    my_putc (' ', stream);
70003570:	47a8      	blx	r5
70003572:	3401      	adds	r4, #1
70003574:	2800      	cmp	r0, #0
70003576:	f6ff ae80 	blt.w	7000327a <__l_vfprintf+0x5e>
7000357a:	4639      	mov	r1, r7
7000357c:	1b33      	subs	r3, r6, r4
7000357e:	2020      	movs	r0, #32
	while (width-- > 0) {
70003580:	2b00      	cmp	r3, #0
70003582:	dcf5      	bgt.n	70003570 <__l_vfprintf+0x354>
70003584:	46ab      	mov	fp, r5
70003586:	4645      	mov	r5, r8
70003588:	e666      	b.n	70003258 <__l_vfprintf+0x3c>
                    } else if (TOLOWER(c) == 'x') {
7000358a:	2b78      	cmp	r3, #120	; 0x78
                        base = ('x' - c) | 16;
7000358c:	bf04      	itt	eq
7000358e:	f1c5 0378 	rsbeq	r3, r5, #120	; 0x78
70003592:	f043 0310 	orreq.w	r3, r3, #16
                    } else if (TOLOWER(c) == 'x') {
70003596:	d055      	beq.n	70003644 <__l_vfprintf+0x428>
                    } else if (TOLOWER(c) == 'b') {
70003598:	2b62      	cmp	r3, #98	; 0x62
7000359a:	f000 81b2 	beq.w	70003902 <__l_vfprintf+0x6e6>
                        my_putc('%', stream);
7000359e:	4639      	mov	r1, r7
700035a0:	2025      	movs	r0, #37	; 0x25
700035a2:	47d8      	blx	fp
700035a4:	2800      	cmp	r0, #0
700035a6:	f6ff ae68 	blt.w	7000327a <__l_vfprintf+0x5e>
                        my_putc(c, stream);
700035aa:	4628      	mov	r0, r5
700035ac:	4639      	mov	r1, r7
700035ae:	47d8      	blx	fp
700035b0:	2800      	cmp	r0, #0
700035b2:	f6ff ae62 	blt.w	7000327a <__l_vfprintf+0x5e>
700035b6:	4645      	mov	r5, r8
700035b8:	3402      	adds	r4, #2
700035ba:	e64d      	b.n	70003258 <__l_vfprintf+0x3c>
            SKIP_FLOAT_ARG(flags, ap);
700035bc:	9b09      	ldr	r3, [sp, #36]	; 0x24
                    arg_to_signed(ap, flags, x_s);
700035be:	0632      	lsls	r2, r6, #24
700035c0:	f100 8172 	bmi.w	700038a8 <__l_vfprintf+0x68c>
700035c4:	1d1a      	adds	r2, r3, #4
700035c6:	05f1      	lsls	r1, r6, #23
700035c8:	9209      	str	r2, [sp, #36]	; 0x24
700035ca:	681a      	ldr	r2, [r3, #0]
700035cc:	bf5c      	itt	pl
700035ce:	4610      	movpl	r0, r2
700035d0:	17c2      	asrpl	r2, r0, #31
700035d2:	d507      	bpl.n	700035e4 <__l_vfprintf+0x3c8>
700035d4:	05b3      	lsls	r3, r6, #22
700035d6:	bf4b      	itete	mi
700035d8:	b250      	sxtbmi	r0, r2
700035da:	b210      	sxthpl	r0, r2
700035dc:	f342 12c0 	sbfxmi	r2, r2, #7, #1
700035e0:	f342 32c0 	sbfxpl	r2, r2, #15, #1
                    if (x_s < 0) {
700035e4:	f026 0110 	bic.w	r1, r6, #16
700035e8:	2a00      	cmp	r2, #0
700035ea:	fa1f fa81 	uxth.w	sl, r1
700035ee:	f2c0 8171 	blt.w	700038d4 <__l_vfprintf+0x6b8>
                    if (x_s == 0 && (flags & FL_PREC) && prec == 0)
700035f2:	ea50 0102 	orrs.w	r1, r0, r2
700035f6:	f040 8190 	bne.w	7000391a <__l_vfprintf+0x6fe>
700035fa:	9a01      	ldr	r2, [sp, #4]
700035fc:	f3c6 1380 	ubfx	r3, r6, #6, #1
70003600:	2a00      	cmp	r2, #0
70003602:	bf14      	ite	ne
70003604:	2300      	movne	r3, #0
70003606:	f003 0301 	andeq.w	r3, r3, #1
7000360a:	f006 0240 	and.w	r2, r6, #64	; 0x40
7000360e:	9202      	str	r2, [sp, #8]
70003610:	2b00      	cmp	r3, #0
70003612:	f040 817b 	bne.w	7000390c <__l_vfprintf+0x6f0>
70003616:	4618      	mov	r0, r3
70003618:	4619      	mov	r1, r3
                        buf_len = __ultoa_invert (x_s, buf, 10) - buf;
7000361a:	230a      	movs	r3, #10
7000361c:	ae0a      	add	r6, sp, #40	; 0x28
7000361e:	4632      	mov	r2, r6
70003620:	f7ff fcbe 	bl	70002fa0 <__ultoa_invert>
70003624:	1b83      	subs	r3, r0, r6
70003626:	e03a      	b.n	7000369e <__l_vfprintf+0x482>
                buf[0] = va_arg (ap, int);
70003628:	9b09      	ldr	r3, [sp, #36]	; 0x24
                size = 1;
7000362a:	f04f 0a01 	mov.w	sl, #1
                pnt = buf;
7000362e:	aa0a      	add	r2, sp, #40	; 0x28
                buf[0] = va_arg (ap, int);
70003630:	1d19      	adds	r1, r3, #4
70003632:	9109      	str	r1, [sp, #36]	; 0x24
70003634:	681b      	ldr	r3, [r3, #0]
70003636:	f88d 3028 	strb.w	r3, [sp, #40]	; 0x28
                goto str_lpad;
7000363a:	e75d      	b.n	700034f8 <__l_vfprintf+0x2dc>
                        base = 16;
7000363c:	2310      	movs	r3, #16
                        flags |= FL_ALT;
7000363e:	f046 0610 	orr.w	r6, r6, #16
                        c = 'x';
70003642:	2578      	movs	r5, #120	; 0x78
            SKIP_FLOAT_ARG(flags, ap);
70003644:	9a09      	ldr	r2, [sp, #36]	; 0x24
                    arg_to_unsigned(ap, flags, x);
70003646:	f016 0c80 	ands.w	ip, r6, #128	; 0x80
7000364a:	f000 80a2 	beq.w	70003792 <__l_vfprintf+0x576>
7000364e:	f416 7100 	ands.w	r1, r6, #512	; 0x200
70003652:	bf1d      	ittte	ne
70003654:	3207      	addne	r2, #7
70003656:	f022 0207 	bicne.w	r2, r2, #7
7000365a:	f102 0108 	addne.w	r1, r2, #8
7000365e:	1d10      	addeq	r0, r2, #4
70003660:	bf15      	itete	ne
70003662:	9109      	strne	r1, [sp, #36]	; 0x24
70003664:	9009      	streq	r0, [sp, #36]	; 0x24
70003666:	e9d2 0100 	ldrdne	r0, r1, [r2]
7000366a:	6810      	ldreq	r0, [r2, #0]
                    if (x == 0)
7000366c:	ea50 0201 	orrs.w	r2, r0, r1
70003670:	f040 80c5 	bne.w	700037fe <__l_vfprintf+0x5e2>
                    if (x == 0 && (flags & FL_PREC) && prec == 0)
70003674:	9a01      	ldr	r2, [sp, #4]
                        flags &= ~FL_ALT;
70003676:	f026 0c16 	bic.w	ip, r6, #22
                    if (x == 0 && (flags & FL_PREC) && prec == 0)
7000367a:	fab2 f282 	clz	r2, r2
                        flags &= ~FL_ALT;
7000367e:	fa1f fa8c 	uxth.w	sl, ip
                    if (x == 0 && (flags & FL_PREC) && prec == 0)
70003682:	0952      	lsrs	r2, r2, #5
70003684:	f006 0c40 	and.w	ip, r6, #64	; 0x40
70003688:	ea12 1296 	ands.w	r2, r2, r6, lsr #6
7000368c:	f8cd c008 	str.w	ip, [sp, #8]
70003690:	f040 8129 	bne.w	700038e6 <__l_vfprintf+0x6ca>
                        buf_len = __ultoa_invert (x, buf, base) - buf;
70003694:	ae0a      	add	r6, sp, #40	; 0x28
70003696:	4632      	mov	r2, r6
70003698:	f7ff fc82 	bl	70002fa0 <__ultoa_invert>
7000369c:	1b83      	subs	r3, r0, r6
                if (flags & FL_PREC) {
7000369e:	9a02      	ldr	r2, [sp, #8]
700036a0:	f00a 0c10 	and.w	ip, sl, #16
700036a4:	b37a      	cbz	r2, 70003706 <__l_vfprintf+0x4ea>
                    if (len < prec) {
700036a6:	9901      	ldr	r1, [sp, #4]
                    flags &= ~FL_ZFILL;
700036a8:	f02a 0201 	bic.w	r2, sl, #1
                    if (len < prec) {
700036ac:	4299      	cmp	r1, r3
                    flags &= ~FL_ZFILL;
700036ae:	b292      	uxth	r2, r2
                    if (len < prec) {
700036b0:	bfdc      	itt	le
700036b2:	f00a 0c10 	andle.w	ip, sl, #16
                    flags &= ~FL_ZFILL;
700036b6:	4692      	movle	sl, r2
                    if (len < prec) {
700036b8:	dd25      	ble.n	70003706 <__l_vfprintf+0x4ea>
                        if (c == '\0')
700036ba:	2d00      	cmp	r5, #0
700036bc:	f040 80ea 	bne.w	70003894 <__l_vfprintf+0x678>
                            flags &= ~FL_ALT;
700036c0:	f02a 0211 	bic.w	r2, sl, #17
700036c4:	fa1f fa82 	uxth.w	sl, r2
700036c8:	9a01      	ldr	r2, [sp, #4]
700036ca:	e071      	b.n	700037b0 <__l_vfprintf+0x594>
                        base = 10;
700036cc:	230a      	movs	r3, #10
                        flags &= ~FL_ALT;
700036ce:	f026 0610 	bic.w	r6, r6, #16
700036d2:	b2b6      	uxth	r6, r6
                        base = 10;
700036d4:	e7b6      	b.n	70003644 <__l_vfprintf+0x428>
                    pnt = va_arg (ap, char *);
700036d6:	9a09      	ldr	r2, [sp, #36]	; 0x24
                    pnt = "(null)";
700036d8:	f644 43dc 	movw	r3, #19676	; 0x4cdc
700036dc:	f2c7 0300 	movt	r3, #28672	; 0x7000
                    pnt = va_arg (ap, char *);
700036e0:	1d11      	adds	r1, r2, #4
700036e2:	9109      	str	r1, [sp, #36]	; 0x24
700036e4:	6812      	ldr	r2, [r2, #0]
                size = strnlen (pnt, size);
700036e6:	9901      	ldr	r1, [sp, #4]
                    pnt = "(null)";
700036e8:	2a00      	cmp	r2, #0
700036ea:	bf08      	it	eq
700036ec:	461a      	moveq	r2, r3
                size = strnlen (pnt, size);
700036ee:	4610      	mov	r0, r2
                size = (flags & FL_PREC) ? (size_t) prec : SIZE_MAX;
700036f0:	f016 0f40 	tst.w	r6, #64	; 0x40
                size = strnlen (pnt, size);
700036f4:	9201      	str	r2, [sp, #4]
700036f6:	bf08      	it	eq
700036f8:	f04f 31ff 	moveq.w	r1, #4294967295	; 0xffffffff
700036fc:	f7ff fc0a 	bl	70002f14 <strnlen>
70003700:	9a01      	ldr	r2, [sp, #4]
70003702:	4682      	mov	sl, r0
70003704:	e6f8      	b.n	700034f8 <__l_vfprintf+0x2dc>
                if (flags & FL_ALT) {
70003706:	f1bc 0f00 	cmp.w	ip, #0
7000370a:	d050      	beq.n	700037ae <__l_vfprintf+0x592>
                    len += 1;
7000370c:	1c5a      	adds	r2, r3, #1
                    if (c != '\0')
7000370e:	b10d      	cbz	r5, 70003714 <__l_vfprintf+0x4f8>
70003710:	461a      	mov	r2, r3
                        len += 1;
70003712:	3202      	adds	r2, #2
                if (!(flags & FL_LPAD)) {
70003714:	f01a 0f08 	tst.w	sl, #8
                width -= len;
70003718:	bf18      	it	ne
7000371a:	eba9 0602 	subne.w	r6, r9, r2
                if (!(flags & FL_LPAD)) {
7000371e:	d053      	beq.n	700037c8 <__l_vfprintf+0x5ac>
                    my_putc ('0', stream);
70003720:	4639      	mov	r1, r7
70003722:	2030      	movs	r0, #48	; 0x30
70003724:	9302      	str	r3, [sp, #8]
70003726:	47d8      	blx	fp
70003728:	2800      	cmp	r0, #0
7000372a:	f6ff ada6 	blt.w	7000327a <__l_vfprintf+0x5e>
                    if (c != '\0')
7000372e:	9b02      	ldr	r3, [sp, #8]
70003730:	2d00      	cmp	r5, #0
70003732:	f040 8094 	bne.w	7000385e <__l_vfprintf+0x642>
                    my_putc ('0', stream);
70003736:	3401      	adds	r4, #1
                while (prec > buf_len) {
70003738:	9a01      	ldr	r2, [sp, #4]
7000373a:	4293      	cmp	r3, r2
7000373c:	bfa8      	it	ge
7000373e:	4625      	movge	r5, r4
70003740:	da12      	bge.n	70003768 <__l_vfprintf+0x54c>
70003742:	9d01      	ldr	r5, [sp, #4]
70003744:	469a      	mov	sl, r3
70003746:	4425      	add	r5, r4
70003748:	1aed      	subs	r5, r5, r3
7000374a:	46a9      	mov	r9, r5
7000374c:	465d      	mov	r5, fp
7000374e:	e001      	b.n	70003754 <__l_vfprintf+0x538>
70003750:	45a1      	cmp	r9, r4
70003752:	d006      	beq.n	70003762 <__l_vfprintf+0x546>
                    my_putc ('0', stream);
70003754:	4639      	mov	r1, r7
70003756:	2030      	movs	r0, #48	; 0x30
70003758:	47a8      	blx	r5
7000375a:	3401      	adds	r4, #1
7000375c:	2800      	cmp	r0, #0
7000375e:	daf7      	bge.n	70003750 <__l_vfprintf+0x534>
70003760:	e58b      	b.n	7000327a <__l_vfprintf+0x5e>
70003762:	46ab      	mov	fp, r5
70003764:	4653      	mov	r3, sl
70003766:	464d      	mov	r5, r9
70003768:	46aa      	mov	sl, r5
7000376a:	ac0a      	add	r4, sp, #40	; 0x28
7000376c:	465d      	mov	r5, fp
7000376e:	eb04 0903 	add.w	r9, r4, r3
70003772:	469b      	mov	fp, r3
70003774:	e005      	b.n	70003782 <__l_vfprintf+0x566>
                    my_putc (buf[--buf_len], stream);
70003776:	f819 0d01 	ldrb.w	r0, [r9, #-1]!
7000377a:	47a8      	blx	r5
7000377c:	2800      	cmp	r0, #0
7000377e:	f6ff ad7c 	blt.w	7000327a <__l_vfprintf+0x5e>
70003782:	4639      	mov	r1, r7
                while (buf_len)
70003784:	45a1      	cmp	r9, r4
70003786:	d1f6      	bne.n	70003776 <__l_vfprintf+0x55a>
70003788:	465b      	mov	r3, fp
7000378a:	46ab      	mov	fp, r5
7000378c:	eb0a 0903 	add.w	r9, sl, r3
70003790:	e6ea      	b.n	70003568 <__l_vfprintf+0x34c>
                    arg_to_unsigned(ap, flags, x);
70003792:	1d11      	adds	r1, r2, #4
70003794:	9109      	str	r1, [sp, #36]	; 0x24
70003796:	f416 7180 	ands.w	r1, r6, #256	; 0x100
7000379a:	6810      	ldr	r0, [r2, #0]
7000379c:	f43f af66 	beq.w	7000366c <__l_vfprintf+0x450>
700037a0:	f416 7100 	ands.w	r1, r6, #512	; 0x200
700037a4:	bf1a      	itte	ne
700037a6:	4661      	movne	r1, ip
700037a8:	b2c0      	uxtbne	r0, r0
700037aa:	b280      	uxtheq	r0, r0
700037ac:	e75e      	b.n	7000366c <__l_vfprintf+0x450>
700037ae:	461a      	mov	r2, r3
                if (!(flags & FL_LPAD)) {
700037b0:	f240 4106 	movw	r1, #1030	; 0x406
                } else if (flags & (FL_NEGATIVE | FL_PLUS | FL_SPACE)) {
700037b4:	ea1a 0101 	ands.w	r1, sl, r1
                    len += 1;
700037b8:	bf18      	it	ne
700037ba:	3201      	addne	r2, #1
                if (!(flags & FL_LPAD)) {
700037bc:	f01a 0c08 	ands.w	ip, sl, #8
                width -= len;
700037c0:	bf18      	it	ne
700037c2:	eba9 0602 	subne.w	r6, r9, r2
                if (!(flags & FL_LPAD)) {
700037c6:	d135      	bne.n	70003834 <__l_vfprintf+0x618>
                    if (flags & FL_ZFILL) {
700037c8:	f01a 0f01 	tst.w	sl, #1
700037cc:	d158      	bne.n	70003880 <__l_vfprintf+0x664>
                    while (len < width) {
700037ce:	4591      	cmp	r9, r2
700037d0:	f340 80a8 	ble.w	70003924 <__l_vfprintf+0x708>
700037d4:	f8cd 8008 	str.w	r8, [sp, #8]
700037d8:	eb09 0604 	add.w	r6, r9, r4
700037dc:	e9cd 3205 	strd	r3, r2, [sp, #20]
700037e0:	1ab6      	subs	r6, r6, r2
700037e2:	9407      	str	r4, [sp, #28]
700037e4:	46b0      	mov	r8, r6
700037e6:	465e      	mov	r6, fp
700037e8:	46e3      	mov	fp, ip
700037ea:	e001      	b.n	700037f0 <__l_vfprintf+0x5d4>
700037ec:	45a0      	cmp	r8, r4
700037ee:	d00e      	beq.n	7000380e <__l_vfprintf+0x5f2>
                        my_putc (' ', stream);
700037f0:	4639      	mov	r1, r7
700037f2:	2020      	movs	r0, #32
700037f4:	47b0      	blx	r6
700037f6:	3401      	adds	r4, #1
700037f8:	2800      	cmp	r0, #0
700037fa:	daf7      	bge.n	700037ec <__l_vfprintf+0x5d0>
700037fc:	e53d      	b.n	7000327a <__l_vfprintf+0x5e>
                    flags &= ~(FL_PLUS | FL_SPACE);
700037fe:	f026 0206 	bic.w	r2, r6, #6
70003802:	f006 0640 	and.w	r6, r6, #64	; 0x40
70003806:	fa1f fa82 	uxth.w	sl, r2
7000380a:	9602      	str	r6, [sp, #8]
7000380c:	e742      	b.n	70003694 <__l_vfprintf+0x478>
                        len++;
7000380e:	e9dd 3205 	ldrd	r3, r2, [sp, #20]
70003812:	46dc      	mov	ip, fp
70003814:	9907      	ldr	r1, [sp, #28]
70003816:	46b3      	mov	fp, r6
70003818:	f8dd 8008 	ldr.w	r8, [sp, #8]
7000381c:	1a56      	subs	r6, r2, r1
7000381e:	4426      	add	r6, r4
                width -= len;
70003820:	eba9 0606 	sub.w	r6, r9, r6
                if (flags & FL_ALT) {
70003824:	f1bc 0f00 	cmp.w	ip, #0
70003828:	f47f af7a 	bne.w	70003720 <__l_vfprintf+0x504>
7000382c:	f240 4106 	movw	r1, #1030	; 0x406
70003830:	ea0a 0101 	and.w	r1, sl, r1
                } else if (flags & (FL_NEGATIVE | FL_PLUS | FL_SPACE)) {
70003834:	2900      	cmp	r1, #0
70003836:	f43f af7f 	beq.w	70003738 <__l_vfprintf+0x51c>
                    my_putc (z, stream);
7000383a:	4639      	mov	r1, r7
                    if (flags & FL_PLUS) z = '+';
7000383c:	f01a 0f02 	tst.w	sl, #2
70003840:	bf14      	ite	ne
70003842:	202b      	movne	r0, #43	; 0x2b
70003844:	2020      	moveq	r0, #32
                    if (flags & FL_NEGATIVE) z = '-';
70003846:	9302      	str	r3, [sp, #8]
70003848:	f41a 6f80 	tst.w	sl, #1024	; 0x400
                    my_putc (z, stream);
7000384c:	bf18      	it	ne
7000384e:	202d      	movne	r0, #45	; 0x2d
70003850:	3401      	adds	r4, #1
70003852:	47d8      	blx	fp
70003854:	9b02      	ldr	r3, [sp, #8]
70003856:	2800      	cmp	r0, #0
70003858:	f6bf af6e 	bge.w	70003738 <__l_vfprintf+0x51c>
7000385c:	e50d      	b.n	7000327a <__l_vfprintf+0x5e>
                        my_putc (c, stream);
7000385e:	4628      	mov	r0, r5
70003860:	4639      	mov	r1, r7
70003862:	9302      	str	r3, [sp, #8]
70003864:	47d8      	blx	fp
70003866:	9b02      	ldr	r3, [sp, #8]
70003868:	3402      	adds	r4, #2
7000386a:	2800      	cmp	r0, #0
7000386c:	f6bf af64 	bge.w	70003738 <__l_vfprintf+0x51c>
70003870:	e503      	b.n	7000327a <__l_vfprintf+0x5e>
70003872:	464b      	mov	r3, r9
                        prec = 0;
70003874:	4656      	mov	r6, sl
70003876:	f8cd a004 	str.w	sl, [sp, #4]
                        width = 0;
7000387a:	46d1      	mov	r9, sl
7000387c:	469a      	mov	sl, r3
7000387e:	e528      	b.n	700032d2 <__l_vfprintf+0xb6>
                        if (len < width) {
70003880:	4591      	cmp	r9, r2
                            prec += width - len;
70003882:	eba9 0602 	sub.w	r6, r9, r2
70003886:	bfd8      	it	le
70003888:	9301      	strle	r3, [sp, #4]
                        if (len < width) {
7000388a:	ddcb      	ble.n	70003824 <__l_vfprintf+0x608>
                            prec += width - len;
7000388c:	199a      	adds	r2, r3, r6
7000388e:	2600      	movs	r6, #0
70003890:	9201      	str	r2, [sp, #4]
                            len = width;
70003892:	e7c7      	b.n	70003824 <__l_vfprintf+0x608>
                if (flags & FL_ALT) {
70003894:	f01a 0c10 	ands.w	ip, sl, #16
70003898:	4692      	mov	sl, r2
                        len = prec;
7000389a:	9a01      	ldr	r2, [sp, #4]
                if (flags & FL_ALT) {
7000389c:	f47f af39 	bne.w	70003712 <__l_vfprintf+0x4f6>
700038a0:	e786      	b.n	700037b0 <__l_vfprintf+0x594>
	if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
700038a2:	2308      	movs	r3, #8
700038a4:	2500      	movs	r5, #0
700038a6:	e6cd      	b.n	70003644 <__l_vfprintf+0x428>
                    arg_to_signed(ap, flags, x_s);
700038a8:	05b0      	lsls	r0, r6, #22
700038aa:	d525      	bpl.n	700038f8 <__l_vfprintf+0x6dc>
700038ac:	3307      	adds	r3, #7
700038ae:	f023 0307 	bic.w	r3, r3, #7
700038b2:	f103 0208 	add.w	r2, r3, #8
700038b6:	9209      	str	r2, [sp, #36]	; 0x24
700038b8:	e9d3 0200 	ldrd	r0, r2, [r3]
700038bc:	e692      	b.n	700035e4 <__l_vfprintf+0x3c8>
                        skip_to_arg(fmt_orig, &my_ap, (flags & FL_PREC) ? prec : width);
700038be:	464a      	mov	r2, r9
700038c0:	a909      	add	r1, sp, #36	; 0x24
700038c2:	9803      	ldr	r0, [sp, #12]
700038c4:	f7ff fbe4 	bl	70003090 <skip_to_arg>
                            width = va_arg(ap, int);
700038c8:	9b09      	ldr	r3, [sp, #36]	; 0x24
700038ca:	1d1a      	adds	r2, r3, #4
700038cc:	9209      	str	r2, [sp, #36]	; 0x24
700038ce:	f8d3 9000 	ldr.w	r9, [r3]
700038d2:	e4fe      	b.n	700032d2 <__l_vfprintf+0xb6>
                    flags &= ~FL_ALT;
700038d4:	f006 0340 	and.w	r3, r6, #64	; 0x40
                        x_s = -x_s;
700038d8:	4240      	negs	r0, r0
                    flags &= ~FL_ALT;
700038da:	f44a 6a80 	orr.w	sl, sl, #1024	; 0x400
                    if (x_s == 0 && (flags & FL_PREC) && prec == 0)
700038de:	9302      	str	r3, [sp, #8]
                        x_s = -x_s;
700038e0:	eb62 0142 	sbc.w	r1, r2, r2, lsl #1
700038e4:	e699      	b.n	7000361a <__l_vfprintf+0x3fe>
                        buf_len = 0;
700038e6:	2200      	movs	r2, #0
                    flags &= ~FL_ZFILL;
700038e8:	f026 0617 	bic.w	r6, r6, #23
                        buf_len = 0;
700038ec:	4613      	mov	r3, r2
                    flags &= ~FL_ZFILL;
700038ee:	fa1f fa86 	uxth.w	sl, r6
                if (flags & FL_ALT) {
700038f2:	e75d      	b.n	700037b0 <__l_vfprintf+0x594>
    int stream_len = 0;
700038f4:	4604      	mov	r4, r0
    return stream_len;
700038f6:	e4c6      	b.n	70003286 <__l_vfprintf+0x6a>
                    arg_to_signed(ap, flags, x_s);
700038f8:	1d1a      	adds	r2, r3, #4
700038fa:	9209      	str	r2, [sp, #36]	; 0x24
700038fc:	6818      	ldr	r0, [r3, #0]
700038fe:	17c2      	asrs	r2, r0, #31
70003900:	e670      	b.n	700035e4 <__l_vfprintf+0x3c8>
                        base = 2;
70003902:	2302      	movs	r3, #2
70003904:	e69e      	b.n	70003644 <__l_vfprintf+0x428>
	return EOF;
70003906:	f04f 34ff 	mov.w	r4, #4294967295	; 0xffffffff
7000390a:	e4bc      	b.n	70003286 <__l_vfprintf+0x6a>
                        buf_len = 0;
7000390c:	2200      	movs	r2, #0
                    flags &= ~FL_ZFILL;
7000390e:	f026 0611 	bic.w	r6, r6, #17
                        buf_len = 0;
70003912:	4613      	mov	r3, r2
                    flags &= ~FL_ZFILL;
70003914:	fa1f fa86 	uxth.w	sl, r6
                if (flags & FL_ALT) {
70003918:	e74a      	b.n	700037b0 <__l_vfprintf+0x594>
                        buf_len = __ultoa_invert (x_s, buf, 10) - buf;
7000391a:	4611      	mov	r1, r2
7000391c:	f006 0340 	and.w	r3, r6, #64	; 0x40
70003920:	9302      	str	r3, [sp, #8]
70003922:	e67a      	b.n	7000361a <__l_vfprintf+0x3fe>
                            prec += width - len;
70003924:	eba9 0602 	sub.w	r6, r9, r2
70003928:	e77c      	b.n	70003824 <__l_vfprintf+0x608>
		if (c >= '0' && c <= '9') {
7000392a:	f1a5 0330 	sub.w	r3, r5, #48	; 0x30
7000392e:	2b09      	cmp	r3, #9
70003930:	f63f ad79 	bhi.w	70003426 <__l_vfprintf+0x20a>
		    if (flags & FL_PREC) {
70003934:	0675      	lsls	r5, r6, #25
70003936:	f57f acc6 	bpl.w	700032c6 <__l_vfprintf+0xaa>
			prec = 10*prec + c;
7000393a:	9a01      	ldr	r2, [sp, #4]
7000393c:	eb02 0282 	add.w	r2, r2, r2, lsl #2
70003940:	eb03 0342 	add.w	r3, r3, r2, lsl #1
70003944:	9301      	str	r3, [sp, #4]
			continue;
70003946:	e4c4      	b.n	700032d2 <__l_vfprintf+0xb6>

70003948 <__file_str_put>:
         * overflow, instead it returns the total number of characters
         * processed but truncates the result to fit within the target
         * buffer. As a result, this function simply stops writing
         * when it reaches the end of the buffer
         */
	if (sstream->pos != sstream->end)
70003948:	e9d1 3204 	ldrd	r3, r2, [r1, #16]
7000394c:	4293      	cmp	r3, r2
            *sstream->pos++ = c;
7000394e:	bf1e      	ittt	ne
70003950:	1c5a      	addne	r2, r3, #1
70003952:	610a      	strne	r2, [r1, #16]
70003954:	7018      	strbne	r0, [r3, #0]
	return (unsigned char) c;
}
70003956:	4770      	bx	lr

70003958 <__z_arm_int_exit_from_thumb>:
70003958:	4778      	bx	pc
7000395a:	e7fd      	b.n	70003958 <__z_arm_int_exit_from_thumb>
7000395c:	eafff582 	b	70000f6c <z_arm_int_exit>

Disassembly of section .boot_section:

00000000 <__boot_spring>:
 * @brief Initialisation of fault handling
 */
void z_arm_fault_init(void)
{
	/* Nothing to do for now */
}
   0:	e59fd004 	ldr	sp, [pc, #4]	; c <___thread_base_t_user_options_OFFSET>
	arch_system_halt(reason);
   4:	fa000024 	blx	9c <MpuP_init>
	handler = pHandler;
   8:	ea000056 	b	168 <____start_veneer>
};

void rsc_table_get(struct fw_resource_table **table_ptr, int *length)
{
	*table_ptr = &resource_table;
	*length = sizeof(resource_table);
   c:	70009ac0 	.word	0x70009ac0

00000010 <MpuP_setRegion>:
	cmp	r0, #0
	bne	_irq_disabled
	cpsie	i
_irq_disabled:

	bx	lr
  10:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
  12:	f893 c004 	ldrb.w	ip, [r3, #4]
{
	uint32_t *ssf_contents = ssf_ptr;
	struct arch_esf oops_esf = { 0 };

	/* TODO: Copy the rest of the register set out of ssf_ptr */
	oops_esf.basic.pc = ssf_contents[3];
  16:	f893 e000 	ldrb.w	lr, [r3]
	z_fatal_error(reason, esf);
  1a:	79de      	ldrb	r6, [r3, #7]
}
  1c:	4604      	mov	r4, r0
  1e:	ea4f 3c0c 	mov.w	ip, ip, lsl #12
   z_vim_irq_enable(irq);
  22:	7998      	ldrb	r0, [r3, #6]
  24:	0200      	lsls	r0, r0, #8
		(void) vfprintf(&console, fmt, ap);
  26:	f400 60e0 	and.w	r0, r0, #1792	; 0x700
}
  2a:	f40c 5c80 	and.w	ip, ip, #4096	; 0x1000
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	sys_write32(BIT(irq_bit_num), VIM_RAW(irq_group_num));
  2e:	ea4c 0c00 	orr.w	ip, ip, r0
  32:	7898      	ldrb	r0, [r3, #2]
  34:	f000 0001 	and.w	r0, r0, #1
  38:	ea4c 0c00 	orr.w	ip, ip, r0
}
  3c:	7958      	ldrb	r0, [r3, #5]
	return dev->state->initialized && (dev->state->init_res == 0U);
  3e:	00c0      	lsls	r0, r0, #3
		return NULL;
  40:	f000 0038 	and.w	r0, r0, #56	; 0x38
  44:	ea4c 0c00 	orr.w	ip, ip, r0
}
  48:	78d8      	ldrb	r0, [r3, #3]
		return NULL;
  4a:	0080      	lsls	r0, r0, #2
}
  4c:	f000 0004 	and.w	r0, r0, #4
	void *ret = sys_heap_aligned_realloc(&z_malloc_heap, ptr,
					     __alignof__(z_max_align_t),
					     requested_size);

	if (ret == NULL && requested_size != 0) {
		errno = ENOMEM;
  50:	f002 021f 	and.w	r2, r2, #31
  54:	ea4c 0c00 	orr.w	ip, ip, r0
	return z_impl_k_mutex_unlock(mutex);
  58:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
  5c:	1c55      	adds	r5, r2, #1
  5e:	f00e 0e01 	and.w	lr, lr, #1
	}

	malloc_unlock();

	return ret;
}
  62:	40a8      	lsls	r0, r5
  64:	ea01 0500 	and.w	r5, r1, r0
	slab->info.num_used--;

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_mem_slab, free, slab);

	k_spin_unlock(&slab->lock, key);
}
  68:	7858      	ldrb	r0, [r3, #1]
  6a:	0040      	lsls	r0, r0, #1
			z_reschedule(&slab->lock, key);
  6c:	ea4e 2e06 	orr.w	lr, lr, r6, lsl #8
	return list->head == list;
  70:	f000 0002 	and.w	r0, r0, #2
		if (unlikely(thread != NULL)) {
  74:	ea4c 0600 	orr.w	r6, ip, r0
  78:	ea4e 0742 	orr.w	r7, lr, r2, lsl #1

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_heap, realloc, heap, ptr, bytes, timeout, ret);

	k_spin_unlock(&heap->lock, key);
	return ret;
}
  7c:	f000 e85c 	blx	138 <MpuP_isEnableAsm>
  80:	4633      	mov	r3, r6
  82:	463a      	mov	r2, r7
}
  84:	4629      	mov	r1, r5
      {
         printk("Event %s Count: %u\r\n", p->events[j].name, p->events[j].value);
      }
      printk("\r\n");
   }
}
  86:	4606      	mov	r6, r0
  88:	4620      	mov	r0, r4
		wfe();
	}

	cpu_map[cpu_num] = cpu_mpid;

	printk("Secondary CPU core %d (MPID:%#x) is up\n", cpu_num, cpu_mpid);
  8a:	f000 e860 	blx	14c <MpuP_setRegionAsm>
  8e:	b906      	cbnz	r6, 92 <CONFIG_CONSOLE_INPUT_MAX_LINE_LEN+0x12>
}
  90:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		_kernel.ready_q.cache = thread;
  92:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
  96:	f000 b863 	b.w	160 <__MpuP_enableAsm_from_thumb>
	node->prev = prev;
  9a:	bf00      	nop

0000009c <MpuP_init>:
  9c:	b570      	push	{r4, r5, r6, lr}
	prev->next = node;
  9e:	f000 e830 	blx	100 <MpuP_disableBRAsm>
}
  a2:	f24b 162c 	movw	r6, #45356	; 0xb12c
   /* Print PMU results for measurements */
   for (i = 0; i < ITERATION_COUNT; i++)
   {
      // printf("Receive Latency: ");
      // tm_pmu_profile_print(pmu_recv_names[i]);
      printf("Send Latency: ");
  a6:	f2c7 0600 	movt	r6, #28672	; 0x7000
      tm_pmu_profile_print(pmu_send_names[i]);
  aa:	6833      	ldr	r3, [r6, #0]
   for (i = 0; i < ITERATION_COUNT; i++)
  ac:	b163      	cbz	r3, c8 <MpuP_init+0x2c>
      tm_pmu_profile_print(pmu_send_names[i]);
  ae:	4c0d      	ldr	r4, [pc, #52]	; (e4 <__data_size+0xc>)
  b0:	2500      	movs	r5, #0
   for (i = 0; i < ITERATION_COUNT; i++)
  b2:	4623      	mov	r3, r4
  b4:	4628      	mov	r0, r5
   }

   tm_thread_suspend(0);
}
  b6:	e954 1202 	ldrd	r1, r2, [r4, #-8]
   tm_thread_suspend(0);
  ba:	3501      	adds	r5, #1
  bc:	f7ff ffa8 	bl	10 <MpuP_setRegion>
  c0:	6833      	ldr	r3, [r6, #0]
  c2:	3410      	adds	r4, #16
  c4:	42ab      	cmp	r3, r5
  c6:	d8f4      	bhi.n	b2 <MpuP_init+0x16>
                gMpuRegionConfig[i].size,
                &gMpuRegionConfig[i].attrs
        );
    }

    if (gMpuConfig.enableBackgroundRegion) {
  c8:	6873      	ldr	r3, [r6, #4]
  ca:	b913      	cbnz	r3, d2 <MpuP_init+0x36>
        MpuP_enableBRAsm();
    }

    if (gMpuConfig.enableMpu) {
  cc:	68b3      	ldr	r3, [r6, #8]
  ce:	b92b      	cbnz	r3, dc <__data_size+0x4>
	    MpuP_enableAsm();
    }
}
  d0:	bd70      	pop	{r4, r5, r6, pc}
        MpuP_enableBRAsm();
  d2:	f000 e82a 	blx	128 <MpuP_enableBRAsm>
    if (gMpuConfig.enableMpu) {
  d6:	68b3      	ldr	r3, [r6, #8]
  d8:	2b00      	cmp	r3, #0
  da:	d0f9      	beq.n	d0 <MpuP_init+0x34>
}
  dc:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	    MpuP_enableAsm();
  e0:	f000 b83e 	b.w	160 <__MpuP_enableAsm_from_thumb>
  e4:	7000b0e4 	.word	0x7000b0e4

000000e8 <MpuP_disableAsm>:
_ASM_FILE_PROLOGUE

/* FUNCTION DEF: void MpuP_disableAsm(void) */
GTEXT(MpuP_disableAsm)
SECTION_FUNC(boot_section, MpuP_disableAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
  e8:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        bic     r0, r0, #0x1             // clear bit 0 in r0
  ec:	e3c00001 	bic	r0, r0, #1
        dsb
  f0:	f57ff04f 	dsb	sy
        mcr     p15, #0, r0, c1, c0, #0  // MPU disabled (bit 0 = 0)
  f4:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        isb                              // flush instruction pipeline
  f8:	f57ff06f 	isb	sy
        bx      LR
  fc:	e12fff1e 	bx	lr

00000100 <MpuP_disableBRAsm>:

/* FUNCTION DEF: void MpuP_disableBRAsm(void) */
GTEXT(MpuP_disableBRAsm)
SECTION_FUNC(boot_section, MpuP_disableBRAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 100:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        bic     r0, r0, #0x20000         // clear bit 17 in r0
 104:	e3c00802 	bic	r0, r0, #131072	; 0x20000
        mcr     p15, #0, r0, c1, c0, #0  // disable background region
 108:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        bx      LR
 10c:	e12fff1e 	bx	lr

00000110 <MpuP_enableAsm>:

/* FUNCTION DEF: void MpuP_enableAsm(void) */
GTEXT(MpuP_enableAsm)
SECTION_FUNC(boot_section, MpuP_enableAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 110:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        orr     r0, r0, #0x1             // set bit 0 in r0
 114:	e3800001 	orr	r0, r0, #1
        dsb
 118:	f57ff04f 	dsb	sy
        mcr     p15, #0, r0, c1, c0, #0  // MPU enabled (bit 0 = 1)
 11c:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        isb                              // flush instruction pipeline
 120:	f57ff06f 	isb	sy
        bx      LR
 124:	e12fff1e 	bx	lr

00000128 <MpuP_enableBRAsm>:

/* FUNCTION DEF: void MpuP_enableBRAsm(void) */
GTEXT(MpuP_enableBRAsm)
SECTION_FUNC(boot_section, MpuP_enableBRAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 128:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        orr     r0, r0, #0x20000         // set bit 17 in r0
 12c:	e3800802 	orr	r0, r0, #131072	; 0x20000
        mcr     p15, #0, r0, c1, c0, #0  // background region enabled
 130:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        bx      LR
 134:	e12fff1e 	bx	lr

00000138 <MpuP_isEnableAsm>:

/* FUNCTION DEF: uint32_t MpuP_isEnableAsm(void) */
GTEXT(MpuP_isEnableAsm)
SECTION_FUNC(boot_section, MpuP_isEnableAsm)
        mov     r0, #0
 138:	e3a00000 	mov	r0, #0
        mrc     p15, #0, r1, c1, c0, #0  // read SCTLR register to r1
 13c:	ee111f10 	mrc	15, 0, r1, cr1, cr0, {0}
        tst     r1, #0x1                 // test bit 0
 140:	e3110001 	tst	r1, #1
        movne   r0, #1                   // if not 0, MPU is enabled
 144:	13a00001 	movne	r0, #1
        bx      LR
 148:	e12fff1e 	bx	lr

0000014c <MpuP_setRegionAsm>:
 * r2 = sizeAndEnable
 * r3 = regionAttrs
 */
GTEXT(MpuP_setRegionAsm)
SECTION_FUNC(boot_section, MpuP_setRegionAsm)
        mcr     p15, #0, r0, c6, c2, #0  // select MPU region
 14c:	ee060f12 	mcr	15, 0, r0, cr6, cr2, {0}
        mcr     p15, #0, r1, c6, c1, #0  // set region base address
 150:	ee061f11 	mcr	15, 0, r1, cr6, cr1, {0}
        mcr     p15, #0, r2, c6, c1, #2  // set region size and enable it
 154:	ee062f51 	mcr	15, 0, r2, cr6, cr1, {2}
        mcr     p15, #0, r3, c6, c1, #4  // set protection attributes
 158:	ee063f91 	mcr	15, 0, r3, cr6, cr1, {4}
        bx      LR
 15c:	e12fff1e 	bx	lr

00000160 <__MpuP_enableAsm_from_thumb>:
		split_chunks(h, c, c + chunks_need);
 160:	4778      	bx	pc
 162:	e7fd      	b.n	160 <__MpuP_enableAsm_from_thumb>
 164:	eaffffe9 	b	110 <MpuP_enableAsm>

00000168 <____start_veneer>:
		free_chunk(h, c + chunks_need);
 168:	e51ff004 	ldr	pc, [pc, #-4]	; 16c <____start_veneer+0x4>
 16c:	70000c48 	.word	0x70000c48
