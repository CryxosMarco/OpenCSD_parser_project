
files/zephyr.elf:     file format elf32-littlearm


Disassembly of section rom_start:

70000000 <_vector_table>:
#include "macro_priv.inc"

_ASM_FILE_PROLOGUE

SECTION_SUBSEC_FUNC(exc_vector_table,_vector_table_section,_vector_table)
	ldr pc, =z_arm_reset             /*                   offset 0 */
70000000:	18 f0 9f e5 18 f0 9f e5 18 f0 9f e5 18 f0 9f e5     ................
	ldr pc, =z_arm_undef_instruction /* undef instruction offset 4 */
	ldr pc, =z_arm_svc               /* svc               offset 8 */
	ldr pc, =z_arm_prefetch_abort    /* prefetch abort offset  0xc */
	ldr pc, =z_arm_data_abort        /* data abort     offset 0x10 */
70000010:	18 f0 9f e5 00 f0 20 e3 14 f0 9f e5 14 f0 9f e5     ...... .........
	ldr pc, =z_arm_reset             /*                   offset 0 */
70000020:	b0 0c 00 70 98 0a 00 70 44 0f 00 70 dc 0a 00 70     ...p...pD..p...p
	ldr pc, =z_arm_data_abort        /* data abort     offset 0x10 */
70000030:	0c 0b 00 70 9c 0d 00 70 79 0a 00 70                 ...p...py..p

Disassembly of section text:

70000040 <strcmp>:
	.fnstart
	.cfi_sections .debug_frame
	.cfi_startproc
	prologue push_ip=HAVE_PAC_LEAF
#ifndef STRCMP_NO_PRECHECK
	ldrb	r2, [src1]
70000040:	7802      	ldrb	r2, [r0, #0]
	ldrb	r3, [src2]
70000042:	780b      	ldrb	r3, [r1, #0]
	cmp	r2, #1
70000044:	2a01      	cmp	r2, #1
	it	cs
70000046:	bf28      	it	cs
	cmpcs	r2, r3
70000048:	429a      	cmpcs	r2, r3
	bne	.Lfastpath_exit
7000004a:	f040 80d8 	bne.w	700001fe <strcmp+0x1be>
#endif
	strd	r4, r5, [sp, #-16]!
7000004e:	e96d 4504 	strd	r4, r5, [sp, #-16]!
	.cfi_adjust_cfa_offset 16
	.cfi_rel_offset 4, 0
	.cfi_rel_offset 5, 4
	orr	tmp1, src1, src2
70000052:	ea40 0401 	orr.w	r4, r0, r1
	strd	r6, r7, [sp, #8]
70000056:	e9cd 6702 	strd	r6, r7, [sp, #8]
	.cfi_rel_offset 6, 8
	.cfi_rel_offset 7, 12
	mvn	const_m1, #0
7000005a:	f06f 0c00 	mvn.w	ip, #0
	lsl	r2, tmp1, #29
7000005e:	ea4f 7244 	mov.w	r2, r4, lsl #29
	cbz	r2, .Lloop_aligned8
70000062:	b31a      	cbz	r2, 700000ac <strcmp+0x6c>

.Lnot_aligned:
	eor	tmp1, src1, src2
70000064:	ea80 0401 	eor.w	r4, r0, r1
	tst	tmp1, #7
70000068:	f014 0f07 	tst.w	r4, #7
	bne	.Lmisaligned8
7000006c:	d16b      	bne.n	70000146 <strcmp+0x106>

	/* Deal with mutual misalignment by aligning downwards and then
	   masking off the unwanted loaded data to prevent a difference.  */
	and	tmp1, src1, #7
7000006e:	f000 0407 	and.w	r4, r0, #7
	bic	src1, src1, #7
70000072:	f020 0007 	bic.w	r0, r0, #7
	and	tmp2, tmp1, #3
70000076:	f004 0503 	and.w	r5, r4, #3
	bic	src2, src2, #7
7000007a:	f021 0107 	bic.w	r1, r1, #7
	lsl	tmp2, tmp2, #3	/* Bytes -> bits.  */
7000007e:	ea4f 05c5 	mov.w	r5, r5, lsl #3
	ldrd	data1a, data1b, [src1], #16
70000082:	e8f0 2304 	ldrd	r2, r3, [r0], #16
	tst	tmp1, #4
70000086:	f014 0f04 	tst.w	r4, #4
	ldrd	data2a, data2b, [src2], #16
7000008a:	e8f1 6704 	ldrd	r6, r7, [r1], #16
	/* In thumb code we can't use MVN with a register shift, but
	   we do have ORN.  */
	S2HI	tmp1, const_m1, tmp2
7000008e:	fa0c f405 	lsl.w	r4, ip, r5
	orn	data1a, data1a, tmp1
70000092:	ea62 0204 	orn	r2, r2, r4
	orn	data2a, data2a, tmp1
70000096:	ea66 0604 	orn	r6, r6, r4
	beq	.Lstart_realigned8
7000009a:	d00b      	beq.n	700000b4 <strcmp+0x74>
	orn	data1b, data1b, tmp1
7000009c:	ea63 0304 	orn	r3, r3, r4
	mov	data1a, const_m1
700000a0:	4662      	mov	r2, ip
	orn	data2b, data2b, tmp1
700000a2:	ea67 0704 	orn	r7, r7, r4
	mov	data2a, const_m1
700000a6:	4666      	mov	r6, ip
	b	.Lstart_realigned8
700000a8:	e004      	b.n	700000b4 <strcmp+0x74>
700000aa:	bf00      	nop
	/* Unwind the inner loop by a factor of 2, giving 16 bytes per
	   pass.  */
	.p2align 5,,12  /* Don't start in the tail bytes of a cache line.  */
	.p2align 2	/* Always word aligned.  */
.Lloop_aligned8:
	ldrd	data1a, data1b, [src1], #16
700000ac:	e8f0 2304 	ldrd	r2, r3, [r0], #16
	ldrd	data2a, data2b, [src2], #16
700000b0:	e8f1 6704 	ldrd	r6, r7, [r1], #16
.Lstart_realigned8:
	uadd8	syndrome_b, data1a, const_m1	/* Only want GE bits,  */
700000b4:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome_a, data1a, data2a
700000b8:	ea82 0406 	eor.w	r4, r2, r6
	sel	syndrome_a, syndrome_a, const_m1
700000bc:	faa4 f48c 	sel	r4, r4, ip
	cbnz	syndrome_a, .Ldiff_in_a
700000c0:	bb6c      	cbnz	r4, 7000011e <strcmp+0xde>
	uadd8	syndrome_b, data1b, const_m1	/* Only want GE bits.  */
700000c2:	fa83 f54c 	uadd8	r5, r3, ip
	eor	syndrome_b, data1b, data2b
700000c6:	ea83 0507 	eor.w	r5, r3, r7
	sel	syndrome_b, syndrome_b, const_m1
700000ca:	faa5 f58c 	sel	r5, r5, ip
	cbnz	syndrome_b, .Ldiff_in_b
700000ce:	b995      	cbnz	r5, 700000f6 <strcmp+0xb6>

	ldrd	data1a, data1b, [src1, #-8]
700000d0:	e950 2302 	ldrd	r2, r3, [r0, #-8]
	ldrd	data2a, data2b, [src2, #-8]
700000d4:	e951 6702 	ldrd	r6, r7, [r1, #-8]
	uadd8	syndrome_b, data1a, const_m1	/* Only want GE bits,  */
700000d8:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome_a, data1a, data2a
700000dc:	ea82 0406 	eor.w	r4, r2, r6
	sel	syndrome_a, syndrome_a, const_m1
700000e0:	faa4 f48c 	sel	r4, r4, ip
	uadd8	syndrome_b, data1b, const_m1	/* Only want GE bits.  */
700000e4:	fa83 f54c 	uadd8	r5, r3, ip
	eor	syndrome_b, data1b, data2b
700000e8:	ea83 0507 	eor.w	r5, r3, r7
	sel	syndrome_b, syndrome_b, const_m1
700000ec:	faa5 f58c 	sel	r5, r5, ip
	/* Can't use CBZ for backwards branch.  */
	orrs	syndrome_b, syndrome_b, syndrome_a /* Only need if s_a == 0 */
700000f0:	4325      	orrs	r5, r4
	beq	.Lloop_aligned8
700000f2:	d0db      	beq.n	700000ac <strcmp+0x6c>

.Ldiff_found:
	cbnz	syndrome_a, .Ldiff_in_a
700000f4:	b99c      	cbnz	r4, 7000011e <strcmp+0xde>

.Ldiff_in_b:
	strcmp_epilogue_aligned syndrome_b, data1b, data2b 1
700000f6:	ba2d      	rev	r5, r5
700000f8:	fab5 f485 	clz	r4, r5
700000fc:	f024 0407 	bic.w	r4, r4, #7
70000100:	fa27 f104 	lsr.w	r1, r7, r4
70000104:	e9dd 6702 	ldrd	r6, r7, [sp, #8]
70000108:	fa23 f304 	lsr.w	r3, r3, r4
7000010c:	f003 00ff 	and.w	r0, r3, #255	; 0xff
70000110:	f001 01ff 	and.w	r1, r1, #255	; 0xff
70000114:	e8fd 4504 	ldrd	r4, r5, [sp], #16
70000118:	eba0 0001 	sub.w	r0, r0, r1
7000011c:	4770      	bx	lr

.Ldiff_in_a:
	.cfi_restore_state
	strcmp_epilogue_aligned syndrome_a, data1a, data2a 1
7000011e:	ba24      	rev	r4, r4
70000120:	fab4 f484 	clz	r4, r4
70000124:	f024 0407 	bic.w	r4, r4, #7
70000128:	fa26 f104 	lsr.w	r1, r6, r4
7000012c:	e9dd 6702 	ldrd	r6, r7, [sp, #8]
70000130:	fa22 f204 	lsr.w	r2, r2, r4
70000134:	f002 00ff 	and.w	r0, r2, #255	; 0xff
70000138:	f001 01ff 	and.w	r1, r1, #255	; 0xff
7000013c:	e8fd 4504 	ldrd	r4, r5, [sp], #16
70000140:	eba0 0001 	sub.w	r0, r0, r1
70000144:	4770      	bx	lr

	.cfi_restore_state
.Lmisaligned8:
	tst	tmp1, #3
70000146:	f014 0f03 	tst.w	r4, #3
	bne	.Lmisaligned4
7000014a:	d13c      	bne.n	700001c6 <strcmp+0x186>
	ands	tmp1, src1, #3
7000014c:	f010 0403 	ands.w	r4, r0, #3
	bne	.Lmutual_align4
70000150:	d128      	bne.n	700001a4 <strcmp+0x164>

	/* Unrolled by a factor of 2, to reduce the number of post-increment
	   operations.  */
.Lloop_aligned4:
	ldr	data1, [src1], #8
70000152:	f850 2b08 	ldr.w	r2, [r0], #8
	ldr	data2, [src2], #8
70000156:	f851 3b08 	ldr.w	r3, [r1], #8
.Lstart_realigned4:
	uadd8	syndrome, data1, const_m1	/* Only need GE bits.  */
7000015a:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome, data1, data2
7000015e:	ea82 0503 	eor.w	r5, r2, r3
	sel	syndrome, syndrome, const_m1
70000162:	faa5 f58c 	sel	r5, r5, ip
	cbnz	syndrome, .Laligned4_done
70000166:	b95d      	cbnz	r5, 70000180 <strcmp+0x140>
	ldr	data1, [src1, #-4]
70000168:	f850 2c04 	ldr.w	r2, [r0, #-4]
	ldr	data2, [src2, #-4]
7000016c:	f851 3c04 	ldr.w	r3, [r1, #-4]
	uadd8	syndrome, data1, const_m1
70000170:	fa82 f54c 	uadd8	r5, r2, ip
	eor	syndrome, data1, data2
70000174:	ea82 0503 	eor.w	r5, r2, r3
	sel	syndrome, syndrome, const_m1
70000178:	faa5 f58c 	sel	r5, r5, ip
	cmp	syndrome, #0
7000017c:	2d00      	cmp	r5, #0
	beq	.Lloop_aligned4
7000017e:	d0e8      	beq.n	70000152 <strcmp+0x112>

.Laligned4_done:
	strcmp_epilogue_aligned syndrome, data1, data2, 0
70000180:	ba2d      	rev	r5, r5
70000182:	fab5 f485 	clz	r4, r5
70000186:	f024 0407 	bic.w	r4, r4, #7
7000018a:	fa23 f104 	lsr.w	r1, r3, r4
7000018e:	fa22 f204 	lsr.w	r2, r2, r4
70000192:	f002 00ff 	and.w	r0, r2, #255	; 0xff
70000196:	f001 01ff 	and.w	r1, r1, #255	; 0xff
7000019a:	e8fd 4504 	ldrd	r4, r5, [sp], #16
7000019e:	eba0 0001 	sub.w	r0, r0, r1
700001a2:	4770      	bx	lr

.Lmutual_align4:
	.cfi_restore_state
	/* Deal with mutual misalignment by aligning downwards and then
	   masking off the unwanted loaded data to prevent a difference.  */
	lsl	tmp1, tmp1, #3	/* Bytes -> bits.  */
700001a4:	ea4f 04c4 	mov.w	r4, r4, lsl #3
	bic	src1, src1, #3
700001a8:	f020 0003 	bic.w	r0, r0, #3
	ldr	data1, [src1], #8
700001ac:	f850 2b08 	ldr.w	r2, [r0], #8
	bic	src2, src2, #3
700001b0:	f021 0103 	bic.w	r1, r1, #3
	ldr	data2, [src2], #8
700001b4:	f851 3b08 	ldr.w	r3, [r1], #8

	/* In thumb code we can't use MVN with a register shift, but
	   we do have ORN.  */
	S2HI	tmp1, const_m1, tmp1
700001b8:	fa0c f404 	lsl.w	r4, ip, r4
	orn	data1, data1, tmp1
700001bc:	ea62 0204 	orn	r2, r2, r4
	orn	data2, data2, tmp1
700001c0:	ea63 0304 	orn	r3, r3, r4
	b	.Lstart_realigned4
700001c4:	e7c9      	b.n	7000015a <strcmp+0x11a>

.Lmisaligned4:
	ands	tmp1, src1, #3
700001c6:	f010 0403 	ands.w	r4, r0, #3
	beq	.Lsrc1_aligned
700001ca:	d01d      	beq.n	70000208 <strcmp+0x1c8>
	sub	src2, src2, tmp1
700001cc:	eba1 0104 	sub.w	r1, r1, r4
	bic	src1, src1, #3
700001d0:	f020 0003 	bic.w	r0, r0, #3
	lsls	tmp1, tmp1, #31
700001d4:	07e4      	lsls	r4, r4, #31
	ldr	data1, [src1], #4
700001d6:	f850 2b04 	ldr.w	r2, [r0], #4
	beq	.Laligned_m2
700001da:	d006      	beq.n	700001ea <strcmp+0x1aa>
	bcs	.Laligned_m1
700001dc:	d212      	bcs.n	70000204 <strcmp+0x1c4>
	add	src2, src2, #4
	cbnz	data2, .Lsrc1_aligned
#else  /* STRCMP_NO_PRECHECK */
	/* If we've done the pre-check, then we don't need to check the
	   first byte again here.  */
	ldrb	data2, [src2, #2]
700001de:	788b      	ldrb	r3, [r1, #2]
	uxtb	tmp1, data1, ror #BYTE2_OFFSET
700001e0:	fa5f f4a2 	uxtb.w	r4, r2, ror #16
	subs	tmp1, tmp1, data2
700001e4:	1ae4      	subs	r4, r4, r3
	bne	.Lmisaligned_exit
700001e6:	d106      	bne.n	700001f6 <strcmp+0x1b6>
	cbz	data2, .Lmisaligned_exit
700001e8:	b12b      	cbz	r3, 700001f6 <strcmp+0x1b6>

.Laligned_m2:
	ldrb	data2, [src2, #3]
700001ea:	78cb      	ldrb	r3, [r1, #3]
	uxtb	tmp1, data1, ror #BYTE3_OFFSET
700001ec:	fa5f f4b2 	uxtb.w	r4, r2, ror #24
	subs	tmp1, tmp1, data2
700001f0:	1ae4      	subs	r4, r4, r3
	bne	.Lmisaligned_exit
700001f2:	d100      	bne.n	700001f6 <strcmp+0x1b6>
	cbnz	data2, .Laligned_m1
700001f4:	b933      	cbnz	r3, 70000204 <strcmp+0x1c4>
#endif

.Lmisaligned_exit:
	.cfi_remember_state
	mov	result, tmp1
700001f6:	4620      	mov	r0, r4
	ldr	r4, [sp], #16
700001f8:	f85d 4b10 	ldr.w	r4, [sp], #16
	.cfi_restore 4
	.cfi_adjust_cfa_offset -16
	epilogue push_ip=HAVE_PAC_LEAF
700001fc:	4770      	bx	lr

#ifndef STRCMP_NO_PRECHECK
.Lfastpath_exit:
	.cfi_restore_state
	.cfi_remember_state
	sub	r0, r2, r3
700001fe:	eba2 0003 	sub.w	r0, r2, r3
	epilogue push_ip=HAVE_PAC_LEAF
70000202:	4770      	bx	lr

.Laligned_m1:
	.cfi_restore_state
	.cfi_remember_state
	add	src2, src2, #4
70000204:	f101 0104 	add.w	r1, r1, #4
#endif
.Lsrc1_aligned:
	.cfi_restore_state
	/* src1 is word aligned, but src2 has no common alignment
	   with it.  */
	ldr	data1, [src1], #4
70000208:	f850 2b04 	ldr.w	r2, [r0], #4
	lsls	tmp1, src2, #31		/* C=src2[1], Z=src2[0].  */
7000020c:	07cc      	lsls	r4, r1, #31

	bic	src2, src2, #3
7000020e:	f021 0103 	bic.w	r1, r1, #3
	ldr	data2, [src2], #4
70000212:	f851 3b04 	ldr.w	r3, [r1], #4
	bhi	.Loverlap1		/* C=1, Z=0 => src2[1:0] = 0b11.  */
70000216:	d848      	bhi.n	700002aa <strcmp+0x26a>
	bcs	.Loverlap2		/* C=1, Z=1 => src2[1:0] = 0b10.  */
70000218:	d224      	bcs.n	70000264 <strcmp+0x224>

	/* (overlap3) C=0, Z=0 => src2[1:0] = 0b01.  */
.Loverlap3:
	bic	tmp1, data1, #MSB
7000021a:	f022 447f 	bic.w	r4, r2, #4278190080	; 0xff000000
	uadd8	syndrome, data1, const_m1
7000021e:	fa82 f54c 	uadd8	r5, r2, ip
	eors	syndrome, tmp1, data2, S2LO #8
70000222:	ea94 2513 	eors.w	r5, r4, r3, lsr #8
	sel	syndrome, syndrome, const_m1
70000226:	faa5 f58c 	sel	r5, r5, ip
	bne	4f
7000022a:	d10a      	bne.n	70000242 <strcmp+0x202>
	cbnz	syndrome, 5f
7000022c:	b965      	cbnz	r5, 70000248 <strcmp+0x208>
	ldr	data2, [src2], #4
7000022e:	f851 3b04 	ldr.w	r3, [r1], #4
	eor	tmp1, tmp1, data1
70000232:	ea84 0402 	eor.w	r4, r4, r2
	cmp	tmp1, data2, S2HI #24
70000236:	ebb4 6f03 	cmp.w	r4, r3, lsl #24
	bne	6f
7000023a:	d10e      	bne.n	7000025a <strcmp+0x21a>
	ldr	data1, [src1], #4
7000023c:	f850 2b04 	ldr.w	r2, [r0], #4
	b	.Loverlap3
70000240:	e7eb      	b.n	7000021a <strcmp+0x1da>
4:
	S2LO	data2, data2, #8
70000242:	ea4f 2313 	mov.w	r3, r3, lsr #8
	b	.Lstrcmp_tail
70000246:	e055      	b.n	700002f4 <strcmp+0x2b4>

5:
	bics	syndrome, syndrome, #MSB
70000248:	f035 457f 	bics.w	r5, r5, #4278190080	; 0xff000000
	bne	.Lstrcmp_done_equal
7000024c:	d14d      	bne.n	700002ea <strcmp+0x2aa>

	/* We can only get here if the MSB of data1 contains 0, so
	   fast-path the exit.  */
	ldrb	result, [src2]
7000024e:	7808      	ldrb	r0, [r1, #0]
	.cfi_remember_state
	ldrd	r4, r5, [sp], #16
70000250:	e8fd 4504 	ldrd	r4, r5, [sp], #16
	.cfi_restore 5
	/* R6/7 Not used in this sequence.  */
	.cfi_restore 6
	.cfi_restore 7
	.cfi_adjust_cfa_offset -16
	neg	result, result
70000254:	f1c0 0000 	rsb	r0, r0, #0
	epilogue push_ip=HAVE_PAC_LEAF
70000258:	4770      	bx	lr

6:
	.cfi_restore_state
	S2LO	data1, data1, #24
7000025a:	ea4f 6212 	mov.w	r2, r2, lsr #24
	and	data2, data2, #LSB
7000025e:	f003 03ff 	and.w	r3, r3, #255	; 0xff
	b	.Lstrcmp_tail
70000262:	e047      	b.n	700002f4 <strcmp+0x2b4>

	.p2align 5,,12	/* Ensure at least 3 instructions in cache line.  */
.Loverlap2:
	and	tmp1, data1, const_m1, S2LO #16
70000264:	ea02 441c 	and.w	r4, r2, ip, lsr #16
	uadd8	syndrome, data1, const_m1
70000268:	fa82 f54c 	uadd8	r5, r2, ip
	eors	syndrome, tmp1, data2, S2LO #16
7000026c:	ea94 4513 	eors.w	r5, r4, r3, lsr #16
	sel	syndrome, syndrome, const_m1
70000270:	faa5 f58c 	sel	r5, r5, ip
	bne	4f
70000274:	d10a      	bne.n	7000028c <strcmp+0x24c>
	cbnz	syndrome, 5f
70000276:	b965      	cbnz	r5, 70000292 <strcmp+0x252>
	ldr	data2, [src2], #4
70000278:	f851 3b04 	ldr.w	r3, [r1], #4
	eor	tmp1, tmp1, data1
7000027c:	ea84 0402 	eor.w	r4, r4, r2
	cmp	tmp1, data2, S2HI #16
70000280:	ebb4 4f03 	cmp.w	r4, r3, lsl #16
	bne	6f
70000284:	d10c      	bne.n	700002a0 <strcmp+0x260>
	ldr	data1, [src1], #4
70000286:	f850 2b04 	ldr.w	r2, [r0], #4
	b	.Loverlap2
7000028a:	e7eb      	b.n	70000264 <strcmp+0x224>
4:
	S2LO	data2, data2, #16
7000028c:	ea4f 4313 	mov.w	r3, r3, lsr #16
	b	.Lstrcmp_tail
70000290:	e030      	b.n	700002f4 <strcmp+0x2b4>
5:
	ands	syndrome, syndrome, const_m1, S2LO #16
70000292:	ea15 451c 	ands.w	r5, r5, ip, lsr #16
	bne	.Lstrcmp_done_equal
70000296:	d128      	bne.n	700002ea <strcmp+0x2aa>

	ldrh	data2, [src2]
70000298:	880b      	ldrh	r3, [r1, #0]
	S2LO	data1, data1, #16
7000029a:	ea4f 4212 	mov.w	r2, r2, lsr #16
#ifdef __ARM_BIG_ENDIAN
	lsl	data2, data2, #16
#endif
	b	.Lstrcmp_tail
7000029e:	e029      	b.n	700002f4 <strcmp+0x2b4>

6:
	S2LO	data1, data1, #16
700002a0:	ea4f 4212 	mov.w	r2, r2, lsr #16
	and	data2, data2, const_m1, S2LO #16
700002a4:	ea03 431c 	and.w	r3, r3, ip, lsr #16
	b	.Lstrcmp_tail
700002a8:	e024      	b.n	700002f4 <strcmp+0x2b4>

	.p2align 5,,12	/* Ensure at least 3 instructions in cache line.  */
.Loverlap1:
	and	tmp1, data1, #LSB
700002aa:	f002 04ff 	and.w	r4, r2, #255	; 0xff
	uadd8	syndrome, data1, const_m1
700002ae:	fa82 f54c 	uadd8	r5, r2, ip
	eors	syndrome, tmp1, data2, S2LO #24
700002b2:	ea94 6513 	eors.w	r5, r4, r3, lsr #24
	sel	syndrome, syndrome, const_m1
700002b6:	faa5 f58c 	sel	r5, r5, ip
	bne	4f
700002ba:	d10a      	bne.n	700002d2 <strcmp+0x292>
	cbnz	syndrome, 5f
700002bc:	b965      	cbnz	r5, 700002d8 <strcmp+0x298>
	ldr	data2, [src2], #4
700002be:	f851 3b04 	ldr.w	r3, [r1], #4
	eor	tmp1, tmp1, data1
700002c2:	ea84 0402 	eor.w	r4, r4, r2
	cmp	tmp1, data2, S2HI #8
700002c6:	ebb4 2f03 	cmp.w	r4, r3, lsl #8
	bne	6f
700002ca:	d109      	bne.n	700002e0 <strcmp+0x2a0>
	ldr	data1, [src1], #4
700002cc:	f850 2b04 	ldr.w	r2, [r0], #4
	b	.Loverlap1
700002d0:	e7eb      	b.n	700002aa <strcmp+0x26a>
4:
	S2LO	data2, data2, #24
700002d2:	ea4f 6313 	mov.w	r3, r3, lsr #24
	b	.Lstrcmp_tail
700002d6:	e00d      	b.n	700002f4 <strcmp+0x2b4>
5:
	tst	syndrome, #LSB
700002d8:	f015 0fff 	tst.w	r5, #255	; 0xff
	bne	.Lstrcmp_done_equal
700002dc:	d105      	bne.n	700002ea <strcmp+0x2aa>
	ldr	data2, [src2]
700002de:	680b      	ldr	r3, [r1, #0]
6:
	S2LO	data1, data1, #8
700002e0:	ea4f 2212 	mov.w	r2, r2, lsr #8
	bic	data2, data2, #MSB
700002e4:	f023 437f 	bic.w	r3, r3, #4278190080	; 0xff000000
	b	.Lstrcmp_tail
700002e8:	e004      	b.n	700002f4 <strcmp+0x2b4>

.Lstrcmp_done_equal:
	mov	result, #0
700002ea:	f04f 0000 	mov.w	r0, #0
	.cfi_remember_state
	ldrd	r4, r5, [sp], #16
700002ee:	e8fd 4504 	ldrd	r4, r5, [sp], #16
	.cfi_restore 5
	/* R6/7 not used in this sequence.  */
	.cfi_restore 6
	.cfi_restore 7
	.cfi_adjust_cfa_offset -16
	epilogue push_ip=HAVE_PAC_LEAF
700002f2:	4770      	bx	lr

.Lstrcmp_tail:
	.cfi_restore_state
#ifndef __ARM_BIG_ENDIAN
	rev	data1, data1
700002f4:	ba12      	rev	r2, r2
	rev	data2, data2
700002f6:	ba1b      	rev	r3, r3
	/* Now everything looks big-endian...  */
#endif
	uadd8	tmp1, data1, const_m1
700002f8:	fa82 f44c 	uadd8	r4, r2, ip
	eor	tmp1, data1, data2
700002fc:	ea82 0403 	eor.w	r4, r2, r3
	sel	syndrome, tmp1, const_m1
70000300:	faa4 f58c 	sel	r5, r4, ip
	clz	tmp1, syndrome
70000304:	fab5 f485 	clz	r4, r5
	lsl	data1, data1, tmp1
70000308:	fa02 f204 	lsl.w	r2, r2, r4
	lsl	data2, data2, tmp1
7000030c:	fa03 f304 	lsl.w	r3, r3, r4
	lsr	result, data1, #24
70000310:	ea4f 6012 	mov.w	r0, r2, lsr #24
	ldrd	r4, r5, [sp], #16
70000314:	e8fd 4504 	ldrd	r4, r5, [sp], #16
	.cfi_restore 5
	/* R6/7 not used in this sequence.  */
	.cfi_restore 6
	.cfi_restore 7
	.cfi_adjust_cfa_offset -16
	sub	result, result, data2, lsr #24
70000318:	eba0 6013 	sub.w	r0, r0, r3, lsr #24
	epilogue push_ip=HAVE_PAC_LEAF
7000031c:	4770      	bx	lr
7000031e:	bf00      	nop

70000320 <_OffsetAbsSyms>:

#include <gen_offset.h>

#include "offsets_aarch32.c"

GEN_ABS_SYM_END
70000320:	4770      	bx	lr
70000322:	bf00      	nop

70000324 <main>:

int main(void)
{
#ifdef USING_ZEPHYR
   extern int rtos_main_zephyr(void);
   return rtos_main_zephyr();
70000324:	f000 b834 	b.w	70000390 <rtos_main_zephyr>

70000328 <tm_interrupt_handler>:
void* test_interrupt_handler = NULL;

/* Define the interrupt handler */
void tm_interrupt_handler(void* args)
{
   if (test_interrupt_handler != NULL)
70000328:	f245 5348 	movw	r3, #21832	; 0x5548
7000032c:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000330:	681b      	ldr	r3, [r3, #0]
70000332:	b103      	cbz	r3, 70000336 <tm_interrupt_handler+0xe>
   {
      /* Call the assigned handler function */
      ((void (*)(void)) test_interrupt_handler)();
70000334:	4718      	bx	r3
   }
}
70000336:	4770      	bx	lr

70000338 <main_task>:
}

void main_task(void* pvParameters)
{
   /* Start Thread-Metric tests */
   printk("Starting Thread-Metric tests...\r\n");
70000338:	f644 3044 	movw	r0, #19268	; 0x4b44
{
7000033c:	b510      	push	{r4, lr}

   /* Initialize custom interrupts*/
   test_interrupt_handler = tm_isr_message_handler;
7000033e:	f240 540d 	movw	r4, #1293	; 0x50d
   printk("Starting Thread-Metric tests...\r\n");
70000342:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000346:	f000 fb55 	bl	700009f4 <printk>
   test_interrupt_handler = tm_isr_message_handler;
7000034a:	f245 5348 	movw	r3, #21832	; 0x5548
7000034e:	f2c7 0300 	movt	r3, #28672	; 0x7000
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
70000352:	2204      	movs	r2, #4
   test_interrupt_handler = tm_isr_message_handler;
70000354:	f2c7 0400 	movt	r4, #28672	; 0x7000
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
70000358:	2101      	movs	r1, #1
7000035a:	200a      	movs	r0, #10
   test_interrupt_handler = tm_isr_message_handler;
7000035c:	601c      	str	r4, [r3, #0]
   z_vim_irq_priority_set(irq, priority, IRQ_TYPE_EDGE);
7000035e:	f000 ff27 	bl	700011b0 <z_vim_irq_priority_set>
   IRQ_CONNECT(SOFTWARE_INTERRUPT_ID, 1, tm_interrupt_handler, NULL, 0);
70000362:	2200      	movs	r2, #0
70000364:	2101      	movs	r1, #1
70000366:	200a      	movs	r0, #10
70000368:	f000 fb74 	bl	70000a54 <z_soc_irq_priority_set>
   irq_enable(SOFTWARE_INTERRUPT_ID);
7000036c:	200a      	movs	r0, #10
7000036e:	f000 fb73 	bl	70000a58 <z_soc_irq_enable>
   z_vim_irq_enable(irq);
70000372:	200a      	movs	r0, #10
70000374:	f000 ff48 	bl	70001208 <z_vim_irq_enable>
   setup_interrupt();

   /* Call the main Thread-Metric function */
   main_message_isr_test();
70000378:	f000 f8be 	bl	700004f8 <main_message_isr_test>
	if (z_syscall_trap()) {
		return (k_tid_t) arch_syscall_invoke0(K_SYSCALL_K_SCHED_CURRENT_THREAD_QUERY);
	}
#endif
	compiler_barrier();
	return z_impl_k_sched_current_thread_query();
7000037c:	f002 f9d2 	bl	70002724 <z_impl_k_sched_current_thread_query>

   /* Delete thread after completion */
   k_thread_abort(k_current_get());
}
70000380:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_ABORT);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_abort(thread);
70000384:	f002 b9d4 	b.w	70002730 <z_impl_k_thread_abort>

70000388 <tm_interrupt_raise>:
   z_vim_arm_enter_irq(irq);
70000388:	200a      	movs	r0, #10
7000038a:	f000 bf4f 	b.w	7000122c <z_vim_arm_enter_irq>
7000038e:	bf00      	nop

70000390 <rtos_main_zephyr>:
/* Thread definition */
K_THREAD_DEFINE(main_thread, 512 /* STACKSIZE */, main_task, NULL, NULL, NULL, MAIN_TASK_PRI, K_USER, -1);

int rtos_main_zephyr(void)
{
   printk("Initializing Zephyr system...\r\n");
70000390:	f644 3068 	movw	r0, #19304	; 0x4b68
{
70000394:	b508      	push	{r3, lr}
   printk("Initializing Zephyr system...\r\n");
70000396:	f2c7 0000 	movt	r0, #28672	; 0x7000
7000039a:	f000 fb2b 	bl	700009f4 <printk>
	z_impl_k_wakeup(thread);
7000039e:	f644 6010 	movw	r0, #19984	; 0x4e10
700003a2:	f2c7 0000 	movt	r0, #28672	; 0x7000
700003a6:	f002 f997 	bl	700026d8 <z_impl_k_wakeup>

   /* Create main task */
   k_thread_start(main_thread);

   printk("Main task created and running...\r\n");
700003aa:	f644 3088 	movw	r0, #19336	; 0x4b88
700003ae:	f2c7 0000 	movt	r0, #28672	; 0x7000
700003b2:	f000 fb1f 	bl	700009f4 <printk>

   return 0;
}
700003b6:	2000      	movs	r0, #0
700003b8:	bd08      	pop	{r3, pc}
700003ba:	bf00      	nop

700003bc <tm_message_isr_to_task_initialize>:
   return checksum;
}

/* Initialization function */
void tm_message_isr_to_task_initialize(void)
{
700003bc:	e92d 43f8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
   int i;
   tm_setup_pmu();
700003c0:	f000 f8ea 	bl	70000598 <tm_setup_pmu>
   tm_queue_create(0);
700003c4:	2000      	movs	r0, #0
700003c6:	f245 744c 	movw	r4, #22348	; 0x574c
700003ca:	f000 f98b 	bl	700006e4 <tm_queue_create>

   /* Precompute PMU names for each iteration so the ISR can avoid runtime formatting */
   for (i = 0; i < ITERATION_COUNT; i++)
700003ce:	f245 564c 	movw	r6, #21836	; 0x554c
   {
      snprintf(pmu_send_names[i], sizeof(pmu_send_names[i]), "S%02d", i);
700003d2:	f644 38b8 	movw	r8, #19384	; 0x4bb8
700003d6:	f2c7 0400 	movt	r4, #28672	; 0x7000
      snprintf(pmu_recv_names[i], sizeof(pmu_recv_names[i]), "R%02d", i);
700003da:	f644 37c0 	movw	r7, #19392	; 0x4bc0
700003de:	f2c7 0600 	movt	r6, #28672	; 0x7000
700003e2:	f504 7900 	add.w	r9, r4, #512	; 0x200
      snprintf(pmu_send_names[i], sizeof(pmu_send_names[i]), "S%02d", i);
700003e6:	f2c7 0800 	movt	r8, #28672	; 0x7000
   for (i = 0; i < ITERATION_COUNT; i++)
700003ea:	2500      	movs	r5, #0
      snprintf(pmu_recv_names[i], sizeof(pmu_recv_names[i]), "R%02d", i);
700003ec:	f2c7 0700 	movt	r7, #28672	; 0x7000
      snprintf(pmu_send_names[i], sizeof(pmu_send_names[i]), "S%02d", i);
700003f0:	462b      	mov	r3, r5
700003f2:	2110      	movs	r1, #16
700003f4:	4620      	mov	r0, r4
700003f6:	4642      	mov	r2, r8
700003f8:	f002 fe12 	bl	70003020 <snprintf>
      snprintf(pmu_recv_names[i], sizeof(pmu_recv_names[i]), "R%02d", i);
700003fc:	2110      	movs	r1, #16
700003fe:	462b      	mov	r3, r5
70000400:	4630      	mov	r0, r6
70000402:	463a      	mov	r2, r7
   for (i = 0; i < ITERATION_COUNT; i++)
70000404:	440c      	add	r4, r1
      snprintf(pmu_recv_names[i], sizeof(pmu_recv_names[i]), "R%02d", i);
70000406:	f002 fe0b 	bl	70003020 <snprintf>
   for (i = 0; i < ITERATION_COUNT; i++)
7000040a:	454c      	cmp	r4, r9
7000040c:	f105 0501 	add.w	r5, r5, #1
70000410:	f106 0610 	add.w	r6, r6, #16
70000414:	d1ec      	bne.n	700003f0 <tm_message_isr_to_task_initialize+0x34>
   }

   /* Create the single receiver thread that drives the entire test */
   tm_thread_create(0, 5, tm_receiver_thread_entry);
70000416:	f240 4231 	movw	r2, #1073	; 0x431
7000041a:	2105      	movs	r1, #5
7000041c:	2000      	movs	r0, #0
7000041e:	f2c7 0200 	movt	r2, #28672	; 0x7000
70000422:	f000 f915 	bl	70000650 <tm_thread_create>
   tm_thread_resume(0);
}
70000426:	e8bd 43f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}
   tm_thread_resume(0);
7000042a:	2000      	movs	r0, #0
7000042c:	f000 b93e 	b.w	700006ac <tm_thread_resume>

70000430 <tm_receiver_thread_entry>:

/* Receiver thread:
   Drives the test by triggering the ISR, measuring the receive latency,
   validating the received message, and finally reporting the results. */
void tm_receiver_thread_entry(void* p1, void* p2, void* p3)
{
70000430:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
70000434:	f8df b0b8 	ldr.w	fp, [pc, #184]	; 700004f0 <tm_receiver_thread_entry+0xc0>
70000438:	f245 744c 	movw	r4, #22348	; 0x574c
7000043c:	f645 2754 	movw	r7, #23124	; 0x5a54
70000440:	f2c7 0400 	movt	r4, #28672	; 0x7000

      /* Check the checksum */
      if (compute_checksum(message_received_arr, MESSAGE_SIZE - 1) != message_received_arr[MESSAGE_SIZE - 1])
      {
         valid = 0;
         printf("Message integrity error in iteration %d: checksum mismatch\r\n", i);
70000444:	f644 3ac8 	movw	sl, #19400	; 0x4bc8
70000448:	f504 7800 	add.w	r8, r4, #512	; 0x200
7000044c:	f2c7 0700 	movt	r7, #28672	; 0x7000
{
70000450:	4625      	mov	r5, r4
         printf("Message integrity error in iteration %d: checksum mismatch\r\n", i);
70000452:	f2c7 0a00 	movt	sl, #28672	; 0x7000
   for (i = 0; i < ITERATION_COUNT; i++)
70000456:	2600      	movs	r6, #0
70000458:	f1ab 0978 	sub.w	r9, fp, #120	; 0x78
      tm_interrupt_raise();
7000045c:	f7ff ff94 	bl	70000388 <tm_interrupt_raise>
      tm_queue_receive(0, message_received_arr);
70000460:	4649      	mov	r1, r9
70000462:	2000      	movs	r0, #0
70000464:	f000 f962 	bl	7000072c <tm_queue_receive>
      tm_pmu_profile_end(pmu_send_names[i]);
70000468:	4628      	mov	r0, r5
7000046a:	f000 f9ad 	bl	700007c8 <tm_pmu_profile_end>
      tm_isr_to_task_counter++;
7000046e:	6839      	ldr	r1, [r7, #0]
70000470:	4b20      	ldr	r3, [pc, #128]	; (700004f4 <tm_receiver_thread_entry+0xc4>)
70000472:	2200      	movs	r2, #0
70000474:	3101      	adds	r1, #1
70000476:	6039      	str	r1, [r7, #0]
      checksum += msg[i];
70000478:	f853 1f04 	ldr.w	r1, [r3, #4]!
   for (int i = 0; i < size; i++)
7000047c:	455b      	cmp	r3, fp
      checksum += msg[i];
7000047e:	440a      	add	r2, r1
   for (int i = 0; i < size; i++)
70000480:	d1fa      	bne.n	70000478 <tm_receiver_thread_entry+0x48>
      if (compute_checksum(message_received_arr, MESSAGE_SIZE - 1) != message_received_arr[MESSAGE_SIZE - 1])
70000482:	f8d9 307c 	ldr.w	r3, [r9, #124]	; 0x7c
70000486:	4293      	cmp	r3, r2
70000488:	d003      	beq.n	70000492 <tm_receiver_thread_entry+0x62>
         printf("Message integrity error in iteration %d: checksum mismatch\r\n", i);
7000048a:	4631      	mov	r1, r6
7000048c:	4650      	mov	r0, sl
7000048e:	f000 fab1 	bl	700009f4 <printk>
   for (i = 0; i < ITERATION_COUNT; i++)
70000492:	3510      	adds	r5, #16
70000494:	4545      	cmp	r5, r8
70000496:	f106 0601 	add.w	r6, r6, #1
7000049a:	d1df      	bne.n	7000045c <tm_receiver_thread_entry+0x2c>
         // For example: error_counter++;
      }
   }

   /* After all iterations, report the results */
   printf("==== ISR-to-Task Benchmark Complete ====\r\n");
7000049c:	f644 4008 	movw	r0, #19464	; 0x4c08
   /* Print PMU results for measurements */
   for (i = 0; i < ITERATION_COUNT; i++)
   {
      // printf("Receive Latency: ");
      // tm_pmu_profile_print(pmu_recv_names[i]);
      printf("Send Latency: ");
700004a0:	f644 4578 	movw	r5, #19576	; 0x4c78
   printf("==== ISR-to-Task Benchmark Complete ====\r\n");
700004a4:	f2c7 0000 	movt	r0, #28672	; 0x7000
700004a8:	f000 faa4 	bl	700009f4 <printk>
   printf("Total messages processed: %lu\r\n", tm_isr_to_task_counter);
700004ac:	f644 4034 	movw	r0, #19508	; 0x4c34
700004b0:	6839      	ldr	r1, [r7, #0]
700004b2:	f2c7 0000 	movt	r0, #28672	; 0x7000
700004b6:	f000 fa9d 	bl	700009f4 <printk>
   printf("Total interrupts processed: %lu\r\n", tm_isr_counter);
700004ba:	f645 2350 	movw	r3, #23120	; 0x5a50
700004be:	f644 4054 	movw	r0, #19540	; 0x4c54
700004c2:	f2c7 0300 	movt	r3, #28672	; 0x7000
700004c6:	f2c7 0000 	movt	r0, #28672	; 0x7000
      printf("Send Latency: ");
700004ca:	f2c7 0500 	movt	r5, #28672	; 0x7000
   printf("Total interrupts processed: %lu\r\n", tm_isr_counter);
700004ce:	6819      	ldr	r1, [r3, #0]
700004d0:	f000 fa90 	bl	700009f4 <printk>
      printf("Send Latency: ");
700004d4:	4628      	mov	r0, r5
700004d6:	f000 fa8d 	bl	700009f4 <printk>
      tm_pmu_profile_print(pmu_send_names[i]);
700004da:	4620      	mov	r0, r4
   for (i = 0; i < ITERATION_COUNT; i++)
700004dc:	3410      	adds	r4, #16
      tm_pmu_profile_print(pmu_send_names[i]);
700004de:	f000 f9bf 	bl	70000860 <tm_pmu_profile_print>
   for (i = 0; i < ITERATION_COUNT; i++)
700004e2:	4544      	cmp	r4, r8
700004e4:	d1f6      	bne.n	700004d4 <tm_receiver_thread_entry+0xa4>
   }

   tm_thread_suspend(0);
}
700004e6:	e8bd 4ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
   tm_thread_suspend(0);
700004ea:	2000      	movs	r0, #0
700004ec:	f000 b8ec 	b.w	700006c8 <tm_thread_suspend>
700004f0:	70005a44 	.word	0x70005a44
700004f4:	700059c8 	.word	0x700059c8

700004f8 <main_message_isr_test>:
   tm_initialize(tm_message_isr_to_task_initialize);
700004f8:	f240 30bd 	movw	r0, #957	; 0x3bd
700004fc:	f2c7 0000 	movt	r0, #28672	; 0x7000
{
70000500:	b508      	push	{r3, lr}
   tm_initialize(tm_message_isr_to_task_initialize);
70000502:	f000 f8a3 	bl	7000064c <tm_initialize>
}
70000506:	2000      	movs	r0, #0
70000508:	bd08      	pop	{r3, pc}
7000050a:	bf00      	nop

7000050c <tm_isr_message_handler>:
   tm_isr_counter++;
7000050c:	f645 2350 	movw	r3, #23120	; 0x5a50
   message[0] = 1;
70000510:	2001      	movs	r0, #1
   tm_isr_counter++;
70000512:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
70000516:	b510      	push	{r4, lr}
   tm_isr_counter++;
70000518:	681a      	ldr	r2, [r3, #0]
   message[1] = isr_message_counter;
7000051a:	f645 244c 	movw	r4, #23116	; 0x5a4c
   message[0] = 1;
7000051e:	f645 1c4c 	movw	ip, #22860	; 0x594c
   message[1] = isr_message_counter;
70000522:	f2c7 0400 	movt	r4, #28672	; 0x7000
   tm_isr_counter++;
70000526:	4402      	add	r2, r0
   message[0] = 1;
70000528:	f2c7 0c00 	movt	ip, #28672	; 0x7000
   tm_isr_counter++;
7000052c:	601a      	str	r2, [r3, #0]
   message[1] = isr_message_counter;
7000052e:	4661      	mov	r1, ip
70000530:	6823      	ldr	r3, [r4, #0]
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
70000532:	2202      	movs	r2, #2
   message[0] = 1;
70000534:	f8cc 0000 	str.w	r0, [ip]
   message[1] = isr_message_counter;
70000538:	f841 3f04 	str.w	r3, [r1, #4]!
      message[i] = 1000 + (isr_message_counter * 10) + i;
7000053c:	6823      	ldr	r3, [r4, #0]
7000053e:	eb03 0383 	add.w	r3, r3, r3, lsl #2
70000542:	eb02 0343 	add.w	r3, r2, r3, lsl #1
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
70000546:	3201      	adds	r2, #1
      message[i] = 1000 + (isr_message_counter * 10) + i;
70000548:	f503 737a 	add.w	r3, r3, #1000	; 0x3e8
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
7000054c:	2a1f      	cmp	r2, #31
      message[i] = 1000 + (isr_message_counter * 10) + i;
7000054e:	f841 3f04 	str.w	r3, [r1, #4]!
   for (i = 2; i < MESSAGE_SIZE - 1; i++)
70000552:	d1f3      	bne.n	7000053c <tm_isr_message_handler+0x30>
70000554:	4b0f      	ldr	r3, [pc, #60]	; (70000594 <tm_isr_message_handler+0x88>)
   unsigned long checksum = 0;
70000556:	2200      	movs	r2, #0
70000558:	f103 007c 	add.w	r0, r3, #124	; 0x7c
      checksum += msg[i];
7000055c:	f853 1f04 	ldr.w	r1, [r3, #4]!
   for (int i = 0; i < size; i++)
70000560:	4283      	cmp	r3, r0
      checksum += msg[i];
70000562:	440a      	add	r2, r1
   for (int i = 0; i < size; i++)
70000564:	d1fa      	bne.n	7000055c <tm_isr_message_handler+0x50>
   tm_pmu_profile_start(pmu_send_names[isr_message_counter]);
70000566:	6820      	ldr	r0, [r4, #0]
70000568:	f245 734c 	movw	r3, #22348	; 0x574c
   message[MESSAGE_SIZE - 1] = compute_checksum(message, MESSAGE_SIZE - 1);
7000056c:	f8cc 207c 	str.w	r2, [ip, #124]	; 0x7c
   tm_pmu_profile_start(pmu_send_names[isr_message_counter]);
70000570:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000574:	eb03 1000 	add.w	r0, r3, r0, lsl #4
70000578:	f000 f8e6 	bl	70000748 <tm_pmu_profile_start>
   tm_queue_send_from_isr(0, message);
7000057c:	f645 114c 	movw	r1, #22860	; 0x594c
70000580:	2000      	movs	r0, #0
70000582:	f2c7 0100 	movt	r1, #28672	; 0x7000
70000586:	f000 f8c3 	bl	70000710 <tm_queue_send_from_isr>
   isr_message_counter++; /* Prepare for next iteration */
7000058a:	6823      	ldr	r3, [r4, #0]
7000058c:	3301      	adds	r3, #1
7000058e:	6023      	str	r3, [r4, #0]
}
70000590:	bd10      	pop	{r4, pc}
70000592:	bf00      	nop
70000594:	70005948 	.word	0x70005948

70000598 <tm_setup_pmu>:
/* --------------------------------------------------------------------------
 * PMU Initialization (called at system boot)
 * -------------------------------------------------------------------------- */
int tm_setup_pmu(void)
{
   printk("Initializing PMU...\r\n");
70000598:	f644 4088 	movw	r0, #19592	; 0x4c88
{
7000059c:	b538      	push	{r3, r4, r5, lr}
   printk("Initializing PMU...\r\n");
7000059e:	f2c7 0000 	movt	r0, #28672	; 0x7000
700005a2:	f000 fa27 	bl	700009f4 <printk>

/* Performance Monitor Control Register (PMCR) */
__STATIC_FORCEINLINE uint32_t pmu_read_pmcr(void)
{
    uint32_t val;
    __asm__ volatile ("mrc p15, 0, %0, c9, c12, 0" : "=r" (val));
700005a6:	ee19 3f1c 	mrc	15, 0, r3, cr9, cr12, {0}

   /* Disable all counters (PMCR.E=0) */
   uint32_t pmcr = pmu_read_pmcr();
   pmcr &= ~0x1;
700005aa:	f023 0301 	bic.w	r3, r3, #1
    return val;
}

__STATIC_FORCEINLINE void pmu_write_pmcr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
700005ae:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}
}

/* Performance Monitor Count Enable Clear Register (PMCNTENCLR) */
__STATIC_FORCEINLINE void pmu_write_cntenclr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 2" : : "r" (val));
700005b2:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
700005b6:	ee09 3f5c 	mcr	15, 0, r3, cr9, cr12, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
700005ba:	2306      	movs	r3, #6
700005bc:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}
    return val;
}

__STATIC_FORCEINLINE void pmu_write_pmccntr(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 0" : : "r" (val));
700005c0:	2400      	movs	r4, #0
700005c2:	ee09 4f1d 	mcr	15, 0, r4, cr9, cr13, {0}
}

/* Event Counter Selection Register (PMSELR) */
__STATIC_FORCEINLINE void pmu_select_event_counter(uint32_t counter_idx)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
700005c6:	ee09 4fbc 	mcr	15, 0, r4, cr9, cr12, {5}

   /* Configure event counters */
   for (uint32_t i = 0; i < gPmuConfig.numEventCounters; i++)
   {
      pmu_select_event_counter(i);
      pmu_write_evtyper(gPmuConfig.eventCounters[i].type);
700005ca:	f24c 2360 	movw	r3, #49760	; 0xc260
700005ce:	f2c7 0300 	movt	r3, #28672	; 0x7000
}

/* Event Type Register (PMXEVTYPER) */
__STATIC_FORCEINLINE void pmu_write_evtyper(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
700005d2:	685a      	ldr	r2, [r3, #4]
700005d4:	ee09 2f3d 	mcr	15, 0, r2, cr9, cr13, {1}
    return val;
}

__STATIC_FORCEINLINE void pmu_write_evcounter(uint32_t val)
{
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
700005d8:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
700005dc:	2501      	movs	r5, #1
700005de:	ee09 5fbc 	mcr	15, 0, r5, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
700005e2:	68da      	ldr	r2, [r3, #12]
700005e4:	ee09 2f3d 	mcr	15, 0, r2, cr9, cr13, {1}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
700005e8:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
700005ec:	2202      	movs	r2, #2
700005ee:	ee09 2fbc 	mcr	15, 0, r2, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 1" : : "r" (val));
700005f2:	695b      	ldr	r3, [r3, #20]
700005f4:	ee09 3f3d 	mcr	15, 0, r3, cr9, cr13, {1}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
700005f8:	ee09 4f5d 	mcr	15, 0, r4, cr9, cr13, {2}
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 1" : : "r" (val));
700005fc:	2307      	movs	r3, #7
700005fe:	f2c8 0300 	movt	r3, #32768	; 0x8000
70000602:	ee09 3f3c 	mcr	15, 0, r3, cr9, cr12, {1}
    __asm__ volatile ("mrc p15, 0, %0, c9, c12, 0" : "=r" (val));
70000606:	ee19 3f1c 	mrc	15, 0, r3, cr9, cr12, {0}
   /*    bit31 => cycle counter, plus bits [0..(numEventCounters-1)] => event counters */
   pmu_write_cntenset((1 << 31) | ((1 << gPmuConfig.numEventCounters) - 1));

   /* Enable counters in PMCR (bit[0] = E=1) */
   pmcr = pmu_read_pmcr();
   pmcr |= 0x1;
7000060a:	432b      	orrs	r3, r5
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 0" : : "r" (val));
7000060c:	ee09 3f1c 	mcr	15, 0, r3, cr9, cr12, {0}

/* PMU User Access Enable Register (PMUSERENR) */
__STATIC_FORCEINLINE void pmu_enable_user_access(void)
{
    uint32_t val;
    __asm__ volatile ("mrc p15, 0, %0, c9, c14, 0" : "=r" (val));
70000610:	ee19 3f1e 	mrc	15, 0, r3, cr9, cr14, {0}
    val |= 1;  // Enable user mode access
70000614:	432b      	orrs	r3, r5
    __asm__ volatile ("mcr p15, 0, %0, c9, c14, 0" : : "r" (val));
70000616:	ee09 3f1e 	mcr	15, 0, r3, cr9, cr14, {0}
/* --------------------------------------------------------------------------
 * Init for the Chache Hits/Misses profile structure
 * -------------------------------------------------------------------------- */
void pmu_init_profile(void)
{
   memset(&gProfileObject, 0, sizeof(gProfileObject));
7000061a:	f645 2358 	movw	r3, #23128	; 0x5a58
7000061e:	4621      	mov	r1, r4
70000620:	f241 320c 	movw	r2, #4876	; 0x130c
70000624:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000628:	4618      	mov	r0, r3
7000062a:	f002 fc93 	bl	70002f54 <memset>
   gProfileObject.logIndex = 0;
   gProfileObject.numEvents = PMU_MAX_EVENT_COUNTERS;
7000062e:	2203      	movs	r2, #3
70000630:	f500 5380 	add.w	r3, r0, #4096	; 0x1000
   printk("PMU Initialized.\r\n");
70000634:	f644 40a0 	movw	r0, #19616	; 0x4ca0
   gProfileObject.bCycleCounter = 1; /* We use cycle counter */
70000638:	f883 5308 	strb.w	r5, [r3, #776]	; 0x308
   printk("PMU Initialized.\r\n");
7000063c:	f2c7 0000 	movt	r0, #28672	; 0x7000
   gProfileObject.numEvents = PMU_MAX_EVENT_COUNTERS;
70000640:	f8c3 2304 	str.w	r2, [r3, #772]	; 0x304
   printk("PMU Initialized.\r\n");
70000644:	f000 f9d6 	bl	700009f4 <printk>
}
70000648:	4620      	mov	r0, r4
7000064a:	bd38      	pop	{r3, r4, r5, pc}

7000064c <tm_initialize>:
   test_initialization_function();
7000064c:	4700      	bx	r0
7000064e:	bf00      	nop

70000650 <tm_thread_create>:
{
70000650:	b5f0      	push	{r4, r5, r6, r7, lr}
   tid = k_thread_create(&test_thread[thread_id], test_stack[thread_id], TM_TEST_STACK_SIZE, entry_function, NULL, NULL,
70000652:	f644 6488 	movw	r4, #20104	; 0x4e88
70000656:	ebc0 1500 	rsb	r5, r0, r0, lsl #4
7000065a:	f2c7 0400 	movt	r4, #28672	; 0x7000
{
7000065e:	4613      	mov	r3, r2
70000660:	b089      	sub	sp, #36	; 0x24
70000662:	f04f 36ff 	mov.w	r6, #4294967295	; 0xffffffff
   tid = k_thread_create(&test_thread[thread_id], test_stack[thread_id], TM_TEST_STACK_SIZE, entry_function, NULL, NULL,
70000666:	eb04 04c5 	add.w	r4, r4, r5, lsl #3
7000066a:	f04f 37ff 	mov.w	r7, #4294967295	; 0xffffffff
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
7000066e:	2500      	movs	r5, #0
70000670:	f44f 6280 	mov.w	r2, #1024	; 0x400
70000674:	9103      	str	r1, [sp, #12]
70000676:	f248 0160 	movw	r1, #32864	; 0x8060
7000067a:	9504      	str	r5, [sp, #16]
7000067c:	f2c7 0100 	movt	r1, #28672	; 0x7000
70000680:	e9cd 5501 	strd	r5, r5, [sp, #4]
70000684:	eb01 2180 	add.w	r1, r1, r0, lsl #10
70000688:	9500      	str	r5, [sp, #0]
7000068a:	4620      	mov	r0, r4
7000068c:	e9cd 6706 	strd	r6, r7, [sp, #24]
70000690:	f001 fce4 	bl	7000205c <z_impl_k_thread_create>
70000694:	4605      	mov	r5, r0
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_SUSPEND);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_suspend(thread);
70000696:	4620      	mov	r0, r4
70000698:	f001 fe8a 	bl	700023b0 <z_impl_k_thread_suspend>
	z_impl_k_wakeup(thread);
7000069c:	4620      	mov	r0, r4
7000069e:	f002 f81b 	bl	700026d8 <z_impl_k_wakeup>
}
700006a2:	1b60      	subs	r0, r4, r5
700006a4:	bf18      	it	ne
700006a6:	2001      	movne	r0, #1
700006a8:	b009      	add	sp, #36	; 0x24
700006aa:	bdf0      	pop	{r4, r5, r6, r7, pc}

700006ac <tm_thread_resume>:
{
700006ac:	b508      	push	{r3, lr}
   k_thread_resume(&test_thread[thread_id]);
700006ae:	f644 6388 	movw	r3, #20104	; 0x4e88
700006b2:	ebc0 1000 	rsb	r0, r0, r0, lsl #4
700006b6:	f2c7 0300 	movt	r3, #28672	; 0x7000
		(void) arch_syscall_invoke1(parm0.x, K_SYSCALL_K_THREAD_RESUME);
		return;
	}
#endif
	compiler_barrier();
	z_impl_k_thread_resume(thread);
700006ba:	eb03 00c0 	add.w	r0, r3, r0, lsl #3
700006be:	f001 ff4b 	bl	70002558 <z_impl_k_thread_resume>
}
700006c2:	2000      	movs	r0, #0
700006c4:	bd08      	pop	{r3, pc}
700006c6:	bf00      	nop

700006c8 <tm_thread_suspend>:
{
700006c8:	b508      	push	{r3, lr}
   k_thread_suspend(&test_thread[thread_id]);
700006ca:	f644 6388 	movw	r3, #20104	; 0x4e88
700006ce:	ebc0 1000 	rsb	r0, r0, r0, lsl #4
700006d2:	f2c7 0300 	movt	r3, #28672	; 0x7000
	z_impl_k_thread_suspend(thread);
700006d6:	eb03 00c0 	add.w	r0, r3, r0, lsl #3
700006da:	f001 fe69 	bl	700023b0 <z_impl_k_thread_suspend>
}
700006de:	2000      	movs	r0, #0
700006e0:	bd08      	pop	{r3, pc}
700006e2:	bf00      	nop

700006e4 <tm_queue_create>:
{
700006e4:	b508      	push	{r3, lr}
   k_msgq_init(&test_msgq[queue_id], &test_msgq_buffer[queue_id][0][0], MESSAGE_SIZE * sizeof(int32_t), 8);
700006e6:	f646 5164 	movw	r1, #28004	; 0x6d64
700006ea:	eb00 0e40 	add.w	lr, r0, r0, lsl #1
700006ee:	f647 5c64 	movw	ip, #32100	; 0x7d64
700006f2:	f2c7 0100 	movt	r1, #28672	; 0x7000
700006f6:	f2c7 0c00 	movt	ip, #28672	; 0x7000
700006fa:	2308      	movs	r3, #8
700006fc:	eb01 2180 	add.w	r1, r1, r0, lsl #10
70000700:	2280      	movs	r2, #128	; 0x80
70000702:	eb0c 100e 	add.w	r0, ip, lr, lsl #4
70000706:	f001 fb35 	bl	70001d74 <k_msgq_init>
}
7000070a:	2000      	movs	r0, #0
7000070c:	bd08      	pop	{r3, pc}
7000070e:	bf00      	nop

70000710 <tm_queue_send_from_isr>:
{
70000710:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
70000714:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
   return k_msgq_put(&test_msgq[queue_id], message_ptr, K_FOREVER);
70000718:	f647 5c64 	movw	ip, #32100	; 0x7d64
7000071c:	eb00 0040 	add.w	r0, r0, r0, lsl #1
70000720:	f2c7 0c00 	movt	ip, #28672	; 0x7000
		union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm2 = { .val = timeout };
		return (int) arch_syscall_invoke4(parm0.x, parm1.x, parm2.split.lo, parm2.split.hi, K_SYSCALL_K_MSGQ_PUT);
	}
#endif
	compiler_barrier();
	return z_impl_k_msgq_put(msgq, data, timeout);
70000724:	eb0c 1000 	add.w	r0, ip, r0, lsl #4
70000728:	f001 bb3a 	b.w	70001da0 <z_impl_k_msgq_put>

7000072c <tm_queue_receive>:
{
7000072c:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
70000730:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
   return k_msgq_get(&test_msgq[queue_id], message_ptr, K_FOREVER);
70000734:	f647 5c64 	movw	ip, #32100	; 0x7d64
70000738:	eb00 0040 	add.w	r0, r0, r0, lsl #1
7000073c:	f2c7 0c00 	movt	ip, #28672	; 0x7000
		union { struct { uintptr_t lo, hi; } split; k_timeout_t val; } parm2 = { .val = timeout };
		return (int) arch_syscall_invoke4(parm0.x, parm1.x, parm2.split.lo, parm2.split.hi, K_SYSCALL_K_MSGQ_GET);
	}
#endif
	compiler_barrier();
	return z_impl_k_msgq_get(msgq, data, timeout);
70000740:	eb0c 1000 	add.w	r0, ip, r0, lsl #4
70000744:	f001 bba2 	b.w	70001e8c <z_impl_k_msgq_get>

70000748 <tm_pmu_profile_start>:
 * - Read "start" values
 * - Store them in the next free slot
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_start(const char* name)
{
   uint32_t idx = gProfileObject.logIndex;
70000748:	f645 2c58 	movw	ip, #23128	; 0x5a58
7000074c:	f2c7 0c00 	movt	ip, #28672	; 0x7000
{
70000750:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
   uint32_t idx = gProfileObject.logIndex;
70000754:	f8dc 4000 	ldr.w	r4, [ip]
   if (idx >= PMU_MAX_LOG_ENTRIES)
70000758:	2c3f      	cmp	r4, #63	; 0x3f
7000075a:	d833      	bhi.n	700007c4 <tm_pmu_profile_start+0x7c>
      /* no more space */
      return;
   }

   TM_PMUProfilePoint* p = &gProfileObject.point[idx];
   p->name = name;
7000075c:	eb04 02c4 	add.w	r2, r4, r4, lsl #3

   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000760:	f50c 5380 	add.w	r3, ip, #4096	; 0x1000
   p->name = name;
70000764:	eb04 0242 	add.w	r2, r4, r2, lsl #1
70000768:	ea4f 0ec4 	mov.w	lr, r4, lsl #3
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
7000076c:	f8d3 5304 	ldr.w	r5, [r3, #772]	; 0x304
   p->name = name;
70000770:	eb0c 0182 	add.w	r1, ip, r2, lsl #2
70000774:	0092      	lsls	r2, r2, #2
70000776:	6048      	str	r0, [r1, #4]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000778:	b1dd      	cbz	r5, 700007b2 <tm_pmu_profile_start+0x6a>
7000077a:	f24c 2660 	movw	r6, #49760	; 0xc260
7000077e:	3234      	adds	r2, #52	; 0x34
70000780:	2300      	movs	r3, #0
70000782:	f2c7 0600 	movt	r6, #28672	; 0x7000
70000786:	4462      	add	r2, ip
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
70000788:	461f      	mov	r7, r3
7000078a:	f106 0804 	add.w	r8, r6, #4
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
7000078e:	ee09 3fbc 	mcr	15, 0, r3, cr9, cr12, {5}
    __asm__ volatile ("mcr p15, 0, %0, c9, c13, 2" : : "r" (val));
70000792:	ee09 7f5d 	mcr	15, 0, r7, cr9, cr13, {2}
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 2" : "=r" (val));
70000796:	ee19 0f5d 	mrc	15, 0, r0, cr9, cr13, {2}
   {
      pmu_select_event_counter(i);
      /* Reset the counters to 0 */
      pmu_write_evcounter(0);
      p->eventStart[i] = pmu_read_evcounter();
7000079a:	f842 0f04 	str.w	r0, [r2, #4]!
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
7000079e:	310c      	adds	r1, #12

      /* Also store name & type */
      p->events[i].name = gPmuEventCfg[i].name;
700007a0:	f856 0033 	ldr.w	r0, [r6, r3, lsl #3]
700007a4:	6088      	str	r0, [r1, #8]
      p->events[i].type = gPmuEventCfg[i].type;
700007a6:	f858 0033 	ldr.w	r0, [r8, r3, lsl #3]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700007aa:	3301      	adds	r3, #1
      p->events[i].type = gPmuEventCfg[i].type;
700007ac:	60c8      	str	r0, [r1, #12]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700007ae:	42ab      	cmp	r3, r5
700007b0:	d1ed      	bne.n	7000078e <tm_pmu_profile_start+0x46>
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 0" : "=r" (val));
700007b2:	ee19 3f1d 	mrc	15, 0, r3, cr9, cr13, {0}
   }
   /* Immediately read them as "start" values */
   p->cycleCountStart = pmu_read_pmccntr();
700007b6:	44a6      	add	lr, r4
700007b8:	eb04 044e 	add.w	r4, r4, lr, lsl #1
700007bc:	eb0c 0c84 	add.w	ip, ip, r4, lsl #2
700007c0:	f8cc 3008 	str.w	r3, [ip, #8]
}
700007c4:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}

700007c8 <tm_pmu_profile_end>:
 * - Read PMU Registers for "end" values
 * - Compute delta
 * - Increase log index
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_end(const char* name)
{
700007c8:	b570      	push	{r4, r5, r6, lr}
   uint32_t idx = gProfileObject.logIndex;
700007ca:	f645 2e58 	movw	lr, #23128	; 0x5a58
700007ce:	f2c7 0e00 	movt	lr, #28672	; 0x7000
700007d2:	f8de 4000 	ldr.w	r4, [lr]
   if (idx >= PMU_MAX_LOG_ENTRIES)
700007d6:	2c3f      	cmp	r4, #63	; 0x3f
700007d8:	d83a      	bhi.n	70000850 <tm_pmu_profile_end+0x88>
700007da:	ee19 1f1d 	mrc	15, 0, r1, cr9, cr13, {0}
   //    return;
   // }

   /* Read end counters */
   p->cycleCountEnd = pmu_read_pmccntr();
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700007de:	f50e 5380 	add.w	r3, lr, #4096	; 0x1000
   p->cycleCountEnd = pmu_read_pmccntr();
700007e2:	eb04 0cc4 	add.w	ip, r4, r4, lsl #3
700007e6:	00e5      	lsls	r5, r4, #3
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700007e8:	f8d3 6304 	ldr.w	r6, [r3, #772]	; 0x304
   p->cycleCountEnd = pmu_read_pmccntr();
700007ec:	eb04 0c4c 	add.w	ip, r4, ip, lsl #1
700007f0:	eb0e 038c 	add.w	r3, lr, ip, lsl #2
700007f4:	ea4f 0c8c 	mov.w	ip, ip, lsl #2
700007f8:	60d9      	str	r1, [r3, #12]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
700007fa:	b356      	cbz	r6, 70000852 <tm_pmu_profile_end+0x8a>
700007fc:	2300      	movs	r3, #0
700007fe:	f10c 0240 	add.w	r2, ip, #64	; 0x40
70000802:	4472      	add	r2, lr
    __asm__ volatile ("mcr p15, 0, %0, c9, c12, 5" : : "r" (counter_idx & 0x1F));
70000804:	ee09 3fbc 	mcr	15, 0, r3, cr9, cr12, {5}
    __asm__ volatile ("mrc p15, 0, %0, c9, c13, 2" : "=r" (val));
70000808:	ee19 0f5d 	mrc	15, 0, r0, cr9, cr13, {2}
   {
      pmu_select_event_counter(i);
      p->eventEnd[i] = pmu_read_evcounter();
7000080c:	f842 0f04 	str.w	r0, [r2, #4]!
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000810:	3301      	adds	r3, #1
70000812:	42b3      	cmp	r3, r6
70000814:	d1f6      	bne.n	70000804 <tm_pmu_profile_end+0x3c>
   }

   /* Compute deltas */
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
70000816:	4425      	add	r5, r4
70000818:	f10c 0034 	add.w	r0, ip, #52	; 0x34
7000081c:	eb04 0545 	add.w	r5, r4, r5, lsl #1
70000820:	f10c 0c1c 	add.w	ip, ip, #28
70000824:	eb0e 0585 	add.w	r5, lr, r5, lsl #2
70000828:	eb03 0343 	add.w	r3, r3, r3, lsl #1
7000082c:	4470      	add	r0, lr
7000082e:	68ae      	ldr	r6, [r5, #8]
70000830:	44f4      	add	ip, lr
70000832:	2200      	movs	r2, #0
70000834:	1b89      	subs	r1, r1, r6
70000836:	6129      	str	r1, [r5, #16]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
   {
      uint32_t diff = p->eventEnd[i] - p->eventStart[i];
70000838:	6901      	ldr	r1, [r0, #16]
7000083a:	f850 5f04 	ldr.w	r5, [r0, #4]!
7000083e:	1b49      	subs	r1, r1, r5
      p->events[i].value = diff;
70000840:	f84c 1022 	str.w	r1, [ip, r2, lsl #2]
   for (uint32_t i = 0; i < gProfileObject.numEvents; i++)
70000844:	3203      	adds	r2, #3
70000846:	429a      	cmp	r2, r3
70000848:	d1f6      	bne.n	70000838 <tm_pmu_profile_end+0x70>
   }

   /* Move to next log slot for future profileStart() */
   gProfileObject.logIndex++;
7000084a:	3401      	adds	r4, #1
7000084c:	f8ce 4000 	str.w	r4, [lr]
}
70000850:	bd70      	pop	{r4, r5, r6, pc}
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
70000852:	689a      	ldr	r2, [r3, #8]
   gProfileObject.logIndex++;
70000854:	3401      	adds	r4, #1
70000856:	f8ce 4000 	str.w	r4, [lr]
   p->cycleCountValue = p->cycleCountEnd - p->cycleCountStart;
7000085a:	1a8a      	subs	r2, r1, r2
7000085c:	611a      	str	r2, [r3, #16]
   gProfileObject.logIndex++;
7000085e:	e7f7      	b.n	70000850 <tm_pmu_profile_end+0x88>

70000860 <tm_pmu_profile_print>:
 * tm_pmu_profile_print_entry(name)
 * - Search for an entry with the given name
 * - Print results
 * -------------------------------------------------------------------------- */
void tm_pmu_profile_print(const char* name)
{
70000860:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
70000864:	f645 2958 	movw	r9, #23128	; 0x5a58
{
70000868:	4680      	mov	r8, r0
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
7000086a:	f2c7 0900 	movt	r9, #28672	; 0x7000
7000086e:	f8d9 a000 	ldr.w	sl, [r9]
70000872:	f1ba 0f00 	cmp.w	sl, #0
70000876:	d00d      	beq.n	70000894 <tm_pmu_profile_print+0x34>
70000878:	464e      	mov	r6, r9
7000087a:	2500      	movs	r5, #0
   {
      TM_PMUProfilePoint* p = &gProfileObject.point[i];
      if (p->name != NULL && strcmp(p->name, name) == 0)
7000087c:	6877      	ldr	r7, [r6, #4]
7000087e:	4641      	mov	r1, r8
70000880:	4638      	mov	r0, r7
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
70000882:	364c      	adds	r6, #76	; 0x4c
      if (p->name != NULL && strcmp(p->name, name) == 0)
70000884:	b11f      	cbz	r7, 7000088e <tm_pmu_profile_print+0x2e>
70000886:	f7ff fbdb 	bl	70000040 <strcmp>
7000088a:	4604      	mov	r4, r0
7000088c:	b158      	cbz	r0, 700008a6 <tm_pmu_profile_print+0x46>
   for (uint32_t i = 0; i < gProfileObject.logIndex; i++)
7000088e:	3501      	adds	r5, #1
70000890:	4555      	cmp	r5, sl
70000892:	d1f3      	bne.n	7000087c <tm_pmu_profile_print+0x1c>
         }
         printk("\r\n");
         return;
      }
   }
   printk("No profile entry found for name: %s\r\n", name);
70000894:	f644 40ec 	movw	r0, #19692	; 0x4cec
70000898:	4641      	mov	r1, r8
7000089a:	f2c7 0000 	movt	r0, #28672	; 0x7000
}
7000089e:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
   printk("No profile entry found for name: %s\r\n", name);
700008a2:	f000 b8a7 	b.w	700009f4 <printk>
         printk("Profile Entry: %s\r\n", p->name);
700008a6:	f644 40b4 	movw	r0, #19636	; 0x4cb4
700008aa:	4639      	mov	r1, r7
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
700008ac:	4e17      	ldr	r6, [pc, #92]	; (7000090c <tm_pmu_profile_print+0xac>)
         printk("Profile Entry: %s\r\n", p->name);
700008ae:	f2c7 0000 	movt	r0, #28672	; 0x7000
700008b2:	f000 f89f 	bl	700009f4 <printk>
         printk("Cycle Count: %u\r\n", p->cycleCountValue);
700008b6:	f644 40c8 	movw	r0, #19656	; 0x4cc8
700008ba:	eb05 03c5 	add.w	r3, r5, r5, lsl #3
700008be:	f2c7 0000 	movt	r0, #28672	; 0x7000
700008c2:	eb05 0543 	add.w	r5, r5, r3, lsl #1
700008c6:	eb09 0985 	add.w	r9, r9, r5, lsl #2
700008ca:	f8d9 1010 	ldr.w	r1, [r9, #16]
700008ce:	f000 f891 	bl	700009f4 <printk>
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
700008d2:	f8d6 3304 	ldr.w	r3, [r6, #772]	; 0x304
700008d6:	b18b      	cbz	r3, 700008fc <tm_pmu_profile_print+0x9c>
            printk("%s Count: %u\r\n", p->events[j].name, p->events[j].value);
700008d8:	f644 45dc 	movw	r5, #19676	; 0x4cdc
700008dc:	f2c7 0500 	movt	r5, #28672	; 0x7000
700008e0:	f8d9 201c 	ldr.w	r2, [r9, #28]
700008e4:	4628      	mov	r0, r5
700008e6:	f8d9 1014 	ldr.w	r1, [r9, #20]
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
700008ea:	3401      	adds	r4, #1
            printk("%s Count: %u\r\n", p->events[j].name, p->events[j].value);
700008ec:	f000 f882 	bl	700009f4 <printk>
         for (uint32_t j = 0; j < gProfileObject.numEvents; j++)
700008f0:	f8d6 3304 	ldr.w	r3, [r6, #772]	; 0x304
700008f4:	f109 090c 	add.w	r9, r9, #12
700008f8:	42a3      	cmp	r3, r4
700008fa:	d8f1      	bhi.n	700008e0 <tm_pmu_profile_print+0x80>
         printk("\r\n");
700008fc:	f644 30a8 	movw	r0, #19368	; 0x4ba8
}
70000900:	e8bd 47f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
         printk("\r\n");
70000904:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000908:	f000 b874 	b.w	700009f4 <printk>
7000090c:	70006a58 	.word	0x70006a58

70000910 <free_list_add>:
	h->free_bytes += chunksz_to_bytes(h, chunk_size(h, c));
#endif
}

static void free_list_add(struct z_heap *h, chunkid_t c)
{
70000910:	b530      	push	{r4, r5, lr}
	void *cmem = &buf[c];

	if (big_heap(h)) {
		return ((uint32_t *)cmem)[f];
	} else {
		return ((uint16_t *)cmem)[f];
70000912:	eb00 04c1 	add.w	r4, r0, r1, lsl #3
70000916:	8863      	ldrh	r3, [r4, #2]
	return chunk_field(h, c, SIZE_AND_USED) & 1U;
}

static inline chunksz_t chunk_size(struct z_heap *h, chunkid_t c)
{
	return chunk_field(h, c, SIZE_AND_USED) >> 1;
70000918:	085b      	lsrs	r3, r3, #1
}

static inline int bucket_idx(struct z_heap *h, chunksz_t sz)
{
	unsigned int usable_sz = sz - min_chunk_size(h) + 1;
	return 31 - __builtin_clz(usable_sz);
7000091a:	fab3 f383 	clz	r3, r3
7000091e:	f1c3 031f 	rsb	r3, r3, #31
	void *cmem = &buf[c];
70000922:	ea4f 0cc1 	mov.w	ip, r1, lsl #3
	if (b->next == 0U) {
70000926:	eb00 0583 	add.w	r5, r0, r3, lsl #2
		((uint16_t *)cmem)[f] = val;
7000092a:	f10c 0c04 	add.w	ip, ip, #4
7000092e:	fa1f fe81 	uxth.w	lr, r1
70000932:	692a      	ldr	r2, [r5, #16]
70000934:	b962      	cbnz	r2, 70000950 <free_list_add+0x40>
		h->avail_buckets |= BIT(bidx);
70000936:	2401      	movs	r4, #1
70000938:	f36e 020f 	bfi	r2, lr, #0, #16
7000093c:	f36e 421f 	bfi	r2, lr, #16, #16
70000940:	409c      	lsls	r4, r3
70000942:	68c3      	ldr	r3, [r0, #12]
70000944:	4323      	orrs	r3, r4
70000946:	60c3      	str	r3, [r0, #12]
		b->next = c;
70000948:	6129      	str	r1, [r5, #16]
7000094a:	f840 200c 	str.w	r2, [r0, ip]
	if (!solo_free_header(h, c)) {
		int bidx = bucket_idx(h, chunk_size(h, c));
		free_list_add_bidx(h, c, bidx);
	}
}
7000094e:	bd30      	pop	{r4, r5, pc}
	void *cmem = &buf[c];
70000950:	00d3      	lsls	r3, r2, #3
		return ((uint16_t *)cmem)[f];
70000952:	3304      	adds	r3, #4
70000954:	5ac1      	ldrh	r1, [r0, r3]
		((uint16_t *)cmem)[f] = val;
70000956:	f820 100c 	strh.w	r1, [r0, ip]
7000095a:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
7000095e:	80e2      	strh	r2, [r4, #6]
70000960:	f8a1 e006 	strh.w	lr, [r1, #6]
70000964:	f820 e003 	strh.w	lr, [r0, r3]
70000968:	bd30      	pop	{r4, r5, pc}
7000096a:	bf00      	nop

7000096c <sys_heap_init>:
		__ASSERT(bytes / CHUNK_UNIT <= 0x7fffffffU, "heap size is too big");
	}

	/* Reserve the end marker chunk's header */
	__ASSERT(bytes > heap_footer_bytes(bytes), "heap size is too small");
	bytes -= heap_footer_bytes(bytes);
7000096c:	3a04      	subs	r2, #4
{
7000096e:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}

	/* Round the start up, the end down */
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
70000972:	188d      	adds	r5, r1, r2
	uintptr_t addr = ROUND_UP(mem, CHUNK_UNIT);
70000974:	1dcc      	adds	r4, r1, #7
70000976:	f024 0407 	bic.w	r4, r4, #7
	__ASSERT(heap_sz > chunksz(sizeof(struct z_heap)), "heap size is too small");

	struct z_heap *h = (struct z_heap *)addr;
	heap->heap = h;
	h->end_chunk = heap_sz;
	h->avail_buckets = 0;
7000097a:	f04f 0800 	mov.w	r8, #0
	uintptr_t end = ROUND_DOWN((uint8_t *)mem + bytes, CHUNK_UNIT);
7000097e:	f025 0507 	bic.w	r5, r5, #7
	heap->heap = h;
70000982:	6004      	str	r4, [r0, #0]
	chunksz_t heap_sz = (end - addr) / CHUNK_UNIT;
70000984:	1b2d      	subs	r5, r5, r4
				     nb_buckets * sizeof(struct z_heap_bucket));

	__ASSERT(chunk0_size + min_chunk_size(h) <= heap_sz, "heap size is too small");

	for (int i = 0; i < nb_buckets; i++) {
		h->buckets[i].next = 0;
70000986:	4641      	mov	r1, r8
70000988:	f104 0010 	add.w	r0, r4, #16
	chunksz_t heap_sz = (end - addr) / CHUNK_UNIT;
7000098c:	08ef      	lsrs	r7, r5, #3
	return 31 - __builtin_clz(usable_sz);
7000098e:	fab7 f287 	clz	r2, r7
	h->avail_buckets = 0;
70000992:	e9c4 7802 	strd	r7, r8, [r4, #8]
	chunksz_t chunk0_size = chunksz(sizeof(struct z_heap) +
70000996:	f1c2 0624 	rsb	r6, r2, #36	; 0x24
	int nb_buckets = bucket_idx(h, heap_sz) + 1;
7000099a:	f1c2 0220 	rsb	r2, r2, #32
	chunksz_t chunk0_size = chunksz(sizeof(struct z_heap) +
7000099e:	00b6      	lsls	r6, r6, #2
	return (bytes + CHUNK_UNIT - 1U) / CHUNK_UNIT;
700009a0:	3607      	adds	r6, #7
		h->buckets[i].next = 0;
700009a2:	0092      	lsls	r2, r2, #2
700009a4:	08f6      	lsrs	r6, r6, #3
700009a6:	f002 fad5 	bl	70002f54 <memset>
		((uint16_t *)cmem)[f] = val;
700009aa:	f8a4 8000 	strh.w	r8, [r4]
	set_chunk_size(h, 0, chunk0_size);
	set_left_chunk_size(h, 0, 0);
	set_chunk_used(h, 0, true);

	/* chunk containing the free heap */
	set_chunk_size(h, chunk0_size, heap_sz - chunk0_size);
700009ae:	1bbb      	subs	r3, r7, r6
	/* the end marker chunk */
	set_chunk_size(h, heap_sz, 0);
	set_left_chunk_size(h, heap_sz, heap_sz - chunk0_size);
	set_chunk_used(h, heap_sz, true);

	free_list_add(h, chunk0_size);
700009b0:	4620      	mov	r0, r4
	chunk_set(h, c, SIZE_AND_USED, size << 1);
700009b2:	0072      	lsls	r2, r6, #1
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
700009b4:	f042 0201 	orr.w	r2, r2, #1
	chunk_set(h, c, SIZE_AND_USED, size << 1);
700009b8:	0059      	lsls	r1, r3, #1
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
700009ba:	8062      	strh	r2, [r4, #2]
		((uint16_t *)cmem)[f] = val;
700009bc:	eb04 02c6 	add.w	r2, r4, r6, lsl #3
700009c0:	8051      	strh	r1, [r2, #2]
700009c2:	1962      	adds	r2, r4, r5
700009c4:	f824 6036 	strh.w	r6, [r4, r6, lsl #3]
700009c8:	4631      	mov	r1, r6
700009ca:	5363      	strh	r3, [r4, r5]
			((uint16_t *)cmem)[SIZE_AND_USED] |= 1U;
700009cc:	2301      	movs	r3, #1
700009ce:	8053      	strh	r3, [r2, #2]
}
700009d0:	e8bd 41f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
	free_list_add(h, chunk0_size);
700009d4:	f7ff bf9c 	b.w	70000910 <free_list_add>

700009d8 <arch_printk_char_out>:
{
	ARG_UNUSED(c);

	/* do nothing */
	return 0;
}
700009d8:	2000      	movs	r0, #0
700009da:	4770      	bx	lr

700009dc <char_out>:
}

static int char_out(int c, void *ctx_p)
{
	ARG_UNUSED(ctx_p);
	return _char_out(c);
700009dc:	f24c 2378 	movw	r3, #49784	; 0xc278
700009e0:	f2c7 0300 	movt	r3, #28672	; 0x7000
700009e4:	681b      	ldr	r3, [r3, #0]
700009e6:	4718      	bx	r3

700009e8 <__printk_hook_install>:
	_char_out = fn;
700009e8:	f24c 2378 	movw	r3, #49784	; 0xc278
700009ec:	f2c7 0300 	movt	r3, #28672	; 0x7000
700009f0:	6018      	str	r0, [r3, #0]
}
700009f2:	4770      	bx	lr

700009f4 <printk>:
 *
 * @param fmt formatted string to output
 */

void printk(const char *fmt, ...)
{
700009f4:	b40f      	push	{r0, r1, r2, r3}
700009f6:	b500      	push	{lr}
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
700009f8:	f640 10dd 	movw	r0, #2525	; 0x9dd
{
700009fc:	b087      	sub	sp, #28
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
700009fe:	2300      	movs	r3, #0
{
70000a00:	aa08      	add	r2, sp, #32
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000a02:	f04f 0c02 	mov.w	ip, #2
70000a06:	f2c7 0000 	movt	r0, #28672	; 0x7000
70000a0a:	e9cd 3304 	strd	r3, r3, [sp, #16]
70000a0e:	e9cd 3002 	strd	r3, r0, [sp, #8]
		(void) vfprintf(&console, fmt, ap);
70000a12:	a802      	add	r0, sp, #8
{
70000a14:	f852 1b04 	ldr.w	r1, [r2], #4
		FILE console = FDEV_SETUP_STREAM((int(*)(char, FILE *))char_out,
70000a18:	f88d c00a 	strb.w	ip, [sp, #10]
	va_list ap;

	va_start(ap, fmt);
70000a1c:	9201      	str	r2, [sp, #4]
		(void) vfprintf(&console, fmt, ap);
70000a1e:	f002 fc71 	bl	70003304 <__l_vfprintf>

	vprintk(fmt, ap);

	va_end(ap);
}
70000a22:	b007      	add	sp, #28
70000a24:	f85d eb04 	ldr.w	lr, [sp], #4
70000a28:	b004      	add	sp, #16
70000a2a:	4770      	bx	lr

70000a2c <z_thread_entry>:
 * This routine does not return, and is marked as such so the compiler won't
 * generate preamble code that is only used by functions that actually return.
 */
FUNC_NORETURN void z_thread_entry(k_thread_entry_t entry,
				 void *p1, void *p2, void *p3)
{
70000a2c:	468c      	mov	ip, r1
70000a2e:	4604      	mov	r4, r0
70000a30:	4611      	mov	r1, r2

	sys_rand_get((uint8_t *)&stack_guard, sizeof(stack_guard));
	__stack_chk_guard = stack_guard;
	__stack_chk_guard <<= 8;
#endif	/* CONFIG_STACK_CANARIES */
	entry(p1, p2, p3);
70000a32:	4660      	mov	r0, ip
70000a34:	461a      	mov	r2, r3
{
70000a36:	b508      	push	{r3, lr}
	entry(p1, p2, p3);
70000a38:	47a0      	blx	r4
	return z_impl_k_sched_current_thread_query();
70000a3a:	f001 fe73 	bl	70002724 <z_impl_k_sched_current_thread_query>
	z_impl_k_thread_abort(thread);
70000a3e:	f001 fe77 	bl	70002730 <z_impl_k_thread_abort>
70000a42:	bf00      	nop

70000a44 <_ConfigAbsSyms>:
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_WARN_DEPRECATED, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_ENFORCE_ZEPHYR_STDINT, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_LEGACY_GENERATED_INCLUDE_PATH, 1);
GEN_ABSOLUTE_SYM_KCONFIG(CONFIG_BENCHMARK_NUM_ITERATIONS, 1000);

GEN_ABS_SYM_END
70000a44:	4770      	bx	lr
70000a46:	bf00      	nop

70000a48 <z_soc_irq_get_active>:

#include "soc.h"

unsigned int z_soc_irq_get_active(void)
{
	return z_vim_irq_get_active();
70000a48:	f000 bb4c 	b.w	700010e4 <z_vim_irq_get_active>

70000a4c <z_soc_irq_eoi>:
}

void z_soc_irq_eoi(unsigned int irq)
{
	z_vim_irq_eoi(irq);
70000a4c:	f000 bb70 	b.w	70001130 <z_vim_irq_eoi>

70000a50 <z_soc_irq_init>:
}

void z_soc_irq_init(void)
{
	z_vim_irq_init();
70000a50:	f000 bb76 	b.w	70001140 <z_vim_irq_init>

70000a54 <z_soc_irq_priority_set>:
}

void z_soc_irq_priority_set(unsigned int irq, unsigned int prio, uint32_t flags)
{
	/* Configure interrupt type and priority */
	z_vim_irq_priority_set(irq, prio, flags);
70000a54:	f000 bbac 	b.w	700011b0 <z_vim_irq_priority_set>

70000a58 <z_soc_irq_enable>:
}

void z_soc_irq_enable(unsigned int irq)
{
	/* Enable interrupt */
	z_vim_irq_enable(irq);
70000a58:	f000 bbd6 	b.w	70001208 <z_vim_irq_enable>

70000a5c <soc_reset_hook>:
	/* Check if interrupt is enabled */
	return z_vim_irq_is_enabled(irq);
}

void soc_reset_hook(void)
{
70000a5c:	b508      	push	{r3, lr}
 *
 */
static ALWAYS_INLINE void sys_cache_instr_enable(void)
{
#if defined(CONFIG_CACHE_MANAGEMENT) && defined(CONFIG_ICACHE)
	cache_instr_enable();
70000a5e:	f000 fa35 	bl	70000ecc <arch_icache_enable>
	/*
	 * Enable the caches only if configured to do so.
	 */
	sys_cache_instr_enable();
	sys_cache_data_enable();
70000a62:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	cache_data_enable();
70000a66:	f000 ba23 	b.w	70000eb0 <arch_dcache_enable>
70000a6a:	bf00      	nop

70000a6c <z_arm_fatal_error>:

		LOG_ERR("Unhandled IRQn: %d", irqn);
	}
#endif

	z_fatal_error(reason, esf);
70000a6c:	f001 b818 	b.w	70001aa0 <z_fatal_error>

70000a70 <z_do_kernel_oops>:
 * @param esf exception frame
 * @param callee_regs Callee-saved registers (R4-R11)
 * @param exc_return EXC_RETURN value present in LR after exception entry.
 */
void z_do_kernel_oops(const struct arch_esf *esf, _callee_saved_t *callee_regs, uint32_t exc_return)
{
70000a70:	4601      	mov	r1, r0
	z_fatal_error(reason, esf);
70000a72:	6800      	ldr	r0, [r0, #0]
70000a74:	f001 b814 	b.w	70001aa0 <z_fatal_error>

70000a78 <z_arm_nmi>:
 * Simply call what is installed in 'static void(*handler)(void)'.
 *
 */

void z_arm_nmi(void)
{
70000a78:	b508      	push	{r3, lr}
	handler();
70000a7a:	f24c 23d8 	movw	r3, #49880	; 0xc2d8
70000a7e:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000a82:	681b      	ldr	r3, [r3, #0]
70000a84:	4798      	blx	r3
	z_arm_int_exit();
}
70000a86:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
	z_arm_int_exit();
70000a8a:	f002 bfd9 	b.w	70003a40 <__z_arm_int_exit_from_thumb>
70000a8e:	bf00      	nop

70000a90 <z_SysNmiOnReset>:
_ASM_FILE_PROLOGUE

GTEXT(z_SysNmiOnReset)

SECTION_FUNC(TEXT, z_SysNmiOnReset)
    wfi
70000a90:	e320f003 	wfi
    b z_SysNmiOnReset
70000a94:	eafffffd 	b	70000a90 <z_SysNmiOnReset>

70000a98 <z_arm_undef_instruction>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_undef_instruction)
	/*
	 * The undefined instruction address is offset by 2 if the previous
	 * mode is Thumb; otherwise, it is offset by 4.
	 */
	push {r0}
70000a98:	e52d0004 	push	{r0}		; (str r0, [sp, #-4]!)
	mrs r0, spsr
70000a9c:	e14f0000 	mrs	r0, SPSR
	tst r0, #T_BIT
70000aa0:	e3100020 	tst	r0, #32
	subeq lr, #4	/* ARM   (!T_BIT) */
70000aa4:	024ee004 	subeq	lr, lr, #4
	subne lr, #2	/* Thumb (T_BIT) */
70000aa8:	124ee002 	subne	lr, lr, #2
	pop {r0}
70000aac:	e49d0004 	pop	{r0}		; (ldr r0, [sp], #4)

	/*
	 * Store r0-r3, r12, lr, lr_und and spsr_und into the stack to
	 * construct an exception stack frame.
	 */
	srsdb sp!, #MODE_UND
70000ab0:	f96d051b 	srsdb	sp!, #27
	stmfd sp, {r0-r3, r12, lr}^
70000ab4:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
	sub sp, #24
70000ab8:	e24dd018 	sub	sp, sp, #24

	/* Increment exception nesting count */
	get_cpu r2
70000abc:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000ac0:	e3c22003 	bic	r2, r2, #3
	ldr r1, [r2, #___cpu_t_nested_OFFSET]
70000ac4:	e5921000 	ldr	r1, [r2]
	add r1, r1, #1
70000ac8:	e2811001 	add	r1, r1, #1
	str r1, [r2, #___cpu_t_nested_OFFSET]
70000acc:	e5821000 	str	r1, [r2]
	cps #MODE_UND

	mov r0, sp
	mov sp, r1
#else
	mov r0, sp
70000ad0:	e1a0000d 	mov	r0, sp
#endif

	bl z_arm_fault_undef_instruction
70000ad4:	fa00001b 	blx	70000b48 <z_arm_fault_undef_instruction>
	exception_exit

	b z_arm_exc_exit
70000ad8:	ea000153 	b	7000102c <z_arm_exc_exit>

70000adc <z_arm_prefetch_abort>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_prefetch_abort)
	/*
	 * The faulting instruction address is always offset by 4 for the
	 * prefetch abort exceptions.
	 */
	sub lr, #4
70000adc:	e24ee004 	sub	lr, lr, #4

	exception_entry MODE_ABT
70000ae0:	f96d0517 	srsdb	sp!, #23
70000ae4:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
70000ae8:	e24dd018 	sub	sp, sp, #24
70000aec:	e1a0000d 	mov	r0, sp
70000af0:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000af4:	e3c22003 	bic	r2, r2, #3
70000af8:	e5921000 	ldr	r1, [r2]
70000afc:	e2811001 	add	r1, r1, #1
70000b00:	e5821000 	str	r1, [r2]
	bl z_arm_fault_prefetch
70000b04:	fa000013 	blx	70000b58 <z_arm_fault_prefetch>
	exception_exit

	b z_arm_exc_exit
70000b08:	ea000147 	b	7000102c <z_arm_exc_exit>

70000b0c <z_arm_data_abort>:
SECTION_SUBSEC_FUNC(TEXT, __exc, z_arm_data_abort)
	/*
	 * The faulting instruction address is always offset by 8 for the data
	 * abort exceptions.
	 */
	sub lr, #8
70000b0c:	e24ee008 	sub	lr, lr, #8

	exception_entry MODE_ABT
70000b10:	f96d0517 	srsdb	sp!, #23
70000b14:	e94d500f 	stmdb	sp, {r0, r1, r2, r3, ip, lr}^
70000b18:	e24dd018 	sub	sp, sp, #24
70000b1c:	e1a0000d 	mov	r0, sp
70000b20:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000b24:	e3c22003 	bic	r2, r2, #3
70000b28:	e5921000 	ldr	r1, [r2]
70000b2c:	e2811001 	add	r1, r1, #1
70000b30:	e5821000 	str	r1, [r2]
	bl z_arm_fault_data
70000b34:	fa00002c 	blx	70000bec <z_arm_fault_data>
	/*
	 * If z_arm_fault_data returns false, then we recovered from
	 * the error.  It may have updated $pc, so copy $pc back to
	 * the true esf from the one passed to z_arm_fault_data.
	 */
	cmp r0, #0
70000b38:	e3500000 	cmp	r0, #0
	ldreq r1, [sp, #24 + FPU_SF_SIZE]
70000b3c:	059d1018 	ldreq	r1, [sp, #24]

	exception_exit

	streq r1, [sp, #24 + FPU_SF_SIZE]
70000b40:	058d1018 	streq	r1, [sp, #24]

	b z_arm_exc_exit
70000b44:	ea000138 	b	7000102c <z_arm_exc_exit>

70000b48 <z_arm_fault_undef_instruction>:
 * @brief Undefined instruction fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_undef_instruction(struct arch_esf *esf)
{
70000b48:	4601      	mov	r1, r0
	uint32_t reason = IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) ?
			  K_ERR_CPU_EXCEPTION :
			  K_ERR_ARM_UNDEFINED_INSTRUCTION;

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70000b4a:	202d      	movs	r0, #45	; 0x2d
{
70000b4c:	b508      	push	{r3, lr}
	z_arm_fatal_error(reason, esf);
70000b4e:	f7ff ff8d 	bl	70000a6c <z_arm_fatal_error>

	/* All undefined instructions are treated as fatal for now */
	return true;
}
70000b52:	2001      	movs	r0, #1
70000b54:	bd08      	pop	{r3, pc}
70000b56:	bf00      	nop

70000b58 <z_arm_fault_prefetch>:
 * @brief Prefetch abort fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_prefetch(struct arch_esf *esf)
{
70000b58:	4601      	mov	r1, r0
70000b5a:	b508      	push	{r3, lr}
    \return               Instruction Fault Status Register value
 */
__STATIC_FORCEINLINE uint32_t __get_IFSR(void)
{
  uint32_t result;
  __get_CP(15, 0, result, 5, 0, 1);
70000b5c:	ee15 2f30 	mrc	15, 0, r2, cr5, cr0, {1}
	__get_CP(15, 0, result, 6, 0, 2);
70000b60:	ee16 3f50 	mrc	15, 0, r3, cr6, cr0, {2}
	/* Read and parse Instruction Fault Status Register (IFSR) */
	uint32_t ifsr = __get_IFSR();
#if defined(CONFIG_AARCH32_ARMV8_R)
	uint32_t fs = ifsr & IFSR_STATUS_Msk;
#else
	uint32_t fs = ((ifsr & IFSR_FS1_Msk) >> 6) | (ifsr & IFSR_FS0_Msk);
70000b64:	0993      	lsrs	r3, r2, #6
70000b66:	f003 0310 	and.w	r3, r3, #16
70000b6a:	f002 020f 	and.w	r2, r2, #15
70000b6e:	4313      	orrs	r3, r2
	switch (status) {
70000b70:	2b19      	cmp	r3, #25
70000b72:	d80e      	bhi.n	70000b92 <z_arm_fault_prefetch+0x3a>
70000b74:	e8df f003 	tbb	[pc, r3]
70000b78:	0d1c3717 	.word	0x0d1c3717
70000b7c:	0d0d0d0d 	.word	0x0d0d0d0d
70000b80:	0d0d0d23 	.word	0x0d0d0d23
70000b84:	0d0d280d 	.word	0x0d0d280d
70000b88:	0d0d0d0d 	.word	0x0d0d0d0d
70000b8c:	0d2d0d0d 	.word	0x0d2d0d0d
70000b90:	1232      	.short	0x1232
	uint32_t reason = K_ERR_CPU_EXCEPTION;
70000b92:	2000      	movs	r0, #0
	if (IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) && (reason >= K_ERR_ARCH_START)) {
		reason = K_ERR_CPU_EXCEPTION;
	}

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70000b94:	f7ff ff6a 	bl	70000a6c <z_arm_fatal_error>

	/* All prefetch aborts are treated as fatal for now */
	return true;
}
70000b98:	2001      	movs	r0, #1
70000b9a:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_PARITY_ERROR;
70000b9c:	2033      	movs	r0, #51	; 0x33
	z_arm_fatal_error(reason, esf);
70000b9e:	f7ff ff65 	bl	70000a6c <z_arm_fatal_error>
}
70000ba2:	2001      	movs	r0, #1
70000ba4:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_BACKGROUND_FAULT;
70000ba6:	202f      	movs	r0, #47	; 0x2f
	z_arm_fatal_error(reason, esf);
70000ba8:	f7ff ff60 	bl	70000a6c <z_arm_fatal_error>
}
70000bac:	2001      	movs	r0, #1
70000bae:	bd08      	pop	{r3, pc}
	__get_CP(14, 0, result, 0, 1, 0);
70000bb0:	ee10 3e11 	mrc	14, 0, r3, cr0, cr1, {0}
		reason = K_ERR_ARM_DEBUG_EVENT;
70000bb4:	2035      	movs	r0, #53	; 0x35
	z_arm_fatal_error(reason, esf);
70000bb6:	f7ff ff59 	bl	70000a6c <z_arm_fatal_error>
}
70000bba:	2001      	movs	r0, #1
70000bbc:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_EXTERNAL_ABORT;
70000bbe:	2031      	movs	r0, #49	; 0x31
	z_arm_fatal_error(reason, esf);
70000bc0:	f7ff ff54 	bl	70000a6c <z_arm_fatal_error>
}
70000bc4:	2001      	movs	r0, #1
70000bc6:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_PERMISSION_FAULT;
70000bc8:	2030      	movs	r0, #48	; 0x30
	z_arm_fatal_error(reason, esf);
70000bca:	f7ff ff4f 	bl	70000a6c <z_arm_fatal_error>
}
70000bce:	2001      	movs	r0, #1
70000bd0:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_EXTERNAL_ABORT;
70000bd2:	2032      	movs	r0, #50	; 0x32
	z_arm_fatal_error(reason, esf);
70000bd4:	f7ff ff4a 	bl	70000a6c <z_arm_fatal_error>
}
70000bd8:	2001      	movs	r0, #1
70000bda:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_PARITY_ERROR;
70000bdc:	2034      	movs	r0, #52	; 0x34
	z_arm_fatal_error(reason, esf);
70000bde:	f7ff ff45 	bl	70000a6c <z_arm_fatal_error>
}
70000be2:	2001      	movs	r0, #1
70000be4:	bd08      	pop	{r3, pc}
	switch (status) {
70000be6:	202e      	movs	r0, #46	; 0x2e
70000be8:	e7d4      	b.n	70000b94 <z_arm_fault_prefetch+0x3c>
70000bea:	bf00      	nop

70000bec <z_arm_fault_data>:
 * @brief Data abort fault handler
 *
 * @return Returns true if the fault is fatal
 */
bool z_arm_fault_data(struct arch_esf *esf)
{
70000bec:	4601      	mov	r1, r0
70000bee:	b508      	push	{r3, lr}
  __get_CP(15, 0, result, 5, 0, 0);
70000bf0:	ee15 2f10 	mrc	15, 0, r2, cr5, cr0, {0}
	__get_CP(15, 0, result, 6, 0, 0);
70000bf4:	ee16 3f10 	mrc	15, 0, r3, cr6, cr0, {0}
	/* Read and parse Data Fault Status Register (DFSR) */
	uint32_t dfsr = __get_DFSR();
#if defined(CONFIG_AARCH32_ARMV8_R)
	uint32_t fs = dfsr & DFSR_STATUS_Msk;
#else
	uint32_t fs = ((dfsr & DFSR_FS1_Msk) >> 6) | (dfsr & DFSR_FS0_Msk);
70000bf8:	0993      	lsrs	r3, r2, #6
70000bfa:	f003 0310 	and.w	r3, r3, #16
70000bfe:	f002 020f 	and.w	r2, r2, #15
70000c02:	4313      	orrs	r3, r2
	switch (status) {
70000c04:	2b19      	cmp	r3, #25
70000c06:	d80e      	bhi.n	70000c26 <z_arm_fault_data+0x3a>
70000c08:	e8df f003 	tbb	[pc, r3]
70000c0c:	0d1c3717 	.word	0x0d1c3717
70000c10:	0d0d0d0d 	.word	0x0d0d0d0d
70000c14:	0d0d0d23 	.word	0x0d0d0d23
70000c18:	0d0d280d 	.word	0x0d0d280d
70000c1c:	0d0d0d0d 	.word	0x0d0d0d0d
70000c20:	0d2d0d0d 	.word	0x0d2d0d0d
70000c24:	1232      	.short	0x1232
	uint32_t reason = K_ERR_CPU_EXCEPTION;
70000c26:	2000      	movs	r0, #0
	if (IS_ENABLED(CONFIG_SIMPLIFIED_EXCEPTION_CODES) && (reason >= K_ERR_ARCH_START)) {
		reason = K_ERR_CPU_EXCEPTION;
	}

	/* Invoke kernel fatal exception handler */
	z_arm_fatal_error(reason, esf);
70000c28:	f7ff ff20 	bl	70000a6c <z_arm_fatal_error>

	/* All data aborts are treated as fatal for now */
	return true;
}
70000c2c:	2001      	movs	r0, #1
70000c2e:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_PARITY_ERROR;
70000c30:	2033      	movs	r0, #51	; 0x33
	z_arm_fatal_error(reason, esf);
70000c32:	f7ff ff1b 	bl	70000a6c <z_arm_fatal_error>
}
70000c36:	2001      	movs	r0, #1
70000c38:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_BACKGROUND_FAULT;
70000c3a:	202f      	movs	r0, #47	; 0x2f
	z_arm_fatal_error(reason, esf);
70000c3c:	f7ff ff16 	bl	70000a6c <z_arm_fatal_error>
}
70000c40:	2001      	movs	r0, #1
70000c42:	bd08      	pop	{r3, pc}
	__get_CP(14, 0, result, 0, 1, 0);
70000c44:	ee10 3e11 	mrc	14, 0, r3, cr0, cr1, {0}
		reason = K_ERR_ARM_DEBUG_EVENT;
70000c48:	2035      	movs	r0, #53	; 0x35
	z_arm_fatal_error(reason, esf);
70000c4a:	f7ff ff0f 	bl	70000a6c <z_arm_fatal_error>
}
70000c4e:	2001      	movs	r0, #1
70000c50:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_SYNC_EXTERNAL_ABORT;
70000c52:	2031      	movs	r0, #49	; 0x31
	z_arm_fatal_error(reason, esf);
70000c54:	f7ff ff0a 	bl	70000a6c <z_arm_fatal_error>
}
70000c58:	2001      	movs	r0, #1
70000c5a:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_PERMISSION_FAULT;
70000c5c:	2030      	movs	r0, #48	; 0x30
	z_arm_fatal_error(reason, esf);
70000c5e:	f7ff ff05 	bl	70000a6c <z_arm_fatal_error>
}
70000c62:	2001      	movs	r0, #1
70000c64:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_EXTERNAL_ABORT;
70000c66:	2032      	movs	r0, #50	; 0x32
	z_arm_fatal_error(reason, esf);
70000c68:	f7ff ff00 	bl	70000a6c <z_arm_fatal_error>
}
70000c6c:	2001      	movs	r0, #1
70000c6e:	bd08      	pop	{r3, pc}
		reason = K_ERR_ARM_ASYNC_PARITY_ERROR;
70000c70:	2034      	movs	r0, #52	; 0x34
	z_arm_fatal_error(reason, esf);
70000c72:	f7ff fefb 	bl	70000a6c <z_arm_fatal_error>
}
70000c76:	2001      	movs	r0, #1
70000c78:	bd08      	pop	{r3, pc}
	switch (status) {
70000c7a:	202e      	movs	r0, #46	; 0x2e
70000c7c:	e7d4      	b.n	70000c28 <z_arm_fault_data+0x3c>
70000c7e:	bf00      	nop

70000c80 <z_arm_interrupt_init>:
	/*
	 * Initialise interrupt controller.
	 */
#ifdef CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER
	/* Invoke SoC-specific interrupt controller initialisation */
	z_soc_irq_init();
70000c80:	f7ff bee6 	b.w	70000a50 <z_soc_irq_init>

70000c84 <relocate_vector_table>:
		write_sysreg64(val, op1, CRm);				\
	}

MAKE_REG_HELPER(mpuir,	     0, 0, 0, 4);
MAKE_REG_HELPER(mpidr,	     0, 0, 0, 5);
MAKE_REG_HELPER(sctlr,	     0, 1, 0, 0);
70000c84:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}

void __weak relocate_vector_table(void)
{
#if defined(CONFIG_XIP) && (CONFIG_FLASH_BASE_ADDRESS != 0) ||                                     \
	!defined(CONFIG_XIP) && (CONFIG_SRAM_BASE_ADDRESS != 0)
	write_sctlr(read_sctlr() & ~HIVECS);
70000c88:	f423 5300 	bic.w	r3, r3, #8192	; 0x2000
70000c8c:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
	size_t vector_size = (size_t)_vector_end - (size_t)_vector_start;
70000c90:	f240 023c 	movw	r2, #60	; 0x3c
70000c94:	f240 0100 	movw	r1, #0
70000c98:	f2c7 0100 	movt	r1, #28672	; 0x7000
	(void)memcpy(VECTOR_ADDRESS, _vector_start, vector_size);
70000c9c:	2000      	movs	r0, #0
	size_t vector_size = (size_t)_vector_end - (size_t)_vector_start;
70000c9e:	f2c7 0200 	movt	r2, #28672	; 0x7000
	(void)memcpy(VECTOR_ADDRESS, _vector_start, vector_size);
70000ca2:	1a52      	subs	r2, r2, r1
70000ca4:	f002 b8ee 	b.w	70002e84 <memcpy>

70000ca8 <z_arm_relocate_vector_table>:
#endif

#endif /* !CONFIG_AARCH32_ARMV8_R */

void z_arm_relocate_vector_table(void)
{
70000ca8:	b508      	push	{r3, lr}
	relocate_vector_table();
70000caa:	f7ff ffeb 	bl	70000c84 <relocate_vector_table>
}
70000cae:	bd08      	pop	{r3, pc}

70000cb0 <__start>:
    ldr r0, =IMP_CSCTLR(CONFIG_CPU_CORTEX_R52_ICACHE_FLASH_WAY,
                        CONFIG_CPU_CORTEX_R52_DCACHE_FLASH_WAY)
    mcr p15, 1, r0, c9, c1, 0
#endif

    ldr r0, =arm_cpu_boot_params
70000cb0:	e59f0054 	ldr	r0, [pc, #84]	; 70000d0c <__start+0x5c>
    b 2f

_primary_core:
#endif

    ldr r4, =z_prep_c
70000cb4:	e59f4054 	ldr	r4, [pc, #84]	; 70000d10 <__start+0x60>
    ldr r5, =(z_arm_fiq_stack + CONFIG_ARMV7_FIQ_STACK_SIZE)
70000cb8:	e59f5054 	ldr	r5, [pc, #84]	; 70000d14 <__start+0x64>
    ldr r6, =(z_interrupt_stacks + CONFIG_ISR_STACK_SIZE)
70000cbc:	e59f6054 	ldr	r6, [pc, #84]	; 70000d18 <__start+0x68>
    ldr r7, =(z_arm_abort_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000cc0:	e59f7054 	ldr	r7, [pc, #84]	; 70000d1c <__start+0x6c>
    ldr r8, =(z_arm_undef_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000cc4:	e59f8054 	ldr	r8, [pc, #84]	; 70000d20 <__start+0x70>
    ldr r9, =(z_arm_svc_stack + CONFIG_ARMV7_SVC_STACK_SIZE)
70000cc8:	e59f9054 	ldr	r9, [pc, #84]	; 70000d24 <__start+0x74>
    ldr r10, =(z_arm_sys_stack + CONFIG_ARMV7_SYS_STACK_SIZE)
70000ccc:	e59fa054 	ldr	sl, [pc, #84]	; 70000d28 <__start+0x78>
    /*
     * Configure stack.
     */

    /* FIQ mode stack */
    msr CPSR_c, #(MODE_FIQ | I_BIT | F_BIT)
70000cd0:	e321f0d1 	msr	CPSR_c, #209	; 0xd1
    mov sp, r5
70000cd4:	e1a0d005 	mov	sp, r5

    /* IRQ mode stack */
    msr CPSR_c, #(MODE_IRQ | I_BIT | F_BIT)
70000cd8:	e321f0d2 	msr	CPSR_c, #210	; 0xd2
    mov sp, r6
70000cdc:	e1a0d006 	mov	sp, r6

    /* ABT mode stack */
    msr CPSR_c, #(MODE_ABT | I_BIT | F_BIT)
70000ce0:	e321f0d7 	msr	CPSR_c, #215	; 0xd7
    mov sp, r7
70000ce4:	e1a0d007 	mov	sp, r7

    /* UND mode stack */
    msr CPSR_c, #(MODE_UND | I_BIT | F_BIT)
70000ce8:	e321f0db 	msr	CPSR_c, #219	; 0xdb
    mov sp, r8
70000cec:	e1a0d008 	mov	sp, r8

    /* SVC mode stack */
    msr CPSR_c, #(MODE_SVC | I_BIT | F_BIT)
70000cf0:	e321f0d3 	msr	CPSR_c, #211	; 0xd3
    mov sp, r9
70000cf4:	e1a0d009 	mov	sp, r9

    /* SYS mode stack */
    msr CPSR_c, #(MODE_SYS | I_BIT | F_BIT)
70000cf8:	e321f0df 	msr	CPSR_c, #223	; 0xdf
    mov sp, r10
70000cfc:	e1a0d00a 	mov	sp, sl

#if defined(CONFIG_SOC_RESET_HOOK)
    /* Execute platform-specific initialisation if applicable */
    bl soc_reset_hook
70000d00:	faffff55 	blx	70000a5c <soc_reset_hook>

#if defined(CONFIG_DISABLE_TCM_ECC)
    bl z_arm_tcm_disable_ecc
#endif

    bl z_arm_relocate_vector_table
70000d04:	faffffe7 	blx	70000ca8 <z_arm_relocate_vector_table>

    bx r4
70000d08:	e12fff14 	bx	r4
    ldr r0, =arm_cpu_boot_params
70000d0c:	7000c2dc 	.word	0x7000c2dc
    ldr r4, =z_prep_c
70000d10:	70000d35 	.word	0x70000d35
    ldr r5, =(z_arm_fiq_stack + CONFIG_ARMV7_FIQ_STACK_SIZE)
70000d14:	7000b160 	.word	0x7000b160
    ldr r6, =(z_interrupt_stacks + CONFIG_ISR_STACK_SIZE)
70000d18:	7000b960 	.word	0x7000b960
    ldr r7, =(z_arm_abort_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000d1c:	7000b060 	.word	0x7000b060
    ldr r8, =(z_arm_undef_stack + CONFIG_ARMV7_EXCEPTION_STACK_SIZE)
70000d20:	7000af60 	.word	0x7000af60
    ldr r9, =(z_arm_svc_stack + CONFIG_ARMV7_SVC_STACK_SIZE)
70000d24:	7000ae60 	.word	0x7000ae60
    ldr r10, =(z_arm_sys_stack + CONFIG_ARMV7_SYS_STACK_SIZE)
70000d28:	7000ac60 	.word	0x7000ac60

70000d2c <z_irq_spurious>:
 */
void z_irq_spurious(const void *unused)
{
	ARG_UNUSED(unused);

	z_arm_fatal_error(K_ERR_SPURIOUS_IRQ, NULL);
70000d2c:	2100      	movs	r1, #0
70000d2e:	2001      	movs	r0, #1
70000d30:	f7ff be9c 	b.w	70000a6c <z_arm_fatal_error>

70000d34 <z_prep_c>:
 *
 * This routine prepares for the execution of and runs C code.
 *
 */
void z_prep_c(void)
{
70000d34:	b508      	push	{r3, lr}
MAKE_REG_HELPER(prlar,	     0, 6, 3, 1);
MAKE_REG_HELPER(mair0,       0, 10, 2, 0);
MAKE_REG_HELPER(vbar,        0, 12, 0, 0);
MAKE_REG_HELPER(cntv_ctl,    0, 14,  3, 1);
MAKE_REG_HELPER(ctr,         0, 0, 0, 1);
MAKE_REG_HELPER(tpidruro,    0, 13, 0, 3);
70000d36:	f647 6338 	movw	r3, #32312	; 0x7e38
70000d3a:	f2c7 0300 	movt	r3, #28672	; 0x7000
70000d3e:	ee0d 3f70 	mcr	15, 0, r3, cr13, cr0, {3}
	write_tpidruro((uintptr_t)&_kernel.cpus[0]);

#if defined(CONFIG_CPU_HAS_FPU)
	z_arm_floating_point_init();
#endif
	z_bss_zero();
70000d42:	f000 ff5f 	bl	70001c04 <z_bss_zero>
	z_data_copy();
#if ((defined(CONFIG_ARMV7_R) || defined(CONFIG_ARMV7_A)) && defined(CONFIG_INIT_STACKS))
	z_arm_init_stacks();
#endif
	z_arm_interrupt_init();
70000d46:	f7ff ff9b 	bl	70000c80 <z_arm_interrupt_init>
#if CONFIG_ARCH_CACHE
	arch_cache_init();
70000d4a:	f000 f8cf 	bl	70000eec <arch_cache_init>
	z_arm_mpu_init();
	z_arm_configure_static_mpu_regions();
#elif defined(CONFIG_ARM_AARCH32_MMU)
	z_arm_mmu_init();
#endif
	z_cstart();
70000d4e:	f000 ff67 	bl	70001c20 <z_cstart>
70000d52:	bf00      	nop

70000d54 <arch_new_thread>:
 * of the ESF.
 */
void arch_new_thread(struct k_thread *thread, k_thread_stack_t *stack,
		     char *stack_ptr, k_thread_entry_t entry,
		     void *p1, void *p2, void *p3)
{
70000d54:	b430      	push	{r4, r5}
	}
#else
	iframe->pc = (uint32_t)z_thread_entry;
#endif

	iframe->a1 = (uint32_t)entry;
70000d56:	f842 3c20 	str.w	r3, [r2, #-32]
#if defined(CONFIG_BIG_ENDIAN)
	iframe->xpsr |= E_BIT;
#endif /* CONFIG_BIG_ENDIAN */

#if defined(CONFIG_COMPILER_ISA_THUMB2)
	iframe->xpsr |= T_BIT;
70000d5a:	f240 153f 	movw	r5, #319	; 0x13f
{
70000d5e:	9b02      	ldr	r3, [sp, #8]
	iframe = Z_STACK_PTR_TO_FRAME(struct __basic_sf, stack_ptr);
70000d60:	f1a2 0420 	sub.w	r4, r2, #32
	iframe->a2 = (uint32_t)p1;
70000d64:	f842 3c1c 	str.w	r3, [r2, #-28]
	iframe->pc = (uint32_t)z_thread_entry;
70000d68:	f640 232d 	movw	r3, #2605	; 0xa2d
		((uintptr_t)iframe - sizeof(struct __fpu_sf));
	memset(iframe, 0, sizeof(struct __fpu_sf));
#endif

	thread->callee_saved.psp = (uint32_t)iframe;
	thread->arch.basepri = 0;
70000d6c:	2100      	movs	r1, #0
	iframe->pc = (uint32_t)z_thread_entry;
70000d6e:	f2c7 0300 	movt	r3, #28672	; 0x7000
	iframe->xpsr |= T_BIT;
70000d72:	f842 5c04 	str.w	r5, [r2, #-4]
	iframe->pc = (uint32_t)z_thread_entry;
70000d76:	f842 3c08 	str.w	r3, [r2, #-8]
{
70000d7a:	9b03      	ldr	r3, [sp, #12]
	iframe->a3 = (uint32_t)p2;
70000d7c:	f842 3c18 	str.w	r3, [r2, #-24]
{
70000d80:	9b04      	ldr	r3, [sp, #16]
	iframe->a4 = (uint32_t)p3;
70000d82:	f842 3c14 	str.w	r3, [r2, #-20]
	thread->callee_saved.psp = (uint32_t)iframe;
70000d86:	6504      	str	r4, [r0, #80]	; 0x50
	thread->arch.basepri = 0;
70000d88:	66c1      	str	r1, [r0, #108]	; 0x6c
	thread->switch_handle = thread;
	/* thread birth happens through the exception return path */
	thread->arch.exception_depth = 1;
	thread->callee_saved.lr = (uint32_t)z_arm_cortex_ar_exit_exc;
#endif
}
70000d8a:	bc30      	pop	{r4, r5}
70000d8c:	4770      	bx	lr
70000d8e:	bf00      	nop

70000d90 <arch_cpu_idle>:

	/*
	 * Clear PRIMASK and flush instruction buffer to immediately service
	 * the wake-up interrupt.
	 */
	cpsie	i
70000d90:	f1080080 	cpsie	i
	isb
70000d94:	f57ff06f 	isb	sy

	bx	lr
70000d98:	e12fff1e 	bx	lr

70000d9c <_isr_wrapper>:
	 * Save away r0-r3, r12 and lr_irq for the previous context to the
	 * process stack since they are clobbered here.  Also, save away lr
	 * and spsr_irq since we may swap processes and return to a different
	 * thread.
	 */
	sub lr, lr, #4
70000d9c:	e24ee004 	sub	lr, lr, #4
	srsdb #MODE_SYS!
70000da0:	f96d051f 	srsdb	sp!, #31
	cps #MODE_SYS
70000da4:	f102001f 	cps	#31
	push {r0-r3, r12, lr}
70000da8:	e92d500f 	push	{r0, r1, r2, r3, ip, lr}
	 * threads have high stack usage.
	 *
	 * When userspace is enabled, this also prevents leaking privileged
	 * information to the user mode.
	 */
	cps #MODE_SVC
70000dac:	f1020013 	cps	#19
	/*
	 * Preserve lr_svc which may contain the branch return address of the
	 * interrupted context in case of a nested interrupt. This value will
	 * be restored prior to exiting the interrupt in z_arm_int_exit.
	 */
	push {lr}
70000db0:	e52de004 	push	{lr}		; (str lr, [sp, #-4]!)

	/* Align stack at double-word boundary */
	and r3, sp, #4
70000db4:	e20d3004 	and	r3, sp, #4
	sub sp, sp, r3
70000db8:	e04dd003 	sub	sp, sp, r3
	push {r2, r3}
70000dbc:	e92d000c 	push	{r2, r3}

	/* Increment interrupt nesting count */
	get_cpu r2
70000dc0:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000dc4:	e3c22003 	bic	r2, r2, #3
	ldr r0, [r2, #___cpu_t_nested_OFFSET]
70000dc8:	e5920000 	ldr	r0, [r2]
	add r0, r0, #1
70000dcc:	e2800001 	add	r0, r0, #1
	str r0, [r2, #___cpu_t_nested_OFFSET]
70000dd0:	e5820000 	str	r0, [r2]

	/* Get active IRQ number from the interrupt controller */
#if !defined(CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER)
	bl arm_gic_get_active
#else
	bl z_soc_irq_get_active
70000dd4:	faffff1b 	blx	70000a48 <z_soc_irq_get_active>
#endif /* !CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER */
	push {r0, r1}
70000dd8:	e92d0003 	push	{r0, r1}
	lsl r0, r0, #3	/* table is 8-byte wide */
70000ddc:	e1a00180 	lsl	r0, r0, #3
	 * to note that most interrupt controllers require that the nested
	 * interrupts are handled after the active interrupt is acknowledged;
	 * this is be done through the `get_active` interrupt controller
	 * interface function.
	 */
	cpsie i
70000de0:	f1080080 	cpsie	i

	/*
	 * Skip calling the isr if it is a spurious interrupt.
	 */
	mov r1, #CONFIG_NUM_IRQS
70000de4:	e3a01c02 	mov	r1, #512	; 0x200
	lsl r1, r1, #3
70000de8:	e1a01181 	lsl	r1, r1, #3
	cmp r0, r1
70000dec:	e1500001 	cmp	r0, r1
	bge spurious_continue
70000df0:	aa000003 	bge	70000e04 <spurious_continue>

	ldr r1, =_sw_isr_table
70000df4:	e59f1018 	ldr	r1, [pc, #24]	; 70000e14 <spurious_continue+0x10>
	add r1, r1, r0	/* table entry: ISRs must have their MSB set to stay
70000df8:	e0811000 	add	r1, r1, r0
			 * in thumb mode */

	ldm r1!,{r0,r3}	/* arg in r0, ISR in r3 */
70000dfc:	e8b10009 	ldm	r1!, {r0, r3}
	blx r3		/* call ISR */
70000e00:	e12fff33 	blx	r3

70000e04 <spurious_continue>:

spurious_continue:
	/* Signal end-of-interrupt */
	pop {r0, r1}
70000e04:	e8bd0003 	pop	{r0, r1}
#if !defined(CONFIG_ARM_CUSTOM_INTERRUPT_CONTROLLER)
	bl arm_gic_eoi
#else
	bl z_soc_irq_eoi
70000e08:	faffff0f 	blx	70000a4c <z_soc_irq_eoi>
#endif

	/* Use 'bx' instead of 'b' because 'bx' can jump further, and use
	 * 'bx' instead of 'blx' because exception return is done in
	 * z_arm_int_exit() */
	ldr r1, =z_arm_int_exit
70000e0c:	e59f1004 	ldr	r1, [pc, #4]	; 70000e18 <spurious_continue+0x14>
	bx r1
70000e10:	e12fff11 	bx	r1
	ldr r1, =_sw_isr_table
70000e14:	70003ac0 	.word	0x70003ac0
	ldr r1, =z_arm_int_exit
70000e18:	70000fd4 	.word	0x70000fd4

70000e1c <arch_dcache_invd_all>:

	return 0;
}

int arch_dcache_invd_all(void)
{
70000e1c:	b5f0      	push	{r4, r5, r6, r7, lr}
 */
__STATIC_FORCEINLINE uint32_t __get_CLIDR(void)
{
  uint32_t result;
//  __ASM volatile("MRC p15, 1, %0, c0, c0, 1" : "=r"(result) : : "memory");
  __get_CP(15, 1, result, 0, 0, 1);
70000e1e:	ee30 6f30 	mrc	15, 1, r6, cr0, cr0, {1}
*/
__STATIC_FORCEINLINE void L1C_CleanInvalidateCache(uint32_t op) {
  uint32_t clidr;
  uint32_t cache_type;
  clidr =  __get_CLIDR();
  for(uint32_t i = 0U; i<7U; i++)
70000e22:	2400      	movs	r4, #0
  {
    cache_type = (clidr >> i*3U) & 0x7UL;
70000e24:	eb04 0344 	add.w	r3, r4, r4, lsl #1
70000e28:	fa26 f303 	lsr.w	r3, r6, r3
70000e2c:	f003 0307 	and.w	r3, r3, #7
    if ((cache_type >= 2U) && (cache_type <= 4U))
70000e30:	3b02      	subs	r3, #2
70000e32:	2b02      	cmp	r3, #2
    cache_type = (clidr >> i*3U) & 0x7UL;
70000e34:	ea4f 0544 	mov.w	r5, r4, lsl #1
    if ((cache_type >= 2U) && (cache_type <= 4U))
70000e38:	d831      	bhi.n	70000e9e <arch_dcache_invd_all+0x82>
  __set_CP(15, 2, value, 0, 0, 0);
70000e3a:	ee40 5f10 	mcr	15, 2, r5, cr0, cr0, {0}
  __get_CP(15, 1, result, 0, 0, 0);
70000e3e:	ee30 7f10 	mrc	15, 1, r7, cr0, cr0, {0}
  num_ways = ((ccsidr & 0x00001FF8U) >> 3U) + 1U;
70000e42:	f3c7 0cc9 	ubfx	ip, r7, #3, #10
70000e46:	f10c 0e01 	add.w	lr, ip, #1
  if (n < 2U) {
70000e4a:	f1bc 0f00 	cmp.w	ip, #0
70000e4e:	d02b      	beq.n	70000ea8 <arch_dcache_invd_all+0x8c>
70000e50:	4672      	mov	r2, lr
  uint8_t log = 0U;
70000e52:	2300      	movs	r3, #0
    t >>= 1U;
70000e54:	0852      	lsrs	r2, r2, #1
    log++;
70000e56:	1c59      	adds	r1, r3, #1
70000e58:	4618      	mov	r0, r3
  while(t > 1U)
70000e5a:	2a01      	cmp	r2, #1
    log++;
70000e5c:	b2cb      	uxtb	r3, r1
  while(t > 1U)
70000e5e:	d1f9      	bne.n	70000e54 <arch_dcache_invd_all+0x38>
  if (n & 1U) { log++; }
70000e60:	f01e 0f01 	tst.w	lr, #1
70000e64:	bf1c      	itt	ne
70000e66:	3002      	addne	r0, #2
70000e68:	b2c3      	uxtbne	r3, r0
  if ((log2_num_ways < 0) || (log2_num_ways > 32)) {
70000e6a:	2b20      	cmp	r3, #32
  shift_way = 32U - (uint32_t)log2_num_ways;
70000e6c:	bf98      	it	ls
70000e6e:	f1c3 0e20 	rsbls	lr, r3, #32
  if ((log2_num_ways < 0) || (log2_num_ways > 32)) {
70000e72:	d814      	bhi.n	70000e9e <arch_dcache_invd_all+0x82>
  log2_linesize = (ccsidr & 0x00000007U) + 2U + 2U;
70000e74:	f007 0007 	and.w	r0, r7, #7
70000e78:	3004      	adds	r0, #4
  num_sets = ((ccsidr & 0x0FFFE000U) >> 13U) + 1U;
70000e7a:	f3c7 374e 	ubfx	r7, r7, #13, #15
    for(int32_t set = num_sets-1; set >= 0; set--)
70000e7e:	463b      	mov	r3, r7
      Dummy = (level << 1U) | (((uint32_t)set) << log2_linesize) | (((uint32_t)way) << shift_way);
70000e80:	fa0c f10e 	lsl.w	r1, ip, lr
70000e84:	4329      	orrs	r1, r5
70000e86:	fa03 f200 	lsl.w	r2, r3, r0
70000e8a:	430a      	orrs	r2, r1
/** \brief  Set DCISW
 */
__STATIC_FORCEINLINE void __set_DCISW(uint32_t value)
{
//  __ASM volatile("MCR p15, 0, %0, c7, c6, 2" : : "r"(value) : "memory")
  __set_CP(15, 0, value, 7, 6, 2);
70000e8c:	ee07 2f56 	mcr	15, 0, r2, cr7, cr6, {2}
    for(int32_t set = num_sets-1; set >= 0; set--)
70000e90:	3b01      	subs	r3, #1
70000e92:	d2f8      	bcs.n	70000e86 <arch_dcache_invd_all+0x6a>
  for(int32_t way = num_ways-1; way >= 0; way--)
70000e94:	f1bc 0c01 	subs.w	ip, ip, #1
70000e98:	d2f1      	bcs.n	70000e7e <arch_dcache_invd_all+0x62>
  \details Ensures the apparent order of the explicit memory operations before
           and after the instruction, without ensuring their completion.
 */
__STATIC_FORCEINLINE  void __DMB(void)
{
  __ASM volatile ("dmb 0xF":::"memory");
70000e9a:	f3bf 8f5f 	dmb	sy
  for(uint32_t i = 0U; i<7U; i++)
70000e9e:	3401      	adds	r4, #1
70000ea0:	2c07      	cmp	r4, #7
70000ea2:	d1bf      	bne.n	70000e24 <arch_dcache_invd_all+0x8>
	L1C_InvalidateDCacheAll();

	return 0;
}
70000ea4:	2000      	movs	r0, #0
70000ea6:	bdf0      	pop	{r4, r5, r6, r7, pc}
70000ea8:	f04f 0e20 	mov.w	lr, #32
70000eac:	e7e2      	b.n	70000e74 <arch_dcache_invd_all+0x58>
70000eae:	bf00      	nop

70000eb0 <arch_dcache_enable>:
{
70000eb0:	b508      	push	{r3, lr}
	arch_dcache_invd_all();
70000eb2:	f7ff ffb3 	bl	70000e1c <arch_dcache_invd_all>
  __get_CP(15, 0, result, 1, 0, 0);
70000eb6:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}
  __ASM volatile ("dsb 0xF":::"memory");
70000eba:	f3bf 8f4f 	dsb	sy
	val |= SCTLR_C_Msk;
70000ebe:	f043 0304 	orr.w	r3, r3, #4
  __set_CP(15, 0, sctlr, 1, 0, 0);
70000ec2:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
  __ASM volatile ("isb 0xF":::"memory");
70000ec6:	f3bf 8f6f 	isb	sy
}
70000eca:	bd08      	pop	{r3, pc}

70000ecc <arch_icache_enable>:
  __set_CP(15, 0, value, 7, 5, 0);
70000ecc:	2300      	movs	r3, #0
70000ece:	ee07 3f15 	mcr	15, 0, r3, cr7, cr5, {0}
  __ASM volatile ("dsb 0xF":::"memory");
70000ed2:	f3bf 8f4f 	dsb	sy
  __ASM volatile ("isb 0xF":::"memory");
70000ed6:	f3bf 8f6f 	isb	sy
  __get_CP(15, 0, result, 1, 0, 0);
70000eda:	ee11 3f10 	mrc	15, 0, r3, cr1, cr0, {0}
#ifdef CONFIG_ICACHE

void arch_icache_enable(void)
{
	arch_icache_invd_all();
	__set_SCTLR(__get_SCTLR() | SCTLR_I_Msk);
70000ede:	f443 5380 	orr.w	r3, r3, #4096	; 0x1000
  __set_CP(15, 0, sctlr, 1, 0, 0);
70000ee2:	ee01 3f10 	mcr	15, 0, r3, cr1, cr0, {0}
70000ee6:	f3bf 8f6f 	isb	sy
	barrier_isync_fence_full();
}
70000eea:	4770      	bx	lr

70000eec <arch_cache_init>:

#endif

void arch_cache_init(void)
{
}
70000eec:	4770      	bx	lr
70000eee:	bf00      	nop

70000ef0 <z_arm_do_swap>:
    bl z_thread_mark_switched_out
    pop {r0, lr}
#endif /* CONFIG_INSTRUMENT_THREAD_SWITCHING */

    /* load current _cpu into r1 and current k_thread into r2 */
    get_cpu r1
70000ef0:	ee1d1f70 	mrc	15, 0, r1, cr13, cr0, {3}
70000ef4:	e3c11003 	bic	r1, r1, #3
    ldr r2, [r1, #___cpu_t_current_OFFSET]
70000ef8:	e5912008 	ldr	r2, [r1, #8]
    /* Store LSB of LR (EXC_RETURN) to the thread's 'mode' word. */
    strb lr, [r2, #_thread_offset_to_mode_exc_return]
#endif

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
70000efc:	e3a00030 	mov	r0, #48	; 0x30
    add r0, r2
70000f00:	e0800002 	add	r0, r0, r2

    /* Store rest of process context */
    cps #MODE_SYS
70000f04:	f102001f 	cps	#31
    stm r0, {r4-r11, sp}
70000f08:	e8802ff0 	stm	r0, {r4, r5, r6, r7, r8, r9, sl, fp, sp}
    cps #MODE_SVC
70000f0c:	f1020013 	cps	#19
    mov r0, #0
    str r0, [r1, #___cpu_t_fp_ctx_OFFSET]
#endif /* CONFIG_FPU_SHARING */

    /* fetch the thread to run from the ready queue cache */
    ldr r3, =_kernel
70000f10:	e59f3028 	ldr	r3, [pc, #40]	; 70000f40 <z_arm_do_swap+0x50>
    ldr r2, [r3, #_kernel_offset_to_ready_q_cache]
70000f14:	e5932014 	ldr	r2, [r3, #20]

    str r2, [r1, #___cpu_t_current_OFFSET]
70000f18:	e5812008 	str	r2, [r1, #8]
#endif

    /* Restore previous interrupt disable state (irq_lock key)
     * (We clear the arch.basepri field after restoring state)
     */
    ldr r0, [r2, #_thread_offset_to_basepri]
70000f1c:	e592006c 	ldr	r0, [r2, #108]	; 0x6c
    movs r3, #0
70000f20:	e3b03000 	movs	r3, #0
    str r3, [r2, #_thread_offset_to_basepri]
70000f24:	e582306c 	str	r3, [r2, #108]	; 0x6c

    /* addr of callee-saved regs in thread in r0 */
    ldr r0, =_thread_offset_to_callee_saved
70000f28:	e3a00030 	mov	r0, #48	; 0x30
    add r0, r2
70000f2c:	e0800002 	add	r0, r0, r2

    /* restore r4-r11 and sp for incoming thread */
    cps #MODE_SYS
70000f30:	f102001f 	cps	#31
    ldm r0, {r4-r11, sp}
70000f34:	e8902ff0 	ldm	r0, {r4, r5, r6, r7, r8, r9, sl, fp, sp}
    cps #MODE_SVC
70000f38:	f1020013 	cps	#19
#endif /* CONFIG_INSTRUMENT_THREAD_SWITCHING */

    /*
     * Cortex-R: return to the caller (z_arm_{exc,int}_exit, or z_arm_svc)
     */
    bx lr
70000f3c:	e12fff1e 	bx	lr
    ldr r3, =_kernel
70000f40:	70007e38 	.word	0x70007e38

70000f44 <z_arm_svc>:
    /*
     * Switch to system mode to store r0-r3 to the process stack pointer.
     * Save r12 and the lr as we could be swapping in another process and
     * returning to a different location.
     */
    srsdb #MODE_SYS!
70000f44:	f96d051f 	srsdb	sp!, #31
    cps #MODE_SYS
70000f48:	f102001f 	cps	#31
    push {r0-r3, r12, lr}
70000f4c:	e92d500f 	push	{r0, r1, r2, r3, ip, lr}
    ldr r0, [r2, #___cpu_t_fp_ctx_OFFSET]
    cmp r0, #0
    streq sp, [r2, #___cpu_t_fp_ctx_OFFSET]
#endif /* CONFIG_FPU_SHARING */

    mov ip, sp
70000f50:	e1a0c00d 	mov	ip, sp

    cps #MODE_SVC
70000f54:	f1020013 	cps	#19

    /*
     * Store lr_svc to the SVC mode stack. This value will be restored prior to
     * exiting the SVC call in z_arm_int_exit.
     */
    push {lr}
70000f58:	e52de004 	push	{lr}		; (str lr, [sp, #-4]!)

    /* Align stack at double-word boundary */
    /* TODO: Question, why push {r2, r3} here */
    and r3, sp, #4
70000f5c:	e20d3004 	and	r3, sp, #4
    sub sp, sp, r3
70000f60:	e04dd003 	sub	sp, sp, r3
    push {r2, r3}
70000f64:	e92d000c 	push	{r2, r3}

    /* Increment interrupt nesting count */
    get_cpu r2
70000f68:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70000f6c:	e3c22003 	bic	r2, r2, #3
    ldr r0, [r2, #___cpu_t_nested_OFFSET]
70000f70:	e5920000 	ldr	r0, [r2]
    add r0, r0, #1
70000f74:	e2800001 	add	r0, r0, #1
    str r0, [r2, #___cpu_t_nested_OFFSET]
70000f78:	e5820000 	str	r0, [r2]

    /* Get SVC number */
    mrs r0, spsr
70000f7c:	e14f0000 	mrs	r0, SPSR
    tst r0, #0x20
70000f80:	e3100020 	tst	r0, #32

    ldreq r1, [lr, #-4]
70000f84:	051e1004 	ldreq	r1, [lr, #-4]
    biceq r1, #0xff000000
70000f88:	03c114ff 	biceq	r1, r1, #-16777216	; 0xff000000
    beq demux
70000f8c:	0a000001 	beq	70000f98 <demux>

    ldr r1, [lr, #-2]
70000f90:	e51e1002 	ldr	r1, [lr, #-2]
    and r1, #0xff
70000f94:	e20110ff 	and	r1, r1, #255	; 0xff

70000f98 <demux>:
#if defined(CONFIG_USERSPACE)
    cmp r1, #_SVC_CALL_SYSTEM_CALL
    beq _do_syscall
#endif

    cmp r1, #_SVC_CALL_CONTEXT_SWITCH
70000f98:	e3510000 	cmp	r1, #0
    beq _context_switch
70000f9c:	0a000001 	beq	70000fa8 <_context_switch>

    cmp r1, #_SVC_CALL_RUNTIME_EXCEPT
70000fa0:	e3510002 	cmp	r1, #2
    beq _oops
70000fa4:	0a000001 	beq	70000fb0 <_oops>

70000fa8 <_context_switch>:
    b z_arm_int_exit
#endif

_context_switch:
    /* handler mode exit, to PendSV */
    bl z_arm_do_swap
70000fa8:	ebffffd0 	bl	70000ef0 <z_arm_do_swap>

    b z_arm_int_exit
70000fac:	ea000008 	b	70000fd4 <z_arm_int_exit>

70000fb0 <_oops>:

_oops:
    /*
     * Pass the exception frame to z_do_kernel_oops.
     */
    cps #MODE_SYS
70000fb0:	f102001f 	cps	#31
    mov r0, sp
70000fb4:	e1a0000d 	mov	r0, sp
    cps #MODE_SVC
70000fb8:	f1020013 	cps	#19
    /* Zero callee_regs and exc_return (only used on Cortex-M) */
    mov r1, #0
70000fbc:	e3a01000 	mov	r1, #0
    mov r2, #0
70000fc0:	e3a02000 	mov	r2, #0
    bl z_do_kernel_oops
70000fc4:	fafffea9 	blx	70000a70 <z_do_kernel_oops>
    b z_arm_int_exit
70000fc8:	ea000001 	b	70000fd4 <z_arm_int_exit>

70000fcc <z_arm_cortex_r_svc>:
    b z_arm_int_exit
#endif

GTEXT(z_arm_cortex_r_svc)
SECTION_FUNC(TEXT, z_arm_cortex_r_svc)
    svc #_SVC_CALL_CONTEXT_SWITCH
70000fcc:	ef000000 	svc	0x00000000
    bx lr
70000fd0:	e12fff1e 	bx	lr

70000fd4 <z_arm_int_exit>:
#endif /* CONFIG_STACK_SENTINEL */

	/* Disable nested interrupts while exiting, this should happens
	 * before context switch also, to ensure interrupts are disabled.
	 */
	cpsid i
70000fd4:	f10c0080 	cpsid	i

#ifdef CONFIG_PREEMPT_ENABLED
	/* Do not context switch if exiting a nested interrupt */
	get_cpu r3
70000fd8:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70000fdc:	e3c33003 	bic	r3, r3, #3
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
70000fe0:	e5930000 	ldr	r0, [r3]
	cmp r0, #1
70000fe4:	e3500001 	cmp	r0, #1
	bhi __EXIT_INT
70000fe8:	8a000004 	bhi	70001000 <__EXIT_INT>

	ldr r1, [r3, #___cpu_t_current_OFFSET]
70000fec:	e5931008 	ldr	r1, [r3, #8]
	ldr r2, =_kernel
70000ff0:	e59f2094 	ldr	r2, [pc, #148]	; 7000108c <__EXIT_EXC+0x18>
	ldr r0, [r2, #_kernel_offset_to_ready_q_cache]
70000ff4:	e5920014 	ldr	r0, [r2, #20]
	cmp r0, r1
70000ff8:	e1500001 	cmp	r0, r1
	blne z_arm_do_swap
70000ffc:	1bffffbb 	blne	70000ef0 <z_arm_do_swap>

70001000 <__EXIT_INT>:
__EXIT_INT:
#endif /* CONFIG_PREEMPT_ENABLED */

	/* Decrement interrupt nesting count */
	get_cpu r2
70001000:	ee1d2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70001004:	e3c22003 	bic	r2, r2, #3
	ldr r0, [r2, #___cpu_t_nested_OFFSET]
70001008:	e5920000 	ldr	r0, [r2]
	sub r0, r0, #1
7000100c:	e2400001 	sub	r0, r0, #1
	str r0, [r2, #___cpu_t_nested_OFFSET]
70001010:	e5820000 	str	r0, [r2]

	/* Restore previous stack pointer */
	pop {r2, r3}
70001014:	e8bd000c 	pop	{r2, r3}
	add sp, sp, r3
70001018:	e08dd003 	add	sp, sp, r3
	/*
	 * Restore lr_svc stored into the SVC mode stack by the mode entry
	 * function. This ensures that the return address of the interrupted
	 * context is preserved in case of interrupt nesting.
	 */
	pop {lr}
7000101c:	e49de004 	pop	{lr}		; (ldr lr, [sp], #4)
	 * IRQ mode and z_arm_svc for SVC mode.
	 *
	 * r0-r3 are either the values from the thread before it was switched
	 * out or they are the args to _new_thread for a new thread.
	 */
	cps #MODE_SYS
70001020:	f102001f 	cps	#31

#if defined(CONFIG_FPU_SHARING)
	fpu_exc_exit
#endif

	pop {r0-r3, r12, lr}
70001024:	e8bd500f 	pop	{r0, r1, r2, r3, ip, lr}
	userspace_exc_exit
	rfeia sp!
70001028:	f8bd0a00 	rfeia	sp!

7000102c <z_arm_exc_exit>:
 *
 * @param fatal True if exiting from a fatal fault; otherwise, false
 */
SECTION_SUBSEC_FUNC(TEXT, _HandlerModeExit, z_arm_exc_exit)
	/* Do not context switch if exiting a nested exception */
	get_cpu r3
7000102c:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70001030:	e3c33003 	bic	r3, r3, #3
	ldr r1, [r3, #___cpu_t_nested_OFFSET]
70001034:	e5931000 	ldr	r1, [r3]
	cmp r1, #1
70001038:	e3510001 	cmp	r1, #1
	bhi __EXIT_EXC
7000103c:	8a00000c 	bhi	70001074 <__EXIT_EXC>

	/* If the fault is not fatal, return to the current thread context */
	cmp r0, #0
70001040:	e3500000 	cmp	r0, #0
	beq __EXIT_EXC
70001044:	0a00000a 	beq	70001074 <__EXIT_EXC>

	/* Clean up exception stack frame */
#if defined(CONFIG_FPU_SHARING)
	add sp, sp, #___fpu_t_SIZEOF
#endif
	add sp, #32
70001048:	e28dd020 	add	sp, sp, #32
	 *
	 * Note that z_arm_do_swap must be called in the SVC mode because it
	 * switches to the SVC mode during context switch and returns to the
	 * caller using lr_svc.
	 */
	cps #MODE_SVC
7000104c:	f1020013 	cps	#19
	bl z_arm_do_swap
70001050:	ebffffa6 	bl	70000ef0 <z_arm_do_swap>

	/* Decrement exception nesting count */
	get_cpu r3
70001054:	ee1d3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70001058:	e3c33003 	bic	r3, r3, #3
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
7000105c:	e5930000 	ldr	r0, [r3]
	sub r0, r0, #1
70001060:	e2400001 	sub	r0, r0, #1
	str r0, [r3, #___cpu_t_nested_OFFSET]
70001064:	e5830000 	str	r0, [r3]

	/* Return to the switched thread */
	cps #MODE_SYS
70001068:	f102001f 	cps	#31
#if defined(CONFIG_FPU_SHARING)
	fpu_exc_exit
#endif
	pop {r0-r3, r12, lr}
7000106c:	e8bd500f 	pop	{r0, r1, r2, r3, ip, lr}
	userspace_exc_exit
	rfeia sp!
70001070:	f8bd0a00 	rfeia	sp!

70001074 <__EXIT_EXC>:

__EXIT_EXC:
	/* Decrement exception nesting count */
	ldr r0, [r3, #___cpu_t_nested_OFFSET]
70001074:	e5930000 	ldr	r0, [r3]
	sub r0, r0, #1
70001078:	e2400001 	sub	r0, r0, #1
	str r0, [r3, #___cpu_t_nested_OFFSET]
7000107c:	e5830000 	str	r0, [r3]
#endif
	/*
	 * Restore r0-r3, r12, lr, lr_und and spsr_und from the exception stack
	 * and return to the current thread.
	 */
	ldmia sp, {r0-r3, r12, lr}^
70001080:	e8dd500f 	ldm	sp, {r0, r1, r2, r3, ip, lr}^
	add sp, #24
70001084:	e28dd018 	add	sp, sp, #24
	rfeia sp!
70001088:	f8bd0a00 	rfeia	sp!
	ldr r2, =_kernel
7000108c:	70007e38 	.word	0x70007e38

70001090 <picolibc_put>:
}
#include <zephyr/syscalls/zephyr_fputc_mrsh.c>
#endif

static int picolibc_put(char a, FILE *f)
{
70001090:	b508      	push	{r3, lr}
	(*_stdout_hook)(a);
70001092:	f647 6324 	movw	r3, #32292	; 0x7e24
70001096:	f2c7 0300 	movt	r3, #28672	; 0x7000
7000109a:	681b      	ldr	r3, [r3, #0]
7000109c:	4798      	blx	r3
	zephyr_fputc(a, f);
	return 0;
}
7000109e:	2000      	movs	r0, #0
700010a0:	bd08      	pop	{r3, pc}
700010a2:	bf00      	nop

700010a4 <__stdout_hook_install>:
FILE *const stdout = &__stdout;
STDIO_ALIAS(stderr);

void __stdout_hook_install(int (*hook)(int))
{
	_stdout_hook = hook;
700010a4:	f647 6124 	movw	r1, #32292	; 0x7e24
	__stdout.flags |= _FDEV_SETUP_WRITE;
700010a8:	f24c 3308 	movw	r3, #49928	; 0xc308
700010ac:	f2c7 0300 	movt	r3, #28672	; 0x7000
700010b0:	789a      	ldrb	r2, [r3, #2]
	_stdout_hook = hook;
700010b2:	f2c7 0100 	movt	r1, #28672	; 0x7000
	__stdout.flags |= _FDEV_SETUP_WRITE;
700010b6:	f042 0202 	orr.w	r2, r2, #2
	_stdout_hook = hook;
700010ba:	6008      	str	r0, [r1, #0]
	__stdout.flags |= _FDEV_SETUP_WRITE;
700010bc:	709a      	strb	r2, [r3, #2]
}
700010be:	4770      	bx	lr

700010c0 <malloc_prepare>:
			break;
		}
		heap_size >>= 1;
	}
#else
	heap_base = UINT_TO_POINTER(HEAP_BASE);
700010c0:	4907      	ldr	r1, [pc, #28]	; (700010e0 <malloc_prepare+0x20>)
	z_malloc_partition.start = POINTER_TO_UINT(heap_base);
	z_malloc_partition.size = heap_size;
	z_malloc_partition.attr = K_MEM_PARTITION_P_RW_U_RW;
#endif

	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
700010c2:	f647 6028 	movw	r0, #32296	; 0x7e28
700010c6:	f2c7 0000 	movt	r0, #28672	; 0x7000
	heap_base = UINT_TO_POINTER(HEAP_BASE);
700010ca:	f021 0107 	bic.w	r1, r1, #7
	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
700010ce:	f1c1 42e0 	rsb	r2, r1, #1879048192	; 0x70000000
700010d2:	f502 3200 	add.w	r2, r2, #131072	; 0x20000
{
700010d6:	b508      	push	{r3, lr}
	sys_heap_init(&z_malloc_heap, heap_base, heap_size);
700010d8:	f7ff fc48 	bl	7000096c <sys_heap_init>

	return 0;
}
700010dc:	2000      	movs	r0, #0
700010de:	bd08      	pop	{r3, pc}
700010e0:	7000c343 	.word	0x7000c343

700010e4 <z_vim_irq_get_active>:

static ALWAYS_INLINE uint32_t sys_read32(mem_addr_t addr)
{
	uint32_t val;

	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700010e4:	2318      	movs	r3, #24
700010e6:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
700010ea:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700010ec:	f3bf 8f5f 	dmb	sy
700010f0:	2320      	movs	r3, #32
700010f2:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
700010f6:	681b      	ldr	r3, [r3, #0]
700010f8:	f3bf 8f5f 	dmb	sy
	actirq = sys_read32(VIM_ACTIRQ);

	/* Check if the irq number is valid, else return invalid irq number.
	 * which will be considered as spurious interrupt
	 */
	if ((actirq & (VIM_ACTIRQ_VALID_MASK)) == 0) {
700010fc:	2b00      	cmp	r3, #0
700010fe:	da14      	bge.n	7000112a <z_vim_irq_get_active+0x46>
		return CONFIG_NUM_IRQS + 1;
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(actirq & VIM_PRIIRQ_NUM_MASK);
70001100:	f3c3 0009 	ubfx	r0, r3, #0, #10
70001104:	f3bf 8f5f 	dmb	sy
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(actirq & VIM_PRIIRQ_NUM_MASK);

	/* Ack the interrupt in IRQSTS register */
	sys_write32(BIT(irq_bit_num), VIM_IRQSTS(irq_group_num));
70001108:	2101      	movs	r1, #1
7000110a:	f44f 6282 	mov.w	r2, #1040	; 0x410
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(actirq & VIM_PRIIRQ_NUM_MASK);
7000110e:	f003 0c1f 	and.w	ip, r3, #31
	sys_write32(BIT(irq_bit_num), VIM_IRQSTS(irq_group_num));
70001112:	f6c2 72ff 	movt	r2, #12287	; 0x2fff
70001116:	f403 7378 	and.w	r3, r3, #992	; 0x3e0
7000111a:	fa01 f10c 	lsl.w	r1, r1, ip
7000111e:	441a      	add	r2, r3
}

static ALWAYS_INLINE void sys_write32(uint32_t data, mem_addr_t addr)
{
	barrier_dmem_fence_full();
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001120:	6011      	str	r1, [r2, #0]

	if (irq_group_num > VIM_MAX_GROUP_NUM) {
70001122:	f5b0 7f08 	cmp.w	r0, #544	; 0x220
70001126:	d200      	bcs.n	7000112a <z_vim_irq_get_active+0x46>
		return (CONFIG_NUM_IRQS + 1);
	}

	return (actirq & VIM_ACTIRQ_NUM_MASK);
}
70001128:	4770      	bx	lr
		return CONFIG_NUM_IRQS + 1;
7000112a:	f240 2001 	movw	r0, #513	; 0x201
7000112e:	4770      	bx	lr

70001130 <z_vim_irq_eoi>:
70001130:	f3bf 8f5f 	dmb	sy
70001134:	2318      	movs	r3, #24
70001136:	2200      	movs	r2, #0
70001138:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
7000113c:	601a      	str	r2, [r3, #0]

void z_vim_irq_eoi(unsigned int irq)
{
	sys_write32(0, VIM_IRQVEC);
}
7000113e:	4770      	bx	lr

70001140 <z_vim_irq_init>:
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001140:	2004      	movs	r0, #4
70001142:	f6c2 70ff 	movt	r0, #12287	; 0x2fff

void z_vim_irq_init(void)
{
70001146:	b500      	push	{lr}
70001148:	6800      	ldr	r0, [r0, #0]
7000114a:	f3bf 8f5f 	dmb	sy
	uint32_t num_of_irqs = sys_read32(VIM_INFO) & VIM_INFO_INTERRUPTS_MASK;
7000114e:	f3c0 000a 	ubfx	r0, r0, #0, #11
	unsigned int irq;

	LOG_DBG("VIM: Number of IRQs = %u\n", num_of_irqs);

	/* make sure all IRQs are initially disabled and cleared */
	for (irq = 0; irq < num_of_irqs; irq+=32)
70001152:	b1b8      	cbz	r0, 70001184 <z_vim_irq_init+0x44>
	{
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
70001154:	f240 4e0c 	movw	lr, #1036	; 0x40c
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
70001158:	f240 4c04 	movw	ip, #1028	; 0x404
	for (irq = 0; irq < num_of_irqs; irq+=32)
7000115c:	2300      	movs	r3, #0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000115e:	f06f 4200 	mvn.w	r2, #2147483648	; 0x80000000
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
70001162:	f6c2 7eff 	movt	lr, #12287	; 0x2fff
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
70001166:	f6c2 7cff 	movt	ip, #12287	; 0x2fff
7000116a:	f3bf 8f5f 	dmb	sy
		sys_write32(BIT_MASK(31), VIM_INTR_EN_CLR(VIM_GET_IRQ_GROUP_NUM(irq)));
7000116e:	eb03 010e 	add.w	r1, r3, lr
70001172:	600a      	str	r2, [r1, #0]
70001174:	f3bf 8f5f 	dmb	sy
		sys_write32(BIT_MASK(31), VIM_STS(VIM_GET_IRQ_GROUP_NUM(irq)));
70001178:	eb03 010c 	add.w	r1, r3, ip
7000117c:	600a      	str	r2, [r1, #0]
	for (irq = 0; irq < num_of_irqs; irq+=32)
7000117e:	3320      	adds	r3, #32
70001180:	4298      	cmp	r0, r3
70001182:	d8f2      	bhi.n	7000116a <z_vim_irq_init+0x2a>
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001184:	2318      	movs	r3, #24
70001186:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
7000118a:	681a      	ldr	r2, [r3, #0]
7000118c:	f3bf 8f5f 	dmb	sy
70001190:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001194:	2200      	movs	r2, #0
70001196:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001198:	231c      	movs	r3, #28
7000119a:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
7000119e:	6819      	ldr	r1, [r3, #0]
700011a0:	f3bf 8f5f 	dmb	sy
700011a4:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700011a8:	601a      	str	r2, [r3, #0]
	/* ACK and clear pending IRQs */
	(void) sys_read32(VIM_IRQVEC);
	sys_write32(0, VIM_IRQVEC);
	(void) sys_read32(VIM_FIQVEC);
	sys_write32(0, VIM_FIQVEC);
}
700011aa:	f85d fb04 	ldr.w	pc, [sp], #4
700011ae:	bf00      	nop

700011b0 <z_vim_irq_priority_set>:

void z_vim_irq_priority_set(unsigned int irq, unsigned int prio, uint32_t flags)
{
	uint32_t irq_group_num, irq_bit_num, regval;

	if (irq > CONFIG_NUM_IRQS || prio > VIM_PRI_INT_MAX ||
700011b0:	290f      	cmp	r1, #15
700011b2:	bf98      	it	ls
700011b4:	f5b0 7f00 	cmpls.w	r0, #512	; 0x200
700011b8:	d824      	bhi.n	70001204 <z_vim_irq_priority_set+0x54>
	    (flags != IRQ_TYPE_EDGE && flags != IRQ_TYPE_LEVEL)) {
700011ba:	1e93      	subs	r3, r2, #2
	if (irq > CONFIG_NUM_IRQS || prio > VIM_PRI_INT_MAX ||
700011bc:	f033 0302 	bics.w	r3, r3, #2
700011c0:	d120      	bne.n	70001204 <z_vim_irq_priority_set+0x54>
700011c2:	f3bf 8f5f 	dmb	sy
		LOG_ERR("%s: Invalid argument irq = %u prio = %u flags = %u\n",
			__func__, irq, prio, flags);
		return;
	}

	sys_write8(prio, VIM_PRI_INT(irq));
700011c6:	f100 6340 	add.w	r3, r0, #201326592	; 0xc000000
700011ca:	f5a3 5370 	sub.w	r3, r3, #15360	; 0x3c00
700011ce:	009b      	lsls	r3, r3, #2
	__asm__ volatile("strb %0, [%1]" : : "r" (data), "r" (addr));
700011d0:	7019      	strb	r1, [r3, #0]

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	regval = sys_read32(VIM_INTTYPE(irq_group_num));
700011d2:	f240 431c 	movw	r3, #1052	; 0x41c
700011d6:	f020 011f 	bic.w	r1, r0, #31
700011da:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
700011de:	440b      	add	r3, r1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700011e0:	6819      	ldr	r1, [r3, #0]
700011e2:	f3bf 8f5f 	dmb	sy

	if (flags == IRQ_TYPE_EDGE) {
		regval |= (BIT(irq_bit_num));
700011e6:	f04f 0c01 	mov.w	ip, #1
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
700011ea:	f000 001f 	and.w	r0, r0, #31
	if (flags == IRQ_TYPE_EDGE) {
700011ee:	2a04      	cmp	r2, #4
		regval |= (BIT(irq_bit_num));
700011f0:	fa0c f000 	lsl.w	r0, ip, r0
700011f4:	bf0c      	ite	eq
700011f6:	ea40 0201 	orreq.w	r2, r0, r1
	} else {
		regval &= ~(BIT(irq_bit_num));
700011fa:	ea21 0200 	bicne.w	r2, r1, r0
700011fe:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001202:	601a      	str	r2, [r3, #0]
	}

	sys_write32(regval, VIM_INTTYPE(irq_group_num));
}
70001204:	4770      	bx	lr
70001206:	bf00      	nop

70001208 <z_vim_irq_enable>:

void z_vim_irq_enable(unsigned int irq)
{
	uint32_t irq_group_num, irq_bit_num;

	if (irq > CONFIG_NUM_IRQS) {
70001208:	f5b0 7f00 	cmp.w	r0, #512	; 0x200
7000120c:	d80d      	bhi.n	7000122a <z_vim_irq_enable+0x22>
7000120e:	f3bf 8f5f 	dmb	sy
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);

	sys_write32(BIT(irq_bit_num), VIM_INTR_EN_SET(irq_group_num));
70001212:	2201      	movs	r2, #1
70001214:	f44f 6381 	mov.w	r3, #1032	; 0x408
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
70001218:	f000 011f 	and.w	r1, r0, #31
	sys_write32(BIT(irq_bit_num), VIM_INTR_EN_SET(irq_group_num));
7000121c:	f6c2 73ff 	movt	r3, #12287	; 0x2fff
70001220:	f020 001f 	bic.w	r0, r0, #31
70001224:	408a      	lsls	r2, r1
70001226:	4403      	add	r3, r0
70001228:	601a      	str	r2, [r3, #0]
}
7000122a:	4770      	bx	lr

7000122c <z_vim_arm_enter_irq>:

void z_vim_arm_enter_irq(int irq)
{
	uint32_t irq_group_num, irq_bit_num;

	if (irq > CONFIG_NUM_IRQS) {
7000122c:	f5b0 7f00 	cmp.w	r0, #512	; 0x200
70001230:	dc1a      	bgt.n	70001268 <z_vim_arm_enter_irq+0x3c>
70001232:	f3bf 8f5f 	dmb	sy
		LOG_ERR("%s: Invalid irq number = %u\n", __func__, irq);
		return;
	}

	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
70001236:	f1d0 0c00 	rsbs	ip, r0, #0
	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
7000123a:	f100 031f 	add.w	r3, r0, #31
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
7000123e:	f00c 0c1f 	and.w	ip, ip, #31

	sys_write32(BIT(irq_bit_num), VIM_RAW(irq_group_num));
70001242:	f04f 0201 	mov.w	r2, #1
	irq_bit_num = VIM_GET_IRQ_BIT_NUM(irq);
70001246:	f000 011f 	and.w	r1, r0, #31
7000124a:	bf58      	it	pl
7000124c:	f1cc 0100 	rsbpl	r1, ip, #0
	irq_group_num = VIM_GET_IRQ_GROUP_NUM(irq);
70001250:	ea13 0320 	ands.w	r3, r3, r0, asr #32
70001254:	bf38      	it	cc
70001256:	4603      	movcc	r3, r0
	sys_write32(BIT(irq_bit_num), VIM_RAW(irq_group_num));
70001258:	f023 031f 	bic.w	r3, r3, #31
7000125c:	f103 5340 	add.w	r3, r3, #805306368	; 0x30000000
70001260:	408a      	lsls	r2, r1
70001262:	f5a3 437c 	sub.w	r3, r3, #64512	; 0xfc00
70001266:	601a      	str	r2, [r3, #0]
}
70001268:	4770      	bx	lr
7000126a:	bf00      	nop

7000126c <console_out>:
		 * function MUST return the byte output.
		 */
		return c;
	}

	if ('\n' == c) {
7000126c:	280a      	cmp	r0, #10
{
7000126e:	b538      	push	{r3, r4, r5, lr}
70001270:	4604      	mov	r4, r0
	if ('\n' == c) {
70001272:	d00d      	beq.n	70001290 <console_out+0x24>
70001274:	f643 25ac 	movw	r5, #15020	; 0x3aac
70001278:	f2c7 0500 	movt	r5, #28672	; 0x7000

static inline void z_impl_uart_poll_out(const struct device *dev, unsigned char out_char)
{
	const struct uart_driver_api *api = (const struct uart_driver_api *)dev->api;

	api->poll_out(dev, out_char);
7000127c:	68ab      	ldr	r3, [r5, #8]
7000127e:	f643 20ac 	movw	r0, #15020	; 0x3aac
70001282:	b2e1      	uxtb	r1, r4
70001284:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001288:	685b      	ldr	r3, [r3, #4]
7000128a:	4798      	blx	r3
	 * As errors cannot be returned, ignore the return value
	 */
	(void)pm_device_runtime_put_async(uart_console_dev, K_MSEC(1));

	return c;
}
7000128c:	4620      	mov	r0, r4
7000128e:	bd38      	pop	{r3, r4, r5, pc}
70001290:	f643 25ac 	movw	r5, #15020	; 0x3aac
70001294:	210d      	movs	r1, #13
70001296:	f2c7 0500 	movt	r5, #28672	; 0x7000
7000129a:	4628      	mov	r0, r5
7000129c:	68ab      	ldr	r3, [r5, #8]
7000129e:	685b      	ldr	r3, [r3, #4]
700012a0:	4798      	blx	r3
		return;
	}
#endif
	compiler_barrier();
	z_impl_uart_poll_out(dev, out_char);
}
700012a2:	e7eb      	b.n	7000127c <console_out+0x10>

700012a4 <uart_console_init>:
 * @brief Initialize one UART as the console/debug port
 *
 * @return 0 if successful, otherwise failed.
 */
static int uart_console_init(void)
{
700012a4:	b508      	push	{r3, lr}
		union { uintptr_t x; const struct device * val; } parm0 = { .val = dev };
		return (bool) arch_syscall_invoke1(parm0.x, K_SYSCALL_DEVICE_IS_READY);
	}
#endif
	compiler_barrier();
	return z_impl_device_is_ready(dev);
700012a6:	f643 20ac 	movw	r0, #15020	; 0x3aac
700012aa:	f2c7 0000 	movt	r0, #28672	; 0x7000
700012ae:	f000 fbe1 	bl	70001a74 <z_impl_device_is_ready>
	if (!device_is_ready(uart_console_dev)) {
700012b2:	b168      	cbz	r0, 700012d0 <uart_console_init+0x2c>
	__stdout_hook_install(console_out);
700012b4:	f241 206d 	movw	r0, #4717	; 0x126d
700012b8:	f2c7 0000 	movt	r0, #28672	; 0x7000
700012bc:	f7ff fef2 	bl	700010a4 <__stdout_hook_install>
	__printk_hook_install(console_out);
700012c0:	f241 206d 	movw	r0, #4717	; 0x126d
700012c4:	f2c7 0000 	movt	r0, #28672	; 0x7000
700012c8:	f7ff fb8e 	bl	700009e8 <__printk_hook_install>
		return -ENODEV;
	}

	uart_console_hook_install();

	return 0;
700012cc:	2000      	movs	r0, #0
}
700012ce:	bd08      	pop	{r3, pc}
		return -ENODEV;
700012d0:	f06f 0012 	mvn.w	r0, #18
}
700012d4:	bd08      	pop	{r3, pc}
700012d6:	bf00      	nop

700012d8 <pinctrl_lookup_state>:
#include <zephyr/drivers/pinctrl.h>

int pinctrl_lookup_state(const struct pinctrl_dev_config *config, uint8_t id,
			 const struct pinctrl_state **state)
{
	*state = &config->states[0];
700012d8:	6803      	ldr	r3, [r0, #0]
700012da:	6013      	str	r3, [r2, #0]
	while (*state < &config->states[config->state_cnt]) {
700012dc:	f890 c004 	ldrb.w	ip, [r0, #4]
700012e0:	eb03 0ccc 	add.w	ip, r3, ip, lsl #3
700012e4:	4563      	cmp	r3, ip
700012e6:	d21f      	bcs.n	70001328 <pinctrl_lookup_state+0x50>
		if (id == (*state)->id) {
700012e8:	f893 c005 	ldrb.w	ip, [r3, #5]
700012ec:	458c      	cmp	ip, r1
			return 0;
		}

		(*state)++;
700012ee:	f103 0308 	add.w	r3, r3, #8
		if (id == (*state)->id) {
700012f2:	d017      	beq.n	70001324 <pinctrl_lookup_state+0x4c>
{
700012f4:	b500      	push	{lr}
700012f6:	e005      	b.n	70001304 <pinctrl_lookup_state+0x2c>
		if (id == (*state)->id) {
700012f8:	f893 c005 	ldrb.w	ip, [r3, #5]
700012fc:	458c      	cmp	ip, r1
		(*state)++;
700012fe:	f103 0308 	add.w	r3, r3, #8
		if (id == (*state)->id) {
70001302:	d00c      	beq.n	7000131e <pinctrl_lookup_state+0x46>
		(*state)++;
70001304:	6013      	str	r3, [r2, #0]
	while (*state < &config->states[config->state_cnt]) {
70001306:	f890 c004 	ldrb.w	ip, [r0, #4]
7000130a:	f8d0 e000 	ldr.w	lr, [r0]
7000130e:	eb0e 0ccc 	add.w	ip, lr, ip, lsl #3
70001312:	4563      	cmp	r3, ip
70001314:	d3f0      	bcc.n	700012f8 <pinctrl_lookup_state+0x20>
	}

	return -ENOENT;
70001316:	f06f 0001 	mvn.w	r0, #1
}
7000131a:	f85d fb04 	ldr.w	pc, [sp], #4
			return 0;
7000131e:	2000      	movs	r0, #0
}
70001320:	f85d fb04 	ldr.w	pc, [sp], #4
			return 0;
70001324:	2000      	movs	r0, #0
}
70001326:	4770      	bx	lr
	return -ENOENT;
70001328:	f06f 0001 	mvn.w	r0, #1
7000132c:	4770      	bx	lr
7000132e:	bf00      	nop

70001330 <pinctrl_ti_k3_init>:

static int pinctrl_ti_k3_init(const struct device *dev)
{
	DEVICE_MMIO_MAP(dev, K_MEM_CACHE_NONE);
	return 0;
}
70001330:	2000      	movs	r0, #0
70001332:	4770      	bx	lr

70001334 <pinctrl_configure_pins>:
	uintptr_t virt_reg_base = DEVICE_MMIO_GET(dev);
70001334:	f24c 3318 	movw	r3, #49944	; 0xc318
70001338:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
7000133c:	b410      	push	{r4}
	uintptr_t virt_reg_base = DEVICE_MMIO_GET(dev);
7000133e:	681c      	ldr	r4, [r3, #0]
	for (uint8_t i = 0; i < pin_cnt; i++) {
70001340:	b151      	cbz	r1, 70001358 <pinctrl_configure_pins+0x24>
70001342:	eb00 01c1 	add.w	r1, r0, r1, lsl #3
		sys_write32(pins[i].value, virt_reg_base + pins[i].offset);
70001346:	6842      	ldr	r2, [r0, #4]
70001348:	f850 3b08 	ldr.w	r3, [r0], #8
7000134c:	4423      	add	r3, r4
7000134e:	f3bf 8f5f 	dmb	sy
70001352:	601a      	str	r2, [r3, #0]
	for (uint8_t i = 0; i < pin_cnt; i++) {
70001354:	4288      	cmp	r0, r1
70001356:	d1f6      	bne.n	70001346 <pinctrl_configure_pins+0x12>
}
70001358:	bc10      	pop	{r4}
7000135a:	2000      	movs	r0, #0
7000135c:	4770      	bx	lr
7000135e:	bf00      	nop

70001360 <uart_ns16550_config_get>:
};

#ifdef CONFIG_UART_USE_RUNTIME_CONFIGURE
static int uart_ns16550_config_get(const struct device *dev,
				   struct uart_config *cfg)
{
70001360:	4603      	mov	r3, r0
	cfg->stop_bits = data->uart_config.stop_bits;
	cfg->data_bits = data->uart_config.data_bits;
	cfg->flow_ctrl = data->uart_config.flow_ctrl;

	return 0;
}
70001362:	2000      	movs	r0, #0
	struct uart_ns16550_dev_data *data = dev->data;
70001364:	691b      	ldr	r3, [r3, #16]
	cfg->baudrate = data->uart_config.baudrate;
70001366:	681a      	ldr	r2, [r3, #0]
70001368:	600a      	str	r2, [r1, #0]
	cfg->parity = data->uart_config.parity;
7000136a:	791a      	ldrb	r2, [r3, #4]
7000136c:	710a      	strb	r2, [r1, #4]
	cfg->stop_bits = data->uart_config.stop_bits;
7000136e:	795a      	ldrb	r2, [r3, #5]
70001370:	714a      	strb	r2, [r1, #5]
	cfg->data_bits = data->uart_config.data_bits;
70001372:	799a      	ldrb	r2, [r3, #6]
70001374:	718a      	strb	r2, [r1, #6]
	cfg->flow_ctrl = data->uart_config.flow_ctrl;
70001376:	79db      	ldrb	r3, [r3, #7]
70001378:	71cb      	strb	r3, [r1, #7]
}
7000137a:	4770      	bx	lr

7000137c <uart_ns16550_poll_out>:
 * @param dev UART device struct
 * @param c Character to send
 */
static void uart_ns16550_poll_out(const struct device *dev,
					   unsigned char c)
{
7000137c:	b410      	push	{r4}
	key = __get_BASEPRI();
	__set_BASEPRI_MAX(_EXC_IRQ_DEFAULT_PRIO);
	__ISB();
#elif defined(CONFIG_ARMV7_R) || defined(CONFIG_AARCH32_ARMV8_R) \
	|| defined(CONFIG_ARMV7_A)
	__asm__ volatile(
7000137e:	f3ef 8400 	mrs	r4, CPSR
70001382:	f004 0480 	and.w	r4, r4, #128	; 0x80
70001386:	b672      	cpsid	i
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	while ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_THRE) == 0) {
70001388:	f04f 0c05 	mov.w	ip, #5
		port = DEVICE_MMIO_GET(dev);
7000138c:	6842      	ldr	r2, [r0, #4]
	while ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_THRE) == 0) {
7000138e:	7d13      	ldrb	r3, [r2, #20]
70001390:	6812      	ldr	r2, [r2, #0]
70001392:	fb1c 2303 	smlabb	r3, ip, r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001396:	681b      	ldr	r3, [r3, #0]
70001398:	f3bf 8f5f 	dmb	sy
7000139c:	069b      	lsls	r3, r3, #26
7000139e:	d5f5      	bpl.n	7000138c <uart_ns16550_poll_out+0x10>
		port = DEVICE_MMIO_GET(dev);
700013a0:	6843      	ldr	r3, [r0, #4]
700013a2:	681b      	ldr	r3, [r3, #0]
700013a4:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700013a8:	6019      	str	r1, [r3, #0]
#elif defined(CONFIG_ARMV7_M_ARMV8_M_MAINLINE)
	__set_BASEPRI(key);
	__ISB();
#elif defined(CONFIG_ARMV7_R) || defined(CONFIG_AARCH32_ARMV8_R) \
	|| defined(CONFIG_ARMV7_A)
	if (key != 0U) {
700013aa:	b904      	cbnz	r4, 700013ae <uart_ns16550_poll_out+0x32>
  \details Enables IRQ interrupts by clearing the I-bit in the CPSR.
           Can only be executed in Privileged modes.
 */
__STATIC_FORCEINLINE void __enable_irq(void)
{
  __ASM volatile ("cpsie i" : : : "memory");
700013ac:	b662      	cpsie	i
	}

	ns16550_outbyte(dev_cfg, THR(dev), c);

	k_spin_unlock(&data->lock, key);
}
700013ae:	bc10      	pop	{r4}
700013b0:	4770      	bx	lr
700013b2:	bf00      	nop

700013b4 <uart_ns16550_err_check>:
	__asm__ volatile(
700013b4:	f3ef 8200 	mrs	r2, CPSR
700013b8:	f002 0280 	and.w	r2, r2, #128	; 0x80
700013bc:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700013be:	6843      	ldr	r3, [r0, #4]
static int uart_ns16550_err_check(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);
	int check = (ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_EOB_MASK);
700013c0:	7d19      	ldrb	r1, [r3, #20]
700013c2:	2005      	movs	r0, #5
700013c4:	681b      	ldr	r3, [r3, #0]
700013c6:	fb10 3001 	smlabb	r0, r0, r1, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700013ca:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700013cc:	f3bf 8f5f 	dmb	sy
	if (key != 0U) {
700013d0:	b902      	cbnz	r2, 700013d4 <uart_ns16550_err_check+0x20>
  __ASM volatile ("cpsie i" : : : "memory");
700013d2:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return check >> 1;
}
700013d4:	f3c0 0043 	ubfx	r0, r0, #1, #4
700013d8:	4770      	bx	lr
700013da:	bf00      	nop

700013dc <uart_ns16550_fifo_fill>:
 * @return Number of bytes sent
 */
static int uart_ns16550_fifo_fill(const struct device *dev,
				  const uint8_t *tx_data,
				  int size)
{
700013dc:	b470      	push	{r4, r5, r6}
	struct uart_ns16550_dev_data *data = dev->data;
700013de:	6905      	ldr	r5, [r0, #16]
	__asm__ volatile(
700013e0:	f3ef 8600 	mrs	r6, CPSR
700013e4:	f006 0680 	and.w	r6, r6, #128	; 0x80
700013e8:	b672      	cpsid	i
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	int i;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
700013ea:	2a00      	cmp	r2, #0
700013ec:	dd15      	ble.n	7000141a <uart_ns16550_fifo_fill+0x3e>
700013ee:	4684      	mov	ip, r0
700013f0:	3901      	subs	r1, #1
700013f2:	2000      	movs	r0, #0
700013f4:	e00a      	b.n	7000140c <uart_ns16550_fifo_fill+0x30>
		port = DEVICE_MMIO_GET(dev);
700013f6:	f8dc 4004 	ldr.w	r4, [ip, #4]
			sys_write32(val, port);
700013fa:	f811 3f01 	ldrb.w	r3, [r1, #1]!
		port = DEVICE_MMIO_GET(dev);
700013fe:	6824      	ldr	r4, [r4, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001400:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001404:	6023      	str	r3, [r4, #0]
	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
70001406:	3001      	adds	r0, #1
70001408:	4282      	cmp	r2, r0
7000140a:	d002      	beq.n	70001412 <uart_ns16550_fifo_fill+0x36>
7000140c:	7a2b      	ldrb	r3, [r5, #8]
7000140e:	4283      	cmp	r3, r0
70001410:	dcf1      	bgt.n	700013f6 <uart_ns16550_fifo_fill+0x1a>
	if (key != 0U) {
70001412:	b906      	cbnz	r6, 70001416 <uart_ns16550_fifo_fill+0x3a>
  __ASM volatile ("cpsie i" : : : "memory");
70001414:	b662      	cpsie	i
	}

	k_spin_unlock(&data->lock, key);

	return i;
}
70001416:	bc70      	pop	{r4, r5, r6}
70001418:	4770      	bx	lr
	for (i = 0; (i < size) && (i < data->fifo_size); i++) {
7000141a:	2000      	movs	r0, #0
7000141c:	e7f9      	b.n	70001412 <uart_ns16550_fifo_fill+0x36>
7000141e:	bf00      	nop

70001420 <uart_ns16550_irq_tx_enable>:
	__asm__ volatile(
70001420:	f3ef 8100 	mrs	r1, CPSR
70001424:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001428:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000142a:	6843      	ldr	r3, [r0, #4]
		for (uint8_t i = 0U; i < num_cpu_states; i++) {
			pm_policy_state_lock_get(cpu_states[i].state, PM_ALL_SUBSTATES);
		}
	}
#endif
	ns16550_outbyte(dev_cfg, IER(dev), ns16550_inbyte(dev_cfg, IER(dev)) | IER_TBE);
7000142c:	7d1a      	ldrb	r2, [r3, #20]
7000142e:	681b      	ldr	r3, [r3, #0]
70001430:	441a      	add	r2, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001432:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001434:	f3bf 8f5f 	dmb	sy
70001438:	f3bf 8f5f 	dmb	sy
7000143c:	f043 0302 	orr.w	r3, r3, #2
			sys_write32(val, port);
70001440:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001442:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
70001444:	b901      	cbnz	r1, 70001448 <uart_ns16550_irq_tx_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
70001446:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);
}
70001448:	4770      	bx	lr
7000144a:	bf00      	nop

7000144c <uart_ns16550_irq_tx_disable>:
	__asm__ volatile(
7000144c:	f3ef 8100 	mrs	r1, CPSR
70001450:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001454:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70001456:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
70001458:	7d13      	ldrb	r3, [r2, #20]
7000145a:	6812      	ldr	r2, [r2, #0]
7000145c:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000145e:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001460:	f3bf 8f5f 	dmb	sy
70001464:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
70001468:	f002 02fd 	and.w	r2, r2, #253	; 0xfd
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000146c:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
7000146e:	b901      	cbnz	r1, 70001472 <uart_ns16550_irq_tx_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
70001470:	b662      	cpsie	i
			pm_policy_state_lock_put(cpu_states[i].state, PM_ALL_SUBSTATES);
		}
	}
#endif
	k_spin_unlock(&data->lock, key);
}
70001472:	4770      	bx	lr

70001474 <uart_ns16550_irq_tx_ready>:
	__asm__ volatile(
70001474:	f3ef 8300 	mrs	r3, CPSR
70001478:	f003 0380 	and.w	r3, r3, #128	; 0x80
7000147c:	b672      	cpsid	i
static int uart_ns16550_irq_tx_ready(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((IIRC(dev) & IIR_ID) == IIR_THRE) ? 1 : 0;
7000147e:	6902      	ldr	r2, [r0, #16]
70001480:	7a50      	ldrb	r0, [r2, #9]
70001482:	f000 0006 	and.w	r0, r0, #6
70001486:	f1a0 0002 	sub.w	r0, r0, #2
7000148a:	fab0 f080 	clz	r0, r0
7000148e:	0940      	lsrs	r0, r0, #5
	if (key != 0U) {
70001490:	b903      	cbnz	r3, 70001494 <uart_ns16550_irq_tx_ready+0x20>
70001492:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
70001494:	4770      	bx	lr
70001496:	bf00      	nop

70001498 <uart_ns16550_irq_tx_complete>:
	__asm__ volatile(
70001498:	f3ef 8200 	mrs	r2, CPSR
7000149c:	f002 0280 	and.w	r2, r2, #128	; 0x80
700014a0:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700014a2:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((ns16550_inbyte(dev_cfg, LSR(dev)) & (LSR_TEMT | LSR_THRE))
700014a4:	7d19      	ldrb	r1, [r3, #20]
700014a6:	2005      	movs	r0, #5
700014a8:	681b      	ldr	r3, [r3, #0]
700014aa:	fb10 3001 	smlabb	r0, r0, r1, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700014ae:	6800      	ldr	r0, [r0, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700014b0:	f3bf 8f5f 	dmb	sy
				== (LSR_TEMT | LSR_THRE)) ? 1 : 0;
700014b4:	f000 0060 	and.w	r0, r0, #96	; 0x60
700014b8:	f1a0 0060 	sub.w	r0, r0, #96	; 0x60
700014bc:	fab0 f080 	clz	r0, r0
700014c0:	0940      	lsrs	r0, r0, #5
	if (key != 0U) {
700014c2:	b902      	cbnz	r2, 700014c6 <uart_ns16550_irq_tx_complete+0x2e>
  __ASM volatile ("cpsie i" : : : "memory");
700014c4:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
700014c6:	4770      	bx	lr

700014c8 <uart_ns16550_irq_rx_enable>:
	__asm__ volatile(
700014c8:	f3ef 8100 	mrs	r1, CPSR
700014cc:	f001 0180 	and.w	r1, r1, #128	; 0x80
700014d0:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700014d2:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev), ns16550_inbyte(dev_cfg, IER(dev)) | IER_RXRDY);
700014d4:	7d1a      	ldrb	r2, [r3, #20]
700014d6:	681b      	ldr	r3, [r3, #0]
700014d8:	441a      	add	r2, r3
700014da:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700014dc:	f3bf 8f5f 	dmb	sy
700014e0:	f3bf 8f5f 	dmb	sy
700014e4:	f043 0301 	orr.w	r3, r3, #1
			sys_write32(val, port);
700014e8:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700014ea:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
700014ec:	b901      	cbnz	r1, 700014f0 <uart_ns16550_irq_rx_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
700014ee:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);
}
700014f0:	4770      	bx	lr
700014f2:	bf00      	nop

700014f4 <uart_ns16550_irq_rx_disable>:
	__asm__ volatile(
700014f4:	f3ef 8100 	mrs	r1, CPSR
700014f8:	f001 0180 	and.w	r1, r1, #128	; 0x80
700014fc:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700014fe:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
70001500:	7d13      	ldrb	r3, [r2, #20]
70001502:	6812      	ldr	r2, [r2, #0]
70001504:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001506:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001508:	f3bf 8f5f 	dmb	sy
7000150c:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
70001510:	f002 02fe 	and.w	r2, r2, #254	; 0xfe
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001514:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
70001516:	b901      	cbnz	r1, 7000151a <uart_ns16550_irq_rx_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
70001518:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) & (~IER_RXRDY));

	k_spin_unlock(&data->lock, key);
}
7000151a:	4770      	bx	lr

7000151c <uart_ns16550_irq_rx_ready>:
	__asm__ volatile(
7000151c:	f3ef 8300 	mrs	r3, CPSR
70001520:	f003 0380 	and.w	r3, r3, #128	; 0x80
70001524:	b672      	cpsid	i
static int uart_ns16550_irq_rx_ready(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = ((IIRC(dev) & IIR_ID) == IIR_RBRF) ? 1 : 0;
70001526:	6902      	ldr	r2, [r0, #16]
70001528:	7a50      	ldrb	r0, [r2, #9]
7000152a:	f000 0006 	and.w	r0, r0, #6
7000152e:	f1a0 0004 	sub.w	r0, r0, #4
70001532:	fab0 f080 	clz	r0, r0
70001536:	0940      	lsrs	r0, r0, #5
	if (key != 0U) {
70001538:	b903      	cbnz	r3, 7000153c <uart_ns16550_irq_rx_ready+0x20>
7000153a:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
7000153c:	4770      	bx	lr
7000153e:	bf00      	nop

70001540 <uart_ns16550_irq_err_enable>:
	__asm__ volatile(
70001540:	f3ef 8100 	mrs	r1, CPSR
70001544:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001548:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
7000154a:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
7000154c:	7d1a      	ldrb	r2, [r3, #20]
7000154e:	681b      	ldr	r3, [r3, #0]
70001550:	441a      	add	r2, r3
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001552:	6813      	ldr	r3, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001554:	f3bf 8f5f 	dmb	sy
70001558:	f3bf 8f5f 	dmb	sy
7000155c:	f043 0304 	orr.w	r3, r3, #4
			sys_write32(val, port);
70001560:	b2db      	uxtb	r3, r3
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001562:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
70001564:	b901      	cbnz	r1, 70001568 <uart_ns16550_irq_err_enable+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
70001566:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) | IER_LSR);

	k_spin_unlock(&data->lock, key);
}
70001568:	4770      	bx	lr
7000156a:	bf00      	nop

7000156c <uart_ns16550_irq_err_disable>:
	__asm__ volatile(
7000156c:	f3ef 8100 	mrs	r1, CPSR
70001570:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001574:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
70001576:	6842      	ldr	r2, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	ns16550_outbyte(dev_cfg, IER(dev),
70001578:	7d13      	ldrb	r3, [r2, #20]
7000157a:	6812      	ldr	r2, [r2, #0]
7000157c:	4413      	add	r3, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000157e:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001580:	f3bf 8f5f 	dmb	sy
70001584:	f3bf 8f5f 	dmb	sy
			sys_write32(val, port);
70001588:	f002 02fb 	and.w	r2, r2, #251	; 0xfb
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000158c:	601a      	str	r2, [r3, #0]
	if (key != 0U) {
7000158e:	b901      	cbnz	r1, 70001592 <uart_ns16550_irq_err_disable+0x26>
  __ASM volatile ("cpsie i" : : : "memory");
70001590:	b662      	cpsie	i
			ns16550_inbyte(dev_cfg, IER(dev)) & (~IER_LSR));

	k_spin_unlock(&data->lock, key);
}
70001592:	4770      	bx	lr

70001594 <uart_ns16550_irq_is_pending>:
	__asm__ volatile(
70001594:	f3ef 8300 	mrs	r3, CPSR
70001598:	f003 0380 	and.w	r3, r3, #128	; 0x80
7000159c:	b672      	cpsid	i
static int uart_ns16550_irq_is_pending(const struct device *dev)
{
	struct uart_ns16550_dev_data *data = dev->data;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	int ret = (!(IIRC(dev) & IIR_NIP)) ? 1 : 0;
7000159e:	6902      	ldr	r2, [r0, #16]
700015a0:	7a50      	ldrb	r0, [r2, #9]
700015a2:	43c0      	mvns	r0, r0
700015a4:	f000 0001 	and.w	r0, r0, #1
	if (key != 0U) {
700015a8:	b903      	cbnz	r3, 700015ac <uart_ns16550_irq_is_pending+0x18>
700015aa:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return ret;
}
700015ac:	4770      	bx	lr
700015ae:	bf00      	nop

700015b0 <uart_ns16550_irq_update>:
	__asm__ volatile(
700015b0:	f3ef 8200 	mrs	r2, CPSR
700015b4:	f002 0280 	and.w	r2, r2, #128	; 0x80
700015b8:	b672      	cpsid	i
		port = DEVICE_MMIO_GET(dev);
700015ba:	6843      	ldr	r3, [r0, #4]
{
	struct uart_ns16550_dev_data *data = dev->data;
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
	k_spinlock_key_t key = k_spin_lock(&data->lock);

	IIRC(dev) = ns16550_inbyte(dev_cfg, IIR(dev));
700015bc:	6901      	ldr	r1, [r0, #16]
700015be:	7d18      	ldrb	r0, [r3, #20]
700015c0:	681b      	ldr	r3, [r3, #0]
700015c2:	eb03 0340 	add.w	r3, r3, r0, lsl #1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700015c6:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700015c8:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
700015cc:	724b      	strb	r3, [r1, #9]
	if (key != 0U) {
700015ce:	b902      	cbnz	r2, 700015d2 <uart_ns16550_irq_update+0x22>
  __ASM volatile ("cpsie i" : : : "memory");
700015d0:	b662      	cpsie	i

	k_spin_unlock(&data->lock, key);

	return 1;
}
700015d2:	2001      	movs	r0, #1
700015d4:	4770      	bx	lr
700015d6:	bf00      	nop

700015d8 <uart_ns16550_irq_callback_set>:
 */
static void uart_ns16550_irq_callback_set(const struct device *dev,
					  uart_irq_callback_user_data_t cb,
					  void *cb_data)
{
	struct uart_ns16550_dev_data * const dev_data = dev->data;
700015d8:	6903      	ldr	r3, [r0, #16]
	__asm__ volatile(
700015da:	f3ef 8000 	mrs	r0, CPSR
700015de:	f000 0080 	and.w	r0, r0, #128	; 0x80
700015e2:	b672      	cpsid	i
	k_spinlock_key_t key = k_spin_lock(&dev_data->lock);

	dev_data->cb = cb;
	dev_data->cb_data = cb_data;
700015e4:	e9c3 1203 	strd	r1, r2, [r3, #12]
	if (key != 0U) {
700015e8:	b900      	cbnz	r0, 700015ec <uart_ns16550_irq_callback_set+0x14>
700015ea:	b662      	cpsie	i

	k_spin_unlock(&dev_data->lock, key);
}
700015ec:	4770      	bx	lr
700015ee:	bf00      	nop

700015f0 <uart_ns16550_isr>:
 *
 * @param arg Argument to ISR.
 */
static void uart_ns16550_isr(const struct device *dev)
{
	struct uart_ns16550_dev_data * const dev_data = dev->data;
700015f0:	6902      	ldr	r2, [r0, #16]
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;

	if (dev_data->cb) {
700015f2:	68d3      	ldr	r3, [r2, #12]
700015f4:	b10b      	cbz	r3, 700015fa <uart_ns16550_isr+0xa>
		dev_data->cb(dev, dev_data->cb_data);
700015f6:	6911      	ldr	r1, [r2, #16]
700015f8:	4718      	bx	r3
	uint8_t cached_ier = ns16550_inbyte(dev_cfg, IER(dev));

	ns16550_outbyte(dev_cfg, IER(dev), 0U);
	ns16550_outbyte(dev_cfg, IER(dev), cached_ier);
#endif
}
700015fa:	4770      	bx	lr

700015fc <uart_ns16550_irq_config_func0>:
#define UART_NS16550_DEVICE_INIT(n)                                                  \
	COND_CODE_1(DT_INST_ON_BUS(n, pcie),                                         \
		    (UART_NS16550_DEVICE_PCIE_INIT(n)),                              \
		    (UART_NS16550_DEVICE_IO_MMIO_INIT(n)))

DT_INST_FOREACH_STATUS_OKAY(UART_NS16550_DEVICE_INIT)
700015fc:	20d2      	movs	r0, #210	; 0xd2
700015fe:	2200      	movs	r2, #0
70001600:	b508      	push	{r3, lr}
70001602:	210f      	movs	r1, #15
70001604:	f7ff fa26 	bl	70000a54 <z_soc_irq_priority_set>
70001608:	e8bd 4008 	ldmia.w	sp!, {r3, lr}
7000160c:	20d2      	movs	r0, #210	; 0xd2
7000160e:	f7ff ba23 	b.w	70000a58 <z_soc_irq_enable>
70001612:	bf00      	nop

70001614 <uart_ns16550_configure>:
{
70001614:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
	uint32_t pclk = 0U;
70001618:	f04f 0900 	mov.w	r9, #0
{
7000161c:	b083      	sub	sp, #12
	struct uart_ns16550_dev_data * const dev_data = dev->data;
7000161e:	6906      	ldr	r6, [r0, #16]
{
70001620:	4604      	mov	r4, r0
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
70001622:	f8d0 8004 	ldr.w	r8, [r0, #4]
{
70001626:	460d      	mov	r5, r1
	uint32_t pclk = 0U;
70001628:	f8cd 9000 	str.w	r9, [sp]
	__asm__ volatile(
7000162c:	f3ef 8700 	mrs	r7, CPSR
70001630:	f007 0780 	and.w	r7, r7, #128	; 0x80
70001634:	b672      	cpsid	i
	if (dev_cfg->pincfg != NULL) {
70001636:	f8d8 0018 	ldr.w	r0, [r8, #24]
7000163a:	b158      	cbz	r0, 70001654 <uart_ns16550_configure+0x40>
				      uint8_t id)
{
	int ret;
	const struct pinctrl_state *state;

	ret = pinctrl_lookup_state(config, id, &state);
7000163c:	4649      	mov	r1, r9
7000163e:	aa01      	add	r2, sp, #4
70001640:	f7ff fe4a 	bl	700012d8 <pinctrl_lookup_state>
	if (ret < 0) {
70001644:	4548      	cmp	r0, r9
70001646:	db05      	blt.n	70001654 <uart_ns16550_configure+0x40>
		return ret;
	}

	return pinctrl_apply_state_direct(config, state);
70001648:	9b01      	ldr	r3, [sp, #4]
	return pinctrl_configure_pins(state->pins, state->pin_cnt, reg);
7000164a:	464a      	mov	r2, r9
7000164c:	7919      	ldrb	r1, [r3, #4]
7000164e:	6818      	ldr	r0, [r3, #0]
70001650:	f7ff fe70 	bl	70001334 <pinctrl_configure_pins>
	dev_data->iir_cache = 0U;
70001654:	2300      	movs	r3, #0
	uint32_t mdr = ns16550_inbyte(dev_cfg, MDR1(dev));
70001656:	2208      	movs	r2, #8
	dev_data->iir_cache = 0U;
70001658:	7273      	strb	r3, [r6, #9]
		port = DEVICE_MMIO_GET(dev);
7000165a:	6861      	ldr	r1, [r4, #4]
	uint32_t mdr = ns16550_inbyte(dev_cfg, MDR1(dev));
7000165c:	7d0b      	ldrb	r3, [r1, #20]
7000165e:	6809      	ldr	r1, [r1, #0]
70001660:	fb12 1303 	smlabb	r3, r2, r3, r1
70001664:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001666:	f3bf 8f5f 	dmb	sy
		port = DEVICE_MMIO_GET(dev);
7000166a:	6861      	ldr	r1, [r4, #4]
	ns16550_outbyte(dev_cfg, MDR1(dev), mdr);
7000166c:	7d08      	ldrb	r0, [r1, #20]
7000166e:	6809      	ldr	r1, [r1, #0]
70001670:	fb12 1200 	smlabb	r2, r2, r0, r1
70001674:	f3bf 8f5f 	dmb	sy
	mdr = ((mdr & ~MDR1_MODE_SELECT_FIELD_MASK) | ((((MDR1_STD_MODE) <<
70001678:	f003 03f8 	and.w	r3, r3, #248	; 0xf8
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000167c:	6013      	str	r3, [r2, #0]
	if (dev_cfg->sys_clk_freq != 0U) {
7000167e:	f8d8 3004 	ldr.w	r3, [r8, #4]
70001682:	2b00      	cmp	r3, #0
70001684:	f000 80ad 	beq.w	700017e2 <uart_ns16550_configure+0x1ce>
		pclk = dev_cfg->sys_clk_freq;
70001688:	9300      	str	r3, [sp, #0]
	set_baud_rate(dev, cfg->baudrate, pclk);
7000168a:	6829      	ldr	r1, [r5, #0]
	if ((baud_rate != 0U) && (pclk != 0U)) {
7000168c:	2900      	cmp	r1, #0
7000168e:	bf18      	it	ne
70001690:	2b00      	cmpne	r3, #0
70001692:	d168      	bne.n	70001766 <uart_ns16550_configure+0x152>
	switch (cfg->data_bits) {
70001694:	79aa      	ldrb	r2, [r5, #6]
70001696:	2a03      	cmp	r2, #3
70001698:	d862      	bhi.n	70001760 <uart_ns16550_configure+0x14c>
	switch (cfg->stop_bits) {
7000169a:	796b      	ldrb	r3, [r5, #5]
7000169c:	2b01      	cmp	r3, #1
7000169e:	f000 80af 	beq.w	70001800 <uart_ns16550_configure+0x1ec>
700016a2:	2b03      	cmp	r3, #3
700016a4:	bf08      	it	eq
700016a6:	f04f 0e04 	moveq.w	lr, #4
700016aa:	d159      	bne.n	70001760 <uart_ns16550_configure+0x14c>
	switch (cfg->parity) {
700016ac:	792b      	ldrb	r3, [r5, #4]
700016ae:	b113      	cbz	r3, 700016b6 <uart_ns16550_configure+0xa2>
700016b0:	2b02      	cmp	r3, #2
700016b2:	d155      	bne.n	70001760 <uart_ns16550_configure+0x14c>
700016b4:	2310      	movs	r3, #16
	dev_data->uart_config = *cfg;
700016b6:	e895 0003 	ldmia.w	r5, {r0, r1}
	ns16550_outbyte(dev_cfg, LCR(dev),
700016ba:	f04f 0c03 	mov.w	ip, #3
	dev_data->uart_config = *cfg;
700016be:	e886 0003 	stmia.w	r6, {r0, r1}
		port = DEVICE_MMIO_GET(dev);
700016c2:	6861      	ldr	r1, [r4, #4]
	ns16550_outbyte(dev_cfg, LCR(dev),
700016c4:	7d08      	ldrb	r0, [r1, #20]
700016c6:	6809      	ldr	r1, [r1, #0]
700016c8:	fb1c 1c00 	smlabb	ip, ip, r0, r1
700016cc:	f3bf 8f5f 	dmb	sy
700016d0:	ea42 020e 	orr.w	r2, r2, lr
			sys_write32(val, port);
700016d4:	4313      	orrs	r3, r2
700016d6:	f8cc 3000 	str.w	r3, [ip]
		port = DEVICE_MMIO_GET(dev);
700016da:	6862      	ldr	r2, [r4, #4]
	if (cfg->flow_ctrl == UART_CFG_FLOW_CTRL_RTS_CTS) {
700016dc:	79eb      	ldrb	r3, [r5, #7]
700016de:	2b01      	cmp	r3, #1
700016e0:	bf0c      	ite	eq
700016e2:	212b      	moveq	r1, #43	; 0x2b
700016e4:	210b      	movne	r1, #11
	ns16550_outbyte(dev_cfg, MDC(dev), mdc);
700016e6:	6813      	ldr	r3, [r2, #0]
700016e8:	7d12      	ldrb	r2, [r2, #20]
700016ea:	eb03 0382 	add.w	r3, r3, r2, lsl #2
700016ee:	f3bf 8f5f 	dmb	sy
700016f2:	6019      	str	r1, [r3, #0]
		port = DEVICE_MMIO_GET(dev);
700016f4:	6863      	ldr	r3, [r4, #4]
	ns16550_outbyte(dev_cfg, FCR(dev),
700016f6:	7d1a      	ldrb	r2, [r3, #20]
700016f8:	6819      	ldr	r1, [r3, #0]
700016fa:	2302      	movs	r3, #2
700016fc:	fb13 1202 	smlabb	r2, r3, r2, r1
70001700:	f3bf 8f5f 	dmb	sy
70001704:	21a7      	movs	r1, #167	; 0xa7
70001706:	6011      	str	r1, [r2, #0]
		port = DEVICE_MMIO_GET(dev);
70001708:	6862      	ldr	r2, [r4, #4]
	if ((ns16550_inbyte(dev_cfg, IIR(dev)) & IIR_FE) == IIR_FE) {
7000170a:	7d11      	ldrb	r1, [r2, #20]
7000170c:	6812      	ldr	r2, [r2, #0]
7000170e:	fb13 2301 	smlabb	r3, r3, r1, r2
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001712:	681b      	ldr	r3, [r3, #0]
70001714:	f3bf 8f5f 	dmb	sy
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
70001718:	2205      	movs	r2, #5
	if ((ns16550_inbyte(dev_cfg, IIR(dev)) & IIR_FE) == IIR_FE) {
7000171a:	f003 03c0 	and.w	r3, r3, #192	; 0xc0
		dev_data->fifo_size = 64;
7000171e:	2bc0      	cmp	r3, #192	; 0xc0
70001720:	bf14      	ite	ne
70001722:	2301      	movne	r3, #1
70001724:	2340      	moveq	r3, #64	; 0x40
70001726:	7233      	strb	r3, [r6, #8]
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
70001728:	6863      	ldr	r3, [r4, #4]
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
7000172a:	7d19      	ldrb	r1, [r3, #20]
7000172c:	681b      	ldr	r3, [r3, #0]
7000172e:	fb12 3301 	smlabb	r3, r2, r1, r3
70001732:	681b      	ldr	r3, [r3, #0]
70001734:	f3bf 8f5f 	dmb	sy
70001738:	07db      	lsls	r3, r3, #31
7000173a:	d504      	bpl.n	70001746 <uart_ns16550_configure+0x132>
		port = DEVICE_MMIO_GET(dev);
7000173c:	6863      	ldr	r3, [r4, #4]
7000173e:	681b      	ldr	r3, [r3, #0]
70001740:	681b      	ldr	r3, [r3, #0]
70001742:	f3bf 8f5f 	dmb	sy
70001746:	6862      	ldr	r2, [r4, #4]
	ns16550_outbyte(dev_cfg, IER(dev), 0x00);
70001748:	7d13      	ldrb	r3, [r2, #20]
7000174a:	6812      	ldr	r2, [r2, #0]
7000174c:	4413      	add	r3, r2
7000174e:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001752:	2000      	movs	r0, #0
70001754:	6018      	str	r0, [r3, #0]
	if (key != 0U) {
70001756:	b907      	cbnz	r7, 7000175a <uart_ns16550_configure+0x146>
  __ASM volatile ("cpsie i" : : : "memory");
70001758:	b662      	cpsie	i
};
7000175a:	b003      	add	sp, #12
7000175c:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	switch (cfg->parity) {
70001760:	f06f 0085 	mvn.w	r0, #133	; 0x85
70001764:	e7f7      	b.n	70001756 <uart_ns16550_configure+0x142>
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
70001766:	6860      	ldr	r0, [r4, #4]
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
70001768:	7d02      	ldrb	r2, [r0, #20]
7000176a:	f04f 0c03 	mov.w	ip, #3
	return ((pclk + (baud_rate << 3)) / baud_rate) >> 4;
7000176e:	eb03 03c1 	add.w	r3, r3, r1, lsl #3
	struct uart_ns16550_dev_data * const dev_data = dev->data;
70001772:	f8d4 e010 	ldr.w	lr, [r4, #16]
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
70001776:	6800      	ldr	r0, [r0, #0]
	return ((pclk + (baud_rate << 3)) / baud_rate) >> 4;
70001778:	fbb3 f3f1 	udiv	r3, r3, r1
		lcr_cache = ns16550_inbyte(dev_cfg, LCR(dev));
7000177c:	fb1c 0202 	smlabb	r2, ip, r2, r0
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001780:	6812      	ldr	r2, [r2, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001782:	f3bf 8f5f 	dmb	sy
		port = DEVICE_MMIO_GET(dev);
70001786:	6860      	ldr	r0, [r4, #4]
		ns16550_outbyte(dev_cfg, LCR(dev), LCR_DLAB | lcr_cache);
70001788:	f890 8014 	ldrb.w	r8, [r0, #20]
7000178c:	6800      	ldr	r0, [r0, #0]
7000178e:	fb1c 0808 	smlabb	r8, ip, r8, r0
70001792:	f3bf 8f5f 	dmb	sy
70001796:	f062 007f 	orn	r0, r2, #127	; 0x7f
			sys_write32(val, port);
7000179a:	b2c0      	uxtb	r0, r0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000179c:	f8c8 0000 	str.w	r0, [r8]
		port = DEVICE_MMIO_GET(dev);
700017a0:	6860      	ldr	r0, [r4, #4]
700017a2:	f8d0 8000 	ldr.w	r8, [r0]
700017a6:	f3bf 8f5f 	dmb	sy
700017aa:	f3c3 1007 	ubfx	r0, r3, #4, #8
700017ae:	f8c8 0000 	str.w	r0, [r8]
700017b2:	f8d4 8004 	ldr.w	r8, [r4, #4]
		ns16550_outbyte(dev_cfg, BRDH(dev), (unsigned char)((divisor >> 8) & 0xff));
700017b6:	f898 0014 	ldrb.w	r0, [r8, #20]
700017ba:	f8d8 8000 	ldr.w	r8, [r8]
700017be:	4440      	add	r0, r8
700017c0:	f3bf 8f5f 	dmb	sy
700017c4:	f3c3 3307 	ubfx	r3, r3, #12, #8
700017c8:	6003      	str	r3, [r0, #0]
		port = DEVICE_MMIO_GET(dev);
700017ca:	6863      	ldr	r3, [r4, #4]
		ns16550_outbyte(dev_cfg, LCR(dev), lcr_cache);
700017cc:	7d18      	ldrb	r0, [r3, #20]
700017ce:	681b      	ldr	r3, [r3, #0]
700017d0:	fb1c 3300 	smlabb	r3, ip, r0, r3
700017d4:	f3bf 8f5f 	dmb	sy
700017d8:	b2d2      	uxtb	r2, r2
700017da:	601a      	str	r2, [r3, #0]
		dev_data->uart_config.baudrate = baud_rate;
700017dc:	f8ce 1000 	str.w	r1, [lr]
700017e0:	e758      	b.n	70001694 <uart_ns16550_configure+0x80>
		if (!device_is_ready(dev_cfg->clock_dev)) {
700017e2:	f8d8 0008 	ldr.w	r0, [r8, #8]
700017e6:	f000 f945 	bl	70001a74 <z_impl_device_is_ready>
700017ea:	b180      	cbz	r0, 7000180e <uart_ns16550_configure+0x1fa>
					   dev_cfg->clock_subsys,
700017ec:	e9d8 0102 	ldrd	r0, r1, [r8, #8]
					 uint32_t *rate)
{
	const struct clock_control_driver_api *api =
		(const struct clock_control_driver_api *)dev->api;

	if (api->get_rate == NULL) {
700017f0:	6883      	ldr	r3, [r0, #8]
700017f2:	68db      	ldr	r3, [r3, #12]
700017f4:	b15b      	cbz	r3, 7000180e <uart_ns16550_configure+0x1fa>
		return -ENOSYS;
	}

	return api->get_rate(dev, sys, rate);
700017f6:	466a      	mov	r2, sp
700017f8:	4798      	blx	r3
		if (clock_control_get_rate(dev_cfg->clock_dev,
700017fa:	b940      	cbnz	r0, 7000180e <uart_ns16550_configure+0x1fa>
	set_baud_rate(dev, cfg->baudrate, pclk);
700017fc:	9b00      	ldr	r3, [sp, #0]
700017fe:	e744      	b.n	7000168a <uart_ns16550_configure+0x76>
		uart_cfg.stop_bits = LCR_1_STB;
70001800:	f04f 0e00 	mov.w	lr, #0
	switch (cfg->parity) {
70001804:	792b      	ldrb	r3, [r5, #4]
70001806:	2b00      	cmp	r3, #0
70001808:	f47f af52 	bne.w	700016b0 <uart_ns16550_configure+0x9c>
7000180c:	e753      	b.n	700016b6 <uart_ns16550_configure+0xa2>
			ret = -EINVAL;
7000180e:	f06f 0015 	mvn.w	r0, #21
70001812:	e7a0      	b.n	70001756 <uart_ns16550_configure+0x142>

70001814 <uart_ns16550_init>:
{
70001814:	b570      	push	{r4, r5, r6, lr}
	ret = uart_ns16550_configure(dev, &data->uart_config);
70001816:	6901      	ldr	r1, [r0, #16]
{
70001818:	4604      	mov	r4, r0
	const struct uart_ns16550_dev_config *dev_cfg = dev->config;
7000181a:	6846      	ldr	r6, [r0, #4]
	ret = uart_ns16550_configure(dev, &data->uart_config);
7000181c:	f7ff fefa 	bl	70001614 <uart_ns16550_configure>
	if (ret != 0) {
70001820:	4605      	mov	r5, r0
70001822:	b910      	cbnz	r0, 7000182a <uart_ns16550_init+0x16>
	dev_cfg->irq_config_func(dev);
70001824:	6933      	ldr	r3, [r6, #16]
70001826:	4620      	mov	r0, r4
70001828:	4798      	blx	r3
}
7000182a:	4628      	mov	r0, r5
7000182c:	bd70      	pop	{r4, r5, r6, pc}
7000182e:	bf00      	nop

70001830 <uart_ns16550_fifo_read>:
{
70001830:	b530      	push	{r4, r5, lr}
	__asm__ volatile(
70001832:	f3ef 8400 	mrs	r4, CPSR
70001836:	f004 0480 	and.w	r4, r4, #128	; 0x80
7000183a:	b672      	cpsid	i
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
7000183c:	2a00      	cmp	r2, #0
7000183e:	dd1d      	ble.n	7000187c <uart_ns16550_fifo_read+0x4c>
70001840:	4686      	mov	lr, r0
70001842:	f101 3cff 	add.w	ip, r1, #4294967295	; 0xffffffff
70001846:	2000      	movs	r0, #0
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
70001848:	2505      	movs	r5, #5
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
7000184a:	f8de 1004 	ldr.w	r1, [lr, #4]
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
7000184e:	7d0b      	ldrb	r3, [r1, #20]
70001850:	6809      	ldr	r1, [r1, #0]
70001852:	fb15 1303 	smlabb	r3, r5, r3, r1
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001856:	681b      	ldr	r3, [r3, #0]
70001858:	f3bf 8f5f 	dmb	sy
7000185c:	07db      	lsls	r3, r3, #31
7000185e:	d50a      	bpl.n	70001876 <uart_ns16550_fifo_read+0x46>
		port = DEVICE_MMIO_GET(dev);
70001860:	f8de 3004 	ldr.w	r3, [lr, #4]
70001864:	681b      	ldr	r3, [r3, #0]
70001866:	681b      	ldr	r3, [r3, #0]
70001868:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
7000186c:	f80c 3f01 	strb.w	r3, [ip, #1]!
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
70001870:	3001      	adds	r0, #1
70001872:	4282      	cmp	r2, r0
70001874:	d1e9      	bne.n	7000184a <uart_ns16550_fifo_read+0x1a>
	if (key != 0U) {
70001876:	b904      	cbnz	r4, 7000187a <uart_ns16550_fifo_read+0x4a>
  __ASM volatile ("cpsie i" : : : "memory");
70001878:	b662      	cpsie	i
}
7000187a:	bd30      	pop	{r4, r5, pc}
	for (i = 0; (i < size) && (ns16550_read_char(dev, &rx_data[i]) != -1); i++) {
7000187c:	2000      	movs	r0, #0
7000187e:	e7fa      	b.n	70001876 <uart_ns16550_fifo_read+0x46>

70001880 <uart_ns16550_poll_in>:
{
70001880:	b410      	push	{r4}
	__asm__ volatile(
70001882:	f3ef 8200 	mrs	r2, CPSR
70001886:	f002 0280 	and.w	r2, r2, #128	; 0x80
7000188a:	b672      	cpsid	i
	const struct uart_ns16550_dev_config * const dev_cfg = dev->config;
7000188c:	6843      	ldr	r3, [r0, #4]
	if ((ns16550_inbyte(dev_cfg, LSR(dev)) & LSR_RXRDY) != 0) {
7000188e:	f893 c014 	ldrb.w	ip, [r3, #20]
70001892:	681c      	ldr	r4, [r3, #0]
70001894:	2305      	movs	r3, #5
70001896:	fb13 430c 	smlabb	r3, r3, ip, r4
7000189a:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
7000189c:	f3bf 8f5f 	dmb	sy
700018a0:	07db      	lsls	r3, r3, #31
700018a2:	d50a      	bpl.n	700018ba <uart_ns16550_poll_in+0x3a>
		port = DEVICE_MMIO_GET(dev);
700018a4:	6843      	ldr	r3, [r0, #4]
700018a6:	681b      	ldr	r3, [r3, #0]
700018a8:	681b      	ldr	r3, [r3, #0]
700018aa:	f3bf 8f5f 	dmb	sy
			return sys_read32(port);
700018ae:	700b      	strb	r3, [r1, #0]
		return 0;
700018b0:	2000      	movs	r0, #0
	if (key != 0U) {
700018b2:	b902      	cbnz	r2, 700018b6 <uart_ns16550_poll_in+0x36>
  __ASM volatile ("cpsie i" : : : "memory");
700018b4:	b662      	cpsie	i
}
700018b6:	bc10      	pop	{r4}
700018b8:	4770      	bx	lr
	return -1;
700018ba:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
700018be:	e7f8      	b.n	700018b2 <uart_ns16550_poll_in+0x32>

700018c0 <sys_clock_driver_init>:
	return delta_ticks;
}

static int sys_clock_driver_init(void)
{
	last_cycle = 0;
700018c0:	f647 6334 	movw	r3, #32308	; 0x7e34

	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
700018c4:	2202      	movs	r2, #2
{
700018c6:	b510      	push	{r4, lr}
	last_cycle = 0;
700018c8:	2400      	movs	r4, #0
700018ca:	f2c7 0300 	movt	r3, #28672	; 0x7000
	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
700018ce:	210f      	movs	r1, #15
700018d0:	209f      	movs	r0, #159	; 0x9f
	last_cycle = 0;
700018d2:	601c      	str	r4, [r3, #0]
	IRQ_CONNECT(TIMER_IRQ_NUM, TIMER_IRQ_PRIO, ti_dmtimer_isr, NULL, TIMER_IRQ_FLAGS);
700018d4:	f7ff f8be 	bl	70000a54 <z_soc_irq_priority_set>
700018d8:	2338      	movs	r3, #56	; 0x38
700018da:	f2c0 2347 	movt	r3, #583	; 0x247
700018de:	681a      	ldr	r2, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
700018e0:	f3bf 8f5f 	dmb	sy
700018e4:	f3bf 8f5f 	dmb	sy
	reg_val = (reg_val & ~(mask)) | (data << shift);
700018e8:	f022 0220 	bic.w	r2, r2, #32
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700018ec:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700018ee:	681a      	ldr	r2, [r3, #0]
700018f0:	f3bf 8f5f 	dmb	sy
700018f4:	f3bf 8f5f 	dmb	sy
700018f8:	f042 0202 	orr.w	r2, r2, #2
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700018fc:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
700018fe:	212c      	movs	r1, #44	; 0x2c
70001900:	f2c0 2147 	movt	r1, #583	; 0x247
70001904:	680a      	ldr	r2, [r1, #0]
70001906:	f3bf 8f5f 	dmb	sy
7000190a:	f3bf 8f5f 	dmb	sy
7000190e:	f042 0201 	orr.w	r2, r2, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001912:	600a      	str	r2, [r1, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001914:	223c      	movs	r2, #60	; 0x3c
70001916:	f2c0 2247 	movt	r2, #583	; 0x247
7000191a:	6811      	ldr	r1, [r2, #0]
7000191c:	f3bf 8f5f 	dmb	sy
70001920:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001924:	6014      	str	r4, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001926:	2240      	movs	r2, #64	; 0x40
70001928:	f2c0 2247 	movt	r2, #583	; 0x247
7000192c:	6811      	ldr	r1, [r2, #0]
7000192e:	f3bf 8f5f 	dmb	sy
70001932:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001936:	6014      	str	r4, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001938:	224c      	movs	r2, #76	; 0x4c
7000193a:	f2c0 2247 	movt	r2, #583	; 0x247
7000193e:	6811      	ldr	r1, [r2, #0]
70001940:	f3bf 8f5f 	dmb	sy
70001944:	f3bf 8f5f 	dmb	sy
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001948:	f246 11a8 	movw	r1, #25000	; 0x61a8
7000194c:	6011      	str	r1, [r2, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000194e:	681a      	ldr	r2, [r3, #0]
70001950:	f3bf 8f5f 	dmb	sy
70001954:	f3bf 8f5f 	dmb	sy
70001958:	f042 0240 	orr.w	r2, r2, #64	; 0x40
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000195c:	601a      	str	r2, [r3, #0]
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
7000195e:	681a      	ldr	r2, [r3, #0]
70001960:	f3bf 8f5f 	dmb	sy
70001964:	f3bf 8f5f 	dmb	sy
70001968:	f042 0201 	orr.w	r2, r2, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
7000196c:	601a      	str	r2, [r3, #0]
	TI_DM_TIMER_WRITE(1, TCLR, CE);

	/* Start the timer */
	TI_DM_TIMER_WRITE(1, TCLR, ST);

	irq_enable(TIMER_IRQ_NUM);
7000196e:	209f      	movs	r0, #159	; 0x9f
70001970:	f7ff f872 	bl	70000a58 <z_soc_irq_enable>

	return 0;
}
70001974:	4620      	mov	r0, r4
70001976:	bd10      	pop	{r4, pc}

70001978 <ti_dmtimer_isr>:
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001978:	2228      	movs	r2, #40	; 0x28
7000197a:	f2c0 2247 	movt	r2, #583	; 0x247
7000197e:	6813      	ldr	r3, [r2, #0]
70001980:	f3bf 8f5f 	dmb	sy
	if (!TI_DM_TIMER_READ(IRQSTATUS)) {
70001984:	b33b      	cbz	r3, 700019d6 <ti_dmtimer_isr+0x5e>
{
70001986:	b410      	push	{r4}
	__asm__ volatile(
70001988:	f3ef 8400 	mrs	r4, CPSR
7000198c:	f004 0480 	and.w	r4, r4, #128	; 0x80
70001990:	b672      	cpsid	i
70001992:	233c      	movs	r3, #60	; 0x3c
70001994:	f2c0 2347 	movt	r3, #583	; 0x247
70001998:	681b      	ldr	r3, [r3, #0]
7000199a:	f3bf 8f5f 	dmb	sy
	uint32_t delta_cycles = curr_cycle - last_cycle;
7000199e:	f647 6134 	movw	r1, #32308	; 0x7e34
700019a2:	f2c7 0100 	movt	r1, #28672	; 0x7000
700019a6:	6808      	ldr	r0, [r1, #0]
	last_cycle = curr_cycle;
700019a8:	600b      	str	r3, [r1, #0]
	uint32_t delta_cycles = curr_cycle - last_cycle;
700019aa:	1a18      	subs	r0, r3, r0
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
700019ac:	f24b 5389 	movw	r3, #46473	; 0xb589
700019b0:	f2c1 43f8 	movt	r3, #5368	; 0x14f8
700019b4:	08c0      	lsrs	r0, r0, #3
700019b6:	fba3 3000 	umull	r3, r0, r3, r0
700019ba:	0a00      	lsrs	r0, r0, #8
700019bc:	6813      	ldr	r3, [r2, #0]
700019be:	f3bf 8f5f 	dmb	sy
700019c2:	f3bf 8f5f 	dmb	sy
	reg_val = (reg_val & ~(mask)) | (data << shift);
700019c6:	f043 0301 	orr.w	r3, r3, #1
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
700019ca:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
700019cc:	b904      	cbnz	r4, 700019d0 <ti_dmtimer_isr+0x58>
  __ASM volatile ("cpsie i" : : : "memory");
700019ce:	b662      	cpsie	i
}
700019d0:	bc10      	pop	{r4}
	sys_clock_announce(delta_ticks);
700019d2:	f000 bfc5 	b.w	70002960 <sys_clock_announce>
700019d6:	4770      	bx	lr

700019d8 <sys_clock_set_timeout>:
	ticks = (ticks == K_TICKS_FOREVER) ? MAX_TICKS : ticks;
700019d8:	1c43      	adds	r3, r0, #1
700019da:	d028      	beq.n	70001a2e <sys_clock_set_timeout+0x56>
	ticks = CLAMP(ticks, 1, (int32_t)MAX_TICKS);
700019dc:	2801      	cmp	r0, #1
700019de:	bfd8      	it	le
700019e0:	f246 10a8 	movwle	r0, #25000	; 0x61a8
700019e4:	dd0a      	ble.n	700019fc <sys_clock_set_timeout+0x24>
700019e6:	f649 7315 	movw	r3, #40725	; 0x9f15
	uint32_t next_cycle = curr_cycle + (ticks * CYC_PER_TICK);
700019ea:	f246 12a8 	movw	r2, #25000	; 0x61a8
	ticks = CLAMP(ticks, 1, (int32_t)MAX_TICKS);
700019ee:	f2c0 0302 	movt	r3, #2
700019f2:	4298      	cmp	r0, r3
700019f4:	bfa8      	it	ge
700019f6:	4618      	movge	r0, r3
	uint32_t next_cycle = curr_cycle + (ticks * CYC_PER_TICK);
700019f8:	fb02 f000 	mul.w	r0, r2, r0
	__asm__ volatile(
700019fc:	f3ef 8100 	mrs	r1, CPSR
70001a00:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001a04:	b672      	cpsid	i
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001a06:	233c      	movs	r3, #60	; 0x3c
70001a08:	f2c0 2347 	movt	r3, #583	; 0x247
70001a0c:	681b      	ldr	r3, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001a0e:	f3bf 8f5f 	dmb	sy
70001a12:	224c      	movs	r2, #76	; 0x4c
70001a14:	f2c0 2247 	movt	r2, #583	; 0x247
70001a18:	f8d2 c000 	ldr.w	ip, [r2]
70001a1c:	f3bf 8f5f 	dmb	sy
70001a20:	f3bf 8f5f 	dmb	sy
70001a24:	4403      	add	r3, r0
	__asm__ volatile("str %0, [%1]" : : "r" (data), "r" (addr));
70001a26:	6013      	str	r3, [r2, #0]
	if (key != 0U) {
70001a28:	b901      	cbnz	r1, 70001a2c <sys_clock_set_timeout+0x54>
  __ASM volatile ("cpsie i" : : : "memory");
70001a2a:	b662      	cpsie	i
}
70001a2c:	4770      	bx	lr
70001a2e:	f645 20c8 	movw	r0, #23240	; 0x5ac8
70001a32:	f6cf 70ff 	movt	r0, #65535	; 0xffff
70001a36:	e7e1      	b.n	700019fc <sys_clock_set_timeout+0x24>

70001a38 <sys_clock_elapsed>:
	__asm__ volatile(
70001a38:	f3ef 8100 	mrs	r1, CPSR
70001a3c:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001a40:	b672      	cpsid	i
	__asm__ volatile("ldr %0, [%1]" : "=r" (val) : "r" (addr));
70001a42:	233c      	movs	r3, #60	; 0x3c
70001a44:	f2c0 2347 	movt	r3, #583	; 0x247
70001a48:	6818      	ldr	r0, [r3, #0]
  __ASM volatile ("dmb 0xF":::"memory");
70001a4a:	f3bf 8f5f 	dmb	sy
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001a4e:	f647 6234 	movw	r2, #32308	; 0x7e34
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70001a52:	f24b 5389 	movw	r3, #46473	; 0xb589
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001a56:	f2c7 0200 	movt	r2, #28672	; 0x7000
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70001a5a:	f2c1 43f8 	movt	r3, #5368	; 0x14f8
	uint32_t delta_cycles = curr_cycle - last_cycle;
70001a5e:	6812      	ldr	r2, [r2, #0]
70001a60:	1a80      	subs	r0, r0, r2
	uint32_t delta_ticks = delta_cycles / CYC_PER_TICK;
70001a62:	08c0      	lsrs	r0, r0, #3
70001a64:	fba3 3000 	umull	r3, r0, r3, r0
70001a68:	0a00      	lsrs	r0, r0, #8
	if (key != 0U) {
70001a6a:	b901      	cbnz	r1, 70001a6e <sys_clock_elapsed+0x36>
  __ASM volatile ("cpsie i" : : : "memory");
70001a6c:	b662      	cpsie	i
}
70001a6e:	4770      	bx	lr

70001a70 <z_device_state_init>:
void z_device_state_init(void)
{
	STRUCT_SECTION_FOREACH(device, dev) {
		k_object_init(dev);
	}
}
70001a70:	4770      	bx	lr
70001a72:	bf00      	nop

70001a74 <z_impl_device_is_ready>:
{
	/*
	 * if an invalid device pointer is passed as argument, this call
	 * reports the `device` as not ready for usage.
	 */
	if (dev == NULL) {
70001a74:	b140      	cbz	r0, 70001a88 <z_impl_device_is_ready+0x14>
		return false;
	}

	return dev->state->initialized && (dev->state->init_res == 0U);
70001a76:	68c3      	ldr	r3, [r0, #12]
70001a78:	7858      	ldrb	r0, [r3, #1]
70001a7a:	f010 0001 	ands.w	r0, r0, #1
70001a7e:	bf1e      	ittt	ne
70001a80:	7818      	ldrbne	r0, [r3, #0]
70001a82:	fab0 f080 	clzne	r0, r0
70001a86:	0940      	lsrne	r0, r0, #5
}
70001a88:	4770      	bx	lr
70001a8a:	bf00      	nop

70001a8c <arch_system_halt>:
	__asm__ volatile(
70001a8c:	f3ef 8300 	mrs	r3, CPSR
70001a90:	f003 0380 	and.w	r3, r3, #128	; 0x80
70001a94:	b672      	cpsid	i
	/* TODO: What's the best way to totally halt the system if SMP
	 * is enabled?
	 */

	(void)arch_irq_lock();
	for (;;) {
70001a96:	e7fe      	b.n	70001a96 <arch_system_halt+0xa>

70001a98 <k_sys_fatal_error_handler>:
/* LCOV_EXCL_STOP */

/* LCOV_EXCL_START */
__weak void k_sys_fatal_error_handler(unsigned int reason,
				      const struct arch_esf *esf)
{
70001a98:	b508      	push	{r3, lr}
	ARG_UNUSED(esf);

	LOG_PANIC();
	LOG_ERR("Halting system");
	arch_system_halt(reason);
70001a9a:	f7ff fff7 	bl	70001a8c <arch_system_halt>
70001a9e:	bf00      	nop

70001aa0 <z_fatal_error>:
	arch_system_halt(reason);
}
/* LCOV_EXCL_STOP */

void z_fatal_error(unsigned int reason, const struct arch_esf *esf)
{
70001aa0:	b538      	push	{r3, r4, r5, lr}
70001aa2:	f3ef 8500 	mrs	r5, CPSR
70001aa6:	f005 0580 	and.w	r5, r5, #128	; 0x80
70001aaa:	b672      	cpsid	i

	struct k_thread *ret = _current_cpu->current;

	arch_irq_unlock(k);
#else
	struct k_thread *ret = _kernel.cpus[0].current;
70001aac:	f647 6238 	movw	r2, #32312	; 0x7e38
70001ab0:	f2c7 0200 	movt	r2, #28672	; 0x7000
70001ab4:	6894      	ldr	r4, [r2, #8]
	 * an IRQ or exception was being handled, or thread context.
	 *
	 * See #17656
	 */
#if defined(CONFIG_ARCH_HAS_NESTED_EXCEPTION_DETECTION)
	if ((esf != NULL) && arch_is_in_nested_exception(esf)) {
70001ab6:	b161      	cbz	r1, 70001ad2 <z_fatal_error+0x32>
70001ab8:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
		LOG_ERR("Current thread: %p (%s)", thread, thread_name_get(thread));
	}

	coredump(reason, esf, thread);

	k_sys_fatal_error_handler(reason, esf);
70001abc:	f7ff ffec 	bl	70001a98 <k_sys_fatal_error_handler>
70001ac0:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
	if (key != 0U) {
70001ac4:	b905      	cbnz	r5, 70001ac8 <z_fatal_error+0x28>
70001ac6:	b662      	cpsie	i
70001ac8:	4620      	mov	r0, r4
	arch_irq_unlock(key);

	if (IS_ENABLED(CONFIG_MULTITHREADING)) {
		k_thread_abort(thread);
	}
}
70001aca:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
70001ace:	f000 be2f 	b.w	70002730 <z_impl_k_thread_abort>
	k_sys_fatal_error_handler(reason, esf);
70001ad2:	f7ff ffe1 	bl	70001a98 <k_sys_fatal_error_handler>
		if ((esf != NULL) && arch_is_in_nested_exception(esf)) {
70001ad6:	e7f5      	b.n	70001ac4 <z_fatal_error+0x24>

70001ad8 <z_sys_init_run_level>:
		/* End marker */
		__init_end,
	};
	const struct init_entry *entry;

	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001ad8:	f644 53a0 	movw	r3, #19872	; 0x4da0
70001adc:	1c42      	adds	r2, r0, #1
70001ade:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
70001ae2:	b570      	push	{r4, r5, r6, lr}
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001ae4:	f853 4020 	ldr.w	r4, [r3, r0, lsl #2]
70001ae8:	f853 6022 	ldr.w	r6, [r3, r2, lsl #2]
70001aec:	42b4      	cmp	r4, r6
70001aee:	d314      	bcc.n	70001b1a <z_sys_init_run_level+0x42>
70001af0:	e01b      	b.n	70001b2a <z_sys_init_run_level+0x52>
		rc = entry->init_fn.dev(dev);
70001af2:	4628      	mov	r0, r5
	if (entry->init_fn.dev != NULL) {
70001af4:	b14b      	cbz	r3, 70001b0a <z_sys_init_run_level+0x32>
		rc = entry->init_fn.dev(dev);
70001af6:	4798      	blx	r3
		if (rc != 0) {
70001af8:	b138      	cbz	r0, 70001b0a <z_sys_init_run_level+0x32>
			dev->state->init_res = rc;
70001afa:	68eb      	ldr	r3, [r5, #12]
			if (rc < 0) {
70001afc:	2800      	cmp	r0, #0
70001afe:	bfb8      	it	lt
70001b00:	4240      	neglt	r0, r0
			if (rc > UINT8_MAX) {
70001b02:	28ff      	cmp	r0, #255	; 0xff
70001b04:	bfa8      	it	ge
70001b06:	20ff      	movge	r0, #255	; 0xff
			dev->state->init_res = rc;
70001b08:	7018      	strb	r0, [r3, #0]
	dev->state->initialized = true;
70001b0a:	68ea      	ldr	r2, [r5, #12]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001b0c:	3408      	adds	r4, #8
	dev->state->initialized = true;
70001b0e:	7853      	ldrb	r3, [r2, #1]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001b10:	42a6      	cmp	r6, r4
	dev->state->initialized = true;
70001b12:	f043 0301 	orr.w	r3, r3, #1
70001b16:	7053      	strb	r3, [r2, #1]
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001b18:	d907      	bls.n	70001b2a <z_sys_init_run_level+0x52>

		sys_trace_sys_init_enter(entry, level);
		if (dev != NULL) {
			result = do_device_init(entry);
		} else {
			result = entry->init_fn.sys();
70001b1a:	e9d4 3500 	ldrd	r3, r5, [r4]
		if (dev != NULL) {
70001b1e:	2d00      	cmp	r5, #0
70001b20:	d1e7      	bne.n	70001af2 <z_sys_init_run_level+0x1a>
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001b22:	3408      	adds	r4, #8
			result = entry->init_fn.sys();
70001b24:	4798      	blx	r3
	for (entry = levels[level]; entry < levels[level+1]; entry++) {
70001b26:	42a6      	cmp	r6, r4
70001b28:	d8f7      	bhi.n	70001b1a <z_sys_init_run_level+0x42>
		}
		sys_trace_sys_init_exit(entry, level, result);
	}
}
70001b2a:	bd70      	pop	{r4, r5, r6, pc}

70001b2c <bg_thread_main>:
	 * may perform memory management tasks (except for
	 * k_mem_map_phys_bare() which is allowed at any time)
	 */
	z_mem_manage_init();
#endif /* CONFIG_MMU */
	z_sys_post_kernel = true;
70001b2c:	f647 635c 	movw	r3, #32348	; 0x7e5c
70001b30:	2201      	movs	r2, #1
70001b32:	f2c7 0300 	movt	r3, #28672	; 0x7000
{
70001b36:	b5f0      	push	{r4, r5, r6, r7, lr}

#if CONFIG_IRQ_OFFLOAD
	arch_irq_offload_init();
#endif
	z_sys_init_run_level(INIT_LEVEL_POST_KERNEL);
70001b38:	2003      	movs	r0, #3
{
70001b3a:	b087      	sub	sp, #28
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b3c:	f644 26c0 	movw	r6, #19136	; 0x4ac0
70001b40:	f644 25f0 	movw	r5, #19184	; 0x4af0
	z_sys_post_kernel = true;
70001b44:	701a      	strb	r2, [r3, #0]
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b46:	f2c7 0600 	movt	r6, #28672	; 0x7000
	z_sys_init_run_level(INIT_LEVEL_POST_KERNEL);
70001b4a:	f7ff ffc5 	bl	70001ad8 <z_sys_init_run_level>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b4e:	f2c7 0500 	movt	r5, #28672	; 0x7000
#endif

#if defined(CONFIG_STACK_POINTER_RANDOM) && (CONFIG_STACK_POINTER_RANDOM != 0)
	z_stack_adjust_initialized = 1;
#endif /* CONFIG_STACK_POINTER_RANDOM */
	boot_banner();
70001b52:	f001 f805 	bl	70002b60 <boot_banner>

	void z_init_static(void);
	z_init_static();
70001b56:	f000 f8d3 	bl	70001d00 <z_init_static>

	/* Final init level before app starts */
	z_sys_init_run_level(INIT_LEVEL_APPLICATION);
70001b5a:	2004      	movs	r0, #4
70001b5c:	f7ff ffbc 	bl	70001ad8 <z_sys_init_run_level>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b60:	42ae      	cmp	r6, r5
70001b62:	d217      	bcs.n	70001b94 <bg_thread_main+0x68>
70001b64:	4634      	mov	r4, r6
		z_setup_new_thread(
70001b66:	6a67      	ldr	r7, [r4, #36]	; 0x24
70001b68:	e9d4 2302 	ldrd	r2, r3, [r4, #8]
70001b6c:	e9d4 0100 	ldrd	r0, r1, [r4]
70001b70:	9705      	str	r7, [sp, #20]
70001b72:	6a27      	ldr	r7, [r4, #32]
70001b74:	9704      	str	r7, [sp, #16]
70001b76:	69e7      	ldr	r7, [r4, #28]
70001b78:	9703      	str	r7, [sp, #12]
70001b7a:	69a7      	ldr	r7, [r4, #24]
70001b7c:	9702      	str	r7, [sp, #8]
70001b7e:	6967      	ldr	r7, [r4, #20]
70001b80:	9701      	str	r7, [sp, #4]
70001b82:	6927      	ldr	r7, [r4, #16]
70001b84:	9700      	str	r7, [sp, #0]
70001b86:	f000 fa39 	bl	70001ffc <z_setup_new_thread>
		thread_data->init_thread->init_data = thread_data;
70001b8a:	6823      	ldr	r3, [r4, #0]
70001b8c:	655c      	str	r4, [r3, #84]	; 0x54
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b8e:	3430      	adds	r4, #48	; 0x30
70001b90:	42ac      	cmp	r4, r5
70001b92:	d3e8      	bcc.n	70001b66 <bg_thread_main+0x3a>
	k_sched_lock();
70001b94:	f000 fcfa 	bl	7000258c <k_sched_lock>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001b98:	42ae      	cmp	r6, r5
70001b9a:	d222      	bcs.n	70001be2 <bg_thread_main+0xb6>
70001b9c:	f644 24c0 	movw	r4, #19136	; 0x4ac0

extern void z_thread_timeout(struct _timeout *timeout);

static inline void z_add_thread_timeout(struct k_thread *thread, k_timeout_t ticks)
{
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
70001ba0:	f242 47b1 	movw	r7, #9393	; 0x24b1
70001ba4:	f2c7 0400 	movt	r4, #28672	; 0x7000
70001ba8:	f2c7 0700 	movt	r7, #28672	; 0x7000
70001bac:	e005      	b.n	70001bba <bg_thread_main+0x8e>
	z_impl_k_wakeup(thread);
70001bae:	4630      	mov	r0, r6
70001bb0:	f000 fd92 	bl	700026d8 <z_impl_k_wakeup>
70001bb4:	3430      	adds	r4, #48	; 0x30
70001bb6:	42ac      	cmp	r4, r5
70001bb8:	d213      	bcs.n	70001be2 <bg_thread_main+0xb6>
		k_timeout_t init_delay = Z_THREAD_INIT_DELAY(thread_data);
70001bba:	e9d4 230a 	ldrd	r2, r3, [r4, #40]	; 0x28
		if (!K_TIMEOUT_EQ(init_delay, K_FOREVER)) {
70001bbe:	f1b3 3fff 	cmp.w	r3, #4294967295	; 0xffffffff
70001bc2:	bf08      	it	eq
70001bc4:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
70001bc8:	d0f4      	beq.n	70001bb4 <bg_thread_main+0x88>
			thread_schedule_new(thread_data->init_thread,
70001bca:	6826      	ldr	r6, [r4, #0]


static inline void thread_schedule_new(struct k_thread *thread, k_timeout_t delay)
{
#ifdef CONFIG_SYS_CLOCK_EXISTS
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
70001bcc:	ea52 0003 	orrs.w	r0, r2, r3
70001bd0:	4639      	mov	r1, r7
70001bd2:	f106 0018 	add.w	r0, r6, #24
70001bd6:	d0ea      	beq.n	70001bae <bg_thread_main+0x82>
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data) {
70001bd8:	3430      	adds	r4, #48	; 0x30
70001bda:	f000 fe07 	bl	700027ec <z_add_timeout>
70001bde:	42ac      	cmp	r4, r5
70001be0:	d3eb      	bcc.n	70001bba <bg_thread_main+0x8e>
	k_sched_unlock();
70001be2:	f000 fce3 	bl	700025ac <k_sched_unlock>
	char **argv = prepare_main_args(&argc);
	(void)main(argc, argv);
#else
	extern int main(void);

	(void)main();
70001be6:	f7fe fb9d 	bl	70000324 <main>
 * Exceptions raised by this thread may be recoverable.
 * (This is the default tag for a thread.)
 */
static inline void z_thread_essential_clear(struct k_thread *thread)
{
	thread->base.user_options &= ~K_ESSENTIAL;
70001bea:	f245 33b0 	movw	r3, #21424	; 0x53b0
70001bee:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001bf2:	7b1a      	ldrb	r2, [r3, #12]
70001bf4:	f022 0201 	bic.w	r2, r2, #1
70001bf8:	731a      	strb	r2, [r3, #12]

#ifdef CONFIG_COVERAGE_DUMP
	/* Dump coverage data once the main() has exited. */
	gcov_coverage_dump();
#endif /* CONFIG_COVERAGE_DUMP */
} /* LCOV_EXCL_LINE ... because we just dumped final coverage data */
70001bfa:	b007      	add	sp, #28
70001bfc:	bdf0      	pop	{r4, r5, r6, r7, pc}
70001bfe:	bf00      	nop

70001c00 <z_early_memset>:
	(void) memset(dst, c, n);
70001c00:	f001 b9a8 	b.w	70002f54 <memset>

70001c04 <z_bss_zero>:
	z_early_memset(__bss_start, 0, __bss_end - __bss_start);
70001c04:	f647 6260 	movw	r2, #32352	; 0x7e60
70001c08:	f644 6010 	movw	r0, #19984	; 0x4e10
70001c0c:	f2c7 0000 	movt	r0, #28672	; 0x7000
70001c10:	2100      	movs	r1, #0
70001c12:	f2c7 0200 	movt	r2, #28672	; 0x7000
70001c16:	1a12      	subs	r2, r2, r0
{
70001c18:	b508      	push	{r3, lr}
	z_early_memset(__bss_start, 0, __bss_end - __bss_start);
70001c1a:	f7ff fff1 	bl	70001c00 <z_early_memset>
}
70001c1e:	bd08      	pop	{r3, pc}

70001c20 <z_cstart>:
 * @return Does not return
 */
__boot_func
FUNC_NO_STACK_PROTECTOR
FUNC_NORETURN void z_cstart(void)
{
70001c20:	b580      	push	{r7, lr}
	/* gcov hook needed to get the coverage report.*/
	gcov_static_init();

	/* initialize early init calls */
	z_sys_init_run_level(INIT_LEVEL_EARLY);
70001c22:	2000      	movs	r0, #0
{
70001c24:	b086      	sub	sp, #24
	z_sys_init_run_level(INIT_LEVEL_EARLY);
70001c26:	f7ff ff57 	bl	70001ad8 <z_sys_init_run_level>
	return ret;
}

static ALWAYS_INLINE void arch_current_thread_set(struct k_thread *thread)
{
	_current_cpu->current = thread;
70001c2a:	f647 6438 	movw	r4, #32312	; 0x7e38
{
	dummy_thread->base.thread_state = _THREAD_DUMMY;
#ifdef CONFIG_SCHED_CPU_MASK
	dummy_thread->base.cpu_mask = -1;
#endif /* CONFIG_SCHED_CPU_MASK */
	dummy_thread->base.user_options = K_ESSENTIAL;
70001c2e:	f245 4328 	movw	r3, #21544	; 0x5428
	dummy_thread->mem_domain_info.mem_domain = &k_mem_domain_default;
#endif /* CONFIG_USERSPACE */
#if (K_HEAP_MEM_POOL_SIZE > 0)
	k_thread_system_pool_assign(dummy_thread);
#else
	dummy_thread->resource_pool = NULL;
70001c32:	2500      	movs	r5, #0
	dummy_thread->base.user_options = K_ESSENTIAL;
70001c34:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001c38:	f240 1201 	movw	r2, #257	; 0x101
70001c3c:	f2c7 0400 	movt	r4, #28672	; 0x7000
	dummy_thread->resource_pool = NULL;
70001c40:	669d      	str	r5, [r3, #104]	; 0x68
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001c42:	2701      	movs	r7, #1
	dummy_thread->base.user_options = K_ESSENTIAL;
70001c44:	819a      	strh	r2, [r3, #12]
	_kernel.ready_q.cache = &z_main_thread;
70001c46:	f245 36b0 	movw	r6, #21424	; 0x53b0
70001c4a:	60a3      	str	r3, [r4, #8]

#if defined(CONFIG_MULTITHREADING)
	z_dummy_thread_init(&_thread_dummy);
#endif /* CONFIG_MULTITHREADING */
	/* do any necessary initialization of static devices */
	z_device_state_init();
70001c4c:	f7ff ff10 	bl	70001a70 <z_device_state_init>
#endif
#if CONFIG_BOARD_EARLY_INIT_HOOK
	board_early_init_hook();
#endif
	/* perform basic hardware initialization */
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_1);
70001c50:	2001      	movs	r0, #1
	_kernel.ready_q.cache = &z_main_thread;
70001c52:	f2c7 0600 	movt	r6, #28672	; 0x7000
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_1);
70001c56:	f7ff ff3f 	bl	70001ad8 <z_sys_init_run_level>
#if defined(CONFIG_SMP)
	arch_smp_init();
#endif
	z_sys_init_run_level(INIT_LEVEL_PRE_KERNEL_2);
70001c5a:	2002      	movs	r0, #2
70001c5c:	f7ff ff3c 	bl	70001ad8 <z_sys_init_run_level>
	z_sched_init();
70001c60:	f000 fcde 	bl	70002620 <z_sched_init>
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001c64:	f644 5398 	movw	r3, #19864	; 0x4d98
70001c68:	f64b 2160 	movw	r1, #47712	; 0xba60
70001c6c:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001c70:	f44f 6280 	mov.w	r2, #1024	; 0x400
70001c74:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001c78:	9305      	str	r3, [sp, #20]
70001c7a:	f641 332d 	movw	r3, #6957	; 0x1b2d
70001c7e:	4630      	mov	r0, r6
70001c80:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001c84:	e9cd 5703 	strd	r5, r7, [sp, #12]
70001c88:	9502      	str	r5, [sp, #8]
70001c8a:	e9cd 5500 	strd	r5, r5, [sp]
	_kernel.ready_q.cache = &z_main_thread;
70001c8e:	6166      	str	r6, [r4, #20]
	stack_ptr = z_setup_new_thread(&z_main_thread, z_main_stack,
70001c90:	f000 f9b4 	bl	70001ffc <z_setup_new_thread>
	thread->base.thread_state &= ~_THREAD_SLEEPING;
70001c94:	7b73      	ldrb	r3, [r6, #13]
	z_ready_thread(&z_main_thread);
70001c96:	4630      	mov	r0, r6
70001c98:	f023 0304 	bic.w	r3, r3, #4
70001c9c:	7373      	strb	r3, [r6, #13]
70001c9e:	f000 fb7b 	bl	70002398 <z_ready_thread>
	z_setup_new_thread(thread, stack,
70001ca2:	230f      	movs	r3, #15
70001ca4:	f245 3638 	movw	r6, #21304	; 0x5338
70001ca8:	f64b 1160 	movw	r1, #47456	; 0xb960
70001cac:	f2c7 0600 	movt	r6, #28672	; 0x7000
70001cb0:	9303      	str	r3, [sp, #12]
70001cb2:	f641 5361 	movw	r3, #7521	; 0x1d61
70001cb6:	f44f 7280 	mov.w	r2, #256	; 0x100
70001cba:	f2c7 0300 	movt	r3, #28672	; 0x7000
70001cbe:	4630      	mov	r0, r6
70001cc0:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001cc4:	e9cd 7504 	strd	r7, r5, [sp, #16]
70001cc8:	e9cd 5501 	strd	r5, r5, [sp, #4]
70001ccc:	9400      	str	r4, [sp, #0]
70001cce:	f000 f995 	bl	70001ffc <z_setup_new_thread>
70001cd2:	7b73      	ldrb	r3, [r6, #13]
	_kernel.cpus[id].irq_stack =
70001cd4:	4a09      	ldr	r2, [pc, #36]	; (70001cfc <z_cstart+0xdc>)
70001cd6:	f023 0304 	bic.w	r3, r3, #4
70001cda:	6062      	str	r2, [r4, #4]
	_kernel.cpus[id].idle_thread = &z_idle_threads[id];
70001cdc:	60e6      	str	r6, [r4, #12]
70001cde:	7373      	strb	r3, [r6, #13]
	_kernel.cpus[id].id = id;
70001ce0:	7425      	strb	r5, [r4, #16]
	__asm__ volatile(
70001ce2:	f3ef 8100 	mrs	r1, CPSR
70001ce6:	f001 0180 	and.w	r1, r1, #128	; 0x80
70001cea:	b672      	cpsid	i
	struct k_thread *ret = _kernel.cpus[0].current;
70001cec:	68a3      	ldr	r3, [r4, #8]

static ALWAYS_INLINE int arch_swap(unsigned int key)
{
	/* store off key and return value */
	arch_current_thread()->arch.basepri = key;
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
70001cee:	f06f 020a 	mvn.w	r2, #10
70001cf2:	e9c3 121b 	strd	r1, r2, [r3, #108]	; 0x6c

	z_arm_cortex_r_svc();
70001cf6:	f7ff e96a 	blx	70000fcc <z_arm_cortex_r_svc>
70001cfa:	b662      	cpsie	i
	CODE_UNREACHABLE; /* LCOV_EXCL_LINE */
70001cfc:	7000b960 	.word	0x7000b960

70001d00 <z_init_static>:
	__do_global_ctors_aux();
	__do_init_array_aux();
#elif defined(__CCAC__) /* ARC MWDT */
	__do_global_ctors_aux();
#endif
}
70001d00:	4770      	bx	lr
70001d02:	bf00      	nop

70001d04 <init_mem_slab_obj_core_list>:
#endif /* CONFIG_OBJ_CORE_STATS_MEM_SLAB */
#endif /* CONFIG_OBJ_CORE_MEM_SLAB */

	/* Initialize statically defined mem_slabs */

	STRUCT_SECTION_FOREACH(k_mem_slab, slab) {
70001d04:	f24c 313c 	movw	r1, #49980	; 0xc33c
70001d08:	f24c 3c3c 	movw	ip, #49980	; 0xc33c
70001d0c:	f2c7 0100 	movt	r1, #28672	; 0x7000
70001d10:	f2c7 0c00 	movt	ip, #28672	; 0x7000
70001d14:	4561      	cmp	r1, ip
70001d16:	d221      	bcs.n	70001d5c <init_mem_slab_obj_core_list+0x58>
{
70001d18:	b410      	push	{r4}
	CHECKIF(((slab->info.block_size | (uintptr_t)slab->buffer) &
70001d1a:	694c      	ldr	r4, [r1, #20]
70001d1c:	688b      	ldr	r3, [r1, #8]
70001d1e:	ea43 0004 	orr.w	r0, r3, r4
70001d22:	f010 0003 	ands.w	r0, r0, #3
70001d26:	d116      	bne.n	70001d56 <init_mem_slab_obj_core_list+0x52>
	p = slab->buffer + slab->info.block_size * (slab->info.num_blocks - 1);
70001d28:	690a      	ldr	r2, [r1, #16]
	slab->free_list = NULL;
70001d2a:	60c8      	str	r0, [r1, #12]
	p = slab->buffer + slab->info.block_size * (slab->info.num_blocks - 1);
70001d2c:	3a01      	subs	r2, #1
70001d2e:	fb04 3202 	mla	r2, r4, r2, r3
	while (p >= slab->buffer) {
70001d32:	4293      	cmp	r3, r2
70001d34:	d901      	bls.n	70001d3a <init_mem_slab_obj_core_list+0x36>
70001d36:	e008      	b.n	70001d4a <init_mem_slab_obj_core_list+0x46>
		p -= slab->info.block_size;
70001d38:	461a      	mov	r2, r3
		*(char **)p = slab->free_list;
70001d3a:	6010      	str	r0, [r2, #0]
		p -= slab->info.block_size;
70001d3c:	4610      	mov	r0, r2
70001d3e:	694b      	ldr	r3, [r1, #20]
	while (p >= slab->buffer) {
70001d40:	688c      	ldr	r4, [r1, #8]
		p -= slab->info.block_size;
70001d42:	1ad3      	subs	r3, r2, r3
	while (p >= slab->buffer) {
70001d44:	42a3      	cmp	r3, r4
70001d46:	d2f7      	bcs.n	70001d38 <init_mem_slab_obj_core_list+0x34>
70001d48:	60ca      	str	r2, [r1, #12]
	STRUCT_SECTION_FOREACH(k_mem_slab, slab) {
70001d4a:	311c      	adds	r1, #28
70001d4c:	4561      	cmp	r1, ip
70001d4e:	d3e4      	bcc.n	70001d1a <init_mem_slab_obj_core_list+0x16>
70001d50:	2000      	movs	r0, #0
#endif /* CONFIG_OBJ_CORE_MEM_SLAB */
	}

out:
	return rc;
}
70001d52:	bc10      	pop	{r4}
70001d54:	4770      	bx	lr
70001d56:	f06f 0015 	mvn.w	r0, #21
	return rc;
70001d5a:	e7fa      	b.n	70001d52 <init_mem_slab_obj_core_list+0x4e>
70001d5c:	2000      	movs	r0, #0
}
70001d5e:	4770      	bx	lr

70001d60 <idle>:
#include <wait_q.h>

LOG_MODULE_DECLARE(os, CONFIG_KERNEL_LOG_LEVEL);

void idle(void *unused1, void *unused2, void *unused3)
{
70001d60:	b508      	push	{r3, lr}
70001d62:	f3ef 8300 	mrs	r3, CPSR
70001d66:	f003 0380 	and.w	r3, r3, #128	; 0x80
70001d6a:	b672      	cpsid	i
 * @note In some architectures, before returning, the function unmasks interrupts
 * unconditionally.
 */
static inline void k_cpu_idle(void)
{
	arch_cpu_idle();
70001d6c:	f7ff e810 	blx	70000d90 <arch_cpu_idle>
70001d70:	e7f7      	b.n	70001d62 <idle+0x2>
70001d72:	bf00      	nop

70001d74 <k_msgq_init>:
}
#endif /* CONFIG_POLL */

void k_msgq_init(struct k_msgq *msgq, char *buffer, size_t msg_size,
		 uint32_t max_msgs)
{
70001d74:	b410      	push	{r4}
	msgq->msg_size = msg_size;
	msgq->max_msgs = max_msgs;
	msgq->buffer_start = buffer;
	msgq->buffer_end = buffer + (max_msgs * msg_size);
70001d76:	fb03 1402 	mla	r4, r3, r2, r1
	msgq->max_msgs = max_msgs;
70001d7a:	e9c0 2302 	strd	r2, r3, [r0, #8]
	msgq->read_ptr = buffer;
	msgq->write_ptr = buffer;
	msgq->used_msgs = 0;
70001d7e:	2200      	movs	r2, #0
	msgq->write_ptr = buffer;
70001d80:	e9c0 1106 	strd	r1, r1, [r0, #24]
	msgq->flags = 0;
	z_waitq_init(&msgq->wait_q);
	msgq->lock = (struct k_spinlock) {};
#ifdef CONFIG_POLL
	sys_dlist_init(&msgq->poll_events);
70001d84:	f100 0324 	add.w	r3, r0, #36	; 0x24
	msgq->buffer_end = buffer + (max_msgs * msg_size);
70001d88:	e9c0 1404 	strd	r1, r4, [r0, #16]
	msgq->used_msgs = 0;
70001d8c:	6202      	str	r2, [r0, #32]
#endif /* CONFIG_OBJ_CORE_MSGQ */

	SYS_PORT_TRACING_OBJ_INIT(k_msgq, msgq);

	k_object_init(msgq);
}
70001d8e:	bc10      	pop	{r4}
	msgq->flags = 0;
70001d90:	f880 202c 	strb.w	r2, [r0, #44]	; 0x2c
 * @param list the doubly-linked list
 */

static inline void sys_dlist_init(sys_dlist_t *list)
{
	list->head = (sys_dnode_t *)list;
70001d94:	6000      	str	r0, [r0, #0]
70001d96:	6040      	str	r0, [r0, #4]
70001d98:	6243      	str	r3, [r0, #36]	; 0x24
70001d9a:	6283      	str	r3, [r0, #40]	; 0x28
}
70001d9c:	4770      	bx	lr
70001d9e:	bf00      	nop

70001da0 <z_impl_k_msgq_put>:
	return 0;
}


int z_impl_k_msgq_put(struct k_msgq *msgq, const void *data, k_timeout_t timeout)
{
70001da0:	e92d 47f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
70001da4:	4604      	mov	r4, r0
70001da6:	b082      	sub	sp, #8
70001da8:	460d      	mov	r5, r1
70001daa:	4616      	mov	r6, r2

	struct k_thread *pending_thread;
	k_spinlock_key_t key;
	int result;

	key = k_spin_lock(&msgq->lock);
70001dac:	f100 0708 	add.w	r7, r0, #8
70001db0:	f3ef 8800 	mrs	r8, CPSR
70001db4:	f008 0880 	and.w	r8, r8, #128	; 0x80
70001db8:	b672      	cpsid	i

	SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_msgq, put, msgq, timeout);

	if (msgq->used_msgs < msgq->max_msgs) {
70001dba:	6a02      	ldr	r2, [r0, #32]
70001dbc:	68c0      	ldr	r0, [r0, #12]
70001dbe:	4282      	cmp	r2, r0
70001dc0:	d224      	bcs.n	70001e0c <z_impl_k_msgq_put+0x6c>
 * @return true if empty, false otherwise
 */

static inline bool sys_dlist_is_empty(sys_dlist_t *list)
{
	return list->head == list;
70001dc2:	f8d4 9000 	ldr.w	r9, [r4]
	__ASSERT_EVAL(, int key = arch_irq_lock(); arch_irq_unlock(key),
		      !arch_irq_unlocked(key), "");

	LOCK_SCHED_SPINLOCK {
		thread = _priq_wait_best(&wait_q->waitq);
		if (unlikely(thread != NULL)) {
70001dc6:	f1b9 0f00 	cmp.w	r9, #0
70001dca:	bf18      	it	ne
70001dcc:	454c      	cmpne	r4, r9
70001dce:	d135      	bne.n	70001e3c <z_impl_k_msgq_put+0x9c>
			return 0;
		} else {
			/* put message in queue */
			__ASSERT_NO_MSG(msgq->write_ptr >= msgq->buffer_start &&
					msgq->write_ptr < msgq->buffer_end);
			(void)memcpy(msgq->write_ptr, (char *)data, msgq->msg_size);
70001dd0:	68a2      	ldr	r2, [r4, #8]
			msgq->used_msgs++;
#ifdef CONFIG_POLL
			handle_poll_events(msgq, K_POLL_STATE_MSGQ_DATA_AVAILABLE);
#endif /* CONFIG_POLL */
		}
		result = 0;
70001dd2:	2600      	movs	r6, #0
			(void)memcpy(msgq->write_ptr, (char *)data, msgq->msg_size);
70001dd4:	69e0      	ldr	r0, [r4, #28]
70001dd6:	f001 f855 	bl	70002e84 <memcpy>
			msgq->write_ptr += msgq->msg_size;
70001dda:	69e3      	ldr	r3, [r4, #28]
70001ddc:	68a2      	ldr	r2, [r4, #8]
	z_handle_obj_poll_events(&msgq->poll_events, state);
70001dde:	2110      	movs	r1, #16
70001de0:	f104 0024 	add.w	r0, r4, #36	; 0x24
			msgq->write_ptr += msgq->msg_size;
70001de4:	4413      	add	r3, r2
			if (msgq->write_ptr == msgq->buffer_end) {
70001de6:	6962      	ldr	r2, [r4, #20]
			msgq->write_ptr += msgq->msg_size;
70001de8:	61e3      	str	r3, [r4, #28]
			if (msgq->write_ptr == msgq->buffer_end) {
70001dea:	4293      	cmp	r3, r2
				msgq->write_ptr = msgq->buffer_start;
70001dec:	bf04      	itt	eq
70001dee:	6923      	ldreq	r3, [r4, #16]
70001df0:	61e3      	streq	r3, [r4, #28]
			msgq->used_msgs++;
70001df2:	6a23      	ldr	r3, [r4, #32]
70001df4:	3301      	adds	r3, #1
70001df6:	6223      	str	r3, [r4, #32]
	z_handle_obj_poll_events(&msgq->poll_events, state);
70001df8:	f000 fe9c 	bl	70002b34 <z_handle_obj_poll_events>
		return result;
	}

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_msgq, put, msgq, timeout, result);

	z_reschedule(&msgq->lock, key);
70001dfc:	4641      	mov	r1, r8
70001dfe:	4638      	mov	r0, r7
70001e00:	f000 fb8e 	bl	70002520 <z_reschedule>

	return result;
}
70001e04:	4630      	mov	r0, r6
70001e06:	b002      	add	sp, #8
70001e08:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
70001e0c:	ea56 0203 	orrs.w	r2, r6, r3
		result = -ENOMSG;
70001e10:	bf08      	it	eq
70001e12:	f06f 0622 	mvneq.w	r6, #34	; 0x22
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
70001e16:	d0f1      	beq.n	70001dfc <z_impl_k_msgq_put+0x5c>
		result = z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
70001e18:	4622      	mov	r2, r4
70001e1a:	f647 6438 	movw	r4, #32312	; 0x7e38
70001e1e:	4641      	mov	r1, r8
70001e20:	f2c7 0400 	movt	r4, #28672	; 0x7000
70001e24:	4638      	mov	r0, r7
		arch_current_thread()->base.swap_data = (void *) data;
70001e26:	68a4      	ldr	r4, [r4, #8]
70001e28:	6165      	str	r5, [r4, #20]
		result = z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
70001e2a:	e9cd 6300 	strd	r6, r3, [sp]
70001e2e:	f000 fb43 	bl	700024b8 <z_pend_curr>
70001e32:	4606      	mov	r6, r0
}
70001e34:	4630      	mov	r0, r6
70001e36:	b002      	add	sp, #8
70001e38:	e8bd 87f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
 */

static inline void sys_dlist_remove(sys_dnode_t *node)
{
	sys_dnode_t *const prev = node->prev;
	sys_dnode_t *const next = node->next;
70001e3c:	e9d9 3200 	ldrd	r3, r2, [r9]
	thread->base.pended_on = NULL;
70001e40:	f04f 0a00 	mov.w	sl, #0

	prev->next = next;
70001e44:	6013      	str	r3, [r2, #0]
}

static inline int z_abort_thread_timeout(struct k_thread *thread)
{
	return z_abort_timeout(&thread->base.timeout);
70001e46:	f109 0018 	add.w	r0, r9, #24
	next->prev = prev;
70001e4a:	605a      	str	r2, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
70001e4c:	f899 300d 	ldrb.w	r3, [r9, #13]
	node->next = NULL;
70001e50:	2200      	movs	r2, #0
70001e52:	f023 0302 	bic.w	r3, r3, #2
70001e56:	f8c9 a008 	str.w	sl, [r9, #8]
			return 0;
70001e5a:	4656      	mov	r6, sl
70001e5c:	f889 300d 	strb.w	r3, [r9, #13]
70001e60:	2300      	movs	r3, #0
70001e62:	e9c9 2300 	strd	r2, r3, [r9]
70001e66:	f000 fd53 	bl	70002910 <z_abort_timeout>
			(void)memcpy(pending_thread->base.swap_data, data,
70001e6a:	68a2      	ldr	r2, [r4, #8]
70001e6c:	f8d9 0014 	ldr.w	r0, [r9, #20]
70001e70:	4629      	mov	r1, r5
70001e72:	f001 f807 	bl	70002e84 <memcpy>
}

static ALWAYS_INLINE void
arch_thread_return_value_set(struct k_thread *thread, unsigned int value)
{
	thread->arch.swap_return_value = value;
70001e76:	f8c9 a070 	str.w	sl, [r9, #112]	; 0x70
			z_ready_thread(pending_thread);
70001e7a:	4648      	mov	r0, r9
70001e7c:	f000 fa8c 	bl	70002398 <z_ready_thread>
			z_reschedule(&msgq->lock, key);
70001e80:	4641      	mov	r1, r8
70001e82:	4638      	mov	r0, r7
70001e84:	f000 fb4c 	bl	70002520 <z_reschedule>
			return 0;
70001e88:	e7bc      	b.n	70001e04 <z_impl_k_msgq_put+0x64>
70001e8a:	bf00      	nop

70001e8c <z_impl_k_msgq_get>:
}
#include <zephyr/syscalls/k_msgq_get_attrs_mrsh.c>
#endif /* CONFIG_USERSPACE */

int z_impl_k_msgq_get(struct k_msgq *msgq, void *data, k_timeout_t timeout)
{
70001e8c:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
70001e90:	4604      	mov	r4, r0
70001e92:	b082      	sub	sp, #8
70001e94:	460e      	mov	r6, r1
70001e96:	4615      	mov	r5, r2

	k_spinlock_key_t key;
	struct k_thread *pending_thread;
	int result;

	key = k_spin_lock(&msgq->lock);
70001e98:	f100 0808 	add.w	r8, r0, #8
70001e9c:	f3ef 8700 	mrs	r7, CPSR
70001ea0:	f007 0780 	and.w	r7, r7, #128	; 0x80
70001ea4:	b672      	cpsid	i

	SYS_PORT_TRACING_OBJ_FUNC_ENTER(k_msgq, get, msgq, timeout);

	if (msgq->used_msgs > 0U) {
70001ea6:	6a02      	ldr	r2, [r0, #32]
70001ea8:	b952      	cbnz	r2, 70001ec0 <z_impl_k_msgq_get+0x34>
			SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_msgq, get, msgq, timeout, 0);

			return 0;
		}
		result = 0;
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
70001eaa:	ea55 0203 	orrs.w	r2, r5, r3
		/* don't wait for a message to become available */
		result = -ENOMSG;
70001eae:	bf08      	it	eq
70001eb0:	f06f 0022 	mvneq.w	r0, #34	; 0x22
	} else if (K_TIMEOUT_EQ(timeout, K_NO_WAIT)) {
70001eb4:	d14d      	bne.n	70001f52 <z_impl_k_msgq_get+0xc6>
	if (key != 0U) {
70001eb6:	b907      	cbnz	r7, 70001eba <z_impl_k_msgq_get+0x2e>
70001eb8:	b662      	cpsie	i
	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_msgq, get, msgq, timeout, result);

	k_spin_unlock(&msgq->lock, key);

	return result;
}
70001eba:	b002      	add	sp, #8
70001ebc:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
		(void)memcpy((char *)data, msgq->read_ptr, msgq->msg_size);
70001ec0:	6882      	ldr	r2, [r0, #8]
70001ec2:	4608      	mov	r0, r1
70001ec4:	69a1      	ldr	r1, [r4, #24]
70001ec6:	f000 ffdd 	bl	70002e84 <memcpy>
		msgq->read_ptr += msgq->msg_size;
70001eca:	69a3      	ldr	r3, [r4, #24]
70001ecc:	68a2      	ldr	r2, [r4, #8]
	return list->head == list;
70001ece:	6825      	ldr	r5, [r4, #0]
70001ed0:	4413      	add	r3, r2
		if (msgq->read_ptr == msgq->buffer_end) {
70001ed2:	6962      	ldr	r2, [r4, #20]
		msgq->read_ptr += msgq->msg_size;
70001ed4:	61a3      	str	r3, [r4, #24]
		if (msgq->read_ptr == msgq->buffer_end) {
70001ed6:	4293      	cmp	r3, r2
			msgq->read_ptr = msgq->buffer_start;
70001ed8:	bf04      	itt	eq
70001eda:	6923      	ldreq	r3, [r4, #16]
70001edc:	61a3      	streq	r3, [r4, #24]
		msgq->used_msgs--;
70001ede:	6a23      	ldr	r3, [r4, #32]
		if (unlikely(thread != NULL)) {
70001ee0:	2d00      	cmp	r5, #0
70001ee2:	bf18      	it	ne
70001ee4:	42ac      	cmpne	r4, r5
70001ee6:	bf18      	it	ne
70001ee8:	2001      	movne	r0, #1
70001eea:	f103 33ff 	add.w	r3, r3, #4294967295	; 0xffffffff
70001eee:	bf08      	it	eq
70001ef0:	2000      	moveq	r0, #0
70001ef2:	6223      	str	r3, [r4, #32]
70001ef4:	d0df      	beq.n	70001eb6 <z_impl_k_msgq_get+0x2a>
	sys_dnode_t *const next = node->next;
70001ef6:	e9d5 3200 	ldrd	r3, r2, [r5]
70001efa:	f105 0018 	add.w	r0, r5, #24
	prev->next = next;
70001efe:	6013      	str	r3, [r2, #0]
	next->prev = prev;
70001f00:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70001f02:	2200      	movs	r2, #0
70001f04:	2300      	movs	r3, #0
70001f06:	e9c5 2300 	strd	r2, r3, [r5]
70001f0a:	7b6b      	ldrb	r3, [r5, #13]
70001f0c:	f023 0302 	bic.w	r3, r3, #2
70001f10:	736b      	strb	r3, [r5, #13]
	thread->base.pended_on = NULL;
70001f12:	2300      	movs	r3, #0
70001f14:	60ab      	str	r3, [r5, #8]
70001f16:	f000 fcfb 	bl	70002910 <z_abort_timeout>
			(void)memcpy(msgq->write_ptr, (char *)pending_thread->base.swap_data,
70001f1a:	68a2      	ldr	r2, [r4, #8]
70001f1c:	6969      	ldr	r1, [r5, #20]
70001f1e:	69e0      	ldr	r0, [r4, #28]
70001f20:	f000 ffb0 	bl	70002e84 <memcpy>
			msgq->write_ptr += msgq->msg_size;
70001f24:	69e3      	ldr	r3, [r4, #28]
70001f26:	68a2      	ldr	r2, [r4, #8]
			z_ready_thread(pending_thread);
70001f28:	4628      	mov	r0, r5
			msgq->write_ptr += msgq->msg_size;
70001f2a:	4413      	add	r3, r2
			if (msgq->write_ptr == msgq->buffer_end) {
70001f2c:	6962      	ldr	r2, [r4, #20]
			msgq->write_ptr += msgq->msg_size;
70001f2e:	61e3      	str	r3, [r4, #28]
			if (msgq->write_ptr == msgq->buffer_end) {
70001f30:	4293      	cmp	r3, r2
				msgq->write_ptr = msgq->buffer_start;
70001f32:	bf04      	itt	eq
70001f34:	6923      	ldreq	r3, [r4, #16]
70001f36:	61e3      	streq	r3, [r4, #28]
			msgq->used_msgs++;
70001f38:	6a23      	ldr	r3, [r4, #32]
70001f3a:	3301      	adds	r3, #1
70001f3c:	6223      	str	r3, [r4, #32]
70001f3e:	2400      	movs	r4, #0
70001f40:	672c      	str	r4, [r5, #112]	; 0x70
			z_ready_thread(pending_thread);
70001f42:	f000 fa29 	bl	70002398 <z_ready_thread>
			z_reschedule(&msgq->lock, key);
70001f46:	4640      	mov	r0, r8
70001f48:	4639      	mov	r1, r7
70001f4a:	f000 fae9 	bl	70002520 <z_reschedule>
			return 0;
70001f4e:	4620      	mov	r0, r4
70001f50:	e7b3      	b.n	70001eba <z_impl_k_msgq_get+0x2e>
		result = z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
70001f52:	4622      	mov	r2, r4
70001f54:	f647 6438 	movw	r4, #32312	; 0x7e38
70001f58:	4639      	mov	r1, r7
70001f5a:	f2c7 0400 	movt	r4, #28672	; 0x7000
70001f5e:	4640      	mov	r0, r8
		arch_current_thread()->base.swap_data = data;
70001f60:	68a4      	ldr	r4, [r4, #8]
70001f62:	6166      	str	r6, [r4, #20]
		result = z_pend_curr(&msgq->lock, key, &msgq->wait_q, timeout);
70001f64:	e9cd 5300 	strd	r5, r3, [sp]
70001f68:	f000 faa6 	bl	700024b8 <z_pend_curr>
}
70001f6c:	b002      	add	sp, #8
70001f6e:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
70001f72:	bf00      	nop

70001f74 <z_impl_k_sem_give>:
	return false;
#endif /* CONFIG_POLL */
}

void z_impl_k_sem_give(struct k_sem *sem)
{
70001f74:	b570      	push	{r4, r5, r6, lr}
	__asm__ volatile(
70001f76:	f3ef 8500 	mrs	r5, CPSR
70001f7a:	f005 0580 	and.w	r5, r5, #128	; 0x80
70001f7e:	b672      	cpsid	i
	return list->head == list;
70001f80:	6804      	ldr	r4, [r0, #0]
		if (unlikely(thread != NULL)) {
70001f82:	2c00      	cmp	r4, #0
70001f84:	bf18      	it	ne
70001f86:	42a0      	cmpne	r0, r4
70001f88:	d113      	bne.n	70001fb2 <z_impl_k_sem_give+0x3e>

	if (unlikely(thread != NULL)) {
		arch_thread_return_value_set(thread, 0);
		z_ready_thread(thread);
	} else {
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
70001f8a:	e9d0 3202 	ldrd	r3, r2, [r0, #8]
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
70001f8e:	2102      	movs	r1, #2
70001f90:	3010      	adds	r0, #16
		sem->count += (sem->count != sem->limit) ? 1U : 0U;
70001f92:	429a      	cmp	r2, r3
70001f94:	bf18      	it	ne
70001f96:	3301      	addne	r3, #1
70001f98:	f840 3c08 	str.w	r3, [r0, #-8]
	z_handle_obj_poll_events(&sem->poll_events, K_POLL_STATE_SEM_AVAILABLE);
70001f9c:	f000 fdca 	bl	70002b34 <z_handle_obj_poll_events>
		resched = handle_poll_events(sem);
	}

	if (unlikely(resched)) {
		z_reschedule(&lock, key);
70001fa0:	f647 6058 	movw	r0, #32344	; 0x7e58
70001fa4:	4629      	mov	r1, r5
70001fa6:	f2c7 0000 	movt	r0, #28672	; 0x7000
	} else {
		k_spin_unlock(&lock, key);
	}

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_sem, give, sem);
}
70001faa:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
		z_reschedule(&lock, key);
70001fae:	f000 bab7 	b.w	70002520 <z_reschedule>
	sys_dnode_t *const next = node->next;
70001fb2:	e9d4 3200 	ldrd	r3, r2, [r4]
	thread->base.pended_on = NULL;
70001fb6:	2600      	movs	r6, #0
	prev->next = next;
70001fb8:	6013      	str	r3, [r2, #0]
	node->next = NULL;
70001fba:	2100      	movs	r1, #0
	next->prev = prev;
70001fbc:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70001fbe:	2000      	movs	r0, #0
70001fc0:	7b63      	ldrb	r3, [r4, #13]
70001fc2:	60a6      	str	r6, [r4, #8]
70001fc4:	e9c4 0100 	strd	r0, r1, [r4]
70001fc8:	f023 0302 	bic.w	r3, r3, #2
70001fcc:	f104 0018 	add.w	r0, r4, #24
70001fd0:	7363      	strb	r3, [r4, #13]
70001fd2:	f000 fc9d 	bl	70002910 <z_abort_timeout>
70001fd6:	6726      	str	r6, [r4, #112]	; 0x70
		z_ready_thread(thread);
70001fd8:	4620      	mov	r0, r4
70001fda:	f000 f9dd 	bl	70002398 <z_ready_thread>
70001fde:	e7df      	b.n	70001fa0 <z_impl_k_sem_give+0x2c>

70001fe0 <k_is_in_isr>:
70001fe0:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
#include <zephyr/arch/arm/cortex_a_r/lib_helpers.h>
#include <zephyr/arch/arm/cortex_a_r/tpidruro.h>

static ALWAYS_INLINE _cpu_t *arch_curr_cpu(void)
{
	return (_cpu_t *)(read_tpidruro() & TPIDRURO_CURR_CPU);
70001fe4:	f023 0303 	bic.w	r3, r3, #3
#endif

/* Check the CPSR mode bits to see if we are in IRQ or FIQ mode */
static ALWAYS_INLINE bool arch_is_in_isr(void)
{
	return (arch_curr_cpu()->nested != 0U);
70001fe8:	6818      	ldr	r0, [r3, #0]
	STRUCT_SECTION_FOREACH(_static_thread_data, thread_data)

bool k_is_in_isr(void)
{
	return arch_is_in_isr();
}
70001fea:	3800      	subs	r0, #0
70001fec:	bf18      	it	ne
70001fee:	2001      	movne	r0, #1
70001ff0:	4770      	bx	lr
70001ff2:	bf00      	nop

70001ff4 <z_impl_k_thread_name_set>:

	SYS_PORT_TRACING_OBJ_FUNC(k_thread, name_set, thread, -ENOSYS);

	return -ENOSYS;
#endif /* CONFIG_THREAD_NAME */
}
70001ff4:	f06f 0057 	mvn.w	r0, #87	; 0x57
70001ff8:	4770      	bx	lr
70001ffa:	bf00      	nop

70001ffc <z_setup_new_thread>:
		stack_buf_size = stack_obj_size - K_THREAD_STACK_RESERVED;
	} else
#endif /* CONFIG_USERSPACE */
	{
		/* Object cannot host a user mode thread */
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
70001ffc:	3207      	adds	r2, #7
70001ffe:	f022 0207 	bic.w	r2, r2, #7
char *z_setup_new_thread(struct k_thread *new_thread,
			 k_thread_stack_t *stack, size_t stack_size,
			 k_thread_entry_t entry,
			 void *p1, void *p2, void *p3,
			 int prio, uint32_t options, const char *name)
{
70002002:	e92d 4370 	stmdb	sp!, {r4, r5, r6, r8, r9, lr}
	stack_ptr = (char *)stack + stack_obj_size;
70002006:	188d      	adds	r5, r1, r2
	SYS_DLIST_FOR_EACH_CONTAINER(&((wq)->waitq), thread_ptr, \
				     base.qnode_dlist)

static inline void z_waitq_init(_wait_q_t *w)
{
	sys_dlist_init(&w->waitq);
70002008:	f100 0258 	add.w	r2, r0, #88	; 0x58

void z_init_thread_base(struct _thread_base *thread_base, int priority,
		       uint32_t initial_state, unsigned int options)
{
	/* k_q_node is initialized upon first insertion in a list */
	thread_base->pended_on = NULL;
7000200c:	2600      	movs	r6, #0
{
7000200e:	b084      	sub	sp, #16
	list->head = (sys_dnode_t *)list;
70002010:	e9c0 2216 	strd	r2, r2, [r0, #88]	; 0x58
	thread_base->user_options = (uint8_t)options;
	thread_base->thread_state = (uint8_t)initial_state;
70002014:	2204      	movs	r2, #4
	thread_base->pended_on = NULL;
70002016:	6086      	str	r6, [r0, #8]
	node->next = NULL;
70002018:	f04f 0800 	mov.w	r8, #0
	thread_base->thread_state = (uint8_t)initial_state;
7000201c:	7342      	strb	r2, [r0, #13]
7000201e:	f04f 0900 	mov.w	r9, #0
{
70002022:	9a0a      	ldr	r2, [sp, #40]	; 0x28
70002024:	4604      	mov	r4, r0

	thread_base->prio = priority;

	thread_base->sched_locked = 0U;
70002026:	73c6      	strb	r6, [r0, #15]
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70002028:	9200      	str	r2, [sp, #0]
{
7000202a:	9a0b      	ldr	r2, [sp, #44]	; 0x2c
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
7000202c:	9201      	str	r2, [sp, #4]
{
7000202e:	9a0c      	ldr	r2, [sp, #48]	; 0x30
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70002030:	9202      	str	r2, [sp, #8]
{
70002032:	9a0d      	ldr	r2, [sp, #52]	; 0x34
	thread_base->prio = priority;
70002034:	7382      	strb	r2, [r0, #14]
{
70002036:	9a0e      	ldr	r2, [sp, #56]	; 0x38
	thread_base->user_options = (uint8_t)options;
70002038:	7302      	strb	r2, [r0, #12]
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
7000203a:	462a      	mov	r2, r5
7000203c:	e9c0 8906 	strd	r8, r9, [r0, #24]
70002040:	f7fe fe88 	bl	70000d54 <arch_new_thread>
70002044:	f647 6338 	movw	r3, #32312	; 0x7e38
	new_thread->init_data = NULL;
70002048:	6566      	str	r6, [r4, #84]	; 0x54
7000204a:	f2c7 0300 	movt	r3, #28672	; 0x7000
}
7000204e:	4628      	mov	r0, r5
	new_thread->resource_pool = arch_current_thread()->resource_pool;
70002050:	689b      	ldr	r3, [r3, #8]
70002052:	6e9b      	ldr	r3, [r3, #104]	; 0x68
70002054:	66a3      	str	r3, [r4, #104]	; 0x68
}
70002056:	b004      	add	sp, #16
70002058:	e8bd 8370 	ldmia.w	sp!, {r4, r5, r6, r8, r9, pc}

7000205c <z_impl_k_thread_create>:
{
7000205c:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
70002060:	f100 0658 	add.w	r6, r0, #88	; 0x58
	thread_base->pended_on = NULL;
70002064:	2500      	movs	r5, #0
{
70002066:	b085      	sub	sp, #20
	list->head = (sys_dnode_t *)list;
70002068:	e9c0 6616 	strd	r6, r6, [r0, #88]	; 0x58
	thread_base->thread_state = (uint8_t)initial_state;
7000206c:	2604      	movs	r6, #4
	thread_base->pended_on = NULL;
7000206e:	6085      	str	r5, [r0, #8]
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
70002070:	3207      	adds	r2, #7
	thread_base->thread_state = (uint8_t)initial_state;
70002072:	7346      	strb	r6, [r0, #13]
	node->next = NULL;
70002074:	f04f 0800 	mov.w	r8, #0
{
70002078:	9e0c      	ldr	r6, [sp, #48]	; 0x30
7000207a:	f04f 0900 	mov.w	r9, #0
	thread_base->sched_locked = 0U;
7000207e:	73c5      	strb	r5, [r0, #15]
		stack_obj_size = K_KERNEL_STACK_LEN(stack_size);
70002080:	f022 0207 	bic.w	r2, r2, #7
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70002084:	9600      	str	r6, [sp, #0]
70002086:	440a      	add	r2, r1
{
70002088:	9e0d      	ldr	r6, [sp, #52]	; 0x34
7000208a:	4604      	mov	r4, r0
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
7000208c:	9601      	str	r6, [sp, #4]
{
7000208e:	9e0e      	ldr	r6, [sp, #56]	; 0x38
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
70002090:	9602      	str	r6, [sp, #8]
{
70002092:	9e0f      	ldr	r6, [sp, #60]	; 0x3c
	thread_base->prio = priority;
70002094:	7386      	strb	r6, [r0, #14]
{
70002096:	9e10      	ldr	r6, [sp, #64]	; 0x40
	thread_base->user_options = (uint8_t)options;
70002098:	7306      	strb	r6, [r0, #12]
7000209a:	e9c0 8906 	strd	r8, r9, [r0, #24]
{
7000209e:	e9dd 7612 	ldrd	r7, r6, [sp, #72]	; 0x48
	arch_new_thread(new_thread, stack, stack_ptr, entry, p1, p2, p3);
700020a2:	f7fe fe57 	bl	70000d54 <arch_new_thread>
	new_thread->init_data = NULL;
700020a6:	6565      	str	r5, [r4, #84]	; 0x54
700020a8:	f647 6338 	movw	r3, #32312	; 0x7e38
700020ac:	f2c7 0300 	movt	r3, #28672	; 0x7000
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
700020b0:	f1b6 3fff 	cmp.w	r6, #4294967295	; 0xffffffff
700020b4:	bf08      	it	eq
700020b6:	f1b7 3fff 	cmpeq.w	r7, #4294967295	; 0xffffffff
	new_thread->resource_pool = arch_current_thread()->resource_pool;
700020ba:	689b      	ldr	r3, [r3, #8]
700020bc:	6e9b      	ldr	r3, [r3, #104]	; 0x68
700020be:	66a3      	str	r3, [r4, #104]	; 0x68
	if (!K_TIMEOUT_EQ(delay, K_FOREVER)) {
700020c0:	d103      	bne.n	700020ca <z_impl_k_thread_create+0x6e>
}
700020c2:	4620      	mov	r0, r4
700020c4:	b005      	add	sp, #20
700020c6:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	if (K_TIMEOUT_EQ(delay, K_NO_WAIT)) {
700020ca:	ea56 0307 	orrs.w	r3, r6, r7
700020ce:	d106      	bne.n	700020de <z_impl_k_thread_create+0x82>
700020d0:	4620      	mov	r0, r4
700020d2:	f000 fb01 	bl	700026d8 <z_impl_k_wakeup>
700020d6:	4620      	mov	r0, r4
700020d8:	b005      	add	sp, #20
700020da:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
700020de:	f242 41b1 	movw	r1, #9393	; 0x24b1
700020e2:	f104 0018 	add.w	r0, r4, #24
700020e6:	463a      	mov	r2, r7
700020e8:	4633      	mov	r3, r6
700020ea:	f2c7 0100 	movt	r1, #28672	; 0x7000
700020ee:	f000 fb7d 	bl	700027ec <z_add_timeout>
700020f2:	4620      	mov	r0, r4
700020f4:	b005      	add	sp, #20
700020f6:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
700020fa:	bf00      	nop

700020fc <unready_thread>:
}
#include <zephyr/syscalls/k_thread_resume_mrsh.c>
#endif /* CONFIG_USERSPACE */

static void unready_thread(struct k_thread *thread)
{
700020fc:	b410      	push	{r4}
	return (thread->base.thread_state & state) != 0U;
700020fe:	7b43      	ldrb	r3, [r0, #13]
	if (z_is_thread_queued(thread)) {
70002100:	061c      	lsls	r4, r3, #24
70002102:	d509      	bpl.n	70002118 <unready_thread+0x1c>
70002104:	2200      	movs	r2, #0
	thread->base.thread_state &= ~_THREAD_QUEUED;
70002106:	f003 037f 	and.w	r3, r3, #127	; 0x7f
	sys_dnode_t *const next = node->next;
7000210a:	e9d0 1400 	ldrd	r1, r4, [r0]
7000210e:	7343      	strb	r3, [r0, #13]
	prev->next = next;
70002110:	6021      	str	r1, [r4, #0]
	next->prev = prev;
70002112:	604c      	str	r4, [r1, #4]
	node->next = NULL;
70002114:	6002      	str	r2, [r0, #0]
70002116:	6042      	str	r2, [r0, #4]
70002118:	f647 6338 	movw	r3, #32312	; 0x7e38
7000211c:	f2c7 0300 	movt	r3, #28672	; 0x7000
	return list->head == list;
70002120:	4619      	mov	r1, r3
70002122:	689c      	ldr	r4, [r3, #8]
70002124:	f851 2f18 	ldr.w	r2, [r1, #24]!
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002128:	428a      	cmp	r2, r1
7000212a:	bf18      	it	ne
7000212c:	2a00      	cmpne	r2, #0
7000212e:	bf08      	it	eq
70002130:	68da      	ldreq	r2, [r3, #12]
					 int preempt_ok)
{
	/* Preemption is OK if it's being explicitly allowed by
	 * software state (e.g. the thread called k_yield())
	 */
	if (preempt_ok != 0) {
70002132:	42a0      	cmp	r0, r4
70002134:	d006      	beq.n	70002144 <unready_thread+0x48>
	}

	__ASSERT(arch_current_thread() != NULL, "");

	/* Or if we're pended/suspended/dummy (duh) */
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
70002136:	7b61      	ldrb	r1, [r4, #13]
70002138:	06c9      	lsls	r1, r1, #27
7000213a:	d103      	bne.n	70002144 <unready_thread+0x48>
	}

	/* Otherwise we have to be running a preemptible thread or
	 * switching to a metairq
	 */
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
7000213c:	89e1      	ldrh	r1, [r4, #14]
		_kernel.ready_q.cache = arch_current_thread();
7000213e:	297f      	cmp	r1, #127	; 0x7f
70002140:	bf88      	it	hi
70002142:	4622      	movhi	r2, r4
70002144:	615a      	str	r2, [r3, #20]
		dequeue_thread(thread);
	}
	update_cache(thread == arch_current_thread());
}
70002146:	bc10      	pop	{r4}
70002148:	4770      	bx	lr
7000214a:	bf00      	nop

7000214c <add_to_waitq_locked>:

/* _sched_spinlock must be held */
static void add_to_waitq_locked(struct k_thread *thread, _wait_q_t *wait_q)
{
7000214c:	b538      	push	{r3, r4, r5, lr}
7000214e:	460d      	mov	r5, r1
	unready_thread(thread);
70002150:	f7ff ffd4 	bl	700020fc <unready_thread>
	thread->base.thread_state |= _THREAD_PENDING;
70002154:	7b43      	ldrb	r3, [r0, #13]
70002156:	f043 0302 	orr.w	r3, r3, #2
7000215a:	7343      	strb	r3, [r0, #13]
	z_mark_thread_as_pending(thread);

	SYS_PORT_TRACING_FUNC(k_thread, sched_pend, thread);

	if (wait_q != NULL) {
7000215c:	b1bd      	cbz	r5, 7000218e <add_to_waitq_locked+0x42>
		thread->base.pended_on = wait_q;
7000215e:	6085      	str	r5, [r0, #8]
70002160:	4604      	mov	r4, r0
70002162:	682b      	ldr	r3, [r5, #0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002164:	429d      	cmp	r5, r3
70002166:	d00d      	beq.n	70002184 <add_to_waitq_locked+0x38>
static ALWAYS_INLINE void z_priq_dumb_add(sys_dlist_t *pq,
					  struct k_thread *thread)
{
	struct k_thread *t;

	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
70002168:	b163      	cbz	r3, 70002184 <add_to_waitq_locked+0x38>
	int32_t b2 = thread_2->base.prio;
7000216a:	f993 c00e 	ldrsb.w	ip, [r3, #14]
	int32_t b1 = thread_1->base.prio;
7000216e:	f994 200e 	ldrsb.w	r2, [r4, #14]
	if (b1 != b2) {
70002172:	4562      	cmp	r2, ip
70002174:	d001      	beq.n	7000217a <add_to_waitq_locked+0x2e>
		if (z_sched_prio_cmp(thread, t) > 0) {
70002176:	4594      	cmp	ip, r2
70002178:	dc0a      	bgt.n	70002190 <add_to_waitq_locked+0x44>
	return (node == list->tail) ? NULL : node->next;
7000217a:	686a      	ldr	r2, [r5, #4]
7000217c:	4293      	cmp	r3, r2
7000217e:	d002      	beq.n	70002186 <add_to_waitq_locked+0x3a>
70002180:	681b      	ldr	r3, [r3, #0]
70002182:	e7f1      	b.n	70002168 <add_to_waitq_locked+0x1c>
70002184:	686a      	ldr	r2, [r5, #4]
	node->prev = tail;
70002186:	e9c4 5200 	strd	r5, r2, [r4]
	tail->next = node;
7000218a:	6014      	str	r4, [r2, #0]
	list->tail = node;
7000218c:	606c      	str	r4, [r5, #4]
		_priq_wait_add(&wait_q->waitq, thread);
	}
}
7000218e:	bd38      	pop	{r3, r4, r5, pc}
	sys_dnode_t *const prev = successor->prev;
70002190:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
70002192:	e9c4 3200 	strd	r3, r2, [r4]
	prev->next = node;
70002196:	6014      	str	r4, [r2, #0]
	successor->prev = node;
70002198:	605c      	str	r4, [r3, #4]
7000219a:	bd38      	pop	{r3, r4, r5, pc}

7000219c <ready_thread>:
	return (thread->base.thread_state & state) != 0U;
7000219c:	7b43      	ldrb	r3, [r0, #13]
	if (!z_is_thread_queued(thread) && z_is_thread_ready(thread)) {
7000219e:	0619      	lsls	r1, r3, #24
700021a0:	d403      	bmi.n	700021aa <ready_thread+0xe>
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
700021a2:	06da      	lsls	r2, r3, #27
700021a4:	d101      	bne.n	700021aa <ready_thread+0xe>
	return node->next != NULL;
700021a6:	6982      	ldr	r2, [r0, #24]
700021a8:	b102      	cbz	r2, 700021ac <ready_thread+0x10>
700021aa:	4770      	bx	lr
	return list->head == list;
700021ac:	f647 6c38 	movw	ip, #32312	; 0x7e38
	thread->base.thread_state |= _THREAD_QUEUED;
700021b0:	f063 037f 	orn	r3, r3, #127	; 0x7f
700021b4:	f2c7 0c00 	movt	ip, #28672	; 0x7000
{
700021b8:	b430      	push	{r4, r5}
	thread->base.thread_state |= _THREAD_QUEUED;
700021ba:	7343      	strb	r3, [r0, #13]
700021bc:	4665      	mov	r5, ip
	return (node == list->tail) ? NULL : node->next;
700021be:	f8dc 401c 	ldr.w	r4, [ip, #28]
	return list->head == list;
700021c2:	f855 3f18 	ldr.w	r3, [r5, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
700021c6:	42ab      	cmp	r3, r5
700021c8:	bf08      	it	eq
700021ca:	2300      	moveq	r3, #0
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
700021cc:	b15b      	cbz	r3, 700021e6 <ready_thread+0x4a>
	int32_t b2 = thread_2->base.prio;
700021ce:	f993 100e 	ldrsb.w	r1, [r3, #14]
	int32_t b1 = thread_1->base.prio;
700021d2:	f990 200e 	ldrsb.w	r2, [r0, #14]
	if (b1 != b2) {
700021d6:	428a      	cmp	r2, r1
700021d8:	d001      	beq.n	700021de <ready_thread+0x42>
		if (z_sched_prio_cmp(thread, t) > 0) {
700021da:	4291      	cmp	r1, r2
700021dc:	dc20      	bgt.n	70002220 <ready_thread+0x84>
	return (node == list->tail) ? NULL : node->next;
700021de:	42a3      	cmp	r3, r4
700021e0:	d001      	beq.n	700021e6 <ready_thread+0x4a>
700021e2:	681b      	ldr	r3, [r3, #0]
700021e4:	e7f2      	b.n	700021cc <ready_thread+0x30>
	node->prev = tail;
700021e6:	e9c0 5400 	strd	r5, r4, [r0]
	tail->next = node;
700021ea:	6020      	str	r0, [r4, #0]
	list->tail = node;
700021ec:	f8cc 001c 	str.w	r0, [ip, #28]
	return list->head == list;
700021f0:	f8dc 3018 	ldr.w	r3, [ip, #24]
700021f4:	f8dc 2008 	ldr.w	r2, [ip, #8]
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
700021f8:	7b51      	ldrb	r1, [r2, #13]
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700021fa:	2b00      	cmp	r3, #0
700021fc:	bf18      	it	ne
700021fe:	42ab      	cmpne	r3, r5
70002200:	bf08      	it	eq
70002202:	f8dc 300c 	ldreq.w	r3, [ip, #12]
70002206:	06c9      	lsls	r1, r1, #27
70002208:	d107      	bne.n	7000221a <ready_thread+0x7e>
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
7000220a:	89d1      	ldrh	r1, [r2, #14]
7000220c:	297f      	cmp	r1, #127	; 0x7f
		_kernel.ready_q.cache = arch_current_thread();
7000220e:	bf88      	it	hi
70002210:	f8cc 2014 	strhi.w	r2, [ip, #20]
70002214:	d901      	bls.n	7000221a <ready_thread+0x7e>
}
70002216:	bc30      	pop	{r4, r5}
70002218:	4770      	bx	lr
		_kernel.ready_q.cache = thread;
7000221a:	f8cc 3014 	str.w	r3, [ip, #20]
}
7000221e:	e7fa      	b.n	70002216 <ready_thread+0x7a>
	sys_dnode_t *const prev = successor->prev;
70002220:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
70002222:	e9c0 3200 	strd	r3, r2, [r0]
	prev->next = node;
70002226:	6010      	str	r0, [r2, #0]
	successor->prev = node;
70002228:	6058      	str	r0, [r3, #4]
}
7000222a:	e7e1      	b.n	700021f0 <ready_thread+0x54>

7000222c <z_thread_halt>:
		halt_thread(thread, terminate ? _THREAD_DEAD : _THREAD_SUSPENDED);
7000222c:	2a00      	cmp	r2, #0
7000222e:	bf0c      	ite	eq
70002230:	2210      	moveq	r2, #16
70002232:	2208      	movne	r2, #8
{
70002234:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	bool dummify = false;

	/* We hold the lock, and the thread is known not to be running
	 * anywhere.
	 */
	if ((thread->base.thread_state & new_state) == 0U) {
70002238:	7b43      	ldrb	r3, [r0, #13]
{
7000223a:	460f      	mov	r7, r1
	if ((thread->base.thread_state & new_state) == 0U) {
7000223c:	ea12 0103 	ands.w	r1, r2, r3
70002240:	bf18      	it	ne
70002242:	f647 6338 	movwne	r3, #32312	; 0x7e38
{
70002246:	4605      	mov	r5, r0
70002248:	bf18      	it	ne
7000224a:	f2c7 0300 	movtne	r3, #28672	; 0x7000
	if ((thread->base.thread_state & new_state) == 0U) {
7000224e:	d122      	bne.n	70002296 <z_thread_halt+0x6a>
		thread->base.thread_state |= new_state;
70002250:	ea42 0003 	orr.w	r0, r2, r3
		if (z_is_thread_queued(thread)) {
70002254:	09db      	lsrs	r3, r3, #7
	thread->base.thread_state &= ~_THREAD_QUEUED;
70002256:	bf17      	itett	ne
70002258:	f000 007f 	andne.w	r0, r0, #127	; 0x7f
		thread->base.thread_state |= new_state;
7000225c:	7368      	strbeq	r0, [r5, #13]
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000225e:	7368      	strbne	r0, [r5, #13]
	sys_dnode_t *const next = node->next;
70002260:	e9d5 3000 	ldrdne	r3, r0, [r5]
	prev->next = next;
70002264:	bf1e      	ittt	ne
70002266:	6003      	strne	r3, [r0, #0]
	next->prev = prev;
70002268:	6058      	strne	r0, [r3, #4]
	node->prev = NULL;
7000226a:	e9c5 1100 	strdne	r1, r1, [r5]
			dequeue_thread(thread);
		}

		if (new_state == _THREAD_DEAD) {
7000226e:	2a08      	cmp	r2, #8
70002270:	d029      	beq.n	700022c6 <z_thread_halt+0x9a>
	return list->head == list;
70002272:	f647 6338 	movw	r3, #32312	; 0x7e38
70002276:	f2c7 0300 	movt	r3, #28672	; 0x7000
7000227a:	461a      	mov	r2, r3
7000227c:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002280:	4291      	cmp	r1, r2
70002282:	d05f      	beq.n	70002344 <z_thread_halt+0x118>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002284:	2900      	cmp	r1, #0
70002286:	d069      	beq.n	7000235c <z_thread_halt+0x130>
		_kernel.ready_q.cache = thread;
70002288:	6159      	str	r1, [r3, #20]
  __ASM volatile ("dmb 0xF":::"memory");
7000228a:	f3bf 8f5f 	dmb	sy
	thread->base.thread_state &= ~(_THREAD_ABORTING | _THREAD_SUSPENDING);
7000228e:	7b6a      	ldrb	r2, [r5, #13]
70002290:	f022 0260 	bic.w	r2, r2, #96	; 0x60
70002294:	736a      	strb	r2, [r5, #13]
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
70002296:	689a      	ldr	r2, [r3, #8]
70002298:	4295      	cmp	r5, r2
7000229a:	d003      	beq.n	700022a4 <z_thread_halt+0x78>
	if (key != 0U) {
7000229c:	b907      	cbnz	r7, 700022a0 <z_thread_halt+0x74>
  __ASM volatile ("cpsie i" : : : "memory");
7000229e:	b662      	cpsie	i
}
700022a0:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
700022a4:	ee1d 2f70 	mrc	15, 0, r2, cr13, cr0, {3}
700022a8:	f022 0203 	bic.w	r2, r2, #3
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
700022ac:	6812      	ldr	r2, [r2, #0]
700022ae:	2a00      	cmp	r2, #0
700022b0:	d1f4      	bne.n	7000229c <z_thread_halt+0x70>
700022b2:	689b      	ldr	r3, [r3, #8]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700022b4:	f06f 020a 	mvn.w	r2, #10
700022b8:	e9c3 721b 	strd	r7, r2, [r3, #108]	; 0x6c
	z_arm_cortex_r_svc();
700022bc:	f7fe ee86 	blx	70000fcc <z_arm_cortex_r_svc>
700022c0:	2f00      	cmp	r7, #0
700022c2:	d0ec      	beq.n	7000229e <z_thread_halt+0x72>
700022c4:	e7ec      	b.n	700022a0 <z_thread_halt+0x74>
			if (thread->base.pended_on != NULL) {
700022c6:	68ab      	ldr	r3, [r5, #8]
700022c8:	b15b      	cbz	r3, 700022e2 <z_thread_halt+0xb6>
	sys_dnode_t *const next = node->next;
700022ca:	e9d5 3100 	ldrd	r3, r1, [r5]
	node->next = NULL;
700022ce:	2200      	movs	r2, #0
	prev->next = next;
700022d0:	600b      	str	r3, [r1, #0]
	next->prev = prev;
700022d2:	6059      	str	r1, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
700022d4:	7b6b      	ldrb	r3, [r5, #13]
	node->prev = NULL;
700022d6:	e9c5 2200 	strd	r2, r2, [r5]
700022da:	f023 0302 	bic.w	r3, r3, #2
700022de:	60aa      	str	r2, [r5, #8]
700022e0:	736b      	strb	r3, [r5, #13]
	return z_abort_timeout(&thread->base.timeout);
700022e2:	f105 0018 	add.w	r0, r5, #24
700022e6:	f000 fb13 	bl	70002910 <z_abort_timeout>
	return list->head == list;
700022ea:	6dac      	ldr	r4, [r5, #88]	; 0x58
}

static inline struct k_thread *z_waitq_head(_wait_q_t *w)
{
	return (struct k_thread *)sys_dlist_peek_head(&w->waitq);
700022ec:	f105 0858 	add.w	r8, r5, #88	; 0x58
	return sys_dlist_is_empty(list) ? NULL : list->head;
700022f0:	45a0      	cmp	r8, r4
700022f2:	d019      	beq.n	70002328 <z_thread_halt+0xfc>
	for (thread = z_waitq_head(wait_q); thread != NULL; thread = z_waitq_head(wait_q)) {
700022f4:	b1c4      	cbz	r4, 70002328 <z_thread_halt+0xfc>
	node->next = NULL;
700022f6:	2600      	movs	r6, #0
700022f8:	e000      	b.n	700022fc <z_thread_halt+0xd0>
700022fa:	b1ac      	cbz	r4, 70002328 <z_thread_halt+0xfc>
	sys_dnode_t *const next = node->next;
700022fc:	e9d4 3200 	ldrd	r3, r2, [r4]
70002300:	f104 0018 	add.w	r0, r4, #24
	prev->next = next;
70002304:	6013      	str	r3, [r2, #0]
	next->prev = prev;
70002306:	605a      	str	r2, [r3, #4]
70002308:	7b63      	ldrb	r3, [r4, #13]
	node->prev = NULL;
7000230a:	e9c4 6600 	strd	r6, r6, [r4]
7000230e:	f023 0302 	bic.w	r3, r3, #2
70002312:	60a6      	str	r6, [r4, #8]
70002314:	7363      	strb	r3, [r4, #13]
70002316:	f000 fafb 	bl	70002910 <z_abort_timeout>
	thread->arch.swap_return_value = value;
7000231a:	6726      	str	r6, [r4, #112]	; 0x70
		ready_thread(thread);
7000231c:	4620      	mov	r0, r4
7000231e:	f7ff ff3d 	bl	7000219c <ready_thread>
	return list->head == list;
70002322:	6dac      	ldr	r4, [r5, #88]	; 0x58
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002324:	45a0      	cmp	r8, r4
70002326:	d1e8      	bne.n	700022fa <z_thread_halt+0xce>
70002328:	f647 6338 	movw	r3, #32312	; 0x7e38
7000232c:	f2c7 0300 	movt	r3, #28672	; 0x7000
			 * ISR that preempted it requires clearing the
			 * arch_current_thread() pointer so the upcoming context
			 * switch doesn't clobber the now-freed
			 * memory
			 */
			if (thread == arch_current_thread() && arch_is_in_isr()) {
70002330:	689a      	ldr	r2, [r3, #8]
70002332:	4295      	cmp	r5, r2
70002334:	d014      	beq.n	70002360 <z_thread_halt+0x134>
	return list->head == list;
70002336:	461a      	mov	r2, r3
70002338:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
7000233c:	4291      	cmp	r1, r2
7000233e:	d001      	beq.n	70002344 <z_thread_halt+0x118>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002340:	2900      	cmp	r1, #0
70002342:	d1a1      	bne.n	70002288 <z_thread_halt+0x5c>
		_kernel.ready_q.cache = thread;
70002344:	68da      	ldr	r2, [r3, #12]
70002346:	615a      	str	r2, [r3, #20]
  __ASM volatile ("dmb 0xF":::"memory");
70002348:	f3bf 8f5f 	dmb	sy
	thread->base.thread_state &= ~(_THREAD_ABORTING | _THREAD_SUSPENDING);
7000234c:	7b6a      	ldrb	r2, [r5, #13]
7000234e:	f022 0260 	bic.w	r2, r2, #96	; 0x60
70002352:	736a      	strb	r2, [r5, #13]
		if ((thread == arch_current_thread()) && !arch_is_in_isr()) {
70002354:	689a      	ldr	r2, [r3, #8]
70002356:	4295      	cmp	r5, r2
70002358:	d1a0      	bne.n	7000229c <z_thread_halt+0x70>
7000235a:	e7a3      	b.n	700022a4 <z_thread_halt+0x78>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
7000235c:	68d9      	ldr	r1, [r3, #12]
#ifdef CONFIG_SMP
		unpend_all(&thread->halt_queue);
#endif /* CONFIG_SMP */
		update_cache(1);

		if (new_state == _THREAD_SUSPENDED) {
7000235e:	e793      	b.n	70002288 <z_thread_halt+0x5c>
70002360:	ee1d 2f70 	mrc	15, 0, r2, cr13, cr0, {3}
70002364:	f022 0203 	bic.w	r2, r2, #3
			if (thread == arch_current_thread() && arch_is_in_isr()) {
70002368:	6812      	ldr	r2, [r2, #0]
7000236a:	2a00      	cmp	r2, #0
7000236c:	d0e3      	beq.n	70002336 <z_thread_halt+0x10a>
	return list->head == list;
7000236e:	461a      	mov	r2, r3
70002370:	f852 1f18 	ldr.w	r1, [r2, #24]!
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002374:	4291      	cmp	r1, r2
70002376:	d00c      	beq.n	70002392 <z_thread_halt+0x166>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002378:	b159      	cbz	r1, 70002392 <z_thread_halt+0x166>
		_kernel.ready_q.cache = thread;
7000237a:	6159      	str	r1, [r3, #20]
7000237c:	f245 4228 	movw	r2, #21544	; 0x5428
70002380:	f240 1101 	movw	r1, #257	; 0x101
70002384:	f2c7 0200 	movt	r2, #28672	; 0x7000
70002388:	8191      	strh	r1, [r2, #12]
	dummy_thread->resource_pool = NULL;
7000238a:	2100      	movs	r1, #0
	_current_cpu->current = thread;
7000238c:	609a      	str	r2, [r3, #8]
7000238e:	6691      	str	r1, [r2, #104]	; 0x68
#ifdef CONFIG_TIMESLICE_PER_THREAD
	dummy_thread->base.slice_ticks = 0;
#endif /* CONFIG_TIMESLICE_PER_THREAD */

	arch_current_thread_set(dummy_thread);
}
70002390:	e7da      	b.n	70002348 <z_thread_halt+0x11c>
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002392:	68d9      	ldr	r1, [r3, #12]
		 * code.  Note that we must leave a non-null switch
		 * handle for any threads spinning in join() (this can
		 * never be used, as our thread is flagged dead, but
		 * it must not be NULL otherwise join can deadlock).
		 */
		if (dummify && !IS_ENABLED(CONFIG_ARCH_POSIX)) {
70002394:	e7f1      	b.n	7000237a <z_thread_halt+0x14e>
70002396:	bf00      	nop

70002398 <z_ready_thread>:
{
70002398:	b510      	push	{r4, lr}
	__asm__ volatile(
7000239a:	f3ef 8400 	mrs	r4, CPSR
7000239e:	f004 0480 	and.w	r4, r4, #128	; 0x80
700023a2:	b672      	cpsid	i
			ready_thread(thread);
700023a4:	f7ff fefa 	bl	7000219c <ready_thread>
	if (key != 0U) {
700023a8:	b904      	cbnz	r4, 700023ac <z_ready_thread+0x14>
  __ASM volatile ("cpsie i" : : : "memory");
700023aa:	b662      	cpsie	i
}
700023ac:	bd10      	pop	{r4, pc}
700023ae:	bf00      	nop

700023b0 <z_impl_k_thread_suspend>:
	struct k_thread *ret = _kernel.cpus[0].current;
700023b0:	f647 6338 	movw	r3, #32312	; 0x7e38
700023b4:	f2c7 0300 	movt	r3, #28672	; 0x7000
	if (thread == arch_current_thread() && !arch_is_in_isr() && !IS_ENABLED(CONFIG_SMP)) {
700023b8:	689a      	ldr	r2, [r3, #8]
700023ba:	4282      	cmp	r2, r0
700023bc:	d00e      	beq.n	700023dc <z_impl_k_thread_suspend+0x2c>
	__asm__ volatile(
700023be:	f3ef 8100 	mrs	r1, CPSR
700023c2:	f001 0180 	and.w	r1, r1, #128	; 0x80
700023c6:	b672      	cpsid	i
	if ((thread->base.thread_state & _THREAD_SUSPENDED) != 0U) {
700023c8:	7b42      	ldrb	r2, [r0, #13]
700023ca:	f012 0210 	ands.w	r2, r2, #16
700023ce:	d002      	beq.n	700023d6 <z_impl_k_thread_suspend+0x26>
	if (key != 0U) {
700023d0:	b919      	cbnz	r1, 700023da <z_impl_k_thread_suspend+0x2a>
700023d2:	b662      	cpsie	i
}
700023d4:	4770      	bx	lr
	z_thread_halt(thread, key, false);
700023d6:	f7ff bf29 	b.w	7000222c <z_thread_halt>
700023da:	4770      	bx	lr
700023dc:	ee1d 1f70 	mrc	15, 0, r1, cr13, cr0, {3}
700023e0:	f021 0103 	bic.w	r1, r1, #3
	if (thread == arch_current_thread() && !arch_is_in_isr() && !IS_ENABLED(CONFIG_SMP)) {
700023e4:	6809      	ldr	r1, [r1, #0]
700023e6:	2900      	cmp	r1, #0
700023e8:	d1e9      	bne.n	700023be <z_impl_k_thread_suspend+0xe>
{
700023ea:	b570      	push	{r4, r5, r6, lr}
	__asm__ volatile(
700023ec:	f3ef 8400 	mrs	r4, CPSR
700023f0:	f004 0480 	and.w	r4, r4, #128	; 0x80
700023f4:	b672      	cpsid	i
	thread->base.thread_state &= ~_THREAD_QUEUED;
700023f6:	7b50      	ldrb	r0, [r2, #13]
	sys_dnode_t *const prev = node->prev;
700023f8:	6856      	ldr	r6, [r2, #4]
	sys_dnode_t *const next = node->next;
700023fa:	6815      	ldr	r5, [r2, #0]
700023fc:	f000 007f 	and.w	r0, r0, #127	; 0x7f
70002400:	f040 0010 	orr.w	r0, r0, #16
70002404:	7350      	strb	r0, [r2, #13]
	return list->head == list;
70002406:	4618      	mov	r0, r3
	prev->next = next;
70002408:	6035      	str	r5, [r6, #0]
	next->prev = prev;
7000240a:	606e      	str	r6, [r5, #4]
	node->next = NULL;
7000240c:	6011      	str	r1, [r2, #0]
7000240e:	6051      	str	r1, [r2, #4]
	return list->head == list;
70002410:	f850 2f18 	ldr.w	r2, [r0, #24]!
70002414:	6899      	ldr	r1, [r3, #8]
	arch_current_thread()->arch.basepri = key;
70002416:	66cc      	str	r4, [r1, #108]	; 0x6c
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
70002418:	4282      	cmp	r2, r0
7000241a:	bf18      	it	ne
7000241c:	2a00      	cmpne	r2, #0
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
7000241e:	f06f 000a 	mvn.w	r0, #10
70002422:	bf08      	it	eq
70002424:	68da      	ldreq	r2, [r3, #12]
70002426:	6708      	str	r0, [r1, #112]	; 0x70
		_kernel.ready_q.cache = thread;
70002428:	615a      	str	r2, [r3, #20]
	z_arm_cortex_r_svc();
7000242a:	f7fe edd0 	blx	70000fcc <z_arm_cortex_r_svc>
	if (key != 0U) {
7000242e:	b904      	cbnz	r4, 70002432 <z_impl_k_thread_suspend+0x82>
  __ASM volatile ("cpsie i" : : : "memory");
70002430:	b662      	cpsie	i
}
70002432:	bd70      	pop	{r4, r5, r6, pc}

70002434 <z_unpend_thread_no_timeout>:
	__asm__ volatile(
70002434:	f3ef 8100 	mrs	r1, CPSR
70002438:	f001 0180 	and.w	r1, r1, #128	; 0x80
7000243c:	b672      	cpsid	i
		if (thread->base.pended_on != NULL) {
7000243e:	6883      	ldr	r3, [r0, #8]
70002440:	b193      	cbz	r3, 70002468 <z_unpend_thread_no_timeout+0x34>
	sys_dnode_t *const next = node->next;
70002442:	e9d0 3200 	ldrd	r3, r2, [r0]
{
70002446:	b430      	push	{r4, r5}
	prev->next = next;
70002448:	6013      	str	r3, [r2, #0]
	node->next = NULL;
7000244a:	2400      	movs	r4, #0
	next->prev = prev;
7000244c:	605a      	str	r2, [r3, #4]
	node->next = NULL;
7000244e:	2500      	movs	r5, #0
70002450:	7b43      	ldrb	r3, [r0, #13]
70002452:	2200      	movs	r2, #0
70002454:	e9c0 4500 	strd	r4, r5, [r0]
70002458:	f023 0302 	bic.w	r3, r3, #2
7000245c:	6082      	str	r2, [r0, #8]
7000245e:	7343      	strb	r3, [r0, #13]
	if (key != 0U) {
70002460:	b901      	cbnz	r1, 70002464 <z_unpend_thread_no_timeout+0x30>
70002462:	b662      	cpsie	i
}
70002464:	bc30      	pop	{r4, r5}
70002466:	4770      	bx	lr
70002468:	b909      	cbnz	r1, 7000246e <z_unpend_thread_no_timeout+0x3a>
7000246a:	b662      	cpsie	i
	K_SPINLOCK(&_sched_spinlock) {
7000246c:	4770      	bx	lr
7000246e:	4770      	bx	lr

70002470 <z_sched_wake_thread>:
{
70002470:	b5d0      	push	{r4, r6, r7, lr}
	__asm__ volatile(
70002472:	f3ef 8400 	mrs	r4, CPSR
70002476:	f004 0480 	and.w	r4, r4, #128	; 0x80
7000247a:	b672      	cpsid	i
		bool killed = (thread->base.thread_state &
7000247c:	7b43      	ldrb	r3, [r0, #13]
		if (!killed) {
7000247e:	f013 0128 	ands.w	r1, r3, #40	; 0x28
70002482:	d112      	bne.n	700024aa <z_sched_wake_thread+0x3a>
			if (thread->base.pended_on != NULL) {
70002484:	6882      	ldr	r2, [r0, #8]
70002486:	b15a      	cbz	r2, 700024a0 <z_sched_wake_thread+0x30>
	sys_dnode_t *const next = node->next;
70002488:	e9d0 3200 	ldrd	r3, r2, [r0]
	node->next = NULL;
7000248c:	2600      	movs	r6, #0
	prev->next = next;
7000248e:	6013      	str	r3, [r2, #0]
	node->next = NULL;
70002490:	2700      	movs	r7, #0
	next->prev = prev;
70002492:	605a      	str	r2, [r3, #4]
70002494:	7b43      	ldrb	r3, [r0, #13]
	node->next = NULL;
70002496:	e9c0 6700 	strd	r6, r7, [r0]
7000249a:	f003 03fd 	and.w	r3, r3, #253	; 0xfd
7000249e:	6081      	str	r1, [r0, #8]
	thread->base.thread_state &= ~_THREAD_SLEEPING;
700024a0:	f023 0304 	bic.w	r3, r3, #4
700024a4:	7343      	strb	r3, [r0, #13]
			ready_thread(thread);
700024a6:	f7ff fe79 	bl	7000219c <ready_thread>
	if (key != 0U) {
700024aa:	b904      	cbnz	r4, 700024ae <z_sched_wake_thread+0x3e>
700024ac:	b662      	cpsie	i
}
700024ae:	bdd0      	pop	{r4, r6, r7, pc}

700024b0 <z_thread_timeout>:
	z_sched_wake_thread(thread, true);
700024b0:	2101      	movs	r1, #1
700024b2:	3818      	subs	r0, #24
700024b4:	f7ff bfdc 	b.w	70002470 <z_sched_wake_thread>

700024b8 <z_pend_curr>:
{
700024b8:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
700024ba:	e9dd 7606 	ldrd	r7, r6, [sp, #24]
700024be:	460d      	mov	r5, r1
700024c0:	4611      	mov	r1, r2
	__asm__ volatile(
700024c2:	f3ef 8300 	mrs	r3, CPSR
700024c6:	f003 0380 	and.w	r3, r3, #128	; 0x80
700024ca:	b672      	cpsid	i
700024cc:	f647 6438 	movw	r4, #32312	; 0x7e38
700024d0:	f2c7 0400 	movt	r4, #28672	; 0x7000
700024d4:	68a0      	ldr	r0, [r4, #8]
	add_to_waitq_locked(thread, wait_q);
700024d6:	f7ff fe39 	bl	7000214c <add_to_waitq_locked>
	if (!K_TIMEOUT_EQ(timeout, K_FOREVER)) {
700024da:	f1b6 3fff 	cmp.w	r6, #4294967295	; 0xffffffff
700024de:	bf08      	it	eq
700024e0:	f1b7 3fff 	cmpeq.w	r7, #4294967295	; 0xffffffff
700024e4:	d008      	beq.n	700024f8 <z_pend_curr+0x40>
	z_add_timeout(&thread->base.timeout, z_thread_timeout, ticks);
700024e6:	f242 41b1 	movw	r1, #9393	; 0x24b1
700024ea:	463a      	mov	r2, r7
700024ec:	4633      	mov	r3, r6
700024ee:	3018      	adds	r0, #24
700024f0:	f2c7 0100 	movt	r1, #28672	; 0x7000
700024f4:	f000 f97a 	bl	700027ec <z_add_timeout>
700024f8:	68a3      	ldr	r3, [r4, #8]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700024fa:	f06f 020a 	mvn.w	r2, #10
700024fe:	e9c3 521b 	strd	r5, r2, [r3, #108]	; 0x6c
	z_arm_cortex_r_svc();
70002502:	f7fe ed64 	blx	70000fcc <z_arm_cortex_r_svc>
	if (key != 0U) {
70002506:	b905      	cbnz	r5, 7000250a <z_pend_curr+0x52>
70002508:	b662      	cpsie	i
	return arch_current_thread()->arch.swap_return_value;
7000250a:	68a3      	ldr	r3, [r4, #8]
}
7000250c:	6f18      	ldr	r0, [r3, #112]	; 0x70
7000250e:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}

70002510 <z_unpend_thread>:
{
70002510:	b510      	push	{r4, lr}
	z_unpend_thread_no_timeout(thread);
70002512:	f7ff ff8f 	bl	70002434 <z_unpend_thread_no_timeout>
}
70002516:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	return z_abort_timeout(&thread->base.timeout);
7000251a:	3018      	adds	r0, #24
7000251c:	f000 b9f8 	b.w	70002910 <z_abort_timeout>

70002520 <z_reschedule>:
	return arch_irq_unlocked(key) && !arch_is_in_isr();
70002520:	b9c1      	cbnz	r1, 70002554 <z_reschedule+0x34>
{
70002522:	b508      	push	{r3, lr}
70002524:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70002528:	f023 0303 	bic.w	r3, r3, #3
	return arch_irq_unlocked(key) && !arch_is_in_isr();
7000252c:	681a      	ldr	r2, [r3, #0]
7000252e:	b97a      	cbnz	r2, 70002550 <z_reschedule+0x30>
70002530:	f647 6338 	movw	r3, #32312	; 0x7e38
70002534:	f2c7 0300 	movt	r3, #28672	; 0x7000
70002538:	6899      	ldr	r1, [r3, #8]
	if (resched(key.key) && need_swap()) {
7000253a:	695b      	ldr	r3, [r3, #20]
7000253c:	428b      	cmp	r3, r1
7000253e:	d007      	beq.n	70002550 <z_reschedule+0x30>
	arch_current_thread()->arch.basepri = key;
70002540:	66ca      	str	r2, [r1, #108]	; 0x6c
70002542:	f06f 030a 	mvn.w	r3, #10
70002546:	670b      	str	r3, [r1, #112]	; 0x70
	z_arm_cortex_r_svc();
70002548:	f7fe ed40 	blx	70000fcc <z_arm_cortex_r_svc>
7000254c:	b662      	cpsie	i
}
7000254e:	bd08      	pop	{r3, pc}
70002550:	b662      	cpsie	i
70002552:	bd08      	pop	{r3, pc}
70002554:	4770      	bx	lr
70002556:	bf00      	nop

70002558 <z_impl_k_thread_resume>:
{
70002558:	b510      	push	{r4, lr}
	__asm__ volatile(
7000255a:	f3ef 8400 	mrs	r4, CPSR
7000255e:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002562:	b672      	cpsid	i
	return (thread->base.thread_state & _THREAD_SUSPENDED) != 0U;
70002564:	7b42      	ldrb	r2, [r0, #13]
	if (!z_is_thread_suspended(thread)) {
70002566:	06d3      	lsls	r3, r2, #27
70002568:	d402      	bmi.n	70002570 <z_impl_k_thread_resume+0x18>
	if (key != 0U) {
7000256a:	b904      	cbnz	r4, 7000256e <z_impl_k_thread_resume+0x16>
7000256c:	b662      	cpsie	i
}
7000256e:	bd10      	pop	{r4, pc}
	thread->base.thread_state &= ~_THREAD_SUSPENDED;
70002570:	f022 0210 	bic.w	r2, r2, #16
70002574:	7342      	strb	r2, [r0, #13]
	ready_thread(thread);
70002576:	f7ff fe11 	bl	7000219c <ready_thread>
	z_reschedule(&_sched_spinlock, key);
7000257a:	f647 6058 	movw	r0, #32344	; 0x7e58
7000257e:	4621      	mov	r1, r4
70002580:	f2c7 0000 	movt	r0, #28672	; 0x7000
}
70002584:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
	z_reschedule(&_sched_spinlock, key);
70002588:	f7ff bfca 	b.w	70002520 <z_reschedule>

7000258c <k_sched_lock>:
	__asm__ volatile(
7000258c:	f3ef 8100 	mrs	r1, CPSR
70002590:	f001 0180 	and.w	r1, r1, #128	; 0x80
70002594:	b672      	cpsid	i
70002596:	f647 6338 	movw	r3, #32312	; 0x7e38
7000259a:	f2c7 0300 	movt	r3, #28672	; 0x7000
7000259e:	689a      	ldr	r2, [r3, #8]
	--arch_current_thread()->base.sched_locked;
700025a0:	7bd3      	ldrb	r3, [r2, #15]
700025a2:	3b01      	subs	r3, #1
700025a4:	73d3      	strb	r3, [r2, #15]
	if (key != 0U) {
700025a6:	b901      	cbnz	r1, 700025aa <k_sched_lock+0x1e>
700025a8:	b662      	cpsie	i
}
700025aa:	4770      	bx	lr

700025ac <k_sched_unlock>:
{
700025ac:	b510      	push	{r4, lr}
	__asm__ volatile(
700025ae:	f3ef 8400 	mrs	r4, CPSR
700025b2:	f004 0480 	and.w	r4, r4, #128	; 0x80
700025b6:	b672      	cpsid	i
700025b8:	f647 6038 	movw	r0, #32312	; 0x7e38
700025bc:	f2c7 0000 	movt	r0, #28672	; 0x7000
	return list->head == list;
700025c0:	4601      	mov	r1, r0
700025c2:	6882      	ldr	r2, [r0, #8]
		++arch_current_thread()->base.sched_locked;
700025c4:	7bd3      	ldrb	r3, [r2, #15]
700025c6:	3301      	adds	r3, #1
700025c8:	73d3      	strb	r3, [r2, #15]
700025ca:	f851 3f18 	ldr.w	r3, [r1, #24]!
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700025ce:	428b      	cmp	r3, r1
700025d0:	bf18      	it	ne
700025d2:	2b00      	cmpne	r3, #0
	if (z_is_thread_prevented_from_running(arch_current_thread())) {
700025d4:	7b51      	ldrb	r1, [r2, #13]
700025d6:	bf08      	it	eq
700025d8:	68c3      	ldreq	r3, [r0, #12]
700025da:	06c9      	lsls	r1, r1, #27
700025dc:	d103      	bne.n	700025e6 <k_sched_unlock+0x3a>
	if (thread_is_preemptible(arch_current_thread()) || thread_is_metairq(thread)) {
700025de:	89d1      	ldrh	r1, [r2, #14]
700025e0:	297f      	cmp	r1, #127	; 0x7f
700025e2:	bf88      	it	hi
700025e4:	4613      	movhi	r3, r2
700025e6:	6143      	str	r3, [r0, #20]
	if (key != 0U) {
700025e8:	b904      	cbnz	r4, 700025ec <k_sched_unlock+0x40>
700025ea:	b662      	cpsie	i
	__asm__ volatile(
700025ec:	f3ef 8300 	mrs	r3, CPSR
700025f0:	f003 0380 	and.w	r3, r3, #128	; 0x80
700025f4:	b672      	cpsid	i
	return arch_irq_unlocked(key) && !arch_is_in_isr();
700025f6:	b983      	cbnz	r3, 7000261a <k_sched_unlock+0x6e>
700025f8:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
700025fc:	f023 0303 	bic.w	r3, r3, #3
70002600:	681b      	ldr	r3, [r3, #0]
70002602:	b95b      	cbnz	r3, 7000261c <k_sched_unlock+0x70>
70002604:	6882      	ldr	r2, [r0, #8]
	if (resched(key) && need_swap()) {
70002606:	6941      	ldr	r1, [r0, #20]
70002608:	4291      	cmp	r1, r2
7000260a:	d007      	beq.n	7000261c <k_sched_unlock+0x70>
	arch_current_thread()->arch.basepri = key;
7000260c:	66d3      	str	r3, [r2, #108]	; 0x6c
7000260e:	f06f 010a 	mvn.w	r1, #10
70002612:	6711      	str	r1, [r2, #112]	; 0x70
	z_arm_cortex_r_svc();
70002614:	f7fe ecda 	blx	70000fcc <z_arm_cortex_r_svc>
70002618:	b662      	cpsie	i
}
7000261a:	bd10      	pop	{r4, pc}
7000261c:	b662      	cpsie	i
7000261e:	bd10      	pop	{r4, pc}

70002620 <z_sched_init>:
{
70002620:	4a02      	ldr	r2, [pc, #8]	; (7000262c <z_sched_init+0xc>)
	list->head = (sys_dnode_t *)list;
70002622:	4613      	mov	r3, r2
70002624:	f843 2918 	str.w	r2, [r3], #-24
70002628:	61da      	str	r2, [r3, #28]
}
7000262a:	4770      	bx	lr
7000262c:	70007e50 	.word	0x70007e50

70002630 <z_impl_k_yield>:
{
70002630:	b570      	push	{r4, r5, r6, lr}
70002632:	f3ef 8600 	mrs	r6, CPSR
70002636:	f006 0680 	and.w	r6, r6, #128	; 0x80
7000263a:	b672      	cpsid	i
7000263c:	f647 6c38 	movw	ip, #32312	; 0x7e38
70002640:	f2c7 0c00 	movt	ip, #28672	; 0x7000
	return list->head == list;
70002644:	4665      	mov	r5, ip
70002646:	f8dc 3008 	ldr.w	r3, [ip, #8]
	thread->base.thread_state &= ~_THREAD_QUEUED;
7000264a:	7b5a      	ldrb	r2, [r3, #13]
7000264c:	f002 027f 	and.w	r2, r2, #127	; 0x7f
70002650:	735a      	strb	r2, [r3, #13]
	node->next = NULL;
70002652:	2200      	movs	r2, #0
	sys_dnode_t *const prev = node->prev;
70002654:	6858      	ldr	r0, [r3, #4]
	sys_dnode_t *const next = node->next;
70002656:	6819      	ldr	r1, [r3, #0]
	prev->next = next;
70002658:	6001      	str	r1, [r0, #0]
	next->prev = prev;
7000265a:	6048      	str	r0, [r1, #4]
	node->next = NULL;
7000265c:	601a      	str	r2, [r3, #0]
7000265e:	605a      	str	r2, [r3, #4]
70002660:	f8dc 0008 	ldr.w	r0, [ip, #8]
	thread->base.thread_state |= _THREAD_QUEUED;
70002664:	7b43      	ldrb	r3, [r0, #13]
70002666:	f063 037f 	orn	r3, r3, #127	; 0x7f
7000266a:	7343      	strb	r3, [r0, #13]
	return list->head == list;
7000266c:	f855 3f18 	ldr.w	r3, [r5, #24]!
	return (node == list->tail) ? NULL : node->next;
70002670:	f8dc 401c 	ldr.w	r4, [ip, #28]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002674:	42ab      	cmp	r3, r5
70002676:	bf08      	it	eq
70002678:	4613      	moveq	r3, r2
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
7000267a:	b163      	cbz	r3, 70002696 <z_impl_k_yield+0x66>
	int32_t b2 = thread_2->base.prio;
7000267c:	f993 100e 	ldrsb.w	r1, [r3, #14]
	int32_t b1 = thread_1->base.prio;
70002680:	f990 200e 	ldrsb.w	r2, [r0, #14]
	if (b1 != b2) {
70002684:	428a      	cmp	r2, r1
70002686:	d001      	beq.n	7000268c <z_impl_k_yield+0x5c>
		if (z_sched_prio_cmp(thread, t) > 0) {
70002688:	4291      	cmp	r1, r2
7000268a:	dc1e      	bgt.n	700026ca <z_impl_k_yield+0x9a>
	return (node == list->tail) ? NULL : node->next;
7000268c:	42a3      	cmp	r3, r4
7000268e:	d002      	beq.n	70002696 <z_impl_k_yield+0x66>
70002690:	681b      	ldr	r3, [r3, #0]
	SYS_DLIST_FOR_EACH_CONTAINER(pq, t, base.qnode_dlist) {
70002692:	2b00      	cmp	r3, #0
70002694:	d1f2      	bne.n	7000267c <z_impl_k_yield+0x4c>
	node->prev = tail;
70002696:	e9c0 5400 	strd	r5, r4, [r0]
	tail->next = node;
7000269a:	6020      	str	r0, [r4, #0]
	list->tail = node;
7000269c:	f8cc 001c 	str.w	r0, [ip, #28]
	return list->head == list;
700026a0:	f8dc 3018 	ldr.w	r3, [ip, #24]
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700026a4:	f06f 010a 	mvn.w	r1, #10
700026a8:	f8dc 2008 	ldr.w	r2, [ip, #8]
	arch_current_thread()->arch.basepri = key;
700026ac:	66d6      	str	r6, [r2, #108]	; 0x6c
	return (thread != NULL) ? thread : _current_cpu->idle_thread;
700026ae:	42ab      	cmp	r3, r5
700026b0:	bf18      	it	ne
700026b2:	2b00      	cmpne	r3, #0
	arch_current_thread()->arch.swap_return_value = -EAGAIN;
700026b4:	6711      	str	r1, [r2, #112]	; 0x70
700026b6:	bf08      	it	eq
700026b8:	f8dc 300c 	ldreq.w	r3, [ip, #12]
		_kernel.ready_q.cache = thread;
700026bc:	f8cc 3014 	str.w	r3, [ip, #20]
	z_arm_cortex_r_svc();
700026c0:	f7fe ec84 	blx	70000fcc <z_arm_cortex_r_svc>
	if (key != 0U) {
700026c4:	b906      	cbnz	r6, 700026c8 <z_impl_k_yield+0x98>
700026c6:	b662      	cpsie	i
}
700026c8:	bd70      	pop	{r4, r5, r6, pc}
	sys_dnode_t *const prev = successor->prev;
700026ca:	685a      	ldr	r2, [r3, #4]
	node->prev = prev;
700026cc:	e9c0 3200 	strd	r3, r2, [r0]
	prev->next = node;
700026d0:	6010      	str	r0, [r2, #0]
	successor->prev = node;
700026d2:	6058      	str	r0, [r3, #4]
}
700026d4:	e7e4      	b.n	700026a0 <z_impl_k_yield+0x70>
700026d6:	bf00      	nop

700026d8 <z_impl_k_wakeup>:
{
700026d8:	b538      	push	{r3, r4, r5, lr}
700026da:	4604      	mov	r4, r0
700026dc:	3018      	adds	r0, #24
700026de:	f000 f917 	bl	70002910 <z_abort_timeout>
	__asm__ volatile(
700026e2:	f3ef 8500 	mrs	r5, CPSR
700026e6:	f005 0580 	and.w	r5, r5, #128	; 0x80
700026ea:	b672      	cpsid	i
	return (thread->base.thread_state & _THREAD_SLEEPING) != 0U;
700026ec:	7b63      	ldrb	r3, [r4, #13]
	if (!z_is_thread_sleeping(thread)) {
700026ee:	075a      	lsls	r2, r3, #29
700026f0:	d402      	bmi.n	700026f8 <z_impl_k_wakeup+0x20>
	if (key != 0U) {
700026f2:	b905      	cbnz	r5, 700026f6 <z_impl_k_wakeup+0x1e>
700026f4:	b662      	cpsie	i
}
700026f6:	bd38      	pop	{r3, r4, r5, pc}
	ready_thread(thread);
700026f8:	4620      	mov	r0, r4
	thread->base.thread_state &= ~_THREAD_SLEEPING;
700026fa:	f023 0304 	bic.w	r3, r3, #4
700026fe:	7363      	strb	r3, [r4, #13]
70002700:	f7ff fd4c 	bl	7000219c <ready_thread>
70002704:	ee1d 3f70 	mrc	15, 0, r3, cr13, cr0, {3}
70002708:	f023 0303 	bic.w	r3, r3, #3
	if (arch_is_in_isr()) {
7000270c:	681b      	ldr	r3, [r3, #0]
7000270e:	2b00      	cmp	r3, #0
70002710:	d1ef      	bne.n	700026f2 <z_impl_k_wakeup+0x1a>
		z_reschedule(&_sched_spinlock, key);
70002712:	f647 6058 	movw	r0, #32344	; 0x7e58
70002716:	4629      	mov	r1, r5
70002718:	f2c7 0000 	movt	r0, #28672	; 0x7000
}
7000271c:	e8bd 4038 	ldmia.w	sp!, {r3, r4, r5, lr}
		z_reschedule(&_sched_spinlock, key);
70002720:	f7ff befe 	b.w	70002520 <z_reschedule>

70002724 <z_impl_k_sched_current_thread_query>:
70002724:	f647 6338 	movw	r3, #32312	; 0x7e38
70002728:	f2c7 0300 	movt	r3, #28672	; 0x7000
}
7000272c:	6898      	ldr	r0, [r3, #8]
7000272e:	4770      	bx	lr

70002730 <z_impl_k_thread_abort>:
	__asm__ volatile(
70002730:	f3ef 8100 	mrs	r1, CPSR
70002734:	f001 0180 	and.w	r1, r1, #128	; 0x80
70002738:	b672      	cpsid	i
	return (thread->base.user_options & K_ESSENTIAL) == K_ESSENTIAL;
7000273a:	7b02      	ldrb	r2, [r0, #12]

void z_thread_abort(struct k_thread *thread)
{
	k_spinlock_key_t key = k_spin_lock(&_sched_spinlock);

	if (z_is_thread_essential(thread)) {
7000273c:	07d2      	lsls	r2, r2, #31
7000273e:	d409      	bmi.n	70002754 <z_impl_k_thread_abort+0x24>
		__ASSERT(false, "aborting essential thread %p", thread);
		k_panic();
		return;
	}

	if ((thread->base.thread_state & _THREAD_DEAD) != 0U) {
70002740:	7b43      	ldrb	r3, [r0, #13]
70002742:	071b      	lsls	r3, r3, #28
70002744:	d502      	bpl.n	7000274c <z_impl_k_thread_abort+0x1c>
	if (key != 0U) {
70002746:	b921      	cbnz	r1, 70002752 <z_impl_k_thread_abort+0x22>
70002748:	b662      	cpsie	i
}
7000274a:	4770      	bx	lr
		k_spin_unlock(&_sched_spinlock, key);
		return;
	}

	z_thread_halt(thread, key, true);
7000274c:	2201      	movs	r2, #1
7000274e:	f7ff bd6d 	b.w	7000222c <z_thread_halt>
	z_thread_abort(thread);

	__ASSERT_NO_MSG((thread->base.thread_state & _THREAD_DEAD) != 0);

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_thread, abort, thread);
}
70002752:	4770      	bx	lr
70002754:	b901      	cbnz	r1, 70002758 <z_impl_k_thread_abort+0x28>
  __ASM volatile ("cpsie i" : : : "memory");
70002756:	b662      	cpsie	i
		k_panic();
70002758:	2004      	movs	r0, #4
7000275a:	b500      	push	{lr}
7000275c:	b662      	cpsie	i
7000275e:	df02      	svc	2
70002760:	f85d eb04 	ldr.w	lr, [sp], #4
		return;
70002764:	4770      	bx	lr
70002766:	bf00      	nop

70002768 <z_sched_wake>:

/*
 * future scheduler.h API implementations
 */
bool z_sched_wake(_wait_q_t *wait_q, int swap_retval, void *swap_data)
{
70002768:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	__asm__ volatile(
7000276c:	f3ef 8800 	mrs	r8, CPSR
70002770:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002774:	b672      	cpsid	i
	return list->head == list;
70002776:	6804      	ldr	r4, [r0, #0]
	bool ret = false;

	K_SPINLOCK(&_sched_spinlock) {
		thread = _priq_wait_best(&wait_q->waitq);

		if (thread != NULL) {
70002778:	42a0      	cmp	r0, r4
7000277a:	bf18      	it	ne
7000277c:	2c00      	cmpne	r4, #0
7000277e:	bf14      	ite	ne
70002780:	2501      	movne	r5, #1
70002782:	2500      	moveq	r5, #0
70002784:	d106      	bne.n	70002794 <z_sched_wake+0x2c>
	if (key != 0U) {
70002786:	f1b8 0f00 	cmp.w	r8, #0
7000278a:	d100      	bne.n	7000278e <z_sched_wake+0x26>
7000278c:	b662      	cpsie	i
			ret = true;
		}
	}

	return ret;
}
7000278e:	4628      	mov	r0, r5
70002790:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	sys_dnode_t *const next = node->next;
70002794:	e9d4 3000 	ldrd	r3, r0, [r4]
	node->next = NULL;
70002798:	2600      	movs	r6, #0
z_thread_return_value_set_with_data(struct k_thread *thread,
				   unsigned int value,
				   void *data)
{
	arch_thread_return_value_set(thread, value);
	thread->base.swap_data = data;
7000279a:	6162      	str	r2, [r4, #20]
7000279c:	2700      	movs	r7, #0
	thread->arch.swap_return_value = value;
7000279e:	6721      	str	r1, [r4, #112]	; 0x70
	thread->base.pended_on = NULL;
700027a0:	2200      	movs	r2, #0
	prev->next = next;
700027a2:	6003      	str	r3, [r0, #0]
	next->prev = prev;
700027a4:	6058      	str	r0, [r3, #4]
	thread->base.thread_state &= ~_THREAD_PENDING;
700027a6:	7b63      	ldrb	r3, [r4, #13]
700027a8:	f023 0302 	bic.w	r3, r3, #2
	node->next = NULL;
700027ac:	e9c4 6700 	strd	r6, r7, [r4]
700027b0:	f104 0018 	add.w	r0, r4, #24
700027b4:	7363      	strb	r3, [r4, #13]
700027b6:	60a2      	str	r2, [r4, #8]
700027b8:	f000 f8aa 	bl	70002910 <z_abort_timeout>
			ready_thread(thread);
700027bc:	4620      	mov	r0, r4
700027be:	f7ff fced 	bl	7000219c <ready_thread>
			ret = true;
700027c2:	e7e0      	b.n	70002786 <z_sched_wake+0x1e>

700027c4 <z_sched_wait>:

int z_sched_wait(struct k_spinlock *lock, k_spinlock_key_t key,
		 _wait_q_t *wait_q, k_timeout_t timeout, void **data)
{
700027c4:	b510      	push	{r4, lr}
700027c6:	b082      	sub	sp, #8
	int ret = z_pend_curr(lock, key, wait_q, timeout);
700027c8:	e9dd 3404 	ldrd	r3, r4, [sp, #16]
700027cc:	e9cd 3400 	strd	r3, r4, [sp]
{
700027d0:	9c06      	ldr	r4, [sp, #24]
	int ret = z_pend_curr(lock, key, wait_q, timeout);
700027d2:	f7ff fe71 	bl	700024b8 <z_pend_curr>

	if (data != NULL) {
700027d6:	b134      	cbz	r4, 700027e6 <z_sched_wait+0x22>
700027d8:	f647 6338 	movw	r3, #32312	; 0x7e38
700027dc:	f2c7 0300 	movt	r3, #28672	; 0x7000
		*data = arch_current_thread()->base.swap_data;
700027e0:	689b      	ldr	r3, [r3, #8]
700027e2:	695b      	ldr	r3, [r3, #20]
700027e4:	6023      	str	r3, [r4, #0]
	}
	return ret;
}
700027e6:	b002      	add	sp, #8
700027e8:	bd10      	pop	{r4, pc}
700027ea:	bf00      	nop

700027ec <z_add_timeout>:
}

void z_add_timeout(struct _timeout *to, _timeout_func_t fn,
		   k_timeout_t timeout)
{
	if (K_TIMEOUT_EQ(timeout, K_FOREVER)) {
700027ec:	f1b3 3fff 	cmp.w	r3, #4294967295	; 0xffffffff
700027f0:	bf08      	it	eq
700027f2:	f1b2 3fff 	cmpeq.w	r2, #4294967295	; 0xffffffff
700027f6:	f000 808a 	beq.w	7000290e <z_add_timeout+0x122>
{
700027fa:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
700027fc:	4606      	mov	r6, r0
700027fe:	461d      	mov	r5, r3
70002800:	4614      	mov	r4, r2
70002802:	4618      	mov	r0, r3
#ifdef CONFIG_KERNEL_COHERENCE
	__ASSERT_NO_MSG(arch_mem_coherent(to));
#endif /* CONFIG_KERNEL_COHERENCE */

	__ASSERT(!sys_dnode_is_linked(&to->node), "");
	to->fn = fn;
70002804:	60b1      	str	r1, [r6, #8]
	__asm__ volatile(
70002806:	f3ef 8700 	mrs	r7, CPSR
7000280a:	f007 0780 	and.w	r7, r7, #128	; 0x80
7000280e:	b672      	cpsid	i

	K_SPINLOCK(&timeout_lock) {
		struct _timeout *t;

		if (IS_ENABLED(CONFIG_TIMEOUT_64BIT) &&
70002810:	3201      	adds	r2, #1
70002812:	f175 33ff 	sbcs.w	r3, r5, #4294967295	; 0xffffffff
70002816:	da5f      	bge.n	700028d8 <z_add_timeout+0xec>
		    (Z_TICK_ABS(timeout.ticks) >= 0)) {
			k_ticks_t ticks = Z_TICK_ABS(timeout.ticks) - curr_tick;
70002818:	f245 42a0 	movw	r2, #21664	; 0x54a0
7000281c:	f06f 0301 	mvn.w	r3, #1
70002820:	f2c7 0200 	movt	r2, #28672	; 0x7000
70002824:	e9d2 1500 	ldrd	r1, r5, [r2]
70002828:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
7000282c:	1a5b      	subs	r3, r3, r1
7000282e:	eb62 0505 	sbc.w	r5, r2, r5
70002832:	1b1c      	subs	r4, r3, r4
70002834:	eb65 0500 	sbc.w	r5, r5, r0

			to->dticks = MAX(1, ticks);
70002838:	2c01      	cmp	r4, #1
7000283a:	f175 0300 	sbcs.w	r3, r5, #0
7000283e:	bfbc      	itt	lt
70002840:	2401      	movlt	r4, #1
70002842:	2500      	movlt	r5, #0
70002844:	6134      	str	r4, [r6, #16]
	return list->head == list;
70002846:	f24c 3030 	movw	r0, #49968	; 0xc330
7000284a:	6175      	str	r5, [r6, #20]
7000284c:	f2c7 0000 	movt	r0, #28672	; 0x7000
	return (node == list->tail) ? NULL : node->next;
70002850:	e9d0 2c00 	ldrd	r2, ip, [r0]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002854:	4282      	cmp	r2, r0
70002856:	d011      	beq.n	7000287c <z_add_timeout+0x90>
		} else {
			to->dticks = timeout.ticks + 1 + elapsed();
		}

		for (t = first(); t != NULL; t = next(t)) {
70002858:	b182      	cbz	r2, 7000287c <z_add_timeout+0x90>
			if (t->dticks > to->dticks) {
7000285a:	e9d2 3104 	ldrd	r3, r1, [r2, #16]
7000285e:	429c      	cmp	r4, r3
70002860:	eb75 0e01 	sbcs.w	lr, r5, r1
70002864:	db48      	blt.n	700028f8 <z_add_timeout+0x10c>
				t->dticks -= to->dticks;
				sys_dlist_insert(&t->node, &to->node);
				break;
			}
			to->dticks -= t->dticks;
70002866:	1ae3      	subs	r3, r4, r3
70002868:	461c      	mov	r4, r3
7000286a:	eb65 0501 	sbc.w	r5, r5, r1
	return (node == list->tail) ? NULL : node->next;
7000286e:	4562      	cmp	r2, ip
70002870:	e9c6 3504 	strd	r3, r5, [r6, #16]
70002874:	d002      	beq.n	7000287c <z_add_timeout+0x90>
70002876:	6812      	ldr	r2, [r2, #0]
		for (t = first(); t != NULL; t = next(t)) {
70002878:	2a00      	cmp	r2, #0
7000287a:	d1ee      	bne.n	7000285a <z_add_timeout+0x6e>
	node->prev = tail;
7000287c:	e9c6 0c00 	strd	r0, ip, [r6]
	tail->next = node;
70002880:	f8cc 6000 	str.w	r6, [ip]
	list->tail = node;
70002884:	6046      	str	r6, [r0, #4]
	return list->head == list;
70002886:	6804      	ldr	r4, [r0, #0]

		if (t == NULL) {
			sys_dlist_append(&timeout_list, &to->node);
		}

		if (to == first() && announce_remaining == 0) {
70002888:	1a20      	subs	r0, r4, r0
7000288a:	bf18      	it	ne
7000288c:	2001      	movne	r0, #1
7000288e:	42a6      	cmp	r6, r4
70002890:	bf18      	it	ne
70002892:	2000      	movne	r0, #0
70002894:	b910      	cbnz	r0, 7000289c <z_add_timeout+0xb0>
	if (key != 0U) {
70002896:	b907      	cbnz	r7, 7000289a <z_add_timeout+0xae>
70002898:	b662      	cpsie	i
			sys_clock_set_timeout(next_timeout(), false);
		}
	}
}
7000289a:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		if (to == first() && announce_remaining == 0) {
7000289c:	f647 6358 	movw	r3, #32344	; 0x7e58
700028a0:	f2c7 0300 	movt	r3, #28672	; 0x7000
700028a4:	681b      	ldr	r3, [r3, #0]
700028a6:	2b00      	cmp	r3, #0
700028a8:	d1f5      	bne.n	70002896 <z_add_timeout+0xaa>
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
700028aa:	f7ff f8c5 	bl	70001a38 <sys_clock_elapsed>
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
700028ae:	6923      	ldr	r3, [r4, #16]
700028b0:	6962      	ldr	r2, [r4, #20]
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
700028b2:	4601      	mov	r1, r0
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
700028b4:	1a18      	subs	r0, r3, r0
700028b6:	eb62 73e1 	sbc.w	r3, r2, r1, asr #31
			sys_clock_set_timeout(next_timeout(), false);
700028ba:	2100      	movs	r1, #0
		ret = MAX(0, to->dticks - ticks_elapsed);
700028bc:	2b00      	cmp	r3, #0
700028be:	bfbc      	itt	lt
700028c0:	2000      	movlt	r0, #0
700028c2:	2300      	movlt	r3, #0
			sys_clock_set_timeout(next_timeout(), false);
700028c4:	f1b0 4f00 	cmp.w	r0, #2147483648	; 0x80000000
700028c8:	f173 0300 	sbcs.w	r3, r3, #0
700028cc:	bfa8      	it	ge
700028ce:	f06f 4000 	mvnge.w	r0, #2147483648	; 0x80000000
700028d2:	f7ff f881 	bl	700019d8 <sys_clock_set_timeout>
700028d6:	e7de      	b.n	70002896 <z_add_timeout+0xaa>
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
700028d8:	f647 6258 	movw	r2, #32344	; 0x7e58
			to->dticks = timeout.ticks + 1 + elapsed();
700028dc:	3401      	adds	r4, #1
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
700028de:	f2c7 0200 	movt	r2, #28672	; 0x7000
			to->dticks = timeout.ticks + 1 + elapsed();
700028e2:	f145 0500 	adc.w	r5, r5, #0
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
700028e6:	6813      	ldr	r3, [r2, #0]
700028e8:	2b00      	cmp	r3, #0
700028ea:	d1ab      	bne.n	70002844 <z_add_timeout+0x58>
700028ec:	f7ff f8a4 	bl	70001a38 <sys_clock_elapsed>
			to->dticks = timeout.ticks + 1 + elapsed();
700028f0:	1904      	adds	r4, r0, r4
700028f2:	eb45 75e0 	adc.w	r5, r5, r0, asr #31
700028f6:	e7a5      	b.n	70002844 <z_add_timeout+0x58>
				t->dticks -= to->dticks;
700028f8:	1b1b      	subs	r3, r3, r4
	sys_dnode_t *const prev = successor->prev;
700028fa:	6854      	ldr	r4, [r2, #4]
700028fc:	eb61 0105 	sbc.w	r1, r1, r5
70002900:	e9c2 3104 	strd	r3, r1, [r2, #16]
	node->next = successor;
70002904:	e9c6 2400 	strd	r2, r4, [r6]
	prev->next = node;
70002908:	6026      	str	r6, [r4, #0]
	successor->prev = node;
7000290a:	6056      	str	r6, [r2, #4]
		if (t == NULL) {
7000290c:	e7bb      	b.n	70002886 <z_add_timeout+0x9a>
7000290e:	4770      	bx	lr

70002910 <z_abort_timeout>:

int z_abort_timeout(struct _timeout *to)
{
70002910:	b430      	push	{r4, r5}
	__asm__ volatile(
70002912:	f3ef 8500 	mrs	r5, CPSR
70002916:	f005 0580 	and.w	r5, r5, #128	; 0x80
7000291a:	b672      	cpsid	i
	return node->next != NULL;
7000291c:	6802      	ldr	r2, [r0, #0]
	int ret = -EINVAL;

	K_SPINLOCK(&timeout_lock) {
		if (sys_dnode_is_linked(&to->node)) {
7000291e:	b1e2      	cbz	r2, 7000295a <z_abort_timeout+0x4a>
	return (node == list->tail) ? NULL : node->next;
70002920:	f24c 3130 	movw	r1, #49968	; 0xc330
70002924:	4603      	mov	r3, r0
70002926:	f2c7 0100 	movt	r1, #28672	; 0x7000
7000292a:	6849      	ldr	r1, [r1, #4]
7000292c:	4288      	cmp	r0, r1
7000292e:	d009      	beq.n	70002944 <z_abort_timeout+0x34>
		next(t)->dticks += t->dticks;
70002930:	6904      	ldr	r4, [r0, #16]
70002932:	6911      	ldr	r1, [r2, #16]
70002934:	6950      	ldr	r0, [r2, #20]
70002936:	1909      	adds	r1, r1, r4
70002938:	695c      	ldr	r4, [r3, #20]
7000293a:	eb40 0004 	adc.w	r0, r0, r4
7000293e:	e9c2 1004 	strd	r1, r0, [r2, #16]
	sys_dnode_t *const next = node->next;
70002942:	681a      	ldr	r2, [r3, #0]
	sys_dnode_t *const prev = node->prev;
70002944:	685c      	ldr	r4, [r3, #4]
	node->next = NULL;
70002946:	2100      	movs	r1, #0
	prev->next = next;
70002948:	6022      	str	r2, [r4, #0]
			remove_timeout(to);
			ret = 0;
7000294a:	4608      	mov	r0, r1
	next->prev = prev;
7000294c:	6054      	str	r4, [r2, #4]
	node->next = NULL;
7000294e:	6019      	str	r1, [r3, #0]
70002950:	6059      	str	r1, [r3, #4]
	if (key != 0U) {
70002952:	b905      	cbnz	r5, 70002956 <z_abort_timeout+0x46>
70002954:	b662      	cpsie	i
		}
	}

	return ret;
}
70002956:	bc30      	pop	{r4, r5}
70002958:	4770      	bx	lr
	int ret = -EINVAL;
7000295a:	f06f 0015 	mvn.w	r0, #21
7000295e:	e7f8      	b.n	70002952 <z_abort_timeout+0x42>

70002960 <sys_clock_announce>:
	}
	return ret;
}

void sys_clock_announce(int32_t ticks)
{
70002960:	e92d 4ff8 	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
70002964:	4603      	mov	r3, r0
	__asm__ volatile(
70002966:	f3ef 8800 	mrs	r8, CPSR
7000296a:	f008 0880 	and.w	r8, r8, #128	; 0x80
7000296e:	b672      	cpsid	i
	return list->head == list;
70002970:	f24c 3930 	movw	r9, #49968	; 0xc330
		announce_remaining += ticks;
		k_spin_unlock(&timeout_lock, key);
		return;
	}

	announce_remaining = ticks;
70002974:	f647 6a58 	movw	sl, #32344	; 0x7e58
70002978:	f2c7 0900 	movt	r9, #28672	; 0x7000
7000297c:	f2c7 0a00 	movt	sl, #28672	; 0x7000
70002980:	f8ca 0000 	str.w	r0, [sl]
70002984:	f8d9 0000 	ldr.w	r0, [r9]
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002988:	4548      	cmp	r0, r9
7000298a:	bf04      	itt	eq
7000298c:	f245 45a0 	movweq	r5, #21664	; 0x54a0
70002990:	f2c7 0500 	movteq	r5, #28672	; 0x7000
70002994:	d068      	beq.n	70002a68 <sys_clock_announce+0x108>

	struct _timeout *t;

	for (t = first();
	     (t != NULL) && (t->dticks <= announce_remaining);
70002996:	2800      	cmp	r0, #0
70002998:	d076      	beq.n	70002a88 <sys_clock_announce+0x128>
7000299a:	f245 45a0 	movw	r5, #21664	; 0x54a0
	node->next = NULL;
7000299e:	f04f 0b00 	mov.w	fp, #0
	     t = first()) {
		int dt = t->dticks;

		curr_tick += dt;
		t->dticks = 0;
700029a2:	2600      	movs	r6, #0
700029a4:	f2c7 0500 	movt	r5, #28672	; 0x7000
700029a8:	2700      	movs	r7, #0
	     (t != NULL) && (t->dticks <= announce_remaining);
700029aa:	e9d0 4204 	ldrd	r4, r2, [r0, #16]
700029ae:	17d9      	asrs	r1, r3, #31
700029b0:	42a3      	cmp	r3, r4
700029b2:	eb71 0c02 	sbcs.w	ip, r1, r2
700029b6:	db29      	blt.n	70002a0c <sys_clock_announce+0xac>
		curr_tick += dt;
700029b8:	e9d5 3200 	ldrd	r3, r2, [r5]
	sys_dnode_t *const prev = node->prev;
700029bc:	6841      	ldr	r1, [r0, #4]
		t->dticks = 0;
700029be:	e9c0 6704 	strd	r6, r7, [r0, #16]
		curr_tick += dt;
700029c2:	191b      	adds	r3, r3, r4
700029c4:	eb42 72e4 	adc.w	r2, r2, r4, asr #31
700029c8:	602b      	str	r3, [r5, #0]
	sys_dnode_t *const next = node->next;
700029ca:	6803      	ldr	r3, [r0, #0]
	prev->next = next;
700029cc:	600b      	str	r3, [r1, #0]
700029ce:	606a      	str	r2, [r5, #4]
	next->prev = prev;
700029d0:	6059      	str	r1, [r3, #4]
	node->next = NULL;
700029d2:	f8c0 b000 	str.w	fp, [r0]
700029d6:	f8c0 b004 	str.w	fp, [r0, #4]
	if (key != 0U) {
700029da:	f1b8 0f00 	cmp.w	r8, #0
700029de:	d100      	bne.n	700029e2 <sys_clock_announce+0x82>
700029e0:	b662      	cpsie	i
		remove_timeout(t);

		k_spin_unlock(&timeout_lock, key);
		t->fn(t);
700029e2:	6883      	ldr	r3, [r0, #8]
700029e4:	4798      	blx	r3
	__asm__ volatile(
700029e6:	f3ef 8800 	mrs	r8, CPSR
700029ea:	f008 0880 	and.w	r8, r8, #128	; 0x80
700029ee:	b672      	cpsid	i
		key = k_spin_lock(&timeout_lock);
		announce_remaining -= dt;
700029f0:	f8da 3000 	ldr.w	r3, [sl]
	return list->head == list;
700029f4:	f8d9 0000 	ldr.w	r0, [r9]
700029f8:	1b1b      	subs	r3, r3, r4
	return sys_dlist_is_empty(list) ? NULL : list->head;
700029fa:	4548      	cmp	r0, r9
700029fc:	f8ca 3000 	str.w	r3, [sl]
70002a00:	d032      	beq.n	70002a68 <sys_clock_announce+0x108>
	     (t != NULL) && (t->dticks <= announce_remaining);
70002a02:	2800      	cmp	r0, #0
70002a04:	d1d1      	bne.n	700029aa <sys_clock_announce+0x4a>
	return list->head == list;
70002a06:	4604      	mov	r4, r0
70002a08:	17d9      	asrs	r1, r3, #31
70002a0a:	e006      	b.n	70002a1a <sys_clock_announce+0xba>
	}

	if (t != NULL) {
		t->dticks -= announce_remaining;
70002a0c:	1ae4      	subs	r4, r4, r3
70002a0e:	eb62 0201 	sbc.w	r2, r2, r1
70002a12:	6104      	str	r4, [r0, #16]
70002a14:	f8d9 4000 	ldr.w	r4, [r9]
70002a18:	6142      	str	r2, [r0, #20]
	}

	curr_tick += announce_remaining;
70002a1a:	682a      	ldr	r2, [r5, #0]
70002a1c:	18d2      	adds	r2, r2, r3
70002a1e:	686b      	ldr	r3, [r5, #4]
70002a20:	602a      	str	r2, [r5, #0]
70002a22:	eb43 0301 	adc.w	r3, r3, r1
	return sys_dlist_is_empty(list) ? NULL : list->head;
70002a26:	454c      	cmp	r4, r9
70002a28:	606b      	str	r3, [r5, #4]
	announce_remaining = 0;
70002a2a:	f04f 0300 	mov.w	r3, #0
70002a2e:	f8ca 3000 	str.w	r3, [sl]
70002a32:	d024      	beq.n	70002a7e <sys_clock_announce+0x11e>
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002a34:	f7ff f800 	bl	70001a38 <sys_clock_elapsed>
	if ((to == NULL) ||
70002a38:	b31c      	cbz	r4, 70002a82 <sys_clock_announce+0x122>
	    ((int64_t)(to->dticks - ticks_elapsed) > (int64_t)INT_MAX)) {
70002a3a:	e9d4 3204 	ldrd	r3, r2, [r4, #16]
70002a3e:	1a1b      	subs	r3, r3, r0
70002a40:	eb62 72e0 	sbc.w	r2, r2, r0, asr #31
	if ((to == NULL) ||
70002a44:	f1b3 4f00 	cmp.w	r3, #2147483648	; 0x80000000
70002a48:	f172 0100 	sbcs.w	r1, r2, #0
70002a4c:	da19      	bge.n	70002a82 <sys_clock_announce+0x122>
		ret = MAX(0, to->dticks - ticks_elapsed);
70002a4e:	2a00      	cmp	r2, #0
70002a50:	bfac      	ite	ge
70002a52:	4618      	movge	r0, r3
70002a54:	2000      	movlt	r0, #0

	sys_clock_set_timeout(next_timeout(), false);
70002a56:	2100      	movs	r1, #0
70002a58:	f7fe ffbe 	bl	700019d8 <sys_clock_set_timeout>
	if (key != 0U) {
70002a5c:	f1b8 0f00 	cmp.w	r8, #0
70002a60:	d100      	bne.n	70002a64 <sys_clock_announce+0x104>
70002a62:	b662      	cpsie	i
	k_spin_unlock(&timeout_lock, key);

#ifdef CONFIG_TIMESLICING
	z_time_slice();
#endif /* CONFIG_TIMESLICING */
}
70002a64:	e8bd 8ff8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
	curr_tick += announce_remaining;
70002a68:	682a      	ldr	r2, [r5, #0]
70002a6a:	18d2      	adds	r2, r2, r3
70002a6c:	602a      	str	r2, [r5, #0]
	announce_remaining = 0;
70002a6e:	f04f 0200 	mov.w	r2, #0
70002a72:	f8ca 2000 	str.w	r2, [sl]
	curr_tick += announce_remaining;
70002a76:	686a      	ldr	r2, [r5, #4]
70002a78:	eb42 72e3 	adc.w	r2, r2, r3, asr #31
70002a7c:	606a      	str	r2, [r5, #4]
	return announce_remaining == 0 ? sys_clock_elapsed() : 0U;
70002a7e:	f7fe ffdb 	bl	70001a38 <sys_clock_elapsed>
		ret = MAX_WAIT;
70002a82:	f06f 4000 	mvn.w	r0, #2147483648	; 0x80000000
70002a86:	e7e6      	b.n	70002a56 <sys_clock_announce+0xf6>
	announce_remaining = 0;
70002a88:	f8ca 0000 	str.w	r0, [sl]
	curr_tick += announce_remaining;
70002a8c:	f245 42a0 	movw	r2, #21664	; 0x54a0
70002a90:	f2c7 0200 	movt	r2, #28672	; 0x7000
70002a94:	e9d2 1000 	ldrd	r1, r0, [r2]
70002a98:	18c9      	adds	r1, r1, r3
70002a9a:	eb40 70e3 	adc.w	r0, r0, r3, asr #31
70002a9e:	e9c2 1000 	strd	r1, r0, [r2]
70002aa2:	e7ec      	b.n	70002a7e <sys_clock_announce+0x11e>

70002aa4 <signal_poll_event.constprop.0>:
}
#include <zephyr/syscalls/k_poll_mrsh.c>
#endif /* CONFIG_USERSPACE */

/* must be called with interrupts locked */
static int signal_poll_event(struct k_poll_event *event, uint32_t state)
70002aa4:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
{
	struct z_poller *poller = event->poller;
70002aa8:	6886      	ldr	r6, [r0, #8]
static int signal_poll_event(struct k_poll_event *event, uint32_t state)
70002aaa:	4604      	mov	r4, r0
70002aac:	460d      	mov	r5, r1
	int retcode = 0;

	if (poller != NULL) {
70002aae:	b136      	cbz	r6, 70002abe <signal_poll_event.constprop.0+0x1a>
		if (poller->mode == MODE_POLL) {
70002ab0:	7873      	ldrb	r3, [r6, #1]
70002ab2:	2b01      	cmp	r3, #1
70002ab4:	d022      	beq.n	70002afc <signal_poll_event.constprop.0+0x58>
			retcode = signal_poller(event, state);
		} else if (poller->mode == MODE_TRIGGERED) {
70002ab6:	2b02      	cmp	r3, #2
70002ab8:	d00c      	beq.n	70002ad4 <signal_poll_event.constprop.0+0x30>
		} else {
			/* Poller is not poll or triggered mode. No action needed.*/
			;
		}

		poller->is_polling = false;
70002aba:	2300      	movs	r3, #0
70002abc:	7033      	strb	r3, [r6, #0]
	event->state |= state;
70002abe:	68e3      	ldr	r3, [r4, #12]
	event->poller = NULL;
70002ac0:	2000      	movs	r0, #0
70002ac2:	60a0      	str	r0, [r4, #8]
	event->state |= state;
70002ac4:	f3c3 3286 	ubfx	r2, r3, #14, #7
70002ac8:	4315      	orrs	r5, r2
70002aca:	f365 3394 	bfi	r3, r5, #14, #7
70002ace:	60e3      	str	r3, [r4, #12]
		}
	}

	set_event_ready(event, state);
	return retcode;
}
70002ad0:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
{
	struct z_poller *poller = event->poller;
	struct k_work_poll *twork =
		CONTAINER_OF(poller, struct k_work_poll, poller);

	if (poller->is_polling && twork->workq != NULL) {
70002ad4:	7833      	ldrb	r3, [r6, #0]
70002ad6:	2b00      	cmp	r3, #0
70002ad8:	d0ef      	beq.n	70002aba <signal_poll_event.constprop.0+0x16>
70002ada:	f856 7c04 	ldr.w	r7, [r6, #-4]
70002ade:	2f00      	cmp	r7, #0
70002ae0:	d0eb      	beq.n	70002aba <signal_poll_event.constprop.0+0x16>
		struct k_work_q *work_q = twork->workq;

		z_abort_timeout(&twork->timeout);
70002ae2:	f106 0014 	add.w	r0, r6, #20
70002ae6:	f7ff ff13 	bl	70002910 <z_abort_timeout>
		twork->poll_result = 0;
70002aea:	2300      	movs	r3, #0
		z_work_submit_to_queue(work_q, &twork->work);
70002aec:	4638      	mov	r0, r7
		z_abort_timeout(&twork->timeout);
70002aee:	f1a6 0814 	sub.w	r8, r6, #20
		twork->poll_result = 0;
70002af2:	62f3      	str	r3, [r6, #44]	; 0x2c
		z_work_submit_to_queue(work_q, &twork->work);
70002af4:	4641      	mov	r1, r8
70002af6:	f000 f977 	bl	70002de8 <z_work_submit_to_queue>
70002afa:	e7de      	b.n	70002aba <signal_poll_event.constprop.0+0x16>
	if (!z_is_thread_pending(thread)) {
70002afc:	f816 3c53 	ldrb.w	r3, [r6, #-83]
70002b00:	079a      	lsls	r2, r3, #30
70002b02:	d5da      	bpl.n	70002aba <signal_poll_event.constprop.0+0x16>
	return p ? CONTAINER_OF(p, struct k_thread, poller) : NULL;
70002b04:	f1a6 0760 	sub.w	r7, r6, #96	; 0x60
	z_unpend_thread(thread);
70002b08:	4638      	mov	r0, r7
70002b0a:	f7ff fd01 	bl	70002510 <z_unpend_thread>
	arch_thread_return_value_set(thread,
70002b0e:	2d08      	cmp	r5, #8
70002b10:	bf14      	ite	ne
70002b12:	2300      	movne	r3, #0
70002b14:	f06f 0303 	mvneq.w	r3, #3
70002b18:	6133      	str	r3, [r6, #16]
	return !((z_is_thread_prevented_from_running(thread)) != 0U ||
70002b1a:	f816 3c53 	ldrb.w	r3, [r6, #-83]
70002b1e:	06db      	lsls	r3, r3, #27
70002b20:	d1cb      	bne.n	70002aba <signal_poll_event.constprop.0+0x16>
70002b22:	f856 3c48 	ldr.w	r3, [r6, #-72]
70002b26:	2b00      	cmp	r3, #0
70002b28:	d1c7      	bne.n	70002aba <signal_poll_event.constprop.0+0x16>
	z_ready_thread(thread);
70002b2a:	4638      	mov	r0, r7
70002b2c:	f7ff fc34 	bl	70002398 <z_ready_thread>
	return 0;
70002b30:	e7c3      	b.n	70002aba <signal_poll_event.constprop.0+0x16>
70002b32:	bf00      	nop

70002b34 <z_handle_obj_poll_events>:
{
70002b34:	4603      	mov	r3, r0
70002b36:	b510      	push	{r4, lr}
	__asm__ volatile(
70002b38:	f3ef 8400 	mrs	r4, CPSR
70002b3c:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002b40:	b672      	cpsid	i
	return list->head == list;
70002b42:	6800      	ldr	r0, [r0, #0]

static inline sys_dnode_t *sys_dlist_get(sys_dlist_t *list)
{
	sys_dnode_t *node = NULL;

	if (!sys_dlist_is_empty(list)) {
70002b44:	4283      	cmp	r3, r0
70002b46:	d008      	beq.n	70002b5a <z_handle_obj_poll_events+0x26>
	sys_dnode_t *const next = node->next;
70002b48:	e9d0 3200 	ldrd	r3, r2, [r0]
	prev->next = next;
70002b4c:	6013      	str	r3, [r2, #0]
	next->prev = prev;
70002b4e:	605a      	str	r2, [r3, #4]
	node->next = NULL;
70002b50:	2300      	movs	r3, #0
70002b52:	6003      	str	r3, [r0, #0]
70002b54:	6043      	str	r3, [r0, #4]
		(void) signal_poll_event(poll_event, state);
70002b56:	f7ff ffa5 	bl	70002aa4 <signal_poll_event.constprop.0>
	if (key != 0U) {
70002b5a:	b904      	cbnz	r4, 70002b5e <z_handle_obj_poll_events+0x2a>
70002b5c:	b662      	cpsie	i
}
70002b5e:	bd10      	pop	{r4, pc}

70002b60 <boot_banner>:
	  */
	printk("\x1b[3J\x1b[2J\x1b[H");
#endif /* CONFIG_BOOT_CLEAR_SCREEN */

#ifdef CONFIG_BOOT_BANNER
	printk("*** " CONFIG_BOOT_BANNER_STRING " " BANNER_VERSION BANNER_POSTFIX " ***\n");
70002b60:	f644 50b8 	movw	r0, #19896	; 0x4db8
70002b64:	f2c7 0000 	movt	r0, #28672	; 0x7000
70002b68:	f7fd bf44 	b.w	700009f4 <printk>

70002b6c <statics_init>:

	SYS_PORT_TRACING_OBJ_INIT(k_heap, heap);
}

static int statics_init(void)
{
70002b6c:	b538      	push	{r3, r4, r5, lr}
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70002b6e:	f24c 343c 	movw	r4, #49980	; 0xc33c
70002b72:	f24c 353c 	movw	r5, #49980	; 0xc33c
70002b76:	f2c7 0400 	movt	r4, #28672	; 0x7000
70002b7a:	f2c7 0500 	movt	r5, #28672	; 0x7000
70002b7e:	42ac      	cmp	r4, r5
70002b80:	d20b      	bcs.n	70002b9a <statics_init+0x2e>
	sys_heap_init(&heap->heap, mem, bytes);
70002b82:	e9d4 1201 	ldrd	r1, r2, [r4, #4]
70002b86:	f104 030c 	add.w	r3, r4, #12
70002b8a:	4620      	mov	r0, r4
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70002b8c:	3414      	adds	r4, #20
	list->head = (sys_dnode_t *)list;
70002b8e:	601b      	str	r3, [r3, #0]
70002b90:	605b      	str	r3, [r3, #4]
	sys_heap_init(&heap->heap, mem, bytes);
70002b92:	f7fd feeb 	bl	7000096c <sys_heap_init>
	STRUCT_SECTION_FOREACH(k_heap, heap) {
70002b96:	42ac      	cmp	r4, r5
70002b98:	d3f3      	bcc.n	70002b82 <statics_init+0x16>
		{
			k_heap_init(heap, heap->heap.init_mem, heap->heap.init_bytes);
		}
	}
	return 0;
}
70002b9a:	2000      	movs	r0, #0
70002b9c:	bd38      	pop	{r3, r4, r5, pc}
70002b9e:	bf00      	nop

70002ba0 <k_sys_work_q_init>:

struct k_work_q k_sys_work_q;

static int k_sys_work_q_init(void)
{
	struct k_work_queue_config cfg = {
70002ba0:	f644 313c 	movw	r1, #19260	; 0x4b3c
		.name = "sysworkq",
		.no_yield = IS_ENABLED(CONFIG_SYSTEM_WORKQUEUE_NO_YIELD),
		.essential = true,
	};

	k_work_queue_start(&k_sys_work_q,
70002ba4:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
	struct k_work_queue_config cfg = {
70002ba8:	f2c7 0100 	movt	r1, #28672	; 0x7000
{
70002bac:	b510      	push	{r4, lr}
	struct k_work_queue_config cfg = {
70002bae:	c903      	ldmia	r1, {r0, r1}
{
70002bb0:	b084      	sub	sp, #16
	k_work_queue_start(&k_sys_work_q,
70002bb2:	f44f 6280 	mov.w	r2, #1024	; 0x400
	struct k_work_queue_config cfg = {
70002bb6:	ac02      	add	r4, sp, #8
	k_work_queue_start(&k_sys_work_q,
70002bb8:	9400      	str	r4, [sp, #0]
	struct k_work_queue_config cfg = {
70002bba:	e884 0003 	stmia.w	r4, {r0, r1}
	k_work_queue_start(&k_sys_work_q,
70002bbe:	f64b 6160 	movw	r1, #48736	; 0xbe60
70002bc2:	f245 40a8 	movw	r0, #21672	; 0x54a8
70002bc6:	f2c7 0100 	movt	r1, #28672	; 0x7000
70002bca:	f2c7 0000 	movt	r0, #28672	; 0x7000
70002bce:	f000 f91b 	bl	70002e08 <k_work_queue_start>
			    sys_work_q_stack,
			    K_KERNEL_STACK_SIZEOF(sys_work_q_stack),
			    CONFIG_SYSTEM_WORKQUEUE_PRIORITY, &cfg);
	return 0;
}
70002bd2:	2000      	movs	r0, #0
70002bd4:	b004      	add	sp, #16
70002bd6:	bd10      	pop	{r4, pc}

70002bd8 <work_queue_main>:
/* Loop executed by a work queue thread.
 *
 * @param workq_ptr pointer to the work queue structure
 */
static void work_queue_main(void *workq_ptr, void *p2, void *p3)
{
70002bd8:	e92d 41f0 	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
 *
 * @return A pointer on the first node of the list (or NULL if none)
 */
static inline sys_snode_t *sys_slist_peek_head(sys_slist_t *list)
{
	return list->head;
70002bdc:	f245 5640 	movw	r6, #21824	; 0x5540
70002be0:	b084      	sub	sp, #16
70002be2:	4605      	mov	r5, r0
70002be4:	f2c7 0600 	movt	r6, #28672	; 0x7000
	return node->next;
70002be8:	2700      	movs	r7, #0
	__asm__ volatile(
70002bea:	f3ef 8800 	mrs	r8, CPSR
70002bee:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002bf2:	b672      	cpsid	i
	return list->head;
70002bf4:	6fac      	ldr	r4, [r5, #120]	; 0x78
 *
 * @return A pointer to the first node of the list (or NULL if empty)
 */
static inline sys_snode_t *sys_slist_get(sys_slist_t *list);

Z_GENLIST_GET(slist, snode)
70002bf6:	2c00      	cmp	r4, #0
70002bf8:	d060      	beq.n	70002cbc <work_queue_main+0xe4>
Z_GENLIST_GET_NOT_EMPTY(slist, snode)
70002bfa:	6fea      	ldr	r2, [r5, #124]	; 0x7c
	return node->next;
70002bfc:	6823      	ldr	r3, [r4, #0]
	list->head = node;
70002bfe:	67ab      	str	r3, [r5, #120]	; 0x78
Z_GENLIST_GET_NOT_EMPTY(slist, snode)
70002c00:	4294      	cmp	r4, r2
	list->tail = node;
70002c02:	bf08      	it	eq
70002c04:	67eb      	streq	r3, [r5, #124]	; 0x7c
	*flagp |= BIT(bit);
70002c06:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
70002c0a:	f043 0302 	orr.w	r3, r3, #2
70002c0e:	f8c5 3090 	str.w	r3, [r5, #144]	; 0x90
	*flagp &= ~BIT(bit);
70002c12:	68e3      	ldr	r3, [r4, #12]
			 * of struct k_work object that has been placed at address NULL,
			 * which should never happen, even line 'if (work != NULL)'
			 * ensures that.
			 * This means that if node is not NULL, then work will not be NULL.
			 */
			handler = work->handler;
70002c14:	6862      	ldr	r2, [r4, #4]
	*flagp &= ~BIT(bit);
70002c16:	f023 0304 	bic.w	r3, r3, #4
70002c1a:	f043 0301 	orr.w	r3, r3, #1
70002c1e:	60e3      	str	r3, [r4, #12]
	if (key != 0U) {
70002c20:	f1b8 0f00 	cmp.w	r8, #0
70002c24:	d100      	bne.n	70002c28 <work_queue_main+0x50>
70002c26:	b662      	cpsie	i
		}

		k_spin_unlock(&lock, key);

		__ASSERT_NO_MSG(handler != NULL);
		handler(work);
70002c28:	4620      	mov	r0, r4
70002c2a:	4790      	blx	r2
	__asm__ volatile(
70002c2c:	f3ef 8800 	mrs	r8, CPSR
70002c30:	f008 0880 	and.w	r8, r8, #128	; 0x80
70002c34:	b672      	cpsid	i
	*flagp &= ~BIT(bit);
70002c36:	68e2      	ldr	r2, [r4, #12]
70002c38:	f022 0301 	bic.w	r3, r2, #1
		 * yield to prevent starving other threads.
		 */
		key = k_spin_lock(&lock);

		flag_clear(&work->flags, K_WORK_RUNNING_BIT);
		if (flag_test(&work->flags, K_WORK_FLUSHING_BIT)) {
70002c3c:	06d1      	lsls	r1, r2, #27
	*flagp &= ~BIT(bit);
70002c3e:	bf58      	it	pl
70002c40:	60e3      	strpl	r3, [r4, #12]
		if (flag_test(&work->flags, K_WORK_FLUSHING_BIT)) {
70002c42:	d432      	bmi.n	70002caa <work_queue_main+0xd2>
			finalize_flush_locked(work);
		}
		if (flag_test(&work->flags, K_WORK_CANCELING_BIT)) {
70002c44:	079a      	lsls	r2, r3, #30
70002c46:	d410      	bmi.n	70002c6a <work_queue_main+0x92>
	*flagp &= ~BIT(bit);
70002c48:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
70002c4c:	f023 0302 	bic.w	r3, r3, #2
	return (*flagp & BIT(bit)) != 0U;
70002c50:	f3c3 2200 	ubfx	r2, r3, #8, #1
	*flagp &= ~BIT(bit);
70002c54:	f8c5 3090 	str.w	r3, [r5, #144]	; 0x90
	if (key != 0U) {
70002c58:	f1b8 0f00 	cmp.w	r8, #0
70002c5c:	d100      	bne.n	70002c60 <work_queue_main+0x88>
70002c5e:	b662      	cpsie	i
		k_spin_unlock(&lock, key);

		/* Optionally yield to prevent the work queue from
		 * starving other threads.
		 */
		if (yield) {
70002c60:	2a00      	cmp	r2, #0
70002c62:	d1c2      	bne.n	70002bea <work_queue_main+0x12>
	z_impl_k_yield();
70002c64:	f7ff fce4 	bl	70002630 <z_impl_k_yield>
}
70002c68:	e7bf      	b.n	70002bea <work_queue_main+0x12>
	return list->head;
70002c6a:	6830      	ldr	r0, [r6, #0]
	*flagp &= ~BIT(bit);
70002c6c:	f023 0302 	bic.w	r3, r3, #2
70002c70:	60e3      	str	r3, [r4, #12]
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(&pending_cancels, wc, tmp, node) {
70002c72:	2800      	cmp	r0, #0
70002c74:	d0e8      	beq.n	70002c48 <work_queue_main+0x70>
		if (wc->work == work) {
70002c76:	6842      	ldr	r2, [r0, #4]
	return node->next;
70002c78:	2100      	movs	r1, #0
70002c7a:	6803      	ldr	r3, [r0, #0]
70002c7c:	4294      	cmp	r4, r2
70002c7e:	d007      	beq.n	70002c90 <work_queue_main+0xb8>
	SYS_SLIST_FOR_EACH_CONTAINER_SAFE(&pending_cancels, wc, tmp, node) {
70002c80:	2b00      	cmp	r3, #0
70002c82:	d0e1      	beq.n	70002c48 <work_queue_main+0x70>
			sys_slist_remove(&pending_cancels, prev, &wc->node);
70002c84:	4601      	mov	r1, r0
70002c86:	4618      	mov	r0, r3
Z_GENLIST_PEEK_NEXT(slist, snode)
70002c88:	681b      	ldr	r3, [r3, #0]
		if (wc->work == work) {
70002c8a:	6842      	ldr	r2, [r0, #4]
70002c8c:	4294      	cmp	r4, r2
70002c8e:	d1f7      	bne.n	70002c80 <work_queue_main+0xa8>
	return node->next;
70002c90:	6803      	ldr	r3, [r0, #0]
 */
static inline void sys_slist_remove(sys_slist_t *list,
				    sys_snode_t *prev_node,
				    sys_snode_t *node);

Z_GENLIST_REMOVE(slist, snode)
70002c92:	2900      	cmp	r1, #0
70002c94:	d042      	beq.n	70002d1c <work_queue_main+0x144>
	parent->next = child;
70002c96:	600b      	str	r3, [r1, #0]
Z_GENLIST_REMOVE(slist, snode)
70002c98:	6873      	ldr	r3, [r6, #4]
70002c9a:	4283      	cmp	r3, r0
	list->tail = node;
70002c9c:	bf08      	it	eq
70002c9e:	6071      	streq	r1, [r6, #4]
	parent->next = child;
70002ca0:	f840 7b08 	str.w	r7, [r0], #8
	z_impl_k_sem_give(sem);
70002ca4:	f7ff f966 	bl	70001f74 <z_impl_k_sem_give>
}
70002ca8:	e7ce      	b.n	70002c48 <work_queue_main+0x70>
	*flagp &= ~BIT(bit);
70002caa:	f022 0211 	bic.w	r2, r2, #17
70002cae:	60e2      	str	r2, [r4, #12]
	z_impl_k_sem_give(sem);
70002cb0:	f104 0010 	add.w	r0, r4, #16
70002cb4:	f7ff f95e 	bl	70001f74 <z_impl_k_sem_give>
	return (*flagp & BIT(bit)) != 0U;
70002cb8:	68e3      	ldr	r3, [r4, #12]
};
70002cba:	e7c3      	b.n	70002c44 <work_queue_main+0x6c>
	return (*flagp & BIT(bit)) != 0U;
70002cbc:	f8d5 3090 	ldr.w	r3, [r5, #144]	; 0x90
	*flagp &= ~BIT(bit);
70002cc0:	f023 0204 	bic.w	r2, r3, #4
		} else if (flag_test_and_clear(&queue->flags,
70002cc4:	075c      	lsls	r4, r3, #29
	*flagp &= ~BIT(bit);
70002cc6:	f8c5 2090 	str.w	r2, [r5, #144]	; 0x90
		} else if (flag_test_and_clear(&queue->flags,
70002cca:	f3c3 0180 	ubfx	r1, r3, #2, #1
70002cce:	d40a      	bmi.n	70002ce6 <work_queue_main+0x10e>
		} else if (flag_test(&queue->flags, K_WORK_QUEUE_STOP_BIT)) {
70002cd0:	06d0      	lsls	r0, r2, #27
70002cd2:	d511      	bpl.n	70002cf8 <work_queue_main+0x120>
	*flagp = flags;
70002cd4:	f8c5 1090 	str.w	r1, [r5, #144]	; 0x90
70002cd8:	f1b8 0f00 	cmp.w	r8, #0
70002cdc:	d100      	bne.n	70002ce0 <work_queue_main+0x108>
70002cde:	b662      	cpsie	i
			k_yield();
		}
	}
}
70002ce0:	b004      	add	sp, #16
70002ce2:	e8bd 81f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
			(void)z_sched_wake_all(&queue->drainq, 1, NULL);
70002ce6:	f105 0488 	add.w	r4, r5, #136	; 0x88
static inline bool z_sched_wake_all(_wait_q_t *wait_q, int swap_retval,
				    void *swap_data)
{
	bool woken = false;

	while (z_sched_wake(wait_q, swap_retval, swap_data)) {
70002cea:	2200      	movs	r2, #0
70002cec:	2101      	movs	r1, #1
70002cee:	4620      	mov	r0, r4
70002cf0:	f7ff fd3a 	bl	70002768 <z_sched_wake>
70002cf4:	2800      	cmp	r0, #0
70002cf6:	d1f8      	bne.n	70002cea <work_queue_main+0x112>
					   K_FOREVER, NULL);
70002cf8:	f04f 32ff 	mov.w	r2, #4294967295	; 0xffffffff
70002cfc:	f04f 33ff 	mov.w	r3, #4294967295	; 0xffffffff
			(void)z_sched_wait(&lock, key, &queue->notifyq,
70002d00:	f647 605c 	movw	r0, #32348	; 0x7e5c
70002d04:	4641      	mov	r1, r8
70002d06:	e9cd 2300 	strd	r2, r3, [sp]
70002d0a:	2300      	movs	r3, #0
70002d0c:	f105 0280 	add.w	r2, r5, #128	; 0x80
70002d10:	9302      	str	r3, [sp, #8]
70002d12:	f2c7 0000 	movt	r0, #28672	; 0x7000
70002d16:	f7ff fd55 	bl	700027c4 <z_sched_wait>
			continue;
70002d1a:	e766      	b.n	70002bea <work_queue_main+0x12>
Z_GENLIST_REMOVE(slist, snode)
70002d1c:	6872      	ldr	r2, [r6, #4]
	list->head = node;
70002d1e:	6033      	str	r3, [r6, #0]
Z_GENLIST_REMOVE(slist, snode)
70002d20:	4282      	cmp	r2, r0
	list->tail = node;
70002d22:	bf08      	it	eq
70002d24:	6073      	streq	r3, [r6, #4]
70002d26:	e7bb      	b.n	70002ca0 <work_queue_main+0xc8>

70002d28 <submit_to_queue_locked>:
{
70002d28:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
	return (*flagp & BIT(bit)) != 0U;
70002d2a:	68c3      	ldr	r3, [r0, #12]
{
70002d2c:	460d      	mov	r5, r1
	if (flag_test(&work->flags, K_WORK_CANCELING_BIT)) {
70002d2e:	079a      	lsls	r2, r3, #30
70002d30:	f3c3 0640 	ubfx	r6, r3, #1, #1
70002d34:	d407      	bmi.n	70002d46 <submit_to_queue_locked+0x1e>
	} else if (!flag_test(&work->flags, K_WORK_QUEUED_BIT)) {
70002d36:	075f      	lsls	r7, r3, #29
	return (*flagp & BIT(bit)) != 0U;
70002d38:	f3c3 0280 	ubfx	r2, r3, #2, #1
	} else if (!flag_test(&work->flags, K_WORK_QUEUED_BIT)) {
70002d3c:	d506      	bpl.n	70002d4c <submit_to_queue_locked+0x24>
		*queuep = NULL;
70002d3e:	2300      	movs	r3, #0
}
70002d40:	4630      	mov	r0, r6
		*queuep = NULL;
70002d42:	602b      	str	r3, [r5, #0]
}
70002d44:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
		ret = -EBUSY;
70002d46:	f06f 060f 	mvn.w	r6, #15
70002d4a:	e7f8      	b.n	70002d3e <submit_to_queue_locked+0x16>
		if (*queuep == NULL) {
70002d4c:	680f      	ldr	r7, [r1, #0]
70002d4e:	4604      	mov	r4, r0
70002d50:	2f00      	cmp	r7, #0
70002d52:	d032      	beq.n	70002dba <submit_to_queue_locked+0x92>
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002d54:	07db      	lsls	r3, r3, #31
		ret = 1;
70002d56:	bf58      	it	pl
70002d58:	2601      	movpl	r6, #1
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002d5a:	d504      	bpl.n	70002d66 <submit_to_queue_locked+0x3e>
			*queuep = work->queue;
70002d5c:	68a7      	ldr	r7, [r4, #8]
			ret = 2;
70002d5e:	2602      	movs	r6, #2
			*queuep = work->queue;
70002d60:	602f      	str	r7, [r5, #0]
	if (queue == NULL) {
70002d62:	2f00      	cmp	r7, #0
70002d64:	d03d      	beq.n	70002de2 <submit_to_queue_locked+0xba>
70002d66:	f647 6338 	movw	r3, #32312	; 0x7e38
70002d6a:	f2c7 0300 	movt	r3, #28672	; 0x7000
	bool chained = (arch_current_thread() == &queue->thread) && !k_is_in_isr();
70002d6e:	689b      	ldr	r3, [r3, #8]
70002d70:	42bb      	cmp	r3, r7
70002d72:	d02d      	beq.n	70002dd0 <submit_to_queue_locked+0xa8>
	return (*flagp & BIT(bit)) != 0U;
70002d74:	f8d7 0090 	ldr.w	r0, [r7, #144]	; 0x90
70002d78:	f3c0 0380 	ubfx	r3, r0, #2, #1
70002d7c:	f3c0 01c0 	ubfx	r1, r0, #3, #1
	if (!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT)) {
70002d80:	07c0      	lsls	r0, r0, #31
70002d82:	d52b      	bpl.n	70002ddc <submit_to_queue_locked+0xb4>
	} else if (draining && !chained) {
70002d84:	f082 0201 	eor.w	r2, r2, #1
70002d88:	4213      	tst	r3, r2
70002d8a:	d1dc      	bne.n	70002d46 <submit_to_queue_locked+0x1e>
	} else if (plugged && !draining) {
70002d8c:	f083 0301 	eor.w	r3, r3, #1
70002d90:	4019      	ands	r1, r3
70002d92:	d1d8      	bne.n	70002d46 <submit_to_queue_locked+0x1e>
	parent->next = child;
70002d94:	6021      	str	r1, [r4, #0]
	return list->tail;
70002d96:	6ffb      	ldr	r3, [r7, #124]	; 0x7c
Z_GENLIST_APPEND(slist, snode)
70002d98:	b1bb      	cbz	r3, 70002dca <submit_to_queue_locked+0xa2>
	parent->next = child;
70002d9a:	601c      	str	r4, [r3, #0]
	list->tail = node;
70002d9c:	67fc      	str	r4, [r7, #124]	; 0x7c
		rv = z_sched_wake(&queue->notifyq, 0, NULL);
70002d9e:	2200      	movs	r2, #0
70002da0:	f107 0080 	add.w	r0, r7, #128	; 0x80
70002da4:	4611      	mov	r1, r2
70002da6:	f7ff fcdf 	bl	70002768 <z_sched_wake>
	*flagp |= BIT(bit);
70002daa:	68e3      	ldr	r3, [r4, #12]
}
70002dac:	4630      	mov	r0, r6
	*flagp |= BIT(bit);
70002dae:	f043 0304 	orr.w	r3, r3, #4
70002db2:	60e3      	str	r3, [r4, #12]
			work->queue = *queuep;
70002db4:	682b      	ldr	r3, [r5, #0]
70002db6:	60a3      	str	r3, [r4, #8]
}
70002db8:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
			*queuep = work->queue;
70002dba:	6887      	ldr	r7, [r0, #8]
70002dbc:	600f      	str	r7, [r1, #0]
	return (*flagp & BIT(bit)) != 0U;
70002dbe:	68c3      	ldr	r3, [r0, #12]
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002dc0:	07de      	lsls	r6, r3, #31
		ret = 1;
70002dc2:	bf58      	it	pl
70002dc4:	2601      	movpl	r6, #1
		if (flag_test(&work->flags, K_WORK_RUNNING_BIT)) {
70002dc6:	d5cc      	bpl.n	70002d62 <submit_to_queue_locked+0x3a>
70002dc8:	e7c8      	b.n	70002d5c <submit_to_queue_locked+0x34>
	list->head = node;
70002dca:	67bc      	str	r4, [r7, #120]	; 0x78
70002dcc:	67fc      	str	r4, [r7, #124]	; 0x7c
	if (queue != NULL) {
70002dce:	e7e6      	b.n	70002d9e <submit_to_queue_locked+0x76>
	bool chained = (arch_current_thread() == &queue->thread) && !k_is_in_isr();
70002dd0:	f7ff f906 	bl	70001fe0 <k_is_in_isr>
70002dd4:	f080 0201 	eor.w	r2, r0, #1
70002dd8:	b2d2      	uxtb	r2, r2
70002dda:	e7cb      	b.n	70002d74 <submit_to_queue_locked+0x4c>
		ret = -ENODEV;
70002ddc:	f06f 0612 	mvn.w	r6, #18
70002de0:	e7ad      	b.n	70002d3e <submit_to_queue_locked+0x16>
		return -EINVAL;
70002de2:	f06f 0615 	mvn.w	r6, #21
70002de6:	e7aa      	b.n	70002d3e <submit_to_queue_locked+0x16>

70002de8 <z_work_submit_to_queue>:
{
70002de8:	b510      	push	{r4, lr}
70002dea:	b082      	sub	sp, #8
70002dec:	9001      	str	r0, [sp, #4]
70002dee:	4608      	mov	r0, r1
	__asm__ volatile(
70002df0:	f3ef 8400 	mrs	r4, CPSR
70002df4:	f004 0480 	and.w	r4, r4, #128	; 0x80
70002df8:	b672      	cpsid	i
	int ret = submit_to_queue_locked(work, &queue);
70002dfa:	a901      	add	r1, sp, #4
70002dfc:	f7ff ff94 	bl	70002d28 <submit_to_queue_locked>
	if (key != 0U) {
70002e00:	b904      	cbnz	r4, 70002e04 <z_work_submit_to_queue+0x1c>
70002e02:	b662      	cpsie	i
}
70002e04:	b002      	add	sp, #8
70002e06:	bd10      	pop	{r4, pc}

70002e08 <k_work_queue_start>:
void k_work_queue_start(struct k_work_q *queue,
			k_thread_stack_t *stack,
			size_t stack_size,
			int prio,
			const struct k_work_queue_config *cfg)
{
70002e08:	b5f0      	push	{r4, r5, r6, r7, lr}
70002e0a:	4604      	mov	r4, r0
70002e0c:	b089      	sub	sp, #36	; 0x24
	list->head = NULL;
70002e0e:	2000      	movs	r0, #0
70002e10:	67a0      	str	r0, [r4, #120]	; 0x78
70002e12:	67e0      	str	r0, [r4, #124]	; 0x7c
	sys_dlist_init(&w->waitq);
70002e14:	f104 0080 	add.w	r0, r4, #128	; 0x80
70002e18:	9d0e      	ldr	r5, [sp, #56]	; 0x38
	list->tail = (sys_dnode_t *)list;
70002e1a:	e9c4 0020 	strd	r0, r0, [r4, #128]	; 0x80
70002e1e:	f104 0088 	add.w	r0, r4, #136	; 0x88
70002e22:	e9c4 0022 	strd	r0, r0, [r4, #136]	; 0x88
	__ASSERT_NO_MSG(queue);
	__ASSERT_NO_MSG(stack);
	__ASSERT_NO_MSG(!flag_test(&queue->flags, K_WORK_QUEUE_STARTED_BIT));
	uint32_t flags = K_WORK_QUEUE_STARTED;
70002e26:	2001      	movs	r0, #1

	sys_slist_init(&queue->pending);
	z_waitq_init(&queue->notifyq);
	z_waitq_init(&queue->drainq);

	if ((cfg != NULL) && cfg->no_yield) {
70002e28:	b12d      	cbz	r5, 70002e36 <k_work_queue_start+0x2e>
70002e2a:	792e      	ldrb	r6, [r5, #4]
		flags |= K_WORK_QUEUE_NO_YIELD;
70002e2c:	f240 1001 	movw	r0, #257	; 0x101
70002e30:	2e00      	cmp	r6, #0
70002e32:	bf08      	it	eq
70002e34:	2001      	moveq	r0, #1
	*flagp = flags;
70002e36:	f04f 36ff 	mov.w	r6, #4294967295	; 0xffffffff
70002e3a:	f04f 37ff 	mov.w	r7, #4294967295	; 0xffffffff
70002e3e:	f8c4 0090 	str.w	r0, [r4, #144]	; 0x90
	return z_impl_k_thread_create(new_thread, stack, stack_size, entry, p1, p2, p3, prio, options, delay);
70002e42:	9303      	str	r3, [sp, #12]
70002e44:	2000      	movs	r0, #0
70002e46:	e9cd 6706 	strd	r6, r7, [sp, #24]
70002e4a:	f642 33d9 	movw	r3, #11225	; 0x2bd9
70002e4e:	9004      	str	r0, [sp, #16]
70002e50:	f2c7 0300 	movt	r3, #28672	; 0x7000
70002e54:	e9cd 0001 	strd	r0, r0, [sp, #4]
70002e58:	4620      	mov	r0, r4
70002e5a:	9400      	str	r4, [sp, #0]
70002e5c:	f7ff f8fe 	bl	7000205c <z_impl_k_thread_create>

	(void)k_thread_create(&queue->thread, stack, stack_size,
			      work_queue_main, queue, NULL, NULL,
			      prio, 0, K_FOREVER);

	if ((cfg != NULL) && (cfg->name != NULL)) {
70002e60:	b155      	cbz	r5, 70002e78 <k_work_queue_start+0x70>
70002e62:	6829      	ldr	r1, [r5, #0]
70002e64:	b111      	cbz	r1, 70002e6c <k_work_queue_start+0x64>
	return z_impl_k_thread_name_set(thread, str);
70002e66:	4620      	mov	r0, r4
70002e68:	f7ff f8c4 	bl	70001ff4 <z_impl_k_thread_name_set>
		k_thread_name_set(&queue->thread, cfg->name);
	}

	if ((cfg != NULL) && (cfg->essential)) {
70002e6c:	796b      	ldrb	r3, [r5, #5]
70002e6e:	b11b      	cbz	r3, 70002e78 <k_work_queue_start+0x70>
		queue->thread.base.user_options |= K_ESSENTIAL;
70002e70:	7b23      	ldrb	r3, [r4, #12]
70002e72:	f043 0301 	orr.w	r3, r3, #1
70002e76:	7323      	strb	r3, [r4, #12]
	z_impl_k_wakeup(thread);
70002e78:	4620      	mov	r0, r4
	}

	k_thread_start(&queue->thread);

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_work_queue, start, queue);
}
70002e7a:	b009      	add	sp, #36	; 0x24
70002e7c:	e8bd 40f0 	ldmia.w	sp!, {r4, r5, r6, r7, lr}
70002e80:	f7ff bc2a 	b.w	700026d8 <z_impl_k_wakeup>

70002e84 <memcpy>:
  long *aligned_dst;
  const long *aligned_src;

  /* If the size is small, or either SRC or DST is unaligned,
     then punt into the byte copy loop.  This should be rare.  */
  if (!TOO_SMALL(len0) && !UNALIGNED (src, dst))
70002e84:	2a0f      	cmp	r2, #15
70002e86:	d913      	bls.n	70002eb0 <memcpy+0x2c>
70002e88:	ea40 0301 	orr.w	r3, r0, r1
70002e8c:	f013 0303 	ands.w	r3, r3, #3
  char *dst = dst0;
70002e90:	bf1c      	itt	ne
70002e92:	4603      	movne	r3, r0
       /* Pick up any residual with a byte copier.  */
      dst = (char*)aligned_dst;
      src = (char*)aligned_src;
    }

  while (len0--)
70002e94:	f102 3cff 	addne.w	ip, r2, #4294967295	; 0xffffffff
  if (!TOO_SMALL(len0) && !UNALIGNED (src, dst))
70002e98:	d010      	beq.n	70002ebc <memcpy+0x38>
70002e9a:	f10c 0c01 	add.w	ip, ip, #1
70002e9e:	3b01      	subs	r3, #1
70002ea0:	448c      	add	ip, r1
    *dst++ = *src++;
70002ea2:	f811 2b01 	ldrb.w	r2, [r1], #1
70002ea6:	f803 2f01 	strb.w	r2, [r3, #1]!
  while (len0--)
70002eaa:	458c      	cmp	ip, r1
70002eac:	d1f9      	bne.n	70002ea2 <memcpy+0x1e>
70002eae:	4770      	bx	lr
  char *dst = dst0;
70002eb0:	4603      	mov	r3, r0
  while (len0--)
70002eb2:	f102 3cff 	add.w	ip, r2, #4294967295	; 0xffffffff
70002eb6:	2a00      	cmp	r2, #0
70002eb8:	d1ef      	bne.n	70002e9a <memcpy+0x16>

  return dst0;
#endif /* not PREFER_SIZE_OVER_SPEED */
}
70002eba:	4770      	bx	lr
{
70002ebc:	b5f0      	push	{r4, r5, r6, r7, lr}
70002ebe:	4684      	mov	ip, r0
70002ec0:	f1a2 0710 	sub.w	r7, r2, #16
70002ec4:	468e      	mov	lr, r1
70002ec6:	093f      	lsrs	r7, r7, #4
70002ec8:	3701      	adds	r7, #1
          *aligned_dst++ = *aligned_src++;
70002eca:	f8de 4008 	ldr.w	r4, [lr, #8]
70002ece:	3301      	adds	r3, #1
70002ed0:	f8de 6000 	ldr.w	r6, [lr]
70002ed4:	429f      	cmp	r7, r3
70002ed6:	f8de 5004 	ldr.w	r5, [lr, #4]
70002eda:	f10c 0c10 	add.w	ip, ip, #16
70002ede:	f84c 4c08 	str.w	r4, [ip, #-8]
70002ee2:	f10e 0e10 	add.w	lr, lr, #16
70002ee6:	f85e 4c04 	ldr.w	r4, [lr, #-4]
70002eea:	f84c 6c10 	str.w	r6, [ip, #-16]
70002eee:	f84c 5c0c 	str.w	r5, [ip, #-12]
70002ef2:	f84c 4c04 	str.w	r4, [ip, #-4]
      while (len0 >= BIGBLOCKSIZE)
70002ef6:	d8e8      	bhi.n	70002eca <memcpy+0x46>
      while (len0 >= LITTLEBLOCKSIZE)
70002ef8:	f012 0f0c 	tst.w	r2, #12
          len0 -= BIGBLOCKSIZE;
70002efc:	f002 050f 	and.w	r5, r2, #15
          *aligned_dst++ = *aligned_src++;
70002f00:	eb01 1107 	add.w	r1, r1, r7, lsl #4
          len0 -= BIGBLOCKSIZE;
70002f04:	bf08      	it	eq
70002f06:	462a      	moveq	r2, r5
          *aligned_dst++ = *aligned_src++;
70002f08:	eb00 1307 	add.w	r3, r0, r7, lsl #4
      while (len0 >= LITTLEBLOCKSIZE)
70002f0c:	d013      	beq.n	70002f36 <memcpy+0xb2>
70002f0e:	3d04      	subs	r5, #4
70002f10:	f025 0c03 	bic.w	ip, r5, #3
70002f14:	1f1c      	subs	r4, r3, #4
70002f16:	08ad      	lsrs	r5, r5, #2
          *aligned_dst++ = *aligned_src++;
70002f18:	460e      	mov	r6, r1
70002f1a:	449c      	add	ip, r3
          *aligned_dst++ = *aligned_src++;
70002f1c:	f856 7b04 	ldr.w	r7, [r6], #4
70002f20:	f844 7f04 	str.w	r7, [r4, #4]!
      while (len0 >= LITTLEBLOCKSIZE)
70002f24:	4564      	cmp	r4, ip
70002f26:	d1f9      	bne.n	70002f1c <memcpy+0x98>
70002f28:	1c6c      	adds	r4, r5, #1
          len0 -= LITTLEBLOCKSIZE;
70002f2a:	f002 0203 	and.w	r2, r2, #3
          *aligned_dst++ = *aligned_src++;
70002f2e:	eb03 0384 	add.w	r3, r3, r4, lsl #2
70002f32:	eb01 0184 	add.w	r1, r1, r4, lsl #2
  while (len0--)
70002f36:	f102 3cff 	add.w	ip, r2, #4294967295	; 0xffffffff
70002f3a:	f10c 0c01 	add.w	ip, ip, #1
70002f3e:	3b01      	subs	r3, #1
70002f40:	448c      	add	ip, r1
70002f42:	b12a      	cbz	r2, 70002f50 <memcpy+0xcc>
    *dst++ = *src++;
70002f44:	f811 2b01 	ldrb.w	r2, [r1], #1
70002f48:	f803 2f01 	strb.w	r2, [r3, #1]!
  while (len0--)
70002f4c:	458c      	cmp	ip, r1
70002f4e:	d1f9      	bne.n	70002f44 <memcpy+0xc0>
}
70002f50:	bdf0      	pop	{r4, r5, r6, r7, pc}
70002f52:	bf00      	nop

70002f54 <memset>:
  unsigned long buffer;
  unsigned long *aligned_addr;
  unsigned int d = c & 0xff;	/* To avoid sign extension, copy C to an
				   unsigned variable.  */

  while (UNALIGNED (s))
70002f54:	0783      	lsls	r3, r0, #30
{
70002f56:	b530      	push	{r4, r5, lr}
  while (UNALIGNED (s))
70002f58:	d04a      	beq.n	70002ff0 <memset+0x9c>
    {
      if (n--)
70002f5a:	1e54      	subs	r4, r2, #1
70002f5c:	2a00      	cmp	r2, #0
70002f5e:	d041      	beq.n	70002fe4 <memset+0x90>
  char *s = (char *) m;
70002f60:	4603      	mov	r3, r0
        *s++ = (char) c;
70002f62:	b2ca      	uxtb	r2, r1
70002f64:	e001      	b.n	70002f6a <memset+0x16>
      if (n--)
70002f66:	3c01      	subs	r4, #1
70002f68:	d33c      	bcc.n	70002fe4 <memset+0x90>
        *s++ = (char) c;
70002f6a:	f803 2b01 	strb.w	r2, [r3], #1
  while (UNALIGNED (s))
70002f6e:	079d      	lsls	r5, r3, #30
70002f70:	d1f9      	bne.n	70002f66 <memset+0x12>
      else
        return m;
    }

  if (!TOO_SMALL (n))
70002f72:	2c03      	cmp	r4, #3
70002f74:	d92f      	bls.n	70002fd6 <memset+0x82>
  unsigned int d = c & 0xff;	/* To avoid sign extension, copy C to an
70002f76:	b2cd      	uxtb	r5, r1
      buffer |= (buffer << 16);
      for (i = 32; i < LBLOCKSIZE * 8; i <<= 1)
        buffer = (buffer << i) | buffer;

      /* Unroll the loop.  */
      while (n >= LBLOCKSIZE*4)
70002f78:	2c0f      	cmp	r4, #15
70002f7a:	eb05 2505 	add.w	r5, r5, r5, lsl #8
70002f7e:	eb05 4505 	add.w	r5, r5, r5, lsl #16
70002f82:	d938      	bls.n	70002ff6 <memset+0xa2>
70002f84:	f1a4 0210 	sub.w	r2, r4, #16
70002f88:	f022 0c0f 	bic.w	ip, r2, #15
70002f8c:	f103 0e10 	add.w	lr, r3, #16
70002f90:	44e6      	add	lr, ip
70002f92:	ea4f 1c12 	mov.w	ip, r2, lsr #4
70002f96:	461a      	mov	r2, r3
        {
          *aligned_addr++ = buffer;
70002f98:	6015      	str	r5, [r2, #0]
      while (n >= LBLOCKSIZE*4)
70002f9a:	3210      	adds	r2, #16
          *aligned_addr++ = buffer;
70002f9c:	f842 5c0c 	str.w	r5, [r2, #-12]
70002fa0:	f842 5c08 	str.w	r5, [r2, #-8]
70002fa4:	f842 5c04 	str.w	r5, [r2, #-4]
      while (n >= LBLOCKSIZE*4)
70002fa8:	4572      	cmp	r2, lr
70002faa:	d1f5      	bne.n	70002f98 <memset+0x44>
          *aligned_addr++ = buffer;
          *aligned_addr++ = buffer;
          *aligned_addr++ = buffer;
70002fac:	f10c 0201 	add.w	r2, ip, #1
          n -= 4*LBLOCKSIZE;
        }

      while (n >= LBLOCKSIZE)
70002fb0:	f014 0f0c 	tst.w	r4, #12
          *aligned_addr++ = buffer;
70002fb4:	eb03 1202 	add.w	r2, r3, r2, lsl #4
          n -= 4*LBLOCKSIZE;
70002fb8:	f004 0c0f 	and.w	ip, r4, #15
      while (n >= LBLOCKSIZE)
70002fbc:	d013      	beq.n	70002fe6 <memset+0x92>
70002fbe:	f1ac 0304 	sub.w	r3, ip, #4
70002fc2:	f023 0303 	bic.w	r3, r3, #3
70002fc6:	3304      	adds	r3, #4
70002fc8:	4413      	add	r3, r2
        {
          *aligned_addr++ = buffer;
70002fca:	f842 5b04 	str.w	r5, [r2], #4
      while (n >= LBLOCKSIZE)
70002fce:	429a      	cmp	r2, r3
70002fd0:	d1fb      	bne.n	70002fca <memset+0x76>
          n -= LBLOCKSIZE;
70002fd2:	f00c 0403 	and.w	r4, ip, #3
      s = (char*)aligned_addr;
    }

#endif /* not PREFER_SIZE_OVER_SPEED */

  while (n--)
70002fd6:	b12c      	cbz	r4, 70002fe4 <memset+0x90>
        *s++ = (char) c;
70002fd8:	b2c9      	uxtb	r1, r1
70002fda:	441c      	add	r4, r3
    *s++ = (char) c;
70002fdc:	f803 1b01 	strb.w	r1, [r3], #1
  while (n--)
70002fe0:	429c      	cmp	r4, r3
70002fe2:	d1fb      	bne.n	70002fdc <memset+0x88>

  return m;
}
70002fe4:	bd30      	pop	{r4, r5, pc}
          n -= 4*LBLOCKSIZE;
70002fe6:	4664      	mov	r4, ip
          *aligned_addr++ = buffer;
70002fe8:	4613      	mov	r3, r2
  while (n--)
70002fea:	2c00      	cmp	r4, #0
70002fec:	d1f4      	bne.n	70002fd8 <memset+0x84>
70002fee:	e7f9      	b.n	70002fe4 <memset+0x90>
  char *s = (char *) m;
70002ff0:	4603      	mov	r3, r0
  while (UNALIGNED (s))
70002ff2:	4614      	mov	r4, r2
70002ff4:	e7bd      	b.n	70002f72 <memset+0x1e>
      while (n >= LBLOCKSIZE*4)
70002ff6:	461a      	mov	r2, r3
70002ff8:	46a4      	mov	ip, r4
70002ffa:	e7e0      	b.n	70002fbe <memset+0x6a>

70002ffc <strnlen>:
strnlen (const char *str,
	size_t n)
{
  const char *start = str;

  while (n-- > 0 && *str)
70002ffc:	4603      	mov	r3, r0
70002ffe:	eb00 0c01 	add.w	ip, r0, r1
70003002:	b911      	cbnz	r1, 7000300a <strnlen+0xe>
70003004:	e00a      	b.n	7000301c <strnlen+0x20>
70003006:	4563      	cmp	r3, ip
70003008:	d006      	beq.n	70003018 <strnlen+0x1c>
    str++;
7000300a:	461a      	mov	r2, r3
7000300c:	3301      	adds	r3, #1
  while (n-- > 0 && *str)
7000300e:	7811      	ldrb	r1, [r2, #0]
70003010:	2900      	cmp	r1, #0
70003012:	d1f8      	bne.n	70003006 <strnlen+0xa>

  return str - start;
70003014:	1a10      	subs	r0, r2, r0
}
70003016:	4770      	bx	lr
  return str - start;
70003018:	1a18      	subs	r0, r3, r0
7000301a:	4770      	bx	lr
  while (n-- > 0 && *str)
7000301c:	4608      	mov	r0, r1
7000301e:	4770      	bx	lr

70003020 <snprintf>:

#include "stdio_private.h"

int
snprintf(char *s, size_t n, const char *fmt, ...)
{
70003020:	b40c      	push	{r2, r3}
	   that f.size will be a max number of nonzero symbols.	*/

	if ((int) n < 0)
		n = (unsigned)INT_MAX + 1;

	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
70003022:	f643 2231 	movw	r2, #14897	; 0x3a31
{
70003026:	4603      	mov	r3, r0
70003028:	b510      	push	{r4, lr}
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
7000302a:	2002      	movs	r0, #2
{
7000302c:	b088      	sub	sp, #32
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
7000302e:	2400      	movs	r4, #0
70003030:	f2c7 0200 	movt	r2, #28672	; 0x7000
70003034:	9305      	str	r3, [sp, #20]
70003036:	e9cd 4201 	strd	r4, r2, [sp, #4]
7000303a:	e9cd 4403 	strd	r4, r4, [sp, #12]
7000303e:	f88d 0006 	strb.w	r0, [sp, #6]
70003042:	9407      	str	r4, [sp, #28]
70003044:	b1a1      	cbz	r1, 70003070 <snprintf+0x50>
70003046:	f1b1 4f00 	cmp.w	r1, #2147483648	; 0x80000000
7000304a:	bf28      	it	cs
7000304c:	f04f 4100 	movcs.w	r1, #2147483648	; 0x80000000

	va_start(ap, fmt);
70003050:	aa0b      	add	r2, sp, #44	; 0x2c
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
70003052:	3901      	subs	r1, #1
70003054:	440b      	add	r3, r1
	i = vfprintf(&f.file, fmt, ap);
70003056:	990a      	ldr	r1, [sp, #40]	; 0x28
70003058:	a801      	add	r0, sp, #4
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
7000305a:	9306      	str	r3, [sp, #24]
	va_start(ap, fmt);
7000305c:	9200      	str	r2, [sp, #0]
	i = vfprintf(&f.file, fmt, ap);
7000305e:	f000 f951 	bl	70003304 <__l_vfprintf>
	va_end(ap);

	if (n)
            *f.pos = '\0';
70003062:	9b05      	ldr	r3, [sp, #20]
70003064:	701c      	strb	r4, [r3, #0]

	return i;
}
70003066:	b008      	add	sp, #32
70003068:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
7000306c:	b002      	add	sp, #8
7000306e:	4770      	bx	lr
	i = vfprintf(&f.file, fmt, ap);
70003070:	990a      	ldr	r1, [sp, #40]	; 0x28
	va_start(ap, fmt);
70003072:	aa0b      	add	r2, sp, #44	; 0x2c
	struct __file_str f = FDEV_SETUP_STRING_WRITE(s, n ? n - 1 : 0);
70003074:	9306      	str	r3, [sp, #24]
	i = vfprintf(&f.file, fmt, ap);
70003076:	a801      	add	r0, sp, #4
	va_start(ap, fmt);
70003078:	9200      	str	r2, [sp, #0]
	i = vfprintf(&f.file, fmt, ap);
7000307a:	f000 f943 	bl	70003304 <__l_vfprintf>
}
7000307e:	b008      	add	sp, #32
70003080:	e8bd 4010 	ldmia.w	sp!, {r4, lr}
70003084:	b002      	add	sp, #8
70003086:	4770      	bx	lr

70003088 <__ultoa_invert>:
#endif
#endif

static __noinline char *
__ultoa_invert(ultoa_unsigned_t val, char *str, int base)
{
70003088:	b570      	push	{r4, r5, r6, lr}
7000308a:	4684      	mov	ip, r0
	char hex = ('a' - '0' - 10 + 16) - base;
7000308c:	f1c3 0437 	rsb	r4, r3, #55	; 0x37
{
70003090:	4610      	mov	r0, r2
	char hex = ('a' - '0' - 10 + 16) - base;
70003092:	b2e2      	uxtb	r2, r4

        base &= 31;
70003094:	f003 041f 	and.w	r4, r3, #31
    switch(base) {
70003098:	2c08      	cmp	r4, #8
        *dig = val & 1;
7000309a:	fa5f fe8c 	uxtb.w	lr, ip
    switch(base) {
7000309e:	d042      	beq.n	70003126 <__ultoa_invert+0x9e>
700030a0:	2c10      	cmp	r4, #16
	q = (n >> 1) + (n >> 2);
700030a2:	ea4f 035c 	mov.w	r3, ip, lsr #1
700030a6:	ea4f 069c 	mov.w	r6, ip, lsr #2
700030aa:	ea43 73c1 	orr.w	r3, r3, r1, lsl #31
700030ae:	ea46 7681 	orr.w	r6, r6, r1, lsl #30
700030b2:	ea4f 0591 	mov.w	r5, r1, lsr #2
    switch(base) {
700030b6:	d04c      	beq.n	70003152 <__ultoa_invert+0xca>
700030b8:	2c02      	cmp	r4, #2
700030ba:	d042      	beq.n	70003142 <__ultoa_invert+0xba>
	q = (n >> 1) + (n >> 2);
700030bc:	199b      	adds	r3, r3, r6
700030be:	eb45 0551 	adc.w	r5, r5, r1, lsr #1
	q = q + (q >> 4);
700030c2:	0919      	lsrs	r1, r3, #4
700030c4:	ea41 7105 	orr.w	r1, r1, r5, lsl #28
700030c8:	185b      	adds	r3, r3, r1
700030ca:	eb45 1515 	adc.w	r5, r5, r5, lsr #4
	q = q + (q >> 8);
700030ce:	0a19      	lsrs	r1, r3, #8
700030d0:	ea41 6105 	orr.w	r1, r1, r5, lsl #24
700030d4:	185b      	adds	r3, r3, r1
700030d6:	eb45 2515 	adc.w	r5, r5, r5, lsr #8
	q = q + (q >> 16);
700030da:	0c19      	lsrs	r1, r3, #16
700030dc:	ea41 4105 	orr.w	r1, r1, r5, lsl #16
700030e0:	185b      	adds	r3, r3, r1
700030e2:	eb45 4515 	adc.w	r5, r5, r5, lsr #16
        q = q + (q >> 32);
700030e6:	195b      	adds	r3, r3, r5
700030e8:	f145 0500 	adc.w	r5, r5, #0
	q = q >> 3;
700030ec:	ea4f 0cd3 	mov.w	ip, r3, lsr #3
700030f0:	ea4c 7c45 	orr.w	ip, ip, r5, lsl #29
700030f4:	08e9      	lsrs	r1, r5, #3
	r = (char) (n - (((q << 2) + q) << 1));
700030f6:	eb0c 038c 	add.w	r3, ip, ip, lsl #2
700030fa:	ebae 0343 	sub.w	r3, lr, r3, lsl #1
700030fe:	b2db      	uxtb	r3, r3
            r -= 10;
70003100:	f1a3 050a 	sub.w	r5, r3, #10
        if (r > 9) {
70003104:	2b09      	cmp	r3, #9
            r -= 10;
70003106:	b2ed      	uxtb	r5, r5
        if (r > 9) {
70003108:	d914      	bls.n	70003134 <__ultoa_invert+0xac>
            q++;
7000310a:	f11c 0c01 	adds.w	ip, ip, #1
7000310e:	f141 0100 	adc.w	r1, r1, #0
                val = udivmod(val, base, &v);
#else
                v = val % base;
                val /= base;
#endif
		if (v > 9)
70003112:	2d09      	cmp	r5, #9
70003114:	d92a      	bls.n	7000316c <__ultoa_invert+0xe4>
                        v += hex;
70003116:	4415      	add	r5, r2
                v += '0';
70003118:	3530      	adds	r5, #48	; 0x30
    switch(base) {
7000311a:	2c08      	cmp	r4, #8
		*str++ = v;
7000311c:	f800 5b01 	strb.w	r5, [r0], #1
        *dig = val & 1;
70003120:	fa5f fe8c 	uxtb.w	lr, ip
    switch(base) {
70003124:	d1bc      	bne.n	700030a0 <__ultoa_invert+0x18>
        return val >> 3;
70003126:	ea4f 0cdc 	mov.w	ip, ip, lsr #3
7000312a:	ea4c 7c41 	orr.w	ip, ip, r1, lsl #29
        *dig = val & 7;
7000312e:	f00e 0307 	and.w	r3, lr, #7
        return val >> 3;
70003132:	08c9      	lsrs	r1, r1, #3
                v += '0';
70003134:	3330      	adds	r3, #48	; 0x30
		*str++ = v;
70003136:	f800 3b01 	strb.w	r3, [r0], #1
	} while (val);
7000313a:	ea5c 0301 	orrs.w	r3, ip, r1
7000313e:	d1ab      	bne.n	70003098 <__ultoa_invert+0x10>
	return str;
}
70003140:	bd70      	pop	{r4, r5, r6, pc}
        return val >> 1;
70003142:	ea4f 0c5c 	mov.w	ip, ip, lsr #1
70003146:	ea4c 7cc1 	orr.w	ip, ip, r1, lsl #31
        *dig = val & 1;
7000314a:	f00e 0301 	and.w	r3, lr, #1
        return val >> 1;
7000314e:	0849      	lsrs	r1, r1, #1
		if (v > 9)
70003150:	e7f0      	b.n	70003134 <__ultoa_invert+0xac>
        *dig = val & 15;
70003152:	f00e 030f 	and.w	r3, lr, #15
		if (v > 9)
70003156:	2b09      	cmp	r3, #9
                        v += hex;
70003158:	bf88      	it	hi
7000315a:	189b      	addhi	r3, r3, r2
        return val >> 4;
7000315c:	ea4f 1c1c 	mov.w	ip, ip, lsr #4
70003160:	ea4c 7c01 	orr.w	ip, ip, r1, lsl #28
                        v += hex;
70003164:	bf88      	it	hi
70003166:	b2db      	uxtbhi	r3, r3
        return val >> 4;
70003168:	0909      	lsrs	r1, r1, #4
		if (v > 9)
7000316a:	e7e3      	b.n	70003134 <__ultoa_invert+0xac>
                v += '0';
7000316c:	3326      	adds	r3, #38	; 0x26
        *dig = val & 1;
7000316e:	fa5f fe8c 	uxtb.w	lr, ip
		*str++ = v;
70003172:	f800 3b01 	strb.w	r3, [r0], #1
    switch(base) {
70003176:	e793      	b.n	700030a0 <__ultoa_invert+0x18>

70003178 <skip_to_arg>:
 * and types to slowly walk the argument vector until it points at the
 * target_argno so that the outer printf code can then extract it.
 */
static void
skip_to_arg(const CHAR *fmt_orig, my_va_list *ap, int target_argno)
{
70003178:	e92d 43f0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
    unsigned c;		/* holds a char from the format string */
    uint16_t flags;
    int current_argno = 1;
7000317c:	f04f 0e01 	mov.w	lr, #1
70003180:	4603      	mov	r3, r0
    int argno;
    int width;
    const CHAR *fmt = fmt_orig;

    while (current_argno < target_argno) {
70003182:	4572      	cmp	r2, lr
70003184:	dc02      	bgt.n	7000318c <skip_to_arg+0x14>
70003186:	e006      	b.n	70003196 <skip_to_arg+0x1e>
        for (;;) {
            c = *fmt++;
            if (!c) return;
            if (c == '%') {
70003188:	2c25      	cmp	r4, #37	; 0x25
7000318a:	d006      	beq.n	7000319a <skip_to_arg+0x22>
7000318c:	469c      	mov	ip, r3
            c = *fmt++;
7000318e:	f813 4b01 	ldrb.w	r4, [r3], #1
            if (!c) return;
70003192:	2c00      	cmp	r4, #0
70003194:	d1f8      	bne.n	70003188 <skip_to_arg+0x10>
            }
            ++current_argno;
            fmt = fmt_orig;
        }
    }
}
70003196:	e8bd 83f0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
                c = *fmt++;
7000319a:	781c      	ldrb	r4, [r3, #0]
                if (c != '%') break;
7000319c:	2c25      	cmp	r4, #37	; 0x25
                c = *fmt++;
7000319e:	f10c 0c02 	add.w	ip, ip, #2
700031a2:	4663      	mov	r3, ip
                if (c != '%') break;
700031a4:	d0f2      	beq.n	7000318c <skip_to_arg+0x14>
        width = 0;
700031a6:	2600      	movs	r6, #0
		switch (c) {
700031a8:	f642 0789 	movw	r7, #10377	; 0x2889
        argno = 0;
700031ac:	46b0      	mov	r8, r6
		switch (c) {
700031ae:	f2c0 0701 	movt	r7, #1
        flags = 0;
700031b2:	4633      	mov	r3, r6
	    if (flags < FL_WIDTH) {
700031b4:	2b1f      	cmp	r3, #31
700031b6:	d847      	bhi.n	70003248 <skip_to_arg+0xd0>
		switch (c) {
700031b8:	f1a4 0520 	sub.w	r5, r4, #32
700031bc:	2d10      	cmp	r5, #16
700031be:	d856      	bhi.n	7000326e <skip_to_arg+0xf6>
700031c0:	fa27 f505 	lsr.w	r5, r7, r5
700031c4:	07ed      	lsls	r5, r5, #31
700031c6:	d434      	bmi.n	70003232 <skip_to_arg+0xba>
		if (c >= '0' && c <= '9') {
700031c8:	f1a4 0530 	sub.w	r5, r4, #48	; 0x30
700031cc:	2d09      	cmp	r5, #9
700031ce:	d952      	bls.n	70003276 <skip_to_arg+0xfe>
                if (c == '$') {
700031d0:	2c24      	cmp	r4, #36	; 0x24
700031d2:	d10a      	bne.n	700031ea <skip_to_arg+0x72>
                    if (argno) {
700031d4:	f1b8 0f00 	cmp.w	r8, #0
700031d8:	d053      	beq.n	70003282 <skip_to_arg+0x10a>
                        if (width == current_argno) {
700031da:	4576      	cmp	r6, lr
700031dc:	d137      	bne.n	7000324e <skip_to_arg+0xd6>
                SKIP_FLOAT_ARG(flags, ap->ap);
700031de:	680d      	ldr	r5, [r1, #0]
                arg_to_unsigned(ap->ap, flags, x);
700031e0:	3504      	adds	r5, #4
                SKIP_FLOAT_ARG(flags, ap->ap);
700031e2:	600d      	str	r5, [r1, #0]
            ++current_argno;
700031e4:	f10e 0e01 	add.w	lr, lr, #1
            fmt = fmt_orig;
700031e8:	e7ca      	b.n	70003180 <skip_to_arg+0x8>
		if (c == '*') {
700031ea:	f024 0504 	bic.w	r5, r4, #4
		if (c == '.') {
700031ee:	2d2a      	cmp	r5, #42	; 0x2a
700031f0:	d02d      	beq.n	7000324e <skip_to_arg+0xd6>
            CHECK_INT_SIZES(c, flags);
700031f2:	f1a4 054c 	sub.w	r5, r4, #76	; 0x4c
700031f6:	2d2e      	cmp	r5, #46	; 0x2e
700031f8:	d81f      	bhi.n	7000323a <skip_to_arg+0xc2>
700031fa:	e8df f005 	tbb	[pc, r5]
700031fe:	1e18      	.short	0x1e18
70003200:	1e1e1e1e 	.word	0x1e1e1e1e
70003204:	1e1e1e1e 	.word	0x1e1e1e1e
70003208:	1e1e1e1e 	.word	0x1e1e1e1e
7000320c:	1e1e1e1e 	.word	0x1e1e1e1e
70003210:	1e1e1e1e 	.word	0x1e1e1e1e
70003214:	1e1e1e1e 	.word	0x1e1e1e1e
70003218:	1e2a1e1e 	.word	0x1e2a1e1e
7000321c:	1e311e18 	.word	0x1e311e18
70003220:	1e1e1e1e 	.word	0x1e1e1e1e
70003224:	1e1a1e1e 	.word	0x1e1a1e1e
70003228:	1e1e1e1e 	.word	0x1e1e1e1e
7000322c:	1a          	.byte	0x1a
7000322d:	00          	.byte	0x00
7000322e:	f443 7320 	orr.w	r3, r3, #640	; 0x280
	} while ( (c = *fmt++) != 0);
70003232:	f81c 4b01 	ldrb.w	r4, [ip], #1
70003236:	2c00      	cmp	r4, #0
70003238:	d1bc      	bne.n	700031b4 <skip_to_arg+0x3c>
        if (argno == 0)
7000323a:	f1b8 0f00 	cmp.w	r8, #0
7000323e:	d0aa      	beq.n	70003196 <skip_to_arg+0x1e>
        if (argno == current_argno) {
70003240:	45f0      	cmp	r8, lr
70003242:	d021      	beq.n	70003288 <skip_to_arg+0x110>
70003244:	4663      	mov	r3, ip
70003246:	e79c      	b.n	70003182 <skip_to_arg+0xa>
	    if (flags < FL_LONG) {
70003248:	2b7f      	cmp	r3, #127	; 0x7f
7000324a:	d8d2      	bhi.n	700031f2 <skip_to_arg+0x7a>
7000324c:	e7bc      	b.n	700031c8 <skip_to_arg+0x50>
                    width = 0;
7000324e:	2600      	movs	r6, #0
70003250:	e7ef      	b.n	70003232 <skip_to_arg+0xba>
            CHECK_INT_SIZES(c, flags);
70003252:	05dd      	lsls	r5, r3, #23
70003254:	bf48      	it	mi
70003256:	f443 7300 	orrmi.w	r3, r3, #512	; 0x200
7000325a:	f443 7380 	orr.w	r3, r3, #256	; 0x100
7000325e:	e7e8      	b.n	70003232 <skip_to_arg+0xba>
70003260:	061c      	lsls	r4, r3, #24
70003262:	bf48      	it	mi
70003264:	f443 7300 	orrmi.w	r3, r3, #512	; 0x200
70003268:	f043 0380 	orr.w	r3, r3, #128	; 0x80
7000326c:	e7e1      	b.n	70003232 <skip_to_arg+0xba>
		if (c >= '0' && c <= '9') {
7000326e:	f1a4 0530 	sub.w	r5, r4, #48	; 0x30
70003272:	2d09      	cmp	r5, #9
70003274:	d8b9      	bhi.n	700031ea <skip_to_arg+0x72>
                    flags |= FL_WIDTH;
70003276:	2320      	movs	r3, #32
                    width = 10 * width + c;
70003278:	eb06 0686 	add.w	r6, r6, r6, lsl #2
7000327c:	eb05 0646 	add.w	r6, r5, r6, lsl #1
		    continue;
70003280:	e7d7      	b.n	70003232 <skip_to_arg+0xba>
70003282:	46b0      	mov	r8, r6
                    width = 0;
70003284:	2600      	movs	r6, #0
70003286:	e7d4      	b.n	70003232 <skip_to_arg+0xba>
                SKIP_FLOAT_ARG(flags, ap->ap);
70003288:	680d      	ldr	r5, [r1, #0]
            if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
7000328a:	f044 0620 	orr.w	r6, r4, #32
                || TOLOWER(c) == 'a'
7000328e:	f1a6 0765 	sub.w	r7, r6, #101	; 0x65
            if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
70003292:	2e61      	cmp	r6, #97	; 0x61
70003294:	bf18      	it	ne
70003296:	2f02      	cmpne	r7, #2
70003298:	d92e      	bls.n	700032f8 <skip_to_arg+0x180>
            } else if (c == 'c') {
7000329a:	3c63      	subs	r4, #99	; 0x63
7000329c:	2c10      	cmp	r4, #16
7000329e:	d825      	bhi.n	700032ec <skip_to_arg+0x174>
700032a0:	a601      	add	r6, pc, #4	; (adr r6, 700032a8 <skip_to_arg+0x130>)
700032a2:	f856 f024 	ldr.w	pc, [r6, r4, lsl #2]
700032a6:	bf00      	nop
700032a8:	700031e1 	.word	0x700031e1
700032ac:	700032ed 	.word	0x700032ed
700032b0:	700032ed 	.word	0x700032ed
700032b4:	700032ed 	.word	0x700032ed
700032b8:	700032ed 	.word	0x700032ed
700032bc:	700032ed 	.word	0x700032ed
700032c0:	700032ed 	.word	0x700032ed
700032c4:	700032ed 	.word	0x700032ed
700032c8:	700032ed 	.word	0x700032ed
700032cc:	700032ed 	.word	0x700032ed
700032d0:	700032ed 	.word	0x700032ed
700032d4:	700032ed 	.word	0x700032ed
700032d8:	700032ed 	.word	0x700032ed
700032dc:	700032ed 	.word	0x700032ed
700032e0:	700032ed 	.word	0x700032ed
700032e4:	700032ed 	.word	0x700032ed
700032e8:	700031e1 	.word	0x700031e1
                arg_to_unsigned(ap->ap, flags, x);
700032ec:	061c      	lsls	r4, r3, #24
700032ee:	f57f af77 	bpl.w	700031e0 <skip_to_arg+0x68>
700032f2:	059b      	lsls	r3, r3, #22
700032f4:	f57f af74 	bpl.w	700031e0 <skip_to_arg+0x68>
700032f8:	3507      	adds	r5, #7
700032fa:	f025 0507 	bic.w	r5, r5, #7
700032fe:	3508      	adds	r5, #8
70003300:	e76f      	b.n	700031e2 <skip_to_arg+0x6a>
70003302:	bf00      	nop

70003304 <__l_vfprintf>:
    return len;
}
#endif

int vfprintf (FILE * stream, const CHAR *fmt, va_list ap_orig)
{
70003304:	e92d 4ff0 	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    int (*put)(char, FILE *) = stream->put;
#define my_putc(c, stream) do { ++stream_len; if (put(c, stream) < 0) goto fail; } while(0)
#endif
#endif

    if ((stream->flags & __SWR) == 0)
70003308:	7883      	ldrb	r3, [r0, #2]
    int (*put)(char, FILE *) = stream->put;
7000330a:	f8d0 b004 	ldr.w	fp, [r0, #4]
    if ((stream->flags & __SWR) == 0)
7000330e:	079e      	lsls	r6, r3, #30
{
70003310:	b09b      	sub	sp, #108	; 0x6c
    if ((stream->flags & __SWR) == 0)
70003312:	f140 836c 	bpl.w	700039ee <__l_vfprintf+0x6ea>
70003316:	4607      	mov	r7, r0
#endif

    for (;;) {

	for (;;) {
	    c = *fmt++;
70003318:	460b      	mov	r3, r1
    va_copy(ap, ap_orig);
7000331a:	9209      	str	r2, [sp, #36]	; 0x24
	    c = *fmt++;
7000331c:	4696      	mov	lr, r2
7000331e:	f813 0b01 	ldrb.w	r0, [r3], #1
	    if (!c) goto ret;
70003322:	2800      	cmp	r0, #0
70003324:	f000 835a 	beq.w	700039dc <__l_vfprintf+0x6d8>
70003328:	460d      	mov	r5, r1
    int stream_len = 0;
7000332a:	2400      	movs	r4, #0
7000332c:	e9cd 1203 	strd	r1, r2, [sp, #12]
70003330:	e00a      	b.n	70003348 <__l_vfprintf+0x44>
	    if (c == '%') {
		c = *fmt++;
		if (c != '%') break;
	    }
	    my_putc (c, stream);
70003332:	4639      	mov	r1, r7
70003334:	b2c0      	uxtb	r0, r0
70003336:	461d      	mov	r5, r3
70003338:	47d8      	blx	fp
7000333a:	3401      	adds	r4, #1
7000333c:	2800      	cmp	r0, #0
7000333e:	db10      	blt.n	70003362 <__l_vfprintf+0x5e>
	    c = *fmt++;
70003340:	462b      	mov	r3, r5
70003342:	f813 0b01 	ldrb.w	r0, [r3], #1
	    if (!c) goto ret;
70003346:	b190      	cbz	r0, 7000336e <__l_vfprintf+0x6a>
	    if (c == '%') {
70003348:	2825      	cmp	r0, #37	; 0x25
7000334a:	d1f2      	bne.n	70003332 <__l_vfprintf+0x2e>
		c = *fmt++;
7000334c:	f105 0802 	add.w	r8, r5, #2
70003350:	786d      	ldrb	r5, [r5, #1]
		if (c != '%') break;
70003352:	2d25      	cmp	r5, #37	; 0x25
70003354:	d10f      	bne.n	70003376 <__l_vfprintf+0x72>
	    my_putc (c, stream);
70003356:	4639      	mov	r1, r7
		c = *fmt++;
70003358:	4645      	mov	r5, r8
	    my_putc (c, stream);
7000335a:	47d8      	blx	fp
7000335c:	3401      	adds	r4, #1
7000335e:	2800      	cmp	r0, #0
70003360:	daee      	bge.n	70003340 <__l_vfprintf+0x3c>
#endif
    return stream_len;
#undef my_putc
#undef ap
  fail:
    stream->flags |= __SERR;
70003362:	78bb      	ldrb	r3, [r7, #2]
    stream_len = -1;
70003364:	f04f 34ff 	mov.w	r4, #4294967295	; 0xffffffff
    stream->flags |= __SERR;
70003368:	f043 0304 	orr.w	r3, r3, #4
7000336c:	70bb      	strb	r3, [r7, #2]
    goto ret;
}
7000336e:	4620      	mov	r0, r4
70003370:	b01b      	add	sp, #108	; 0x6c
70003372:	e8bd 8ff0 	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
        argno = 0;
70003376:	f04f 0a00 	mov.w	sl, #0
	width = 0;
7000337a:	46d1      	mov	r9, sl
	flags = 0;
7000337c:	4656      	mov	r6, sl
	prec = 0;
7000337e:	f8cd a004 	str.w	sl, [sp, #4]
	    if (flags < FL_WIDTH) {
70003382:	2e1f      	cmp	r6, #31
70003384:	d857      	bhi.n	70003436 <__l_vfprintf+0x132>
		switch (c) {
70003386:	f1a5 0320 	sub.w	r3, r5, #32
7000338a:	2b10      	cmp	r3, #16
7000338c:	d80a      	bhi.n	700033a4 <__l_vfprintf+0xa0>
7000338e:	e8df f003 	tbb	[pc, r3]
70003392:	0946      	.short	0x0946
70003394:	09094909 	.word	0x09094909
70003398:	09091409 	.word	0x09091409
7000339c:	4f094409 	.word	0x4f094409
700033a0:	0909      	.short	0x0909
700033a2:	4c          	.byte	0x4c
700033a3:	00          	.byte	0x00
		if (c >= '0' && c <= '9') {
700033a4:	f1a5 0330 	sub.w	r3, r5, #48	; 0x30
700033a8:	2b09      	cmp	r3, #9
700033aa:	f200 80b0 	bhi.w	7000350e <__l_vfprintf+0x20a>
		    width = 10*width + c;
700033ae:	eb09 0989 	add.w	r9, r9, r9, lsl #2
		    flags |= FL_WIDTH;
700033b2:	f046 0620 	orr.w	r6, r6, #32
		    width = 10*width + c;
700033b6:	eb03 0949 	add.w	r9, r3, r9, lsl #1
	} while ( (c = *fmt++) != 0);
700033ba:	f818 5b01 	ldrb.w	r5, [r8], #1
700033be:	2d00      	cmp	r5, #0
700033c0:	d1df      	bne.n	70003382 <__l_vfprintf+0x7e>
        if (argno) {
700033c2:	9502      	str	r5, [sp, #8]
700033c4:	2320      	movs	r3, #32
700033c6:	f1ba 0f00 	cmp.w	sl, #0
700033ca:	f040 80c9 	bne.w	70003560 <__l_vfprintf+0x25c>
	if (prec < 0) {
700033ce:	9a01      	ldr	r2, [sp, #4]
700033d0:	2a00      	cmp	r2, #0
	    prec = 0;
700033d2:	bfbf      	itttt	lt
700033d4:	2200      	movlt	r2, #0
	    flags &= ~FL_PREC;
700033d6:	f026 0640 	biclt.w	r6, r6, #64	; 0x40
	    prec = 0;
700033da:	9201      	strlt	r2, [sp, #4]
	    flags &= ~FL_PREC;
700033dc:	b2b6      	uxthlt	r6, r6
	if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
700033de:	9a02      	ldr	r2, [sp, #8]
700033e0:	2a00      	cmp	r2, #0
700033e2:	f040 80f1 	bne.w	700035c8 <__l_vfprintf+0x2c4>
            if (c == 'c') {
700033e6:	f1a5 0263 	sub.w	r2, r5, #99	; 0x63
700033ea:	2a12      	cmp	r2, #18
700033ec:	f200 8141 	bhi.w	70003672 <__l_vfprintf+0x36e>
700033f0:	e8df f012 	tbh	[pc, r2, lsl #1]
700033f4:	0158018e 	.word	0x0158018e
700033f8:	013f013f 	.word	0x013f013f
700033fc:	013f013f 	.word	0x013f013f
70003400:	013f0158 	.word	0x013f0158
70003404:	013f013f 	.word	0x013f013f
70003408:	013f013f 	.word	0x013f013f
7000340c:	019802cb 	.word	0x019802cb
70003410:	013f013f 	.word	0x013f013f
70003414:	013f01e5 	.word	0x013f01e5
70003418:	01e0      	.short	0x01e0
		    flags |= FL_PLUS;
7000341a:	f046 0602 	orr.w	r6, r6, #2
		    flags |= FL_SPACE;
7000341e:	f046 0604 	orr.w	r6, r6, #4
		    continue;
70003422:	e7ca      	b.n	700033ba <__l_vfprintf+0xb6>
		    flags |= FL_ALT;
70003424:	f046 0610 	orr.w	r6, r6, #16
		    continue;
70003428:	e7c7      	b.n	700033ba <__l_vfprintf+0xb6>
		    flags |= FL_ZFILL;
7000342a:	f046 0601 	orr.w	r6, r6, #1
		    continue;
7000342e:	e7c4      	b.n	700033ba <__l_vfprintf+0xb6>
		    flags |= FL_LPAD;
70003430:	f046 0608 	orr.w	r6, r6, #8
		    continue;
70003434:	e7c1      	b.n	700033ba <__l_vfprintf+0xb6>
	    if (flags < FL_LONG) {
70003436:	2e7f      	cmp	r6, #127	; 0x7f
70003438:	f240 82eb 	bls.w	70003a12 <__l_vfprintf+0x70e>
            CHECK_INT_SIZES(c, flags);
7000343c:	f1a5 034c 	sub.w	r3, r5, #76	; 0x4c
70003440:	2b2e      	cmp	r3, #46	; 0x2e
70003442:	d87e      	bhi.n	70003542 <__l_vfprintf+0x23e>
70003444:	a201      	add	r2, pc, #4	; (adr r2, 7000344c <__l_vfprintf+0x148>)
70003446:	f852 f023 	ldr.w	pc, [r2, r3, lsl #2]
7000344a:	bf00      	nop
7000344c:	70003509 	.word	0x70003509
70003450:	70003543 	.word	0x70003543
70003454:	70003543 	.word	0x70003543
70003458:	70003543 	.word	0x70003543
7000345c:	70003543 	.word	0x70003543
70003460:	70003543 	.word	0x70003543
70003464:	70003543 	.word	0x70003543
70003468:	70003543 	.word	0x70003543
7000346c:	70003543 	.word	0x70003543
70003470:	70003543 	.word	0x70003543
70003474:	70003543 	.word	0x70003543
70003478:	70003543 	.word	0x70003543
7000347c:	70003543 	.word	0x70003543
70003480:	70003543 	.word	0x70003543
70003484:	70003543 	.word	0x70003543
70003488:	70003543 	.word	0x70003543
7000348c:	70003543 	.word	0x70003543
70003490:	70003543 	.word	0x70003543
70003494:	70003543 	.word	0x70003543
70003498:	70003543 	.word	0x70003543
7000349c:	70003543 	.word	0x70003543
700034a0:	70003543 	.word	0x70003543
700034a4:	70003543 	.word	0x70003543
700034a8:	70003543 	.word	0x70003543
700034ac:	70003543 	.word	0x70003543
700034b0:	70003543 	.word	0x70003543
700034b4:	70003543 	.word	0x70003543
700034b8:	70003543 	.word	0x70003543
700034bc:	70003583 	.word	0x70003583
700034c0:	70003543 	.word	0x70003543
700034c4:	70003509 	.word	0x70003509
700034c8:	70003543 	.word	0x70003543
700034cc:	70003575 	.word	0x70003575
700034d0:	70003543 	.word	0x70003543
700034d4:	70003543 	.word	0x70003543
700034d8:	70003543 	.word	0x70003543
700034dc:	70003543 	.word	0x70003543
700034e0:	70003543 	.word	0x70003543
700034e4:	70003543 	.word	0x70003543
700034e8:	70003543 	.word	0x70003543
700034ec:	700033bb 	.word	0x700033bb
700034f0:	70003543 	.word	0x70003543
700034f4:	70003543 	.word	0x70003543
700034f8:	70003543 	.word	0x70003543
700034fc:	70003543 	.word	0x70003543
70003500:	70003543 	.word	0x70003543
70003504:	700033bb 	.word	0x700033bb
70003508:	f446 7620 	orr.w	r6, r6, #640	; 0x280
7000350c:	e755      	b.n	700033ba <__l_vfprintf+0xb6>
		if (c == '*') {
7000350e:	2d2a      	cmp	r5, #42	; 0x2a
70003510:	d03e      	beq.n	70003590 <__l_vfprintf+0x28c>
		if (c == '.') {
70003512:	2d2e      	cmp	r5, #46	; 0x2e
70003514:	d052      	beq.n	700035bc <__l_vfprintf+0x2b8>
                if (c == '$') {
70003516:	2d24      	cmp	r5, #36	; 0x24
70003518:	d190      	bne.n	7000343c <__l_vfprintf+0x138>
                    if (argno) {
7000351a:	f1ba 0f00 	cmp.w	sl, #0
7000351e:	f000 821c 	beq.w	7000395a <__l_vfprintf+0x656>
                        va_copy(ap, ap_orig);
70003522:	9b04      	ldr	r3, [sp, #16]
                        skip_to_arg(fmt_orig, &my_ap, (flags & FL_PREC) ? prec : width);
70003524:	0672      	lsls	r2, r6, #25
                        va_copy(ap, ap_orig);
70003526:	9309      	str	r3, [sp, #36]	; 0x24
                        skip_to_arg(fmt_orig, &my_ap, (flags & FL_PREC) ? prec : width);
70003528:	f140 823d 	bpl.w	700039a6 <__l_vfprintf+0x6a2>
7000352c:	9a01      	ldr	r2, [sp, #4]
7000352e:	a909      	add	r1, sp, #36	; 0x24
70003530:	9803      	ldr	r0, [sp, #12]
70003532:	f7ff fe21 	bl	70003178 <skip_to_arg>
                            prec = va_arg(ap, int);
70003536:	9b09      	ldr	r3, [sp, #36]	; 0x24
70003538:	1d1a      	adds	r2, r3, #4
7000353a:	9209      	str	r2, [sp, #36]	; 0x24
7000353c:	681b      	ldr	r3, [r3, #0]
7000353e:	9301      	str	r3, [sp, #4]
70003540:	e73b      	b.n	700033ba <__l_vfprintf+0xb6>
	if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
70003542:	f045 0320 	orr.w	r3, r5, #32
            || TOLOWER(c) == 'a'
70003546:	f1a3 0265 	sub.w	r2, r3, #101	; 0x65
7000354a:	2b61      	cmp	r3, #97	; 0x61
7000354c:	bf18      	it	ne
7000354e:	2a02      	cmpne	r2, #2
70003550:	bf94      	ite	ls
70003552:	2201      	movls	r2, #1
70003554:	2200      	movhi	r2, #0
70003556:	9202      	str	r2, [sp, #8]
        if (argno) {
70003558:	f1ba 0f00 	cmp.w	sl, #0
7000355c:	f43f af37 	beq.w	700033ce <__l_vfprintf+0xca>
            va_copy(ap, ap_orig);
70003560:	9305      	str	r3, [sp, #20]
            skip_to_arg(fmt_orig, &my_ap, argno);
70003562:	4652      	mov	r2, sl
            va_copy(ap, ap_orig);
70003564:	9b04      	ldr	r3, [sp, #16]
            skip_to_arg(fmt_orig, &my_ap, argno);
70003566:	a909      	add	r1, sp, #36	; 0x24
70003568:	9803      	ldr	r0, [sp, #12]
            va_copy(ap, ap_orig);
7000356a:	9309      	str	r3, [sp, #36]	; 0x24
            skip_to_arg(fmt_orig, &my_ap, argno);
7000356c:	f7ff fe04 	bl	70003178 <skip_to_arg>
70003570:	9b05      	ldr	r3, [sp, #20]
70003572:	e72c      	b.n	700033ce <__l_vfprintf+0xca>
            CHECK_INT_SIZES(c, flags);
70003574:	0633      	lsls	r3, r6, #24
70003576:	bf48      	it	mi
70003578:	f446 7600 	orrmi.w	r6, r6, #512	; 0x200
7000357c:	f046 0680 	orr.w	r6, r6, #128	; 0x80
70003580:	e71b      	b.n	700033ba <__l_vfprintf+0xb6>
70003582:	05f5      	lsls	r5, r6, #23
70003584:	bf48      	it	mi
70003586:	f446 7600 	orrmi.w	r6, r6, #512	; 0x200
7000358a:	f446 7680 	orr.w	r6, r6, #256	; 0x100
7000358e:	e714      	b.n	700033ba <__l_vfprintf+0xb6>
                    if (argno)
70003590:	f1ba 0f00 	cmp.w	sl, #0
70003594:	f47f af11 	bne.w	700033ba <__l_vfprintf+0xb6>
			prec = va_arg(ap, int);
70003598:	9b09      	ldr	r3, [sp, #36]	; 0x24
		    if (flags & FL_PREC) {
7000359a:	0670      	lsls	r0, r6, #25
			prec = va_arg(ap, int);
7000359c:	f103 0204 	add.w	r2, r3, #4
700035a0:	9209      	str	r2, [sp, #36]	; 0x24
		    if (flags & FL_PREC) {
700035a2:	d4cb      	bmi.n	7000353c <__l_vfprintf+0x238>
			width = va_arg(ap, int);
700035a4:	f8d3 9000 	ldr.w	r9, [r3]
			if (width < 0) {
700035a8:	f1b9 0f00 	cmp.w	r9, #0
			flags |= FL_WIDTH;
700035ac:	bfae      	itee	ge
700035ae:	f046 0620 	orrge.w	r6, r6, #32
			    width = -width;
700035b2:	f1c9 0900 	rsblt	r9, r9, #0
			    flags |= FL_LPAD;
700035b6:	f046 0628 	orrlt.w	r6, r6, #40	; 0x28
700035ba:	e6fe      	b.n	700033ba <__l_vfprintf+0xb6>
		    if (flags & FL_PREC)
700035bc:	0671      	lsls	r1, r6, #25
700035be:	f53f aed6 	bmi.w	7000336e <__l_vfprintf+0x6a>
		    flags |= FL_PREC;
700035c2:	f046 0640 	orr.w	r6, r6, #64	; 0x40
		    continue;
700035c6:	e6f8      	b.n	700033ba <__l_vfprintf+0xb6>
            SKIP_FLOAT_ARG(flags, ap);
700035c8:	9b09      	ldr	r3, [sp, #36]	; 0x24
	    pnt = "*float*";
700035ca:	f644 6208 	movw	r2, #19976	; 0x4e08
	    size = sizeof ("*float*") - 1;
700035ce:	f04f 0a07 	mov.w	sl, #7
	    pnt = "*float*";
700035d2:	f2c7 0200 	movt	r2, #28672	; 0x7000
            SKIP_FLOAT_ARG(flags, ap);
700035d6:	3307      	adds	r3, #7
700035d8:	f023 0307 	bic.w	r3, r3, #7
700035dc:	3308      	adds	r3, #8
700035de:	9309      	str	r3, [sp, #36]	; 0x24
                    while ((size_t) width > size) {
700035e0:	4649      	mov	r1, r9
                if (!(flags & FL_LPAD)) {
700035e2:	0730      	lsls	r0, r6, #28
700035e4:	d419      	bmi.n	7000361a <__l_vfprintf+0x316>
                    while ((size_t) width > size) {
700035e6:	45ca      	cmp	sl, r9
700035e8:	bf3e      	ittt	cc
700035ea:	465d      	movcc	r5, fp
700035ec:	4616      	movcc	r6, r2
700035ee:	46cb      	movcc	fp, r9
700035f0:	d303      	bcc.n	700035fa <__l_vfprintf+0x2f6>
700035f2:	e012      	b.n	7000361a <__l_vfprintf+0x316>
700035f4:	459a      	cmp	sl, r3
700035f6:	d208      	bcs.n	7000360a <__l_vfprintf+0x306>
                        width--;
700035f8:	4699      	mov	r9, r3
                        my_putc (' ', stream);
700035fa:	4639      	mov	r1, r7
700035fc:	2020      	movs	r0, #32
700035fe:	47a8      	blx	r5
                        width--;
70003600:	f109 33ff 	add.w	r3, r9, #4294967295	; 0xffffffff
                        my_putc (' ', stream);
70003604:	2800      	cmp	r0, #0
70003606:	daf5      	bge.n	700035f4 <__l_vfprintf+0x2f0>
70003608:	e6ab      	b.n	70003362 <__l_vfprintf+0x5e>
7000360a:	4659      	mov	r1, fp
7000360c:	3401      	adds	r4, #1
7000360e:	4632      	mov	r2, r6
70003610:	440c      	add	r4, r1
70003612:	46ab      	mov	fp, r5
70003614:	eba4 0409 	sub.w	r4, r4, r9
                    while ((size_t) width > size) {
70003618:	4619      	mov	r1, r3
                    while (size--)
7000361a:	4623      	mov	r3, r4
7000361c:	465e      	mov	r6, fp
7000361e:	4614      	mov	r4, r2
70003620:	eb02 050a 	add.w	r5, r2, sl
70003624:	4693      	mov	fp, r2
70003626:	4699      	mov	r9, r3
70003628:	9101      	str	r1, [sp, #4]
7000362a:	e005      	b.n	70003638 <__l_vfprintf+0x334>
                        my_putc (*pnt++, stream);
7000362c:	f814 0b01 	ldrb.w	r0, [r4], #1
70003630:	47b0      	blx	r6
70003632:	2800      	cmp	r0, #0
70003634:	f6ff ae95 	blt.w	70003362 <__l_vfprintf+0x5e>
70003638:	4639      	mov	r1, r7
                    while (size--)
7000363a:	42ac      	cmp	r4, r5
7000363c:	d1f6      	bne.n	7000362c <__l_vfprintf+0x328>
7000363e:	465a      	mov	r2, fp
70003640:	464b      	mov	r3, r9
70003642:	9901      	ldr	r1, [sp, #4]
70003644:	46a1      	mov	r9, r4
70003646:	46b3      	mov	fp, r6
70003648:	1a9b      	subs	r3, r3, r2
                width -= size;
7000364a:	eba1 060a 	sub.w	r6, r1, sl
7000364e:	4499      	add	r9, r3
                while (prec > buf_len) {
70003650:	464c      	mov	r4, r9
70003652:	444e      	add	r6, r9
70003654:	465d      	mov	r5, fp
70003656:	e004      	b.n	70003662 <__l_vfprintf+0x35e>
	    my_putc (' ', stream);
70003658:	47a8      	blx	r5
7000365a:	3401      	adds	r4, #1
7000365c:	2800      	cmp	r0, #0
7000365e:	f6ff ae80 	blt.w	70003362 <__l_vfprintf+0x5e>
70003662:	4639      	mov	r1, r7
70003664:	1b33      	subs	r3, r6, r4
70003666:	2020      	movs	r0, #32
	while (width-- > 0) {
70003668:	2b00      	cmp	r3, #0
7000366a:	dcf5      	bgt.n	70003658 <__l_vfprintf+0x354>
7000366c:	46ab      	mov	fp, r5
7000366e:	4645      	mov	r5, r8
70003670:	e666      	b.n	70003340 <__l_vfprintf+0x3c>
                    } else if (TOLOWER(c) == 'x') {
70003672:	2b78      	cmp	r3, #120	; 0x78
                        base = ('x' - c) | 16;
70003674:	bf04      	itt	eq
70003676:	f1c5 0378 	rsbeq	r3, r5, #120	; 0x78
7000367a:	f043 0310 	orreq.w	r3, r3, #16
                    } else if (TOLOWER(c) == 'x') {
7000367e:	d055      	beq.n	7000372c <__l_vfprintf+0x428>
                    } else if (TOLOWER(c) == 'b') {
70003680:	2b62      	cmp	r3, #98	; 0x62
70003682:	f000 81b2 	beq.w	700039ea <__l_vfprintf+0x6e6>
                        my_putc('%', stream);
70003686:	4639      	mov	r1, r7
70003688:	2025      	movs	r0, #37	; 0x25
7000368a:	47d8      	blx	fp
7000368c:	2800      	cmp	r0, #0
7000368e:	f6ff ae68 	blt.w	70003362 <__l_vfprintf+0x5e>
                        my_putc(c, stream);
70003692:	4628      	mov	r0, r5
70003694:	4639      	mov	r1, r7
70003696:	47d8      	blx	fp
70003698:	2800      	cmp	r0, #0
7000369a:	f6ff ae62 	blt.w	70003362 <__l_vfprintf+0x5e>
7000369e:	4645      	mov	r5, r8
700036a0:	3402      	adds	r4, #2
700036a2:	e64d      	b.n	70003340 <__l_vfprintf+0x3c>
            SKIP_FLOAT_ARG(flags, ap);
700036a4:	9b09      	ldr	r3, [sp, #36]	; 0x24
                    arg_to_signed(ap, flags, x_s);
700036a6:	0632      	lsls	r2, r6, #24
700036a8:	f100 8172 	bmi.w	70003990 <__l_vfprintf+0x68c>
700036ac:	1d1a      	adds	r2, r3, #4
700036ae:	05f1      	lsls	r1, r6, #23
700036b0:	9209      	str	r2, [sp, #36]	; 0x24
700036b2:	681a      	ldr	r2, [r3, #0]
700036b4:	bf5c      	itt	pl
700036b6:	4610      	movpl	r0, r2
700036b8:	17c2      	asrpl	r2, r0, #31
700036ba:	d507      	bpl.n	700036cc <__l_vfprintf+0x3c8>
700036bc:	05b3      	lsls	r3, r6, #22
700036be:	bf4b      	itete	mi
700036c0:	b250      	sxtbmi	r0, r2
700036c2:	b210      	sxthpl	r0, r2
700036c4:	f342 12c0 	sbfxmi	r2, r2, #7, #1
700036c8:	f342 32c0 	sbfxpl	r2, r2, #15, #1
                    if (x_s < 0) {
700036cc:	f026 0110 	bic.w	r1, r6, #16
700036d0:	2a00      	cmp	r2, #0
700036d2:	fa1f fa81 	uxth.w	sl, r1
700036d6:	f2c0 8171 	blt.w	700039bc <__l_vfprintf+0x6b8>
                    if (x_s == 0 && (flags & FL_PREC) && prec == 0)
700036da:	ea50 0102 	orrs.w	r1, r0, r2
700036de:	f040 8190 	bne.w	70003a02 <__l_vfprintf+0x6fe>
700036e2:	9a01      	ldr	r2, [sp, #4]
700036e4:	f3c6 1380 	ubfx	r3, r6, #6, #1
700036e8:	2a00      	cmp	r2, #0
700036ea:	bf14      	ite	ne
700036ec:	2300      	movne	r3, #0
700036ee:	f003 0301 	andeq.w	r3, r3, #1
700036f2:	f006 0240 	and.w	r2, r6, #64	; 0x40
700036f6:	9202      	str	r2, [sp, #8]
700036f8:	2b00      	cmp	r3, #0
700036fa:	f040 817b 	bne.w	700039f4 <__l_vfprintf+0x6f0>
700036fe:	4618      	mov	r0, r3
70003700:	4619      	mov	r1, r3
                        buf_len = __ultoa_invert (x_s, buf, 10) - buf;
70003702:	230a      	movs	r3, #10
70003704:	ae0a      	add	r6, sp, #40	; 0x28
70003706:	4632      	mov	r2, r6
70003708:	f7ff fcbe 	bl	70003088 <__ultoa_invert>
7000370c:	1b83      	subs	r3, r0, r6
7000370e:	e03a      	b.n	70003786 <__l_vfprintf+0x482>
                buf[0] = va_arg (ap, int);
70003710:	9b09      	ldr	r3, [sp, #36]	; 0x24
                size = 1;
70003712:	f04f 0a01 	mov.w	sl, #1
                pnt = buf;
70003716:	aa0a      	add	r2, sp, #40	; 0x28
                buf[0] = va_arg (ap, int);
70003718:	1d19      	adds	r1, r3, #4
7000371a:	9109      	str	r1, [sp, #36]	; 0x24
7000371c:	681b      	ldr	r3, [r3, #0]
7000371e:	f88d 3028 	strb.w	r3, [sp, #40]	; 0x28
                goto str_lpad;
70003722:	e75d      	b.n	700035e0 <__l_vfprintf+0x2dc>
                        base = 16;
70003724:	2310      	movs	r3, #16
                        flags |= FL_ALT;
70003726:	f046 0610 	orr.w	r6, r6, #16
                        c = 'x';
7000372a:	2578      	movs	r5, #120	; 0x78
            SKIP_FLOAT_ARG(flags, ap);
7000372c:	9a09      	ldr	r2, [sp, #36]	; 0x24
                    arg_to_unsigned(ap, flags, x);
7000372e:	f016 0c80 	ands.w	ip, r6, #128	; 0x80
70003732:	f000 80a2 	beq.w	7000387a <__l_vfprintf+0x576>
70003736:	f416 7100 	ands.w	r1, r6, #512	; 0x200
7000373a:	bf1d      	ittte	ne
7000373c:	3207      	addne	r2, #7
7000373e:	f022 0207 	bicne.w	r2, r2, #7
70003742:	f102 0108 	addne.w	r1, r2, #8
70003746:	1d10      	addeq	r0, r2, #4
70003748:	bf15      	itete	ne
7000374a:	9109      	strne	r1, [sp, #36]	; 0x24
7000374c:	9009      	streq	r0, [sp, #36]	; 0x24
7000374e:	e9d2 0100 	ldrdne	r0, r1, [r2]
70003752:	6810      	ldreq	r0, [r2, #0]
                    if (x == 0)
70003754:	ea50 0201 	orrs.w	r2, r0, r1
70003758:	f040 80c5 	bne.w	700038e6 <__l_vfprintf+0x5e2>
                    if (x == 0 && (flags & FL_PREC) && prec == 0)
7000375c:	9a01      	ldr	r2, [sp, #4]
                        flags &= ~FL_ALT;
7000375e:	f026 0c16 	bic.w	ip, r6, #22
                    if (x == 0 && (flags & FL_PREC) && prec == 0)
70003762:	fab2 f282 	clz	r2, r2
                        flags &= ~FL_ALT;
70003766:	fa1f fa8c 	uxth.w	sl, ip
                    if (x == 0 && (flags & FL_PREC) && prec == 0)
7000376a:	0952      	lsrs	r2, r2, #5
7000376c:	f006 0c40 	and.w	ip, r6, #64	; 0x40
70003770:	ea12 1296 	ands.w	r2, r2, r6, lsr #6
70003774:	f8cd c008 	str.w	ip, [sp, #8]
70003778:	f040 8129 	bne.w	700039ce <__l_vfprintf+0x6ca>
                        buf_len = __ultoa_invert (x, buf, base) - buf;
7000377c:	ae0a      	add	r6, sp, #40	; 0x28
7000377e:	4632      	mov	r2, r6
70003780:	f7ff fc82 	bl	70003088 <__ultoa_invert>
70003784:	1b83      	subs	r3, r0, r6
                if (flags & FL_PREC) {
70003786:	9a02      	ldr	r2, [sp, #8]
70003788:	f00a 0c10 	and.w	ip, sl, #16
7000378c:	b37a      	cbz	r2, 700037ee <__l_vfprintf+0x4ea>
                    if (len < prec) {
7000378e:	9901      	ldr	r1, [sp, #4]
                    flags &= ~FL_ZFILL;
70003790:	f02a 0201 	bic.w	r2, sl, #1
                    if (len < prec) {
70003794:	4299      	cmp	r1, r3
                    flags &= ~FL_ZFILL;
70003796:	b292      	uxth	r2, r2
                    if (len < prec) {
70003798:	bfdc      	itt	le
7000379a:	f00a 0c10 	andle.w	ip, sl, #16
                    flags &= ~FL_ZFILL;
7000379e:	4692      	movle	sl, r2
                    if (len < prec) {
700037a0:	dd25      	ble.n	700037ee <__l_vfprintf+0x4ea>
                        if (c == '\0')
700037a2:	2d00      	cmp	r5, #0
700037a4:	f040 80ea 	bne.w	7000397c <__l_vfprintf+0x678>
                            flags &= ~FL_ALT;
700037a8:	f02a 0211 	bic.w	r2, sl, #17
700037ac:	fa1f fa82 	uxth.w	sl, r2
700037b0:	9a01      	ldr	r2, [sp, #4]
700037b2:	e071      	b.n	70003898 <__l_vfprintf+0x594>
                        base = 10;
700037b4:	230a      	movs	r3, #10
                        flags &= ~FL_ALT;
700037b6:	f026 0610 	bic.w	r6, r6, #16
700037ba:	b2b6      	uxth	r6, r6
                        base = 10;
700037bc:	e7b6      	b.n	7000372c <__l_vfprintf+0x428>
                    pnt = va_arg (ap, char *);
700037be:	9a09      	ldr	r2, [sp, #36]	; 0x24
                    pnt = "(null)";
700037c0:	f644 6300 	movw	r3, #19968	; 0x4e00
700037c4:	f2c7 0300 	movt	r3, #28672	; 0x7000
                    pnt = va_arg (ap, char *);
700037c8:	1d11      	adds	r1, r2, #4
700037ca:	9109      	str	r1, [sp, #36]	; 0x24
700037cc:	6812      	ldr	r2, [r2, #0]
                size = strnlen (pnt, size);
700037ce:	9901      	ldr	r1, [sp, #4]
                    pnt = "(null)";
700037d0:	2a00      	cmp	r2, #0
700037d2:	bf08      	it	eq
700037d4:	461a      	moveq	r2, r3
                size = strnlen (pnt, size);
700037d6:	4610      	mov	r0, r2
                size = (flags & FL_PREC) ? (size_t) prec : SIZE_MAX;
700037d8:	f016 0f40 	tst.w	r6, #64	; 0x40
                size = strnlen (pnt, size);
700037dc:	9201      	str	r2, [sp, #4]
700037de:	bf08      	it	eq
700037e0:	f04f 31ff 	moveq.w	r1, #4294967295	; 0xffffffff
700037e4:	f7ff fc0a 	bl	70002ffc <strnlen>
700037e8:	9a01      	ldr	r2, [sp, #4]
700037ea:	4682      	mov	sl, r0
700037ec:	e6f8      	b.n	700035e0 <__l_vfprintf+0x2dc>
                if (flags & FL_ALT) {
700037ee:	f1bc 0f00 	cmp.w	ip, #0
700037f2:	d050      	beq.n	70003896 <__l_vfprintf+0x592>
                    len += 1;
700037f4:	1c5a      	adds	r2, r3, #1
                    if (c != '\0')
700037f6:	b10d      	cbz	r5, 700037fc <__l_vfprintf+0x4f8>
700037f8:	461a      	mov	r2, r3
                        len += 1;
700037fa:	3202      	adds	r2, #2
                if (!(flags & FL_LPAD)) {
700037fc:	f01a 0f08 	tst.w	sl, #8
                width -= len;
70003800:	bf18      	it	ne
70003802:	eba9 0602 	subne.w	r6, r9, r2
                if (!(flags & FL_LPAD)) {
70003806:	d053      	beq.n	700038b0 <__l_vfprintf+0x5ac>
                    my_putc ('0', stream);
70003808:	4639      	mov	r1, r7
7000380a:	2030      	movs	r0, #48	; 0x30
7000380c:	9302      	str	r3, [sp, #8]
7000380e:	47d8      	blx	fp
70003810:	2800      	cmp	r0, #0
70003812:	f6ff ada6 	blt.w	70003362 <__l_vfprintf+0x5e>
                    if (c != '\0')
70003816:	9b02      	ldr	r3, [sp, #8]
70003818:	2d00      	cmp	r5, #0
7000381a:	f040 8094 	bne.w	70003946 <__l_vfprintf+0x642>
                    my_putc ('0', stream);
7000381e:	3401      	adds	r4, #1
                while (prec > buf_len) {
70003820:	9a01      	ldr	r2, [sp, #4]
70003822:	4293      	cmp	r3, r2
70003824:	bfa8      	it	ge
70003826:	4625      	movge	r5, r4
70003828:	da12      	bge.n	70003850 <__l_vfprintf+0x54c>
7000382a:	9d01      	ldr	r5, [sp, #4]
7000382c:	469a      	mov	sl, r3
7000382e:	4425      	add	r5, r4
70003830:	1aed      	subs	r5, r5, r3
70003832:	46a9      	mov	r9, r5
70003834:	465d      	mov	r5, fp
70003836:	e001      	b.n	7000383c <__l_vfprintf+0x538>
70003838:	45a1      	cmp	r9, r4
7000383a:	d006      	beq.n	7000384a <__l_vfprintf+0x546>
                    my_putc ('0', stream);
7000383c:	4639      	mov	r1, r7
7000383e:	2030      	movs	r0, #48	; 0x30
70003840:	47a8      	blx	r5
70003842:	3401      	adds	r4, #1
70003844:	2800      	cmp	r0, #0
70003846:	daf7      	bge.n	70003838 <__l_vfprintf+0x534>
70003848:	e58b      	b.n	70003362 <__l_vfprintf+0x5e>
7000384a:	46ab      	mov	fp, r5
7000384c:	4653      	mov	r3, sl
7000384e:	464d      	mov	r5, r9
70003850:	46aa      	mov	sl, r5
70003852:	ac0a      	add	r4, sp, #40	; 0x28
70003854:	465d      	mov	r5, fp
70003856:	eb04 0903 	add.w	r9, r4, r3
7000385a:	469b      	mov	fp, r3
7000385c:	e005      	b.n	7000386a <__l_vfprintf+0x566>
                    my_putc (buf[--buf_len], stream);
7000385e:	f819 0d01 	ldrb.w	r0, [r9, #-1]!
70003862:	47a8      	blx	r5
70003864:	2800      	cmp	r0, #0
70003866:	f6ff ad7c 	blt.w	70003362 <__l_vfprintf+0x5e>
7000386a:	4639      	mov	r1, r7
                while (buf_len)
7000386c:	45a1      	cmp	r9, r4
7000386e:	d1f6      	bne.n	7000385e <__l_vfprintf+0x55a>
70003870:	465b      	mov	r3, fp
70003872:	46ab      	mov	fp, r5
70003874:	eb0a 0903 	add.w	r9, sl, r3
70003878:	e6ea      	b.n	70003650 <__l_vfprintf+0x34c>
                    arg_to_unsigned(ap, flags, x);
7000387a:	1d11      	adds	r1, r2, #4
7000387c:	9109      	str	r1, [sp, #36]	; 0x24
7000387e:	f416 7180 	ands.w	r1, r6, #256	; 0x100
70003882:	6810      	ldr	r0, [r2, #0]
70003884:	f43f af66 	beq.w	70003754 <__l_vfprintf+0x450>
70003888:	f416 7100 	ands.w	r1, r6, #512	; 0x200
7000388c:	bf1a      	itte	ne
7000388e:	4661      	movne	r1, ip
70003890:	b2c0      	uxtbne	r0, r0
70003892:	b280      	uxtheq	r0, r0
70003894:	e75e      	b.n	70003754 <__l_vfprintf+0x450>
70003896:	461a      	mov	r2, r3
                if (!(flags & FL_LPAD)) {
70003898:	f240 4106 	movw	r1, #1030	; 0x406
                } else if (flags & (FL_NEGATIVE | FL_PLUS | FL_SPACE)) {
7000389c:	ea1a 0101 	ands.w	r1, sl, r1
                    len += 1;
700038a0:	bf18      	it	ne
700038a2:	3201      	addne	r2, #1
                if (!(flags & FL_LPAD)) {
700038a4:	f01a 0c08 	ands.w	ip, sl, #8
                width -= len;
700038a8:	bf18      	it	ne
700038aa:	eba9 0602 	subne.w	r6, r9, r2
                if (!(flags & FL_LPAD)) {
700038ae:	d135      	bne.n	7000391c <__l_vfprintf+0x618>
                    if (flags & FL_ZFILL) {
700038b0:	f01a 0f01 	tst.w	sl, #1
700038b4:	d158      	bne.n	70003968 <__l_vfprintf+0x664>
                    while (len < width) {
700038b6:	4591      	cmp	r9, r2
700038b8:	f340 80a8 	ble.w	70003a0c <__l_vfprintf+0x708>
700038bc:	f8cd 8008 	str.w	r8, [sp, #8]
700038c0:	eb09 0604 	add.w	r6, r9, r4
700038c4:	e9cd 3205 	strd	r3, r2, [sp, #20]
700038c8:	1ab6      	subs	r6, r6, r2
700038ca:	9407      	str	r4, [sp, #28]
700038cc:	46b0      	mov	r8, r6
700038ce:	465e      	mov	r6, fp
700038d0:	46e3      	mov	fp, ip
700038d2:	e001      	b.n	700038d8 <__l_vfprintf+0x5d4>
700038d4:	45a0      	cmp	r8, r4
700038d6:	d00e      	beq.n	700038f6 <__l_vfprintf+0x5f2>
                        my_putc (' ', stream);
700038d8:	4639      	mov	r1, r7
700038da:	2020      	movs	r0, #32
700038dc:	47b0      	blx	r6
700038de:	3401      	adds	r4, #1
700038e0:	2800      	cmp	r0, #0
700038e2:	daf7      	bge.n	700038d4 <__l_vfprintf+0x5d0>
700038e4:	e53d      	b.n	70003362 <__l_vfprintf+0x5e>
                    flags &= ~(FL_PLUS | FL_SPACE);
700038e6:	f026 0206 	bic.w	r2, r6, #6
700038ea:	f006 0640 	and.w	r6, r6, #64	; 0x40
700038ee:	fa1f fa82 	uxth.w	sl, r2
700038f2:	9602      	str	r6, [sp, #8]
700038f4:	e742      	b.n	7000377c <__l_vfprintf+0x478>
                        len++;
700038f6:	e9dd 3205 	ldrd	r3, r2, [sp, #20]
700038fa:	46dc      	mov	ip, fp
700038fc:	9907      	ldr	r1, [sp, #28]
700038fe:	46b3      	mov	fp, r6
70003900:	f8dd 8008 	ldr.w	r8, [sp, #8]
70003904:	1a56      	subs	r6, r2, r1
70003906:	4426      	add	r6, r4
                width -= len;
70003908:	eba9 0606 	sub.w	r6, r9, r6
                if (flags & FL_ALT) {
7000390c:	f1bc 0f00 	cmp.w	ip, #0
70003910:	f47f af7a 	bne.w	70003808 <__l_vfprintf+0x504>
70003914:	f240 4106 	movw	r1, #1030	; 0x406
70003918:	ea0a 0101 	and.w	r1, sl, r1
                } else if (flags & (FL_NEGATIVE | FL_PLUS | FL_SPACE)) {
7000391c:	2900      	cmp	r1, #0
7000391e:	f43f af7f 	beq.w	70003820 <__l_vfprintf+0x51c>
                    my_putc (z, stream);
70003922:	4639      	mov	r1, r7
                    if (flags & FL_PLUS) z = '+';
70003924:	f01a 0f02 	tst.w	sl, #2
70003928:	bf14      	ite	ne
7000392a:	202b      	movne	r0, #43	; 0x2b
7000392c:	2020      	moveq	r0, #32
                    if (flags & FL_NEGATIVE) z = '-';
7000392e:	9302      	str	r3, [sp, #8]
70003930:	f41a 6f80 	tst.w	sl, #1024	; 0x400
                    my_putc (z, stream);
70003934:	bf18      	it	ne
70003936:	202d      	movne	r0, #45	; 0x2d
70003938:	3401      	adds	r4, #1
7000393a:	47d8      	blx	fp
7000393c:	9b02      	ldr	r3, [sp, #8]
7000393e:	2800      	cmp	r0, #0
70003940:	f6bf af6e 	bge.w	70003820 <__l_vfprintf+0x51c>
70003944:	e50d      	b.n	70003362 <__l_vfprintf+0x5e>
                        my_putc (c, stream);
70003946:	4628      	mov	r0, r5
70003948:	4639      	mov	r1, r7
7000394a:	9302      	str	r3, [sp, #8]
7000394c:	47d8      	blx	fp
7000394e:	9b02      	ldr	r3, [sp, #8]
70003950:	3402      	adds	r4, #2
70003952:	2800      	cmp	r0, #0
70003954:	f6bf af64 	bge.w	70003820 <__l_vfprintf+0x51c>
70003958:	e503      	b.n	70003362 <__l_vfprintf+0x5e>
7000395a:	464b      	mov	r3, r9
                        prec = 0;
7000395c:	4656      	mov	r6, sl
7000395e:	f8cd a004 	str.w	sl, [sp, #4]
                        width = 0;
70003962:	46d1      	mov	r9, sl
70003964:	469a      	mov	sl, r3
70003966:	e528      	b.n	700033ba <__l_vfprintf+0xb6>
                        if (len < width) {
70003968:	4591      	cmp	r9, r2
                            prec += width - len;
7000396a:	eba9 0602 	sub.w	r6, r9, r2
7000396e:	bfd8      	it	le
70003970:	9301      	strle	r3, [sp, #4]
                        if (len < width) {
70003972:	ddcb      	ble.n	7000390c <__l_vfprintf+0x608>
                            prec += width - len;
70003974:	199a      	adds	r2, r3, r6
70003976:	2600      	movs	r6, #0
70003978:	9201      	str	r2, [sp, #4]
                            len = width;
7000397a:	e7c7      	b.n	7000390c <__l_vfprintf+0x608>
                if (flags & FL_ALT) {
7000397c:	f01a 0c10 	ands.w	ip, sl, #16
70003980:	4692      	mov	sl, r2
                        len = prec;
70003982:	9a01      	ldr	r2, [sp, #4]
                if (flags & FL_ALT) {
70003984:	f47f af39 	bne.w	700037fa <__l_vfprintf+0x4f6>
70003988:	e786      	b.n	70003898 <__l_vfprintf+0x594>
	if ((TOLOWER(c) >= 'e' && TOLOWER(c) <= 'g')
7000398a:	2308      	movs	r3, #8
7000398c:	2500      	movs	r5, #0
7000398e:	e6cd      	b.n	7000372c <__l_vfprintf+0x428>
                    arg_to_signed(ap, flags, x_s);
70003990:	05b0      	lsls	r0, r6, #22
70003992:	d525      	bpl.n	700039e0 <__l_vfprintf+0x6dc>
70003994:	3307      	adds	r3, #7
70003996:	f023 0307 	bic.w	r3, r3, #7
7000399a:	f103 0208 	add.w	r2, r3, #8
7000399e:	9209      	str	r2, [sp, #36]	; 0x24
700039a0:	e9d3 0200 	ldrd	r0, r2, [r3]
700039a4:	e692      	b.n	700036cc <__l_vfprintf+0x3c8>
                        skip_to_arg(fmt_orig, &my_ap, (flags & FL_PREC) ? prec : width);
700039a6:	464a      	mov	r2, r9
700039a8:	a909      	add	r1, sp, #36	; 0x24
700039aa:	9803      	ldr	r0, [sp, #12]
700039ac:	f7ff fbe4 	bl	70003178 <skip_to_arg>
                            width = va_arg(ap, int);
700039b0:	9b09      	ldr	r3, [sp, #36]	; 0x24
700039b2:	1d1a      	adds	r2, r3, #4
700039b4:	9209      	str	r2, [sp, #36]	; 0x24
700039b6:	f8d3 9000 	ldr.w	r9, [r3]
700039ba:	e4fe      	b.n	700033ba <__l_vfprintf+0xb6>
                    flags &= ~FL_ALT;
700039bc:	f006 0340 	and.w	r3, r6, #64	; 0x40
                        x_s = -x_s;
700039c0:	4240      	negs	r0, r0
                    flags &= ~FL_ALT;
700039c2:	f44a 6a80 	orr.w	sl, sl, #1024	; 0x400
                    if (x_s == 0 && (flags & FL_PREC) && prec == 0)
700039c6:	9302      	str	r3, [sp, #8]
                        x_s = -x_s;
700039c8:	eb62 0142 	sbc.w	r1, r2, r2, lsl #1
700039cc:	e699      	b.n	70003702 <__l_vfprintf+0x3fe>
                        buf_len = 0;
700039ce:	2200      	movs	r2, #0
                    flags &= ~FL_ZFILL;
700039d0:	f026 0617 	bic.w	r6, r6, #23
                        buf_len = 0;
700039d4:	4613      	mov	r3, r2
                    flags &= ~FL_ZFILL;
700039d6:	fa1f fa86 	uxth.w	sl, r6
                if (flags & FL_ALT) {
700039da:	e75d      	b.n	70003898 <__l_vfprintf+0x594>
    int stream_len = 0;
700039dc:	4604      	mov	r4, r0
    return stream_len;
700039de:	e4c6      	b.n	7000336e <__l_vfprintf+0x6a>
                    arg_to_signed(ap, flags, x_s);
700039e0:	1d1a      	adds	r2, r3, #4
700039e2:	9209      	str	r2, [sp, #36]	; 0x24
700039e4:	6818      	ldr	r0, [r3, #0]
700039e6:	17c2      	asrs	r2, r0, #31
700039e8:	e670      	b.n	700036cc <__l_vfprintf+0x3c8>
                        base = 2;
700039ea:	2302      	movs	r3, #2
700039ec:	e69e      	b.n	7000372c <__l_vfprintf+0x428>
	return EOF;
700039ee:	f04f 34ff 	mov.w	r4, #4294967295	; 0xffffffff
700039f2:	e4bc      	b.n	7000336e <__l_vfprintf+0x6a>
                        buf_len = 0;
700039f4:	2200      	movs	r2, #0
                    flags &= ~FL_ZFILL;
700039f6:	f026 0611 	bic.w	r6, r6, #17
                        buf_len = 0;
700039fa:	4613      	mov	r3, r2
                    flags &= ~FL_ZFILL;
700039fc:	fa1f fa86 	uxth.w	sl, r6
                if (flags & FL_ALT) {
70003a00:	e74a      	b.n	70003898 <__l_vfprintf+0x594>
                        buf_len = __ultoa_invert (x_s, buf, 10) - buf;
70003a02:	4611      	mov	r1, r2
70003a04:	f006 0340 	and.w	r3, r6, #64	; 0x40
70003a08:	9302      	str	r3, [sp, #8]
70003a0a:	e67a      	b.n	70003702 <__l_vfprintf+0x3fe>
                            prec += width - len;
70003a0c:	eba9 0602 	sub.w	r6, r9, r2
70003a10:	e77c      	b.n	7000390c <__l_vfprintf+0x608>
		if (c >= '0' && c <= '9') {
70003a12:	f1a5 0330 	sub.w	r3, r5, #48	; 0x30
70003a16:	2b09      	cmp	r3, #9
70003a18:	f63f ad79 	bhi.w	7000350e <__l_vfprintf+0x20a>
		    if (flags & FL_PREC) {
70003a1c:	0675      	lsls	r5, r6, #25
70003a1e:	f57f acc6 	bpl.w	700033ae <__l_vfprintf+0xaa>
			prec = 10*prec + c;
70003a22:	9a01      	ldr	r2, [sp, #4]
70003a24:	eb02 0282 	add.w	r2, r2, r2, lsl #2
70003a28:	eb03 0342 	add.w	r3, r3, r2, lsl #1
70003a2c:	9301      	str	r3, [sp, #4]
			continue;
70003a2e:	e4c4      	b.n	700033ba <__l_vfprintf+0xb6>

70003a30 <__file_str_put>:
         * overflow, instead it returns the total number of characters
         * processed but truncates the result to fit within the target
         * buffer. As a result, this function simply stops writing
         * when it reaches the end of the buffer
         */
	if (sstream->pos != sstream->end)
70003a30:	e9d1 3204 	ldrd	r3, r2, [r1, #16]
70003a34:	4293      	cmp	r3, r2
            *sstream->pos++ = c;
70003a36:	bf1e      	ittt	ne
70003a38:	1c5a      	addne	r2, r3, #1
70003a3a:	610a      	strne	r2, [r1, #16]
70003a3c:	7018      	strbne	r0, [r3, #0]
	return (unsigned char) c;
}
70003a3e:	4770      	bx	lr

70003a40 <__z_arm_int_exit_from_thumb>:
70003a40:	4778      	bx	pc
70003a42:	e7fd      	b.n	70003a40 <__z_arm_int_exit_from_thumb>
70003a44:	eafff562 	b	70000fd4 <z_arm_int_exit>

Disassembly of section .boot_section:

00000000 <__boot_spring>:
 * @brief Initialisation of fault handling
 */
void z_arm_fault_init(void)
{
	/* Nothing to do for now */
}
   0:	e59fd004 	ldr	sp, [pc, #4]	; c <___thread_base_t_user_options_OFFSET>
	arch_system_halt(reason);
   4:	fa000024 	blx	9c <MpuP_init>
	handler = pHandler;
   8:	ea000054 	b	160 <____start_veneer>
};

void rsc_table_get(struct fw_resource_table **table_ptr, int *length)
{
	*table_ptr = &resource_table;
	*length = sizeof(resource_table);
   c:	7000ac60 	.word	0x7000ac60

00000010 <MpuP_setRegion>:
	cmp	r0, #0
	bne	_irq_disabled
	cpsie	i
_irq_disabled:

	bx	lr
  10:	b5f8      	push	{r3, r4, r5, r6, r7, lr}
  12:	f893 c004 	ldrb.w	ip, [r3, #4]
   for (int i = 0; i < size; i++)
  16:	f893 e000 	ldrb.w	lr, [r3]
}
  1a:	79de      	ldrb	r6, [r3, #7]
}
  1c:	4604      	mov	r4, r0
  1e:	ea4f 3c0c 	mov.w	ip, ip, lsl #12
   z_vim_irq_enable(irq);
  22:	7998      	ldrb	r0, [r3, #6]
  24:	0200      	lsls	r0, r0, #8
		(void) vfprintf(&console, fmt, ap);
  26:	f400 60e0 	and.w	r0, r0, #1792	; 0x700
}
  2a:	f40c 5c80 	and.w	ip, ip, #4096	; 0x1000
		if ((dev->name == name) || (strcmp(name, dev->name) == 0)) {
  2e:	ea4c 0c00 	orr.w	ip, ip, r0
  32:	7898      	ldrb	r0, [r3, #2]
	return dev->state->initialized && (dev->state->init_res == 0U);
  34:	f000 0001 	and.w	r0, r0, #1
  38:	ea4c 0c00 	orr.w	ip, ip, r0
  3c:	7958      	ldrb	r0, [r3, #5]
  3e:	00c0      	lsls	r0, r0, #3
		return NULL;
  40:	f000 0038 	and.w	r0, r0, #56	; 0x38
  44:	ea4c 0c00 	orr.w	ip, ip, r0
}
  48:	78d8      	ldrb	r0, [r3, #3]
		return NULL;
  4a:	0080      	lsls	r0, r0, #2
}
  4c:	f000 0004 	and.w	r0, r0, #4
	void *ret = sys_heap_aligned_realloc(&z_malloc_heap, ptr,
					     __alignof__(z_max_align_t),
					     requested_size);

	if (ret == NULL && requested_size != 0) {
		errno = ENOMEM;
  50:	f002 021f 	and.w	r2, r2, #31
  54:	ea4c 0c00 	orr.w	ip, ip, r0
	return z_impl_k_mutex_unlock(mutex);
  58:	f04f 30ff 	mov.w	r0, #4294967295	; 0xffffffff
  5c:	1c55      	adds	r5, r2, #1
  5e:	f00e 0e01 	and.w	lr, lr, #1
	}

	malloc_unlock();

	return ret;
}
  62:	40a8      	lsls	r0, r5
  64:	ea01 0500 	and.w	r5, r1, r0
	slab->info.num_used--;

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_mem_slab, free, slab);

	k_spin_unlock(&slab->lock, key);
}
  68:	7858      	ldrb	r0, [r3, #1]
  6a:	0040      	lsls	r0, r0, #1
			z_reschedule(&slab->lock, key);
  6c:	ea4e 2e06 	orr.w	lr, lr, r6, lsl #8
	return list->head == list;
  70:	f000 0002 	and.w	r0, r0, #2
		if (unlikely(thread != NULL)) {
  74:	ea4c 0600 	orr.w	r6, ip, r0
  78:	ea4e 0742 	orr.w	r7, lr, r2, lsl #1

	SYS_PORT_TRACING_OBJ_FUNC_EXIT(k_heap, realloc, heap, ptr, bytes, timeout, ret);

	k_spin_unlock(&heap->lock, key);
	return ret;
}
  7c:	f000 e85c 	blx	138 <MpuP_isEnableAsm>
  80:	4633      	mov	r3, r6
  82:	463a      	mov	r2, r7
}
  84:	4629      	mov	r1, r5
      {
         printk("Event %s Count: %u\r\n", p->events[j].name, p->events[j].value);
      }
      printk("\r\n");
   }
}
  86:	4606      	mov	r6, r0
  88:	4620      	mov	r0, r4
		wfe();
	}

	cpu_map[cpu_num] = cpu_mpid;

	printk("Secondary CPU core %d (MPID:%#x) is up\n", cpu_num, cpu_mpid);
  8a:	f000 e860 	blx	14c <MpuP_setRegionAsm>
  8e:	b906      	cbnz	r6, 92 <CONFIG_CONSOLE_INPUT_MAX_LINE_LEN+0x12>
}
  90:	bdf8      	pop	{r3, r4, r5, r6, r7, pc}
  92:	e8bd 40f8 	ldmia.w	sp!, {r3, r4, r5, r6, r7, lr}
		_kernel.ready_q.cache = thread;
  96:	f000 b867 	b.w	168 <__MpuP_enableAsm_from_thumb>
	node->prev = prev;
  9a:	bf00      	nop

0000009c <MpuP_init>:
  9c:	b570      	push	{r4, r5, r6, lr}
	prev->next = node;
  9e:	f000 e830 	blx	100 <MpuP_disableBRAsm>
}
  a2:	f24c 26cc 	movw	r6, #49868	; 0xc2cc
    MpuP_disableBRAsm();

    /*
     * Initialize MPU regions
     */
    for (i = 0; i < gMpuConfig.numRegions; i++)
  a6:	f2c7 0600 	movt	r6, #28672	; 0x7000
  aa:	6833      	ldr	r3, [r6, #0]
  ac:	b163      	cbz	r3, c8 <MpuP_init+0x2c>
  ae:	4c0d      	ldr	r4, [pc, #52]	; (e4 <__data_size+0xc>)
  b0:	2500      	movs	r5, #0
    {
        MpuP_setRegion(i,
  b2:	4623      	mov	r3, r4
  b4:	4628      	mov	r0, r5
  b6:	e954 1202 	ldrd	r1, r2, [r4, #-8]
    for (i = 0; i < gMpuConfig.numRegions; i++)
  ba:	3501      	adds	r5, #1
        MpuP_setRegion(i,
  bc:	f7ff ffa8 	bl	10 <MpuP_setRegion>
    for (i = 0; i < gMpuConfig.numRegions; i++)
  c0:	6833      	ldr	r3, [r6, #0]
  c2:	3410      	adds	r4, #16
  c4:	42ab      	cmp	r3, r5
  c6:	d8f4      	bhi.n	b2 <MpuP_init+0x16>
                gMpuRegionConfig[i].size,
                &gMpuRegionConfig[i].attrs
        );
    }

    if (gMpuConfig.enableBackgroundRegion) {
  c8:	6873      	ldr	r3, [r6, #4]
  ca:	b913      	cbnz	r3, d2 <MpuP_init+0x36>
        MpuP_enableBRAsm();
    }

    if (gMpuConfig.enableMpu) {
  cc:	68b3      	ldr	r3, [r6, #8]
  ce:	b92b      	cbnz	r3, dc <__data_size+0x4>
	    MpuP_enableAsm();
    }
}
  d0:	bd70      	pop	{r4, r5, r6, pc}
        MpuP_enableBRAsm();
  d2:	f000 e82a 	blx	128 <MpuP_enableBRAsm>
    if (gMpuConfig.enableMpu) {
  d6:	68b3      	ldr	r3, [r6, #8]
  d8:	2b00      	cmp	r3, #0
  da:	d0f9      	beq.n	d0 <MpuP_init+0x34>
}
  dc:	e8bd 4070 	ldmia.w	sp!, {r4, r5, r6, lr}
	    MpuP_enableAsm();
  e0:	f000 b842 	b.w	168 <__MpuP_enableAsm_from_thumb>
  e4:	7000c284 	.word	0x7000c284

000000e8 <MpuP_disableAsm>:
_ASM_FILE_PROLOGUE

/* FUNCTION DEF: void MpuP_disableAsm(void) */
GTEXT(MpuP_disableAsm)
SECTION_FUNC(boot_section, MpuP_disableAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
  e8:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        bic     r0, r0, #0x1             // clear bit 0 in r0
  ec:	e3c00001 	bic	r0, r0, #1
        dsb
  f0:	f57ff04f 	dsb	sy
        mcr     p15, #0, r0, c1, c0, #0  // MPU disabled (bit 0 = 0)
  f4:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        isb                              // flush instruction pipeline
  f8:	f57ff06f 	isb	sy
        bx      LR
  fc:	e12fff1e 	bx	lr

00000100 <MpuP_disableBRAsm>:

/* FUNCTION DEF: void MpuP_disableBRAsm(void) */
GTEXT(MpuP_disableBRAsm)
SECTION_FUNC(boot_section, MpuP_disableBRAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 100:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        bic     r0, r0, #0x20000         // clear bit 17 in r0
 104:	e3c00802 	bic	r0, r0, #131072	; 0x20000
        mcr     p15, #0, r0, c1, c0, #0  // disable background region
 108:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        bx      LR
 10c:	e12fff1e 	bx	lr

00000110 <MpuP_enableAsm>:

/* FUNCTION DEF: void MpuP_enableAsm(void) */
GTEXT(MpuP_enableAsm)
SECTION_FUNC(boot_section, MpuP_enableAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 110:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        orr     r0, r0, #0x1             // set bit 0 in r0
 114:	e3800001 	orr	r0, r0, #1
        dsb
 118:	f57ff04f 	dsb	sy
        mcr     p15, #0, r0, c1, c0, #0  // MPU enabled (bit 0 = 1)
 11c:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        isb                              // flush instruction pipeline
 120:	f57ff06f 	isb	sy
        bx      LR
 124:	e12fff1e 	bx	lr

00000128 <MpuP_enableBRAsm>:

/* FUNCTION DEF: void MpuP_enableBRAsm(void) */
GTEXT(MpuP_enableBRAsm)
SECTION_FUNC(boot_section, MpuP_enableBRAsm)
        mrc     p15, #0, r0, c1, c0, #0  // read SCTLR register
 128:	ee110f10 	mrc	15, 0, r0, cr1, cr0, {0}
        orr     r0, r0, #0x20000         // set bit 17 in r0
 12c:	e3800802 	orr	r0, r0, #131072	; 0x20000
        mcr     p15, #0, r0, c1, c0, #0  // background region enabled
 130:	ee010f10 	mcr	15, 0, r0, cr1, cr0, {0}
        bx      LR
 134:	e12fff1e 	bx	lr

00000138 <MpuP_isEnableAsm>:

/* FUNCTION DEF: uint32_t MpuP_isEnableAsm(void) */
GTEXT(MpuP_isEnableAsm)
SECTION_FUNC(boot_section, MpuP_isEnableAsm)
        mov     r0, #0
 138:	e3a00000 	mov	r0, #0
        mrc     p15, #0, r1, c1, c0, #0  // read SCTLR register to r1
 13c:	ee111f10 	mrc	15, 0, r1, cr1, cr0, {0}
        tst     r1, #0x1                 // test bit 0
 140:	e3110001 	tst	r1, #1
        movne   r0, #1                   // if not 0, MPU is enabled
 144:	13a00001 	movne	r0, #1
        bx      LR
 148:	e12fff1e 	bx	lr

0000014c <MpuP_setRegionAsm>:
 * r2 = sizeAndEnable
 * r3 = regionAttrs
 */
GTEXT(MpuP_setRegionAsm)
SECTION_FUNC(boot_section, MpuP_setRegionAsm)
        mcr     p15, #0, r0, c6, c2, #0  // select MPU region
 14c:	ee060f12 	mcr	15, 0, r0, cr6, cr2, {0}
        mcr     p15, #0, r1, c6, c1, #0  // set region base address
 150:	ee061f11 	mcr	15, 0, r1, cr6, cr1, {0}
        mcr     p15, #0, r2, c6, c1, #2  // set region size and enable it
 154:	ee062f51 	mcr	15, 0, r2, cr6, cr1, {2}
        mcr     p15, #0, r3, c6, c1, #4  // set protection attributes
 158:	ee063f91 	mcr	15, 0, r3, cr6, cr1, {4}
        bx      LR
 15c:	e12fff1e 	bx	lr

00000160 <____start_veneer>:
		split_chunks(h, c, c + chunks_need);
 160:	e51ff004 	ldr	pc, [pc, #-4]	; 164 <____start_veneer+0x4>
 164:	70000cb0 	.word	0x70000cb0

00000168 <__MpuP_enableAsm_from_thumb>:
		free_chunk(h, c + chunks_need);
 168:	4778      	bx	pc
 16a:	e7fd      	b.n	168 <__MpuP_enableAsm_from_thumb>
 16c:	eaffffe7 	b	110 <MpuP_enableAsm>
